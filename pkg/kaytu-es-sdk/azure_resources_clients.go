// Code is generated by go generate. DO NOT EDIT.
package kaytu

import (
	"context"
	"encoding/json"
	"fmt"
	azureDescriber "github.com/kaytu-io/kaytu-azure-describer/azure/describer"
	azure "github.com/kaytu-io/kaytu-azure-describer/azure/model"
	essdk "github.com/kaytu-io/kaytu-util/pkg/kaytu-es-sdk"
	"github.com/turbot/steampipe-plugin-sdk/v5/plugin"
)

type Client struct {
	essdk.Client
}

// ==========================  START: APIManagement =============================

type APIManagement struct {
	Description   azure.APIManagementDescription `json:"description"`
	Metadata      azure.Metadata                 `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

func (r *APIManagement) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.APIManagementDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type APIManagementHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  APIManagement `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type APIManagementHits struct {
	Total essdk.SearchTotal  `json:"total"`
	Hits  []APIManagementHit `json:"hits"`
}

type APIManagementSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  APIManagementHits `json:"hits"`
}

type APIManagementPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewAPIManagementPaginator(filters []essdk.BoolFilter, limit *int64) (APIManagementPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_apimanagement_service", filters, limit)
	if err != nil {
		return APIManagementPaginator{}, err
	}

	p := APIManagementPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p APIManagementPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p APIManagementPaginator) NextPage(ctx context.Context) ([]APIManagement, error) {
	var response APIManagementSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []APIManagement
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listAPIManagementFilters = map[string]string{
	"additional_locations":              "description.APIManagement.Properties.AdditionalLocations",
	"api_version_constraint":            "description.APIManagement.Properties.APIVersionConstraint",
	"certificates":                      "description.APIManagement.Properties.Certificates",
	"custom_properties":                 "description.APIManagement.Properties.CustomProperties",
	"developer_portal_url":              "description.APIManagement.Properties.DeveloperPortalURL",
	"diagnostic_settings":               "description.DiagnosticSettingsResources",
	"disable_gateway":                   "description.APIManagement.Properties.DisableGateway",
	"enable_client_certificate":         "description.APIManagement.Properties.EnableClientCertificate",
	"etag":                              "description.APIManagement.Etag",
	"gateway_regional_url":              "description.APIManagement.Properties.GatewayRegionalURL",
	"gateway_url":                       "description.APIManagement.Properties.GatewayURL",
	"host_name_configurations":          "description.APIManagement.Properties.HostnameConfigurations",
	"id":                                "description.APIManagement.ID",
	"identity_principal_id":             "description.APIManagement.Identity.PrincipalID",
	"identity_tenant_id":                "description.APIManagement.Identity.TenantID",
	"identity_type":                     "description.APIManagement.Identity.Type",
	"identity_user_assigned_identities": "description.APIManagement.Identity.UserAssignedIdentities",
	"kaytu_account_id":                  "metadata.SourceID",
	"management_api_url":                "description.APIManagement.Properties.ManagementAPIURL",
	"name":                              "description.APIManagement.Name",
	"notification_sender_email":         "description.APIManagement.Properties.NotificationSenderEmail",
	"portal_url":                        "description.APIManagement.Properties.PortalURL",
	"private_ip_addresses":              "description.APIManagement.Properties.PrivateIPAddresses",
	"provisioning_state":                "description.APIManagement.Properties.ProvisioningState",
	"public_ip_addresses":               "description.APIManagement.Properties.PublicIPAddresses",
	"publisher_email":                   "description.APIManagement.Properties.PublisherEmail",
	"publisher_name":                    "description.APIManagement.Properties.PublisherName",
	"resource_group":                    "description.ResourceGroup",
	"restore":                           "description.APIManagement.Properties.Restore",
	"scm_url":                           "description.APIManagement.Properties.ScmURL",
	"sku_capacity":                      "description.APIManagement.SKU.Capacity",
	"sku_name":                          "description.APIManagement.SKU.Name",
	"tags":                              "description.APIManagement.Tags",
	"target_provisioning_state":         "description.APIManagement.Properties.TargetProvisioningState",
	"title":                             "description.APIManagement.Name",
	"type":                              "description.APIManagement.Type",
	"virtual_network_configuration_id":  "description.APIManagement.Properties.VirtualNetworkConfiguration.Vnetid",
	"virtual_network_configuration_subnet_name":        "description.APIManagement.Properties.VirtualNetworkConfiguration.Subnetname",
	"virtual_network_configuration_subnet_resource_id": "description.APIManagement.Properties.VirtualNetworkConfiguration.SubnetResourceID",
	"virtual_network_type":                             "description.APIManagement.Properties.VirtualNetworkType",
	"zones":                                            "description.APIManagement.Zones",
}

func ListAPIManagement(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAPIManagement")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewAPIManagementPaginator(essdk.BuildFilter(ctx, d.QueryContext, listAPIManagementFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAPIManagementFilters = map[string]string{
	"additional_locations":              "description.APIManagement.Properties.AdditionalLocations",
	"api_version_constraint":            "description.APIManagement.Properties.APIVersionConstraint",
	"certificates":                      "description.APIManagement.Properties.Certificates",
	"custom_properties":                 "description.APIManagement.Properties.CustomProperties",
	"developer_portal_url":              "description.APIManagement.Properties.DeveloperPortalURL",
	"diagnostic_settings":               "description.DiagnosticSettingsResources",
	"disable_gateway":                   "description.APIManagement.Properties.DisableGateway",
	"enable_client_certificate":         "description.APIManagement.Properties.EnableClientCertificate",
	"etag":                              "description.APIManagement.Etag",
	"gateway_regional_url":              "description.APIManagement.Properties.GatewayRegionalURL",
	"gateway_url":                       "description.APIManagement.Properties.GatewayURL",
	"host_name_configurations":          "description.APIManagement.Properties.HostnameConfigurations",
	"id":                                "description.APIManagement.ID",
	"identity_principal_id":             "description.APIManagement.Identity.PrincipalID",
	"identity_tenant_id":                "description.APIManagement.Identity.TenantID",
	"identity_type":                     "description.APIManagement.Identity.Type",
	"identity_user_assigned_identities": "description.APIManagement.Identity.UserAssignedIdentities",
	"kaytu_account_id":                  "metadata.SourceID",
	"management_api_url":                "description.APIManagement.Properties.ManagementAPIURL",
	"name":                              "description.APIManagement.name",
	"notification_sender_email":         "description.APIManagement.Properties.NotificationSenderEmail",
	"portal_url":                        "description.APIManagement.Properties.PortalURL",
	"private_ip_addresses":              "description.APIManagement.Properties.PrivateIPAddresses",
	"provisioning_state":                "description.APIManagement.Properties.ProvisioningState",
	"public_ip_addresses":               "description.APIManagement.Properties.PublicIPAddresses",
	"publisher_email":                   "description.APIManagement.Properties.PublisherEmail",
	"publisher_name":                    "description.APIManagement.Properties.PublisherName",
	"resource_group":                    "description.ResourceGroup",
	"restore":                           "description.APIManagement.Properties.Restore",
	"scm_url":                           "description.APIManagement.Properties.ScmURL",
	"sku_capacity":                      "description.APIManagement.SKU.Capacity",
	"sku_name":                          "description.APIManagement.SKU.Name",
	"tags":                              "description.APIManagement.Tags",
	"target_provisioning_state":         "description.APIManagement.Properties.TargetProvisioningState",
	"title":                             "description.APIManagement.Name",
	"type":                              "description.APIManagement.Type",
	"virtual_network_configuration_id":  "description.APIManagement.Properties.VirtualNetworkConfiguration.Vnetid",
	"virtual_network_configuration_subnet_name":        "description.APIManagement.Properties.VirtualNetworkConfiguration.Subnetname",
	"virtual_network_configuration_subnet_resource_id": "description.APIManagement.Properties.VirtualNetworkConfiguration.SubnetResourceID",
	"virtual_network_type":                             "description.APIManagement.Properties.VirtualNetworkType",
	"zones":                                            "description.APIManagement.Zones",
}

func GetAPIManagement(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAPIManagement")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewAPIManagementPaginator(essdk.BuildFilter(ctx, d.QueryContext, getAPIManagementFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: APIManagement =============================

// ==========================  START: AutomationAccounts =============================

type AutomationAccounts struct {
	Description   azure.AutomationAccountsDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

func (r *AutomationAccounts) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.AutomationAccountsDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type AutomationAccountsHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  AutomationAccounts `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type AutomationAccountsHits struct {
	Total essdk.SearchTotal       `json:"total"`
	Hits  []AutomationAccountsHit `json:"hits"`
}

type AutomationAccountsSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  AutomationAccountsHits `json:"hits"`
}

type AutomationAccountsPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewAutomationAccountsPaginator(filters []essdk.BoolFilter, limit *int64) (AutomationAccountsPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_automation_automationaccounts", filters, limit)
	if err != nil {
		return AutomationAccountsPaginator{}, err
	}

	p := AutomationAccountsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AutomationAccountsPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p AutomationAccountsPaginator) NextPage(ctx context.Context) ([]AutomationAccounts, error) {
	var response AutomationAccountsSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AutomationAccounts
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listAutomationAccountsFilters = map[string]string{
	"creation_time":      "description.Automation.Properties.CreationTime",
	"description":        "description.Automation.Properties.Description",
	"etag":               "description.Automation.Etag",
	"id":                 "description.Automation.ID",
	"kaytu_account_id":   "metadata.SourceID",
	"last_modified_by":   "description.Automation.Properties.LastModifiedBy",
	"last_modified_time": "description.Automation.Properties.LastModifiedTime",
	"name":               "description.Automation.Name",
	"sku_capacity":       "description.Automation.Properties.SKU.Capacity",
	"sku_family":         "description.Automation.Properties.SKU.Family",
	"sku_name":           "description.Automation.Properties.SKU.Name",
	"state":              "description.Automation.Properties.State",
	"tags":               "description.Automation.Tags",
	"title":              "description.Automation.Name",
	"type":               "description.Automation.Type",
}

func ListAutomationAccounts(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAutomationAccounts")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewAutomationAccountsPaginator(essdk.BuildFilter(ctx, d.QueryContext, listAutomationAccountsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAutomationAccountsFilters = map[string]string{
	"creation_time":      "description.Automation.Properties.CreationTime",
	"description":        "description.Automation.Properties.Description",
	"etag":               "description.Automation.Etag",
	"id":                 "description.Automation.ID",
	"kaytu_account_id":   "metadata.SourceID",
	"last_modified_by":   "description.Automation.Properties.LastModifiedBy",
	"last_modified_time": "description.Automation.Properties.LastModifiedTime",
	"name":               "description.Automation.Name",
	"sku_capacity":       "description.Automation.Properties.SKU.Capacity",
	"sku_family":         "description.Automation.Properties.SKU.Family",
	"sku_name":           "description.Automation.Properties.SKU.Name",
	"state":              "description.Automation.Properties.State",
	"tags":               "description.Automation.Tags",
	"title":              "description.Automation.Name",
	"type":               "description.Automation.Type",
}

func GetAutomationAccounts(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAutomationAccounts")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewAutomationAccountsPaginator(essdk.BuildFilter(ctx, d.QueryContext, getAutomationAccountsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AutomationAccounts =============================

// ==========================  START: AutomationVariables =============================

type AutomationVariables struct {
	Description   azure.AutomationVariablesDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

func (r *AutomationVariables) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.AutomationVariablesDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type AutomationVariablesHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  AutomationVariables `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type AutomationVariablesHits struct {
	Total essdk.SearchTotal        `json:"total"`
	Hits  []AutomationVariablesHit `json:"hits"`
}

type AutomationVariablesSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  AutomationVariablesHits `json:"hits"`
}

type AutomationVariablesPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewAutomationVariablesPaginator(filters []essdk.BoolFilter, limit *int64) (AutomationVariablesPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_automation_automationvariables", filters, limit)
	if err != nil {
		return AutomationVariablesPaginator{}, err
	}

	p := AutomationVariablesPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AutomationVariablesPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p AutomationVariablesPaginator) NextPage(ctx context.Context) ([]AutomationVariables, error) {
	var response AutomationVariablesSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AutomationVariables
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listAutomationVariablesFilters = map[string]string{
	"account_name":       "description.AccountName",
	"creation_time":      "description.Automation.Properties.CreationTime",
	"description":        "description.Automation.Properties.Description",
	"id":                 "description.Automation.ID",
	"is_encrypted":       "description.Automation.Properties.IsEncrypted",
	"kaytu_account_id":   "metadata.SourceID",
	"last_modified_time": "description.Automation.Properties.LastModifiedTime",
	"name":               "description.Automation.Name",
	"resource_group":     "description.ResourceGroup",
	"title":              "description.Automation.Name",
	"type":               "description.Automation.Type",
	"value":              "description.Automation.Properties.Value",
}

func ListAutomationVariables(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAutomationVariables")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewAutomationVariablesPaginator(essdk.BuildFilter(ctx, d.QueryContext, listAutomationVariablesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAutomationVariablesFilters = map[string]string{
	"account_name":       "description.AccountName",
	"creation_time":      "description.Automation.Properties.CreationTime",
	"description":        "description.Automation.Properties.Description",
	"id":                 "description.Automation.ID",
	"is_encrypted":       "description.Automation.Properties.IsEncrypted",
	"kaytu_account_id":   "metadata.SourceID",
	"last_modified_time": "description.Automation.Properties.LastModifiedTime",
	"name":               "description.Automation.Name",
	"resource_group":     "description.ResourceGroup",
	"title":              "description.Automation.Name",
	"type":               "description.Automation.Type",
	"value":              "description.Automation.Properties.Value",
}

func GetAutomationVariables(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAutomationVariables")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewAutomationVariablesPaginator(essdk.BuildFilter(ctx, d.QueryContext, getAutomationVariablesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AutomationVariables =============================

// ==========================  START: AppConfiguration =============================

type AppConfiguration struct {
	Description   azure.AppConfigurationDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *AppConfiguration) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.AppConfigurationDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type AppConfigurationHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  AppConfiguration `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type AppConfigurationHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []AppConfigurationHit `json:"hits"`
}

type AppConfigurationSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  AppConfigurationHits `json:"hits"`
}

type AppConfigurationPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewAppConfigurationPaginator(filters []essdk.BoolFilter, limit *int64) (AppConfigurationPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_appconfiguration_configurationstores", filters, limit)
	if err != nil {
		return AppConfigurationPaginator{}, err
	}

	p := AppConfigurationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppConfigurationPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p AppConfigurationPaginator) NextPage(ctx context.Context) ([]AppConfiguration, error) {
	var response AppConfigurationSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppConfiguration
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listAppConfigurationFilters = map[string]string{
	"diagnostic_settings": "description.DiagnosticSettingsResources",
	"encryption":          "description.ConfigurationStore.Properties.Encryption",
	"endpoint":            "description.ConfigurationStore.Properties.Endpoint",
	"id":                  "description.ConfigurationStore.ID",
	"identity":            "description.ConfigurationStore.Identity",
	"kaytu_account_id":    "metadata.SourceID",
	"name":                "description.ConfigurationStore.Name",
	"provisioning_state":  "description.ConfigurationStore.Properties.ProvisioningState",
	"resource_group":      "description.ResourceGroup",
	"sku_name":            "description.ConfigurationStore.SKU.Name",
	"tags":                "description.ConfigurationStore.Tags",
	"title":               "description.ConfigurationStore.Name",
	"type":                "description.ConfigurationStore.Type",
}

func ListAppConfiguration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppConfiguration")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewAppConfigurationPaginator(essdk.BuildFilter(ctx, d.QueryContext, listAppConfigurationFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppConfigurationFilters = map[string]string{
	"diagnostic_settings": "description.DiagnosticSettingsResources",
	"encryption":          "description.ConfigurationStore.Properties.Encryption",
	"endpoint":            "description.ConfigurationStore.Properties.Endpoint",
	"id":                  "description.ConfigurationStore.ID",
	"identity":            "description.ConfigurationStore.Identity",
	"kaytu_account_id":    "metadata.SourceID",
	"name":                "description.ConfigurationStore.name",
	"provisioning_state":  "description.ConfigurationStore.Properties.ProvisioningState",
	"resource_group":      "description.ResourceGroup",
	"sku_name":            "description.ConfigurationStore.SKU.Name",
	"tags":                "description.ConfigurationStore.Tags",
	"title":               "description.ConfigurationStore.Name",
	"type":                "description.ConfigurationStore.Type",
}

func GetAppConfiguration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppConfiguration")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewAppConfigurationPaginator(essdk.BuildFilter(ctx, d.QueryContext, getAppConfigurationFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppConfiguration =============================

// ==========================  START: AppServiceEnvironment =============================

type AppServiceEnvironment struct {
	Description   azure.AppServiceEnvironmentDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

func (r *AppServiceEnvironment) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.AppServiceEnvironmentDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type AppServiceEnvironmentHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  AppServiceEnvironment `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type AppServiceEnvironmentHits struct {
	Total essdk.SearchTotal          `json:"total"`
	Hits  []AppServiceEnvironmentHit `json:"hits"`
}

type AppServiceEnvironmentSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  AppServiceEnvironmentHits `json:"hits"`
}

type AppServiceEnvironmentPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewAppServiceEnvironmentPaginator(filters []essdk.BoolFilter, limit *int64) (AppServiceEnvironmentPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_web_hostingenvironments", filters, limit)
	if err != nil {
		return AppServiceEnvironmentPaginator{}, err
	}

	p := AppServiceEnvironmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppServiceEnvironmentPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p AppServiceEnvironmentPaginator) NextPage(ctx context.Context) ([]AppServiceEnvironment, error) {
	var response AppServiceEnvironmentSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppServiceEnvironment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listAppServiceEnvironmentFilters = map[string]string{
	"cluster_settings":               "description.AppServiceEnvironmentResource.Properties.ClusterSettings",
	"default_front_end_scale_factor": "description.AppServiceEnvironmentResource.Properties.FrontEndScaleFactor",
	"dynamic_cache_enabled":          "description.AppServiceEnvironmentResource.Properties.EnableAcceleratedNetworking",
	"front_end_scale_factor":         "description.AppServiceEnvironmentResource.Properties.FrontEndScaleFactor",
	"has_linux_workers":              "description.AppServiceEnvironmentResource.Properties.HasLinuxWorkers",
	"id":                             "description.AppServiceEnvironmentResource.ID",
	"internal_load_balancing_mode":   "description.AppServiceEnvironmentResource.Properties.InternalLoadBalancingMode",
	"is_healthy_environment":         "description.AppServiceEnvironmentResource.Properties.EnvironmentIsHealthy",
	"kaytu_account_id":               "metadata.SourceID",
	"kind":                           "description.AppServiceEnvironmentResource.Kind",
	"name":                           "description.AppServiceEnvironmentResource.Name",
	"provisioning_state":             "description.AppServiceEnvironmentResource.Properties.ProvisioningState",
	"status":                         "description.AppServiceEnvironmentResource.Properties.Status",
	"suspended":                      "description.AppServiceEnvironmentResource.Properties.Suspended",
	"tags":                           "description.AppServiceEnvironmentResource.Tags",
	"title":                          "description.AppServiceEnvironmentResource.Name",
	"type":                           "description.AppServiceEnvironmentResource.Type",
}

func ListAppServiceEnvironment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppServiceEnvironment")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewAppServiceEnvironmentPaginator(essdk.BuildFilter(ctx, d.QueryContext, listAppServiceEnvironmentFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppServiceEnvironmentFilters = map[string]string{
	"cluster_settings":               "description.AppServiceEnvironmentResource.Properties.ClusterSettings",
	"default_front_end_scale_factor": "description.AppServiceEnvironmentResource.Properties.FrontEndScaleFactor",
	"dynamic_cache_enabled":          "description.AppServiceEnvironmentResource.Properties.EnableAcceleratedNetworking",
	"front_end_scale_factor":         "description.AppServiceEnvironmentResource.Properties.FrontEndScaleFactor",
	"has_linux_workers":              "description.AppServiceEnvironmentResource.Properties.HasLinuxWorkers",
	"id":                             "description.AppServiceEnvironmentResource.ID",
	"internal_load_balancing_mode":   "description.AppServiceEnvironmentResource.Properties.InternalLoadBalancingMode",
	"is_healthy_environment":         "description.AppServiceEnvironmentResource.Properties.EnvironmentIsHealthy",
	"kaytu_account_id":               "metadata.SourceID",
	"kind":                           "description.AppServiceEnvironmentResource.Kind",
	"name":                           "description.AppServiceEnvironmentResource.name",
	"provisioning_state":             "description.AppServiceEnvironmentResource.Properties.ProvisioningState",
	"resource_group":                 "description.ResourceGroup",
	"status":                         "description.AppServiceEnvironmentResource.Properties.Status",
	"suspended":                      "description.AppServiceEnvironmentResource.Properties.Suspended",
	"tags":                           "description.AppServiceEnvironmentResource.Tags",
	"title":                          "description.AppServiceEnvironmentResource.Name",
	"type":                           "description.AppServiceEnvironmentResource.Type",
}

func GetAppServiceEnvironment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppServiceEnvironment")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewAppServiceEnvironmentPaginator(essdk.BuildFilter(ctx, d.QueryContext, getAppServiceEnvironmentFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppServiceEnvironment =============================

// ==========================  START: AppServiceFunctionApp =============================

type AppServiceFunctionApp struct {
	Description   azure.AppServiceFunctionAppDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

func (r *AppServiceFunctionApp) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.AppServiceFunctionAppDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type AppServiceFunctionAppHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  AppServiceFunctionApp `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type AppServiceFunctionAppHits struct {
	Total essdk.SearchTotal          `json:"total"`
	Hits  []AppServiceFunctionAppHit `json:"hits"`
}

type AppServiceFunctionAppSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  AppServiceFunctionAppHits `json:"hits"`
}

type AppServiceFunctionAppPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewAppServiceFunctionAppPaginator(filters []essdk.BoolFilter, limit *int64) (AppServiceFunctionAppPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_web_sites", filters, limit)
	if err != nil {
		return AppServiceFunctionAppPaginator{}, err
	}

	p := AppServiceFunctionAppPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppServiceFunctionAppPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p AppServiceFunctionAppPaginator) NextPage(ctx context.Context) ([]AppServiceFunctionApp, error) {
	var response AppServiceFunctionAppSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppServiceFunctionApp
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listAppServiceFunctionAppFilters = map[string]string{
	"auth_settings":                  "description.SiteAuthSettings",
	"client_affinity_enabled":        "description.Site.Properties.ClientAffinityEnabled",
	"client_cert_enabled":            "description.Site.Properties.ClientCertEnabled",
	"configuration":                  "description.SiteConfigResource",
	"default_site_hostname":          "description.Site.Properties.DefaultHostName",
	"enabled":                        "description.Site.Properties.Enabled",
	"host_name_disabled":             "description.Site.Properties.HostNamesDisabled",
	"host_names":                     "description.Site.Properties.HostNames",
	"https_only":                     "description.Site.Properties.HTTPSOnly",
	"id":                             "description.Site.ID",
	"kaytu_account_id":               "metadata.SourceID",
	"kind":                           "description.Site.Kind",
	"name":                           "description.Site.Name",
	"outbound_ip_addresses":          "description.Site.Properties.OutboundIPAddresses",
	"possible_outbound_ip_addresses": "description.Site.Properties.PossibleOutboundIPAddresses",
	"reserved":                       "description.Site.Properties.Reserved",
	"site_config":                    "description.Site.Properties.SiteConfig",
	"state":                          "description.Site.Properties.State",
	"tags":                           "description.Site.Tags",
	"title":                          "description.Site.Name",
	"type":                           "description.Site.Properties.Type",
}

func ListAppServiceFunctionApp(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppServiceFunctionApp")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewAppServiceFunctionAppPaginator(essdk.BuildFilter(ctx, d.QueryContext, listAppServiceFunctionAppFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppServiceFunctionAppFilters = map[string]string{
	"auth_settings":                  "description.SiteAuthSettings",
	"client_affinity_enabled":        "description.Site.Properties.ClientAffinityEnabled",
	"client_cert_enabled":            "description.Site.Properties.ClientCertEnabled",
	"configuration":                  "description.SiteConfigResource",
	"default_site_hostname":          "description.Site.Properties.DefaultHostName",
	"enabled":                        "description.Site.Properties.Enabled",
	"host_name_disabled":             "description.Site.Properties.HostNamesDisabled",
	"host_names":                     "description.Site.Properties.HostNames",
	"https_only":                     "description.Site.Properties.HTTPSOnly",
	"id":                             "description.Site.ID",
	"kaytu_account_id":               "metadata.SourceID",
	"kind":                           "description.Site.Kind",
	"name":                           "description.Site.name",
	"outbound_ip_addresses":          "description.Site.Properties.OutboundIPAddresses",
	"possible_outbound_ip_addresses": "description.Site.Properties.PossibleOutboundIPAddresses",
	"reserved":                       "description.Site.Properties.Reserved",
	"resource_group":                 "description.ResourceGroup",
	"site_config":                    "description.Site.Properties.SiteConfig",
	"state":                          "description.Site.Properties.State",
	"tags":                           "description.Site.Tags",
	"title":                          "description.Site.Name",
	"type":                           "description.Site.Properties.Type",
}

func GetAppServiceFunctionApp(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppServiceFunctionApp")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewAppServiceFunctionAppPaginator(essdk.BuildFilter(ctx, d.QueryContext, getAppServiceFunctionAppFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppServiceFunctionApp =============================

// ==========================  START: AppServiceWebApp =============================

type AppServiceWebApp struct {
	Description   azure.AppServiceWebAppDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *AppServiceWebApp) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.AppServiceWebAppDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type AppServiceWebAppHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  AppServiceWebApp `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type AppServiceWebAppHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []AppServiceWebAppHit `json:"hits"`
}

type AppServiceWebAppSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  AppServiceWebAppHits `json:"hits"`
}

type AppServiceWebAppPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewAppServiceWebAppPaginator(filters []essdk.BoolFilter, limit *int64) (AppServiceWebAppPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_web_staticsites", filters, limit)
	if err != nil {
		return AppServiceWebAppPaginator{}, err
	}

	p := AppServiceWebAppPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppServiceWebAppPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p AppServiceWebAppPaginator) NextPage(ctx context.Context) ([]AppServiceWebApp, error) {
	var response AppServiceWebAppSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppServiceWebApp
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listAppServiceWebAppFilters = map[string]string{
	"auth_settings":                  "description.SiteAuthSettings",
	"client_affinity_enabled":        "description.Site.Properties.ClientAffinityEnabled",
	"client_cert_enabled":            "description.Site.Properties.ClientCertEnabled",
	"configuration":                  "description.SiteConfigResource",
	"default_site_hostname":          "description.Site.Properties.DefaultHostName",
	"diagnostic_logs_configuration":  "description.SiteLogConfig",
	"enabled":                        "description.Site.Properties.Enabled",
	"host_name_disabled":             "description.Site.Properties.HostNamesDisabled",
	"host_names":                     "description.Site.Properties.HostNames",
	"https_only":                     "description.Site.Properties.HTTPSOnly",
	"id":                             "description.Site.ID",
	"kaytu_account_id":               "metadata.SourceID",
	"kind":                           "description.Site.Kind",
	"name":                           "description.Site.Name",
	"outbound_ip_addresses":          "description.Site.Properties.OutboundIPAddresses",
	"possible_outbound_ip_addresses": "description.Site.Properties.PossibleOutboundIPAddresses",
	"reserved":                       "description.Site.Properties.Reserved",
	"site_config":                    "description.Site.Properties.SiteConfig",
	"state":                          "description.Site.Properties.State",
	"tags":                           "description.Site.Tags",
	"title":                          "description.Site.Name",
	"type":                           "description.Site.Type",
	"vnet_connection":                "description.VnetInfo",
}

func ListAppServiceWebApp(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppServiceWebApp")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewAppServiceWebAppPaginator(essdk.BuildFilter(ctx, d.QueryContext, listAppServiceWebAppFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppServiceWebAppFilters = map[string]string{
	"auth_settings":                  "description.SiteAuthSettings",
	"client_affinity_enabled":        "description.Site.Properties.ClientAffinityEnabled",
	"client_cert_enabled":            "description.Site.Properties.ClientCertEnabled",
	"configuration":                  "description.SiteConfigResource",
	"default_site_hostname":          "description.Site.Properties.DefaultHostName",
	"diagnostic_logs_configuration":  "description.SiteLogConfig",
	"enabled":                        "description.Site.Properties.Enabled",
	"host_name_disabled":             "description.Site.Properties.HostNamesDisabled",
	"host_names":                     "description.Site.Properties.HostNames",
	"https_only":                     "description.Site.Properties.HTTPSOnly",
	"id":                             "description.Site.ID",
	"kaytu_account_id":               "metadata.SourceID",
	"kind":                           "description.Site.Kind",
	"name":                           "description.Site.name",
	"outbound_ip_addresses":          "description.Site.Properties.OutboundIPAddresses",
	"possible_outbound_ip_addresses": "description.Site.Properties.PossibleOutboundIPAddresses",
	"reserved":                       "description.Site.Properties.Reserved",
	"resource_group":                 "description.ResourceGroup",
	"site_config":                    "description.Site.Properties.SiteConfig",
	"state":                          "description.Site.Properties.State",
	"tags":                           "description.Site.Tags",
	"title":                          "description.Site.Name",
	"type":                           "description.Site.Type",
	"vnet_connection":                "description.VnetInfo",
}

func GetAppServiceWebApp(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppServiceWebApp")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewAppServiceWebAppPaginator(essdk.BuildFilter(ctx, d.QueryContext, getAppServiceWebAppFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppServiceWebApp =============================

// ==========================  START: AppServiceWebAppSlot =============================

type AppServiceWebAppSlot struct {
	Description   azure.AppServiceWebAppSlotDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

func (r *AppServiceWebAppSlot) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.AppServiceWebAppSlotDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type AppServiceWebAppSlotHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  AppServiceWebAppSlot `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type AppServiceWebAppSlotHits struct {
	Total essdk.SearchTotal         `json:"total"`
	Hits  []AppServiceWebAppSlotHit `json:"hits"`
}

type AppServiceWebAppSlotSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  AppServiceWebAppSlotHits `json:"hits"`
}

type AppServiceWebAppSlotPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewAppServiceWebAppSlotPaginator(filters []essdk.BoolFilter, limit *int64) (AppServiceWebAppSlotPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_web_staticsitesslot", filters, limit)
	if err != nil {
		return AppServiceWebAppSlotPaginator{}, err
	}

	p := AppServiceWebAppSlotPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppServiceWebAppSlotPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p AppServiceWebAppSlotPaginator) NextPage(ctx context.Context) ([]AppServiceWebAppSlot, error) {
	var response AppServiceWebAppSlotSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppServiceWebAppSlot
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listAppServiceWebAppSlotFilters = map[string]string{
	"app_name":                       "description.AppName",
	"availability_state":             "description.Site.Properties.AvailabilityState",
	"client_affinity_enabled":        "description.Site.Properties.ClientAffinityEnabled",
	"client_cert_exclusion_paths":    "description.Site.Properties.ClientCertExclusionPaths",
	"client_cert_mode":               "description.Site.Properties.ClientCertMode",
	"container_size":                 "description.Site.Properties.ContainerSize",
	"custom_domain_verification_id":  "description.Site.Properties.CustomDomainVerificationID",
	"default_host_name":              "description.Site.Properties.DefaultHostName",
	"enabled":                        "description.Site.Properties.Enabled",
	"enabled_host_names":             "description.Site.Properties.EnabledHostNames",
	"host_name_ssl_states":           "description.Site.Properties.HostNameSSLStates",
	"host_names":                     "description.Site.Properties.HostNames",
	"host_names_disabled":            "description.Site.Properties.HostNamesDisabled",
	"hosting_environment_profile":    "description.Site.Properties.HostingEnvironmentProfile",
	"https_only":                     "description.Site.Properties.HTTPSOnly",
	"hyper_v":                        "description.Site.Properties.HyperV",
	"id":                             "description.Site.ID",
	"identity":                       "description.Site.Identity",
	"is_default_container":           "description.Site.Properties.IsDefaultContainer",
	"is_xenon":                       "description.Site.Properties.IsXenon",
	"kind":                           "description.Site.Kind",
	"last_modified_time_utc":         "description.Site.Properties.LastModifiedTimeUTC",
	"outbound_ip_addresses":          "description.Site.Properties.OutboundIPAddresses",
	"possible_outbound_ip_addresses": "description.Site.Properties.PossibleOutboundIPAddresses",
	"redundancy_mode":                "description.Site.Properties.RedundancyMode",
	"repository_site_name":           "description.Site.Properties.RepositorySiteName",
	"reserved":                       "description.Site.Properties.Reserved",
	"resource_group":                 "description.ResourceGroup",
	"scm_site_also_stopped":          "description.Site.Properties.ScmSiteAlsoStopped",
	"server_farm_id":                 "description.Site.Properties.ServerFarmID",
	"site_config":                    "description.Site.Properties.SiteConfig",
	"slot_swap_status":               "description.Site.Properties.SlotSwapStatus",
	"state":                          "description.Site.Properties.State",
	"suspended_till":                 "description.Site.Properties.SuspendedTill",
	"tags":                           "description.Site.Tags",
	"target_swap_slot":               "description.Site.Properties.TargetSwapSlot",
	"title":                          "description.Site.Name",
	"traffic_manager_host_names":     "description.Site.Properties.TrafficManagerHostNames",
	"type":                           "description.Site.Type",
	"usage_state":                    "description.Site.Properties.UsageState",
}

func ListAppServiceWebAppSlot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppServiceWebAppSlot")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewAppServiceWebAppSlotPaginator(essdk.BuildFilter(ctx, d.QueryContext, listAppServiceWebAppSlotFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppServiceWebAppSlotFilters = map[string]string{
	"app_name":                       "description.AppName",
	"availability_state":             "description.Site.Properties.AvailabilityState",
	"client_affinity_enabled":        "description.Site.Properties.ClientAffinityEnabled",
	"client_cert_exclusion_paths":    "description.Site.Properties.ClientCertExclusionPaths",
	"client_cert_mode":               "description.Site.Properties.ClientCertMode",
	"container_size":                 "description.Site.Properties.ContainerSize",
	"custom_domain_verification_id":  "description.Site.Properties.CustomDomainVerificationID",
	"default_host_name":              "description.Site.Properties.DefaultHostName",
	"enabled":                        "description.Site.Properties.Enabled",
	"enabled_host_names":             "description.Site.Properties.EnabledHostNames",
	"host_name_ssl_states":           "description.Site.Properties.HostNameSSLStates",
	"host_names":                     "description.Site.Properties.HostNames",
	"host_names_disabled":            "description.Site.Properties.HostNamesDisabled",
	"hosting_environment_profile":    "description.Site.Properties.HostingEnvironmentProfile",
	"https_only":                     "description.Site.Properties.HTTPSOnly",
	"hyper_v":                        "description.Site.Properties.HyperV",
	"id":                             "description.Site.ID",
	"identity":                       "description.Site.Identity",
	"is_default_container":           "description.Site.Properties.IsDefaultContainer",
	"is_xenon":                       "description.Site.Properties.IsXenon",
	"kind":                           "description.Site.Kind",
	"last_modified_time_utc":         "description.Site.Properties.LastModifiedTimeUTC",
	"outbound_ip_addresses":          "description.Site.Properties.OutboundIPAddresses",
	"possible_outbound_ip_addresses": "description.Site.Properties.PossibleOutboundIPAddresses",
	"redundancy_mode":                "description.Site.Properties.RedundancyMode",
	"repository_site_name":           "description.Site.Properties.RepositorySiteName",
	"reserved":                       "description.Site.Properties.Reserved",
	"resource_group":                 "description.ResourceGroup",
	"scm_site_also_stopped":          "description.Site.Properties.ScmSiteAlsoStopped",
	"server_farm_id":                 "description.Site.Properties.ServerFarmID",
	"site_config":                    "description.Site.Properties.SiteConfig",
	"slot_swap_status":               "description.Site.Properties.SlotSwapStatus",
	"state":                          "description.Site.Properties.State",
	"suspended_till":                 "description.Site.Properties.SuspendedTill",
	"tags":                           "description.Site.Tags",
	"target_swap_slot":               "description.Site.Properties.TargetSwapSlot",
	"title":                          "description.Site.Name",
	"traffic_manager_host_names":     "description.Site.Properties.TrafficManagerHostNames",
	"type":                           "description.Site.Type",
	"usage_state":                    "description.Site.Properties.UsageState",
}

func GetAppServiceWebAppSlot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppServiceWebAppSlot")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewAppServiceWebAppSlotPaginator(essdk.BuildFilter(ctx, d.QueryContext, getAppServiceWebAppSlotFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppServiceWebAppSlot =============================

// ==========================  START: AppServicePlan =============================

type AppServicePlan struct {
	Description   azure.AppServicePlanDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

func (r *AppServicePlan) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.AppServicePlanDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type AppServicePlanHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  AppServicePlan `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type AppServicePlanHits struct {
	Total essdk.SearchTotal   `json:"total"`
	Hits  []AppServicePlanHit `json:"hits"`
}

type AppServicePlanSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  AppServicePlanHits `json:"hits"`
}

type AppServicePlanPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewAppServicePlanPaginator(filters []essdk.BoolFilter, limit *int64) (AppServicePlanPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_web_plan", filters, limit)
	if err != nil {
		return AppServicePlanPaginator{}, err
	}

	p := AppServicePlanPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppServicePlanPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p AppServicePlanPaginator) NextPage(ctx context.Context) ([]AppServicePlan, error) {
	var response AppServicePlanSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppServicePlan
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listAppServicePlanFilters = map[string]string{
	"apps":                         "description.Apps",
	"hyper_v":                      "description.Plan.Properties.HyperV",
	"id":                           "description.Plan.ID",
	"is_spot":                      "description.Plan.Properties.IsSpot",
	"is_xenon":                     "description.Plan.Properties.IsXenon",
	"kaytu_account_id":             "metadata.SourceID",
	"kind":                         "description.Plan.Kind",
	"maximum_elastic_worker_count": "description.Plan.Properties.MaximumElasticWorkerCount",
	"maximum_number_of_workers":    "description.Plan.Properties.MaximumNumberOfWorkers",
	"name":                         "description.Plan.Name",
	"per_site_scaling":             "description.Plan.Properties.PerSiteScaling",
	"provisioning_state":           "description.Plan.Properties.ProvisioningState",
	"reserved":                     "description.Plan.Properties.Reserved",
	"sku_capacity":                 "description.Plan.SKU.Capacity",
	"sku_family":                   "description.Plan.SKU.Family",
	"sku_name":                     "description.Plan.SKU.Name",
	"sku_size":                     "description.Plan.SKU.Size",
	"sku_tier":                     "description.Plan.SKU.Tier",
	"status":                       "description.Plan.Properties.Status",
	"tags":                         "description.Plan.Tags",
	"title":                        "description.Plan.Name",
	"type":                         "description.Plan.Type",
}

func ListAppServicePlan(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppServicePlan")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewAppServicePlanPaginator(essdk.BuildFilter(ctx, d.QueryContext, listAppServicePlanFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppServicePlanFilters = map[string]string{
	"apps":                         "description.Apps",
	"hyper_v":                      "description.Plan.Properties.HyperV",
	"id":                           "description.Plan.ID",
	"is_spot":                      "description.Plan.Properties.IsSpot",
	"is_xenon":                     "description.Plan.Properties.IsXenon",
	"kaytu_account_id":             "metadata.SourceID",
	"kind":                         "description.Plan.Kind",
	"maximum_elastic_worker_count": "description.Plan.Properties.MaximumElasticWorkerCount",
	"maximum_number_of_workers":    "description.Plan.Properties.MaximumNumberOfWorkers",
	"name":                         "description.Site.name",
	"per_site_scaling":             "description.Plan.Properties.PerSiteScaling",
	"provisioning_state":           "description.Plan.Properties.ProvisioningState",
	"reserved":                     "description.Plan.Properties.Reserved",
	"resource_group":               "description.ResourceGroup",
	"sku_capacity":                 "description.Plan.SKU.Capacity",
	"sku_family":                   "description.Plan.SKU.Family",
	"sku_name":                     "description.Plan.SKU.Name",
	"sku_size":                     "description.Plan.SKU.Size",
	"sku_tier":                     "description.Plan.SKU.Tier",
	"status":                       "description.Plan.Properties.Status",
	"tags":                         "description.Plan.Tags",
	"title":                        "description.Plan.Name",
	"type":                         "description.Plan.Type",
}

func GetAppServicePlan(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppServicePlan")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewAppServicePlanPaginator(essdk.BuildFilter(ctx, d.QueryContext, getAppServicePlanFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppServicePlan =============================

// ==========================  START: ContainerApp =============================

type ContainerApp struct {
	Description   azure.ContainerAppDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

func (r *ContainerApp) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ContainerAppDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ContainerAppHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ContainerApp  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ContainerAppHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []ContainerAppHit `json:"hits"`
}

type ContainerAppSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  ContainerAppHits `json:"hits"`
}

type ContainerAppPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewContainerAppPaginator(filters []essdk.BoolFilter, limit *int64) (ContainerAppPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_app_containerapps", filters, limit)
	if err != nil {
		return ContainerAppPaginator{}, err
	}

	p := ContainerAppPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ContainerAppPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ContainerAppPaginator) NextPage(ctx context.Context) ([]ContainerApp, error) {
	var response ContainerAppSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ContainerApp
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listContainerAppFilters = map[string]string{
	"id":               "description.Server.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Server.Name",
	"tags":             "description.Server.Tags",
	"title":            "description.Server.Name",
}

func ListContainerApp(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListContainerApp")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewContainerAppPaginator(essdk.BuildFilter(ctx, d.QueryContext, listContainerAppFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getContainerAppFilters = map[string]string{
	"id":               "description.Server.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Server.Name",
	"tags":             "description.Server.Tags",
	"title":            "description.Server.Name",
}

func GetContainerApp(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetContainerApp")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewContainerAppPaginator(essdk.BuildFilter(ctx, d.QueryContext, getContainerAppFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ContainerApp =============================

// ==========================  START: AppManagedEnvironment =============================

type AppManagedEnvironment struct {
	Description   azure.AppManagedEnvironmentDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

func (r *AppManagedEnvironment) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.AppManagedEnvironmentDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type AppManagedEnvironmentHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  AppManagedEnvironment `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type AppManagedEnvironmentHits struct {
	Total essdk.SearchTotal          `json:"total"`
	Hits  []AppManagedEnvironmentHit `json:"hits"`
}

type AppManagedEnvironmentSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  AppManagedEnvironmentHits `json:"hits"`
}

type AppManagedEnvironmentPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewAppManagedEnvironmentPaginator(filters []essdk.BoolFilter, limit *int64) (AppManagedEnvironmentPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_app_managedenvironments", filters, limit)
	if err != nil {
		return AppManagedEnvironmentPaginator{}, err
	}

	p := AppManagedEnvironmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppManagedEnvironmentPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p AppManagedEnvironmentPaginator) NextPage(ctx context.Context) ([]AppManagedEnvironment, error) {
	var response AppManagedEnvironmentSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppManagedEnvironment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listAppManagedEnvironmentFilters = map[string]string{
	"id":               "description.HostingEnvironment.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.HostingEnvironment.Name",
	"tags":             "description.HostingEnvironment.Tags",
	"title":            "description.HostingEnvironment.Name",
}

func ListAppManagedEnvironment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppManagedEnvironment")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewAppManagedEnvironmentPaginator(essdk.BuildFilter(ctx, d.QueryContext, listAppManagedEnvironmentFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppManagedEnvironmentFilters = map[string]string{
	"id":               "description.HostingEnvironment.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.HostingEnvironment.Name",
	"tags":             "description.HostingEnvironment.Tags",
	"title":            "description.HostingEnvironment.Name",
}

func GetAppManagedEnvironment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppManagedEnvironment")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewAppManagedEnvironmentPaginator(essdk.BuildFilter(ctx, d.QueryContext, getAppManagedEnvironmentFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppManagedEnvironment =============================

// ==========================  START: WebServerFarms =============================

type WebServerFarms struct {
	Description   azure.WebServerFarmsDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

func (r *WebServerFarms) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.WebServerFarmsDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type WebServerFarmsHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  WebServerFarms `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type WebServerFarmsHits struct {
	Total essdk.SearchTotal   `json:"total"`
	Hits  []WebServerFarmsHit `json:"hits"`
}

type WebServerFarmsSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  WebServerFarmsHits `json:"hits"`
}

type WebServerFarmsPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewWebServerFarmsPaginator(filters []essdk.BoolFilter, limit *int64) (WebServerFarmsPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_web_serverfarms", filters, limit)
	if err != nil {
		return WebServerFarmsPaginator{}, err
	}

	p := WebServerFarmsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p WebServerFarmsPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p WebServerFarmsPaginator) NextPage(ctx context.Context) ([]WebServerFarms, error) {
	var response WebServerFarmsSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []WebServerFarms
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listWebServerFarmsFilters = map[string]string{
	"id":               "description.ServerFarm.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.ServerFarm.Name",
	"tags":             "description.ServerFarm.Tags",
	"title":            "description.ServerFarm.Name",
}

func ListWebServerFarms(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListWebServerFarms")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewWebServerFarmsPaginator(essdk.BuildFilter(ctx, d.QueryContext, listWebServerFarmsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getWebServerFarmsFilters = map[string]string{
	"id":               "description.ServerFarm.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.ServerFarm.Name",
	"tags":             "description.ServerFarm.Tags",
	"title":            "description.ServerFarm.Name",
}

func GetWebServerFarms(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetWebServerFarms")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewWebServerFarmsPaginator(essdk.BuildFilter(ctx, d.QueryContext, getWebServerFarmsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: WebServerFarms =============================

// ==========================  START: Blueprint =============================

type Blueprint struct {
	Description   azure.BlueprintDescription `json:"description"`
	Metadata      azure.Metadata             `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

func (r *Blueprint) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.BlueprintDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type BlueprintHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  Blueprint     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type BlueprintHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []BlueprintHit    `json:"hits"`
}

type BlueprintSearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  BlueprintHits `json:"hits"`
}

type BlueprintPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewBlueprintPaginator(filters []essdk.BoolFilter, limit *int64) (BlueprintPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_blueprint_blueprints", filters, limit)
	if err != nil {
		return BlueprintPaginator{}, err
	}

	p := BlueprintPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BlueprintPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p BlueprintPaginator) NextPage(ctx context.Context) ([]Blueprint, error) {
	var response BlueprintSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []Blueprint
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listBlueprintFilters = map[string]string{
	"id":               "description.Blueprints.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Blueprint.Name",
	"tags":             "description.Blueprint.Name",
	"title":            "description.Blueprint.Name",
}

func ListBlueprint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBlueprint")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewBlueprintPaginator(essdk.BuildFilter(ctx, d.QueryContext, listBlueprintFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBlueprintFilters = map[string]string{
	"id":               "description.Blueprints.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Blueprint.Name",
	"tags":             "description.Blueprint.Name",
	"title":            "description.Blueprint.Name",
}

func GetBlueprint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBlueprint")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewBlueprintPaginator(essdk.BuildFilter(ctx, d.QueryContext, getBlueprintFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: Blueprint =============================

// ==========================  START: ComputeDisk =============================

type ComputeDisk struct {
	Description   azure.ComputeDiskDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

func (r *ComputeDisk) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeDiskDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeDiskHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ComputeDisk   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ComputeDiskHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []ComputeDiskHit  `json:"hits"`
}

type ComputeDiskSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  ComputeDiskHits `json:"hits"`
}

type ComputeDiskPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeDiskPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeDiskPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_disks", filters, limit)
	if err != nil {
		return ComputeDiskPaginator{}, err
	}

	p := ComputeDiskPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeDiskPaginator) NextPage(ctx context.Context) ([]ComputeDisk, error) {
	var response ComputeDiskSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDisk
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskFilters = map[string]string{
	"creation_data_gallery_image_reference_id":  "description.Disk.Properties.CreationData.GalleryImageReference.ID",
	"creation_data_gallery_image_reference_lun": "description.Disk.Properties.CreationData.GalleryImageReference.Lun",
	"creation_data_image_reference_id":          "description.Disk.Properties.CreationData.ImageReference.ID",
	"creation_data_image_reference_lun":         "description.Disk.Properties.CreationData.ImageReference.Lun",
	"creation_data_option":                      "description.Disk.Properties.CreationData.CreateOption",
	"creation_data_source_resource_id":          "description.Disk.Properties.CreationData.SourceResourceID",
	"creation_data_source_unique_id":            "description.Disk.Properties.CreationData.SourceUniqueID",
	"creation_data_source_uri":                  "description.Disk.Properties.CreationData.SourceURI",
	"creation_data_storage_account_id":          "description.Disk.Properties.CreationData.StorageAccountID",
	"creation_data_upload_size_bytes":           "description.Disk.Properties.CreationData.UploadSizeBytes",
	"disk_access_id":                            "description.Disk.Properties.DiskAccessID",
	"disk_iops_mbps_read_only":                  "description.Disk.Properties.DiskMBpsReadOnly",
	"disk_iops_mbps_read_write":                 "description.Disk.Properties.DiskMBpsReadWrite",
	"disk_iops_read_only":                       "description.Disk.Properties.DiskMBpsReadOnly",
	"disk_iops_read_write":                      "description.Disk.Properties.DiskMBpsReadWrite",
	"disk_size_bytes":                           "description.Disk.Properties.DiskSizeBytes",
	"disk_size_gb":                              "description.Disk.Properties.DiskSizeGB",
	"disk_state":                                "description.Disk.Properties.DiskState",
	"encryption_disk_encryption_set_id":         "description.Disk.Properties.Encryption.DiskEncryptionSetID",
	"encryption_settings_collection_enabled":    "description.Disk.Properties.EncryptionSettingsCollection.Enabled",
	"encryption_settings_collection_settings":   "description.Disk.Properties.EncryptionSettingsCollection.EncryptionSettings",
	"encryption_settings_collection_version":    "description.Disk.Properties.EncryptionSettingsCollection.EncryptionSettingsVersion",
	"encryption_type":                           "description.Disk.Properties.Encryption.Type",
	"hyper_v_generation":                        "description.Disk.Properties.HyperVGeneration",
	"id":                                        "description.Disk.ID",
	"kaytu_account_id":                          "metadata.SourceID",
	"managed_by":                                "description.Disk.ManagedBy",
	"managed_by_extended":                       "description.Disk.ManagedByExtended",
	"max_shares":                                "description.Disk.Properties.MaxShares",
	"name":                                      "description.Disk.Name",
	"network_access_policy":                     "description.Disk.Properties.NetworkAccessPolicy",
	"os_type":                                   "description.Disk.Properties.OSType",
	"provisioning_state":                        "description.Disk.ProvisioningState",
	"resource_group":                            "description.ResourceGroup",
	"share_info":                                "description.Disk.Properties.ShareInfo",
	"sku_name":                                  "description.Disk.SKU.Name",
	"sku_tier":                                  "description.Disk.SKU.Tier",
	"tags":                                      "description.Disk.Tags",
	"title":                                     "description.Disk.Name",
	"type":                                      "description.Disk.Type",
	"unique_id":                                 "description.Disk.Properties.UniqueID",
	"zones":                                     "description.Disk.Zones",
}

func ListComputeDisk(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDisk")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeDiskPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeDiskFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskFilters = map[string]string{
	"creation_data_gallery_image_reference_id":  "description.Disk.Properties.CreationData.GalleryImageReference.ID",
	"creation_data_gallery_image_reference_lun": "description.Disk.Properties.CreationData.GalleryImageReference.Lun",
	"creation_data_image_reference_id":          "description.Disk.Properties.CreationData.ImageReference.ID",
	"creation_data_image_reference_lun":         "description.Disk.Properties.CreationData.ImageReference.Lun",
	"creation_data_option":                      "description.Disk.Properties.CreationData.CreateOption",
	"creation_data_source_resource_id":          "description.Disk.Properties.CreationData.SourceResourceID",
	"creation_data_source_unique_id":            "description.Disk.Properties.CreationData.SourceUniqueID",
	"creation_data_source_uri":                  "description.Disk.Properties.CreationData.SourceURI",
	"creation_data_storage_account_id":          "description.Disk.Properties.CreationData.StorageAccountID",
	"creation_data_upload_size_bytes":           "description.Disk.Properties.CreationData.UploadSizeBytes",
	"disk_access_id":                            "description.Disk.Properties.DiskAccessID",
	"disk_iops_mbps_read_only":                  "description.Disk.Properties.DiskMBpsReadOnly",
	"disk_iops_mbps_read_write":                 "description.Disk.Properties.DiskMBpsReadWrite",
	"disk_iops_read_only":                       "description.Disk.Properties.DiskMBpsReadOnly",
	"disk_iops_read_write":                      "description.Disk.Properties.DiskMBpsReadWrite",
	"disk_size_bytes":                           "description.Disk.Properties.DiskSizeBytes",
	"disk_size_gb":                              "description.Disk.Properties.DiskSizeGB",
	"disk_state":                                "description.Disk.Properties.DiskState",
	"encryption_disk_encryption_set_id":         "description.Disk.Properties.Encryption.DiskEncryptionSetID",
	"encryption_settings_collection_enabled":    "description.Disk.Properties.EncryptionSettingsCollection.Enabled",
	"encryption_settings_collection_settings":   "description.Disk.Properties.EncryptionSettingsCollection.EncryptionSettings",
	"encryption_settings_collection_version":    "description.Disk.Properties.EncryptionSettingsCollection.EncryptionSettingsVersion",
	"encryption_type":                           "description.Disk.Properties.Encryption.Type",
	"hyper_v_generation":                        "description.Disk.Properties.HyperVGeneration",
	"id":                                        "description.Disk.ID",
	"kaytu_account_id":                          "metadata.SourceID",
	"managed_by":                                "description.Disk.ManagedBy",
	"managed_by_extended":                       "description.Disk.ManagedByExtended",
	"max_shares":                                "description.Disk.Properties.MaxShares",
	"name":                                      "description.Disk.name",
	"network_access_policy":                     "description.Disk.Properties.NetworkAccessPolicy",
	"os_type":                                   "description.Disk.Properties.OSType",
	"provisioning_state":                        "description.Disk.ProvisioningState",
	"resource_group":                            "description.ResourceGroup",
	"share_info":                                "description.Disk.Properties.ShareInfo",
	"sku_name":                                  "description.Disk.SKU.Name",
	"sku_tier":                                  "description.Disk.SKU.Tier",
	"tags":                                      "description.Disk.Tags",
	"title":                                     "description.Disk.Name",
	"type":                                      "description.Disk.Type",
	"unique_id":                                 "description.Disk.Properties.UniqueID",
	"zones":                                     "description.Disk.Zones",
}

func GetComputeDisk(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDisk")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeDiskPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeDiskFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDisk =============================

// ==========================  START: ComputeDiskReadOps =============================

type ComputeDiskReadOps struct {
	Description   azure.ComputeDiskReadOpsDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

func (r *ComputeDiskReadOps) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeDiskReadOpsDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeDiskReadOpsHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  ComputeDiskReadOps `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type ComputeDiskReadOpsHits struct {
	Total essdk.SearchTotal       `json:"total"`
	Hits  []ComputeDiskReadOpsHit `json:"hits"`
}

type ComputeDiskReadOpsSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  ComputeDiskReadOpsHits `json:"hits"`
}

type ComputeDiskReadOpsPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeDiskReadOpsPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeDiskReadOpsPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_disksreadops", filters, limit)
	if err != nil {
		return ComputeDiskReadOpsPaginator{}, err
	}

	p := ComputeDiskReadOpsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskReadOpsPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeDiskReadOpsPaginator) NextPage(ctx context.Context) ([]ComputeDiskReadOps, error) {
	var response ComputeDiskReadOpsSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskReadOps
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskReadOpsFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func ListComputeDiskReadOps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskReadOps")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeDiskReadOpsPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeDiskReadOpsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskReadOpsFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func GetComputeDiskReadOps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskReadOps")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeDiskReadOpsPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeDiskReadOpsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskReadOps =============================

// ==========================  START: ComputeDiskReadOpsDaily =============================

type ComputeDiskReadOpsDaily struct {
	Description   azure.ComputeDiskReadOpsDailyDescription `json:"description"`
	Metadata      azure.Metadata                           `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

func (r *ComputeDiskReadOpsDaily) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeDiskReadOpsDailyDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeDiskReadOpsDailyHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  ComputeDiskReadOpsDaily `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type ComputeDiskReadOpsDailyHits struct {
	Total essdk.SearchTotal            `json:"total"`
	Hits  []ComputeDiskReadOpsDailyHit `json:"hits"`
}

type ComputeDiskReadOpsDailySearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  ComputeDiskReadOpsDailyHits `json:"hits"`
}

type ComputeDiskReadOpsDailyPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeDiskReadOpsDailyPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeDiskReadOpsDailyPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_disksreadopsdaily", filters, limit)
	if err != nil {
		return ComputeDiskReadOpsDailyPaginator{}, err
	}

	p := ComputeDiskReadOpsDailyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskReadOpsDailyPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeDiskReadOpsDailyPaginator) NextPage(ctx context.Context) ([]ComputeDiskReadOpsDaily, error) {
	var response ComputeDiskReadOpsDailySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskReadOpsDaily
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskReadOpsDailyFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func ListComputeDiskReadOpsDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskReadOpsDaily")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeDiskReadOpsDailyPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeDiskReadOpsDailyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskReadOpsDailyFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func GetComputeDiskReadOpsDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskReadOpsDaily")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeDiskReadOpsDailyPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeDiskReadOpsDailyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskReadOpsDaily =============================

// ==========================  START: ComputeDiskReadOpsHourly =============================

type ComputeDiskReadOpsHourly struct {
	Description   azure.ComputeDiskReadOpsHourlyDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

func (r *ComputeDiskReadOpsHourly) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeDiskReadOpsHourlyDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeDiskReadOpsHourlyHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  ComputeDiskReadOpsHourly `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type ComputeDiskReadOpsHourlyHits struct {
	Total essdk.SearchTotal             `json:"total"`
	Hits  []ComputeDiskReadOpsHourlyHit `json:"hits"`
}

type ComputeDiskReadOpsHourlySearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  ComputeDiskReadOpsHourlyHits `json:"hits"`
}

type ComputeDiskReadOpsHourlyPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeDiskReadOpsHourlyPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeDiskReadOpsHourlyPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_disksreadopshourly", filters, limit)
	if err != nil {
		return ComputeDiskReadOpsHourlyPaginator{}, err
	}

	p := ComputeDiskReadOpsHourlyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskReadOpsHourlyPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeDiskReadOpsHourlyPaginator) NextPage(ctx context.Context) ([]ComputeDiskReadOpsHourly, error) {
	var response ComputeDiskReadOpsHourlySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskReadOpsHourly
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskReadOpsHourlyFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func ListComputeDiskReadOpsHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskReadOpsHourly")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeDiskReadOpsHourlyPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeDiskReadOpsHourlyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskReadOpsHourlyFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func GetComputeDiskReadOpsHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskReadOpsHourly")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeDiskReadOpsHourlyPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeDiskReadOpsHourlyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskReadOpsHourly =============================

// ==========================  START: ComputeDiskWriteOps =============================

type ComputeDiskWriteOps struct {
	Description   azure.ComputeDiskWriteOpsDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

func (r *ComputeDiskWriteOps) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeDiskWriteOpsDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeDiskWriteOpsHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  ComputeDiskWriteOps `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type ComputeDiskWriteOpsHits struct {
	Total essdk.SearchTotal        `json:"total"`
	Hits  []ComputeDiskWriteOpsHit `json:"hits"`
}

type ComputeDiskWriteOpsSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  ComputeDiskWriteOpsHits `json:"hits"`
}

type ComputeDiskWriteOpsPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeDiskWriteOpsPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeDiskWriteOpsPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_diskswriteops", filters, limit)
	if err != nil {
		return ComputeDiskWriteOpsPaginator{}, err
	}

	p := ComputeDiskWriteOpsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskWriteOpsPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeDiskWriteOpsPaginator) NextPage(ctx context.Context) ([]ComputeDiskWriteOps, error) {
	var response ComputeDiskWriteOpsSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskWriteOps
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskWriteOpsFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func ListComputeDiskWriteOps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskWriteOps")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeDiskWriteOpsPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeDiskWriteOpsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskWriteOpsFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func GetComputeDiskWriteOps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskWriteOps")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeDiskWriteOpsPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeDiskWriteOpsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskWriteOps =============================

// ==========================  START: ComputeDiskWriteOpsDaily =============================

type ComputeDiskWriteOpsDaily struct {
	Description   azure.ComputeDiskWriteOpsDailyDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

func (r *ComputeDiskWriteOpsDaily) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeDiskWriteOpsDailyDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeDiskWriteOpsDailyHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  ComputeDiskWriteOpsDaily `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type ComputeDiskWriteOpsDailyHits struct {
	Total essdk.SearchTotal             `json:"total"`
	Hits  []ComputeDiskWriteOpsDailyHit `json:"hits"`
}

type ComputeDiskWriteOpsDailySearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  ComputeDiskWriteOpsDailyHits `json:"hits"`
}

type ComputeDiskWriteOpsDailyPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeDiskWriteOpsDailyPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeDiskWriteOpsDailyPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_diskswriteopsdaily", filters, limit)
	if err != nil {
		return ComputeDiskWriteOpsDailyPaginator{}, err
	}

	p := ComputeDiskWriteOpsDailyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskWriteOpsDailyPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeDiskWriteOpsDailyPaginator) NextPage(ctx context.Context) ([]ComputeDiskWriteOpsDaily, error) {
	var response ComputeDiskWriteOpsDailySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskWriteOpsDaily
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskWriteOpsDailyFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func ListComputeDiskWriteOpsDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskWriteOpsDaily")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeDiskWriteOpsDailyPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeDiskWriteOpsDailyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskWriteOpsDailyFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func GetComputeDiskWriteOpsDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskWriteOpsDaily")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeDiskWriteOpsDailyPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeDiskWriteOpsDailyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskWriteOpsDaily =============================

// ==========================  START: ComputeDiskWriteOpsHourly =============================

type ComputeDiskWriteOpsHourly struct {
	Description   azure.ComputeDiskWriteOpsHourlyDescription `json:"description"`
	Metadata      azure.Metadata                             `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

func (r *ComputeDiskWriteOpsHourly) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeDiskWriteOpsHourlyDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeDiskWriteOpsHourlyHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  ComputeDiskWriteOpsHourly `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type ComputeDiskWriteOpsHourlyHits struct {
	Total essdk.SearchTotal              `json:"total"`
	Hits  []ComputeDiskWriteOpsHourlyHit `json:"hits"`
}

type ComputeDiskWriteOpsHourlySearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  ComputeDiskWriteOpsHourlyHits `json:"hits"`
}

type ComputeDiskWriteOpsHourlyPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeDiskWriteOpsHourlyPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeDiskWriteOpsHourlyPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_diskswriteopshourly", filters, limit)
	if err != nil {
		return ComputeDiskWriteOpsHourlyPaginator{}, err
	}

	p := ComputeDiskWriteOpsHourlyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskWriteOpsHourlyPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeDiskWriteOpsHourlyPaginator) NextPage(ctx context.Context) ([]ComputeDiskWriteOpsHourly, error) {
	var response ComputeDiskWriteOpsHourlySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskWriteOpsHourly
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskWriteOpsHourlyFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func ListComputeDiskWriteOpsHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskWriteOpsHourly")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeDiskWriteOpsHourlyPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeDiskWriteOpsHourlyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskWriteOpsHourlyFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func GetComputeDiskWriteOpsHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskWriteOpsHourly")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeDiskWriteOpsHourlyPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeDiskWriteOpsHourlyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskWriteOpsHourly =============================

// ==========================  START: ComputeDiskAccess =============================

type ComputeDiskAccess struct {
	Description   azure.ComputeDiskAccessDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

func (r *ComputeDiskAccess) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeDiskAccessDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeDiskAccessHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  ComputeDiskAccess `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type ComputeDiskAccessHits struct {
	Total essdk.SearchTotal      `json:"total"`
	Hits  []ComputeDiskAccessHit `json:"hits"`
}

type ComputeDiskAccessSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  ComputeDiskAccessHits `json:"hits"`
}

type ComputeDiskAccessPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeDiskAccessPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeDiskAccessPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_diskaccesses", filters, limit)
	if err != nil {
		return ComputeDiskAccessPaginator{}, err
	}

	p := ComputeDiskAccessPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskAccessPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeDiskAccessPaginator) NextPage(ctx context.Context) ([]ComputeDiskAccess, error) {
	var response ComputeDiskAccessSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskAccess
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskAccessFilters = map[string]string{
	"id":                 "description.DiskAccess.ID",
	"kaytu_account_id":   "metadata.SourceID",
	"name":               "description.DiskAccess.Name",
	"provisioning_state": "description.DiskAccess.Properties.ProvisioningState",
	"resource_group":     "description.ResourceGroup",
	"tags":               "description.DiskAccess.Tags",
	"title":              "description.DiskAccess.Name",
	"type":               "description.DiskAccess.Type",
}

func ListComputeDiskAccess(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskAccess")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeDiskAccessPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeDiskAccessFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskAccessFilters = map[string]string{
	"id":                 "description.DiskAccess.ID",
	"kaytu_account_id":   "metadata.SourceID",
	"name":               "description.DiskAccess.name",
	"provisioning_state": "description.DiskAccess.Properties.ProvisioningState",
	"resource_group":     "description.ResourceGroup",
	"tags":               "description.DiskAccess.Tags",
	"title":              "description.DiskAccess.Name",
	"type":               "description.DiskAccess.Type",
}

func GetComputeDiskAccess(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskAccess")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeDiskAccessPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeDiskAccessFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskAccess =============================

// ==========================  START: ComputeVirtualMachineScaleSet =============================

type ComputeVirtualMachineScaleSet struct {
	Description   azure.ComputeVirtualMachineScaleSetDescription `json:"description"`
	Metadata      azure.Metadata                                 `json:"metadata"`
	ResourceJobID int                                            `json:"resource_job_id"`
	SourceJobID   int                                            `json:"source_job_id"`
	ResourceType  string                                         `json:"resource_type"`
	SourceType    string                                         `json:"source_type"`
	ID            string                                         `json:"id"`
	ARN           string                                         `json:"arn"`
	SourceID      string                                         `json:"source_id"`
}

func (r *ComputeVirtualMachineScaleSet) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeVirtualMachineScaleSetDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeVirtualMachineScaleSetHit struct {
	ID      string                        `json:"_id"`
	Score   float64                       `json:"_score"`
	Index   string                        `json:"_index"`
	Type    string                        `json:"_type"`
	Version int64                         `json:"_version,omitempty"`
	Source  ComputeVirtualMachineScaleSet `json:"_source"`
	Sort    []interface{}                 `json:"sort"`
}

type ComputeVirtualMachineScaleSetHits struct {
	Total essdk.SearchTotal                  `json:"total"`
	Hits  []ComputeVirtualMachineScaleSetHit `json:"hits"`
}

type ComputeVirtualMachineScaleSetSearchResponse struct {
	PitID string                            `json:"pit_id"`
	Hits  ComputeVirtualMachineScaleSetHits `json:"hits"`
}

type ComputeVirtualMachineScaleSetPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeVirtualMachineScaleSetPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeVirtualMachineScaleSetPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_virtualmachinescalesets", filters, limit)
	if err != nil {
		return ComputeVirtualMachineScaleSetPaginator{}, err
	}

	p := ComputeVirtualMachineScaleSetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeVirtualMachineScaleSetPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeVirtualMachineScaleSetPaginator) NextPage(ctx context.Context) ([]ComputeVirtualMachineScaleSet, error) {
	var response ComputeVirtualMachineScaleSetSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeVirtualMachineScaleSet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeVirtualMachineScaleSetFilters = map[string]string{
	"do_not_run_extensions_on_overprovisioned_vms": "description.VirtualMachineScaleSet.Properties.DoNotRunExtensionsOnOverprovisionedVMs",
	"extensions":                          "description.VirtualMachineScaleSetExtensions",
	"id":                                  "description.VirtualMachineScaleSet.ID",
	"identity":                            "description.VirtualMachineScaleSet.Identity",
	"kaytu_account_id":                    "metadata.SourceID",
	"location":                            "description.VirtualMachineScaleSet.Location",
	"name":                                "description.VirtualMachineScaleSet.Name",
	"overprovision":                       "description.VirtualMachineScaleSet.Properties.Overprovision",
	"plan":                                "description.VirtualMachineScaleSet.Plan",
	"platform_fault_domain_count":         "description.VirtualMachineScaleSet.Properties.PlatformFaultDomainCount",
	"provisioning_state":                  "description.VirtualMachineScaleSet.Properties.ProvisioningState",
	"resource_group":                      "description.ResourceGroup",
	"scale_in_policy":                     "description.VirtualMachineScaleSet.Properties.ScaleInPolicy",
	"single_placement_group":              "description.VirtualMachineScaleSet.Properties.SinglePlacementGroup",
	"sku_capacity":                        "description.VirtualMachineScaleSet.SKU.Capacity",
	"sku_name":                            "description.VirtualMachineScaleSet.SKU.Name",
	"sku_tier":                            "description.VirtualMachineScaleSet.SKU.Tier",
	"tags":                                "description.VirtualMachineScaleSet.Tags",
	"tags_src":                            "description.VirtualMachineScaleSet.Tags",
	"title":                               "description.VirtualMachineScaleSet.Name",
	"type":                                "description.VirtualMachineScaleSet.Type",
	"unique_id":                           "description.VirtualMachineScaleSet.Properties.UniqueID",
	"upgrade_policy":                      "description.VirtualMachineScaleSet.Properties.UpgradePolicy",
	"virtual_machine_diagnostics_profile": "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.DiagnosticsProfile",
	"virtual_machine_extension_profile":   "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.ExtensionProfile",
	"virtual_machine_network_profile":     "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.NetworkProfile",
	"virtual_machine_os_profile":          "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.OSProfile",
	"virtual_machine_security_profile":    "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.SecurityProfile",
	"virtual_machine_storage_profile":     "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.StorageProfile",
	"zones":                               "description.VirtualMachineScaleSet.Zones",
}

func ListComputeVirtualMachineScaleSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeVirtualMachineScaleSet")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeVirtualMachineScaleSetPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeVirtualMachineScaleSetFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeVirtualMachineScaleSetFilters = map[string]string{
	"do_not_run_extensions_on_overprovisioned_vms": "description.VirtualMachineScaleSet.Properties.DoNotRunExtensionsOnOverprovisionedVMs",
	"extensions":                          "description.VirtualMachineScaleSetExtensions",
	"id":                                  "description.VirtualMachineScaleSet.ID",
	"identity":                            "description.VirtualMachineScaleSet.Identity",
	"kaytu_account_id":                    "metadata.SourceID",
	"location":                            "description.VirtualMachineScaleSet.Location",
	"name":                                "description.VirtualMachineScaleSet.name",
	"overprovision":                       "description.VirtualMachineScaleSet.Properties.Overprovision",
	"plan":                                "description.VirtualMachineScaleSet.Plan",
	"platform_fault_domain_count":         "description.VirtualMachineScaleSet.Properties.PlatformFaultDomainCount",
	"provisioning_state":                  "description.VirtualMachineScaleSet.Properties.ProvisioningState",
	"resource_group":                      "description.ResourceGroup",
	"scale_in_policy":                     "description.VirtualMachineScaleSet.Properties.ScaleInPolicy",
	"single_placement_group":              "description.VirtualMachineScaleSet.Properties.SinglePlacementGroup",
	"sku_capacity":                        "description.VirtualMachineScaleSet.SKU.Capacity",
	"sku_name":                            "description.VirtualMachineScaleSet.SKU.Name",
	"sku_tier":                            "description.VirtualMachineScaleSet.SKU.Tier",
	"tags":                                "description.VirtualMachineScaleSet.Tags",
	"tags_src":                            "description.VirtualMachineScaleSet.Tags",
	"title":                               "description.VirtualMachineScaleSet.Name",
	"type":                                "description.VirtualMachineScaleSet.Type",
	"unique_id":                           "description.VirtualMachineScaleSet.Properties.UniqueID",
	"upgrade_policy":                      "description.VirtualMachineScaleSet.Properties.UpgradePolicy",
	"virtual_machine_diagnostics_profile": "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.DiagnosticsProfile",
	"virtual_machine_extension_profile":   "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.ExtensionProfile",
	"virtual_machine_network_profile":     "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.NetworkProfile",
	"virtual_machine_os_profile":          "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.OSProfile",
	"virtual_machine_security_profile":    "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.SecurityProfile",
	"virtual_machine_storage_profile":     "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.StorageProfile",
	"zones":                               "description.VirtualMachineScaleSet.Zones",
}

func GetComputeVirtualMachineScaleSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeVirtualMachineScaleSet")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeVirtualMachineScaleSetPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeVirtualMachineScaleSetFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeVirtualMachineScaleSet =============================

// ==========================  START: ComputeVirtualMachineScaleSetNetworkInterface =============================

type ComputeVirtualMachineScaleSetNetworkInterface struct {
	Description   azure.ComputeVirtualMachineScaleSetNetworkInterfaceDescription `json:"description"`
	Metadata      azure.Metadata                                                 `json:"metadata"`
	ResourceJobID int                                                            `json:"resource_job_id"`
	SourceJobID   int                                                            `json:"source_job_id"`
	ResourceType  string                                                         `json:"resource_type"`
	SourceType    string                                                         `json:"source_type"`
	ID            string                                                         `json:"id"`
	ARN           string                                                         `json:"arn"`
	SourceID      string                                                         `json:"source_id"`
}

func (r *ComputeVirtualMachineScaleSetNetworkInterface) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeVirtualMachineScaleSetNetworkInterfaceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeVirtualMachineScaleSetNetworkInterfaceHit struct {
	ID      string                                        `json:"_id"`
	Score   float64                                       `json:"_score"`
	Index   string                                        `json:"_index"`
	Type    string                                        `json:"_type"`
	Version int64                                         `json:"_version,omitempty"`
	Source  ComputeVirtualMachineScaleSetNetworkInterface `json:"_source"`
	Sort    []interface{}                                 `json:"sort"`
}

type ComputeVirtualMachineScaleSetNetworkInterfaceHits struct {
	Total essdk.SearchTotal                                  `json:"total"`
	Hits  []ComputeVirtualMachineScaleSetNetworkInterfaceHit `json:"hits"`
}

type ComputeVirtualMachineScaleSetNetworkInterfaceSearchResponse struct {
	PitID string                                            `json:"pit_id"`
	Hits  ComputeVirtualMachineScaleSetNetworkInterfaceHits `json:"hits"`
}

type ComputeVirtualMachineScaleSetNetworkInterfacePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeVirtualMachineScaleSetNetworkInterfacePaginator(filters []essdk.BoolFilter, limit *int64) (ComputeVirtualMachineScaleSetNetworkInterfacePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_virtualmachinescalesets_networkinterfaces", filters, limit)
	if err != nil {
		return ComputeVirtualMachineScaleSetNetworkInterfacePaginator{}, err
	}

	p := ComputeVirtualMachineScaleSetNetworkInterfacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeVirtualMachineScaleSetNetworkInterfacePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeVirtualMachineScaleSetNetworkInterfacePaginator) NextPage(ctx context.Context) ([]ComputeVirtualMachineScaleSetNetworkInterface, error) {
	var response ComputeVirtualMachineScaleSetNetworkInterfaceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeVirtualMachineScaleSetNetworkInterface
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeVirtualMachineScaleSetNetworkInterfaceFilters = map[string]string{
	"id":               "description.NetworkInterface.ID",
	"kaytu_account_id": "metadata.SourceID",
	"mac_address":      "description.NetworkInterface.MacAddress",
	"name":             "description.NetworkInterface.Name",
	"resource_group":   "description.ResourceGroup",
	"scale_set_name":   "description.VirtualMachineScaleSet.Name",
	"tags":             "description.NetworkInterface.Tags",
	"title":            "description.NetworkInterface.Name",
	"type":             "description.NetworkInterface.Type",
}

func ListComputeVirtualMachineScaleSetNetworkInterface(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeVirtualMachineScaleSetNetworkInterface")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeVirtualMachineScaleSetNetworkInterfacePaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeVirtualMachineScaleSetNetworkInterfaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeVirtualMachineScaleSetNetworkInterfaceFilters = map[string]string{
	"id":               "description.NetworkInterface.ID",
	"kaytu_account_id": "metadata.SourceID",
	"mac_address":      "description.NetworkInterface.MacAddress",
	"name":             "description.NetworkInterface.Name",
	"resource_group":   "description.ResourceGroup",
	"scale_set_name":   "description.VirtualMachineScaleSet.Name",
	"tags":             "description.NetworkInterface.Tags",
	"title":            "description.NetworkInterface.Name",
	"type":             "description.NetworkInterface.Type",
}

func GetComputeVirtualMachineScaleSetNetworkInterface(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeVirtualMachineScaleSetNetworkInterface")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeVirtualMachineScaleSetNetworkInterfacePaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeVirtualMachineScaleSetNetworkInterfaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeVirtualMachineScaleSetNetworkInterface =============================

// ==========================  START: ComputeVirtualMachineScaleSetVm =============================

type ComputeVirtualMachineScaleSetVm struct {
	Description   azure.ComputeVirtualMachineScaleSetVmDescription `json:"description"`
	Metadata      azure.Metadata                                   `json:"metadata"`
	ResourceJobID int                                              `json:"resource_job_id"`
	SourceJobID   int                                              `json:"source_job_id"`
	ResourceType  string                                           `json:"resource_type"`
	SourceType    string                                           `json:"source_type"`
	ID            string                                           `json:"id"`
	ARN           string                                           `json:"arn"`
	SourceID      string                                           `json:"source_id"`
}

func (r *ComputeVirtualMachineScaleSetVm) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeVirtualMachineScaleSetVmDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeVirtualMachineScaleSetVmHit struct {
	ID      string                          `json:"_id"`
	Score   float64                         `json:"_score"`
	Index   string                          `json:"_index"`
	Type    string                          `json:"_type"`
	Version int64                           `json:"_version,omitempty"`
	Source  ComputeVirtualMachineScaleSetVm `json:"_source"`
	Sort    []interface{}                   `json:"sort"`
}

type ComputeVirtualMachineScaleSetVmHits struct {
	Total essdk.SearchTotal                    `json:"total"`
	Hits  []ComputeVirtualMachineScaleSetVmHit `json:"hits"`
}

type ComputeVirtualMachineScaleSetVmSearchResponse struct {
	PitID string                              `json:"pit_id"`
	Hits  ComputeVirtualMachineScaleSetVmHits `json:"hits"`
}

type ComputeVirtualMachineScaleSetVmPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeVirtualMachineScaleSetVmPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeVirtualMachineScaleSetVmPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_virtualmachinescalesets_virtualmachines", filters, limit)
	if err != nil {
		return ComputeVirtualMachineScaleSetVmPaginator{}, err
	}

	p := ComputeVirtualMachineScaleSetVmPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeVirtualMachineScaleSetVmPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeVirtualMachineScaleSetVmPaginator) NextPage(ctx context.Context) ([]ComputeVirtualMachineScaleSetVm, error) {
	var response ComputeVirtualMachineScaleSetVmSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeVirtualMachineScaleSetVm
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeVirtualMachineScaleSetVmFilters = map[string]string{
	"additional_capabilities":             "description.VirtualMachineScaleSet.Properties.AdditionalCapabilities",
	"availability_set":                    "description.ScaleSetVM.Properties.AvailabilitySet",
	"id":                                  "description.NetworkInterface.ID",
	"instance_id":                         "description.ScaleSetVM.InstanceID",
	"kaytu_account_id":                    "metadata.SourceID",
	"latest_model_applied":                "description.VirtualMachineScaleSet.Properties.LatestModelApplied",
	"license_type":                        "description.VirtualMachineScaleSet.Properties.LicenseType",
	"location":                            "description.ScaleSetVM.Location",
	"model_definition_applied":            "description.ScaleSetVM.Properties.ModelDefinitionApplied",
	"name":                                "description.ScaleSetVM.Name",
	"plan":                                "description.ScaleSetVM.Plan",
	"protection_policy":                   "description.VirtualMachineScaleSet.Properties.SpotRestorePolicy",
	"provisioning_state":                  "description.VirtualMachineScaleSet.Properties.ProvisioningState",
	"resource_group":                      "description.ResourceGroup",
	"resources":                           "description.ScaleSetVM.Resources",
	"scale_set_name":                      "description.VirtualMachineScaleSet.Name",
	"sku_capacity":                        "description.ScaleSetVM.SKU.Capacity",
	"sku_name":                            "description.ScaleSetVM.SKU.Name",
	"sku_tier":                            "description.ScaleSetVM.SKU.Tier",
	"tags":                                "description.ScaleSetVM.Tags",
	"tags_src":                            "description.ScaleSetVM.Tags",
	"title":                               "description.ScaleSetVM.Name",
	"type":                                "description.ScaleSetVM.Type",
	"upgrade_policy":                      "description.VirtualMachineScaleSet.Properties.UpgradePolicy",
	"virtual_machine_diagnostics_profile": "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.DiagnosticsProfile",
	"virtual_machine_hardware_profile":    "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.HardwareProfile",
	"virtual_machine_network_profile":     "description.ScaleSetVM.Properties.NetworkProfile.NetworkInterfaces",
	"virtual_machine_network_profile_configuration": "description.ScaleSetVM.Properties.NetworkProfileConfiguration",
	"virtual_machine_os_profile":                    "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.OSProfile",
	"virtual_machine_security_profile":              "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.SecurityProfile",
	"virtual_machine_storage_profile":               "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.StorageProfile",
	"vm_id":                                         "description.ScaleSetVM.Properties.VMID",
	"zones":                                         "description.ScaleSetVM.Zones",
}

func ListComputeVirtualMachineScaleSetVm(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeVirtualMachineScaleSetVm")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeVirtualMachineScaleSetVmPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeVirtualMachineScaleSetVmFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeVirtualMachineScaleSetVmFilters = map[string]string{
	"additional_capabilities":             "description.VirtualMachineScaleSet.Properties.AdditionalCapabilities",
	"availability_set":                    "description.ScaleSetVM.Properties.AvailabilitySet",
	"id":                                  "description.NetworkInterface.ID",
	"instance_id":                         "description.ScaleSetVM.InstanceID",
	"kaytu_account_id":                    "metadata.SourceID",
	"latest_model_applied":                "description.VirtualMachineScaleSet.Properties.LatestModelApplied",
	"license_type":                        "description.VirtualMachineScaleSet.Properties.LicenseType",
	"location":                            "description.ScaleSetVM.Location",
	"model_definition_applied":            "description.ScaleSetVM.Properties.ModelDefinitionApplied",
	"name":                                "description.ScaleSetVM.Name",
	"plan":                                "description.ScaleSetVM.Plan",
	"protection_policy":                   "description.VirtualMachineScaleSet.Properties.SpotRestorePolicy",
	"provisioning_state":                  "description.VirtualMachineScaleSet.Properties.ProvisioningState",
	"resource_group":                      "description.ResourceGroup",
	"resources":                           "description.ScaleSetVM.Resources",
	"scale_set_name":                      "description.VirtualMachineScaleSet.name",
	"sku_capacity":                        "description.ScaleSetVM.SKU.Capacity",
	"sku_name":                            "description.ScaleSetVM.SKU.Name",
	"sku_tier":                            "description.ScaleSetVM.SKU.Tier",
	"tags":                                "description.ScaleSetVM.Tags",
	"tags_src":                            "description.ScaleSetVM.Tags",
	"title":                               "description.ScaleSetVM.Name",
	"type":                                "description.ScaleSetVM.Type",
	"upgrade_policy":                      "description.VirtualMachineScaleSet.Properties.UpgradePolicy",
	"virtual_machine_diagnostics_profile": "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.DiagnosticsProfile",
	"virtual_machine_hardware_profile":    "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.HardwareProfile",
	"virtual_machine_network_profile":     "description.ScaleSetVM.Properties.NetworkProfile.NetworkInterfaces",
	"virtual_machine_network_profile_configuration": "description.ScaleSetVM.Properties.NetworkProfileConfiguration",
	"virtual_machine_os_profile":                    "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.OSProfile",
	"virtual_machine_security_profile":              "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.SecurityProfile",
	"virtual_machine_storage_profile":               "description.VirtualMachineScaleSet.Properties.VirtualMachineProfile.StorageProfile",
	"vm_id":                                         "description.ScaleSetVM.Properties.VMID",
	"zones":                                         "description.ScaleSetVM.Zones",
}

func GetComputeVirtualMachineScaleSetVm(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeVirtualMachineScaleSetVm")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeVirtualMachineScaleSetVmPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeVirtualMachineScaleSetVmFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeVirtualMachineScaleSetVm =============================

// ==========================  START: ComputeSnapshots =============================

type ComputeSnapshots struct {
	Description   azure.ComputeSnapshotsDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *ComputeSnapshots) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeSnapshotsDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeSnapshotsHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  ComputeSnapshots `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type ComputeSnapshotsHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []ComputeSnapshotsHit `json:"hits"`
}

type ComputeSnapshotsSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  ComputeSnapshotsHits `json:"hits"`
}

type ComputeSnapshotsPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeSnapshotsPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeSnapshotsPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_snapshots", filters, limit)
	if err != nil {
		return ComputeSnapshotsPaginator{}, err
	}

	p := ComputeSnapshotsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeSnapshotsPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeSnapshotsPaginator) NextPage(ctx context.Context) ([]ComputeSnapshots, error) {
	var response ComputeSnapshotsSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeSnapshots
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeSnapshotsFilters = map[string]string{
	"create_option":                         "description.Snapshot.Properties.CreationData.CreateOption",
	"disk_access_id":                        "description.Snapshot.Properties.DiskAccessID",
	"disk_encryption_set_id":                "description.Snapshot.Properties.Encryption.DiskEncryptionSetID",
	"disk_size_bytes":                       "description.Snapshot.Properties.DiskSizeBytes",
	"disk_size_gb":                          "description.Snapshot.Properties.DiskSizeGB",
	"encryption_setting_collection_enabled": "description.Snapshot.Properties.EncryptionSettingsCollection.Enabled",
	"encryption_setting_version":            "description.Snapshot.Properties.EncryptionSettingsCollection.EncryptionSettingsVersion",
	"encryption_settings":                   "description.Snapshot.Properties.EncryptionSettingsCollection.EncryptionSettings",
	"encryption_type":                       "description.Snapshot.Properties.Encryption.Type",
	"gallery_image_reference_id":            "description.Snapshot.Properties.CreationData.GalleryImageReference.ID",
	"gallery_reference_lun":                 "description.Snapshot.Properties.CreationData.GalleryImageReference.Lun",
	"hyperv_generation":                     "description.Snapshot.Properties.HyperVGeneration",
	"id":                                    "description.Snapshot.ID",
	"image_reference_id":                    "description.Snapshot.Properties.CreationData.ImageReference.ID",
	"image_reference_lun":                   "description.Snapshot.Properties.CreationData.ImageReference.Lun",
	"incremental":                           "description.Snapshot.Properties.Incremental",
	"kaytu_account_id":                      "metadata.SourceID",
	"name":                                  "description.Snapshot.Name",
	"network_access_policy":                 "description.Snapshot.Properties.NetworkAccessPolicy",
	"os_type":                               "description.Snapshot.Properties.OSType",
	"provisioning_state":                    "description.Snapshot.Properties.ProvisioningState",
	"resource_group":                        "description.ResourceGroup",
	"sku_name":                              "description.Snapshot.SKU.Name",
	"sku_tier":                              "description.Snapshot.SKU.Tier",
	"source_resource_id":                    "description.Snapshot.Properties.CreationData.SourceResourceID",
	"source_unique_id":                      "description.Snapshot.Properties.CreationData.SourceUniqueID",
	"source_uri":                            "description.Snapshot.Properties.CreationData.SourceURI",
	"storage_account_id":                    "description.Snapshot.Properties.CreationData.StorageAccountID",
	"tags":                                  "description.Snapshot.Tags",
	"title":                                 "description.Snapshot.Name",
	"type":                                  "description.Snapshot.Type",
	"unique_id":                             "description.Snapshot.Properties.UniqueID",
	"upload_size_bytes":                     "description.Snapshot.Properties.CreationData.UploadSizeBytes",
}

func ListComputeSnapshots(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeSnapshots")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeSnapshotsPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeSnapshotsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeSnapshotsFilters = map[string]string{
	"create_option":                         "description.Snapshot.Properties.CreationData.CreateOption",
	"disk_access_id":                        "description.Snapshot.Properties.DiskAccessID",
	"disk_encryption_set_id":                "description.Snapshot.Properties.Encryption.DiskEncryptionSetID",
	"disk_size_bytes":                       "description.Snapshot.Properties.DiskSizeBytes",
	"disk_size_gb":                          "description.Snapshot.Properties.DiskSizeGB",
	"encryption_setting_collection_enabled": "description.Snapshot.Properties.EncryptionSettingsCollection.Enabled",
	"encryption_setting_version":            "description.Snapshot.Properties.EncryptionSettingsCollection.EncryptionSettingsVersion",
	"encryption_settings":                   "description.Snapshot.Properties.EncryptionSettingsCollection.EncryptionSettings",
	"encryption_type":                       "description.Snapshot.Properties.Encryption.Type",
	"gallery_image_reference_id":            "description.Snapshot.Properties.CreationData.GalleryImageReference.ID",
	"gallery_reference_lun":                 "description.Snapshot.Properties.CreationData.GalleryImageReference.Lun",
	"hyperv_generation":                     "description.Snapshot.Properties.HyperVGeneration",
	"id":                                    "description.Snapshot.ID",
	"image_reference_id":                    "description.Snapshot.Properties.CreationData.ImageReference.ID",
	"image_reference_lun":                   "description.Snapshot.Properties.CreationData.ImageReference.Lun",
	"incremental":                           "description.Snapshot.Properties.Incremental",
	"kaytu_account_id":                      "metadata.SourceID",
	"name":                                  "description.Snapshot.Name",
	"network_access_policy":                 "description.Snapshot.Properties.NetworkAccessPolicy",
	"os_type":                               "description.Snapshot.Properties.OSType",
	"provisioning_state":                    "description.Snapshot.Properties.ProvisioningState",
	"resource_group":                        "description.ResourceGroup",
	"sku_name":                              "description.Snapshot.SKU.Name",
	"sku_tier":                              "description.Snapshot.SKU.Tier",
	"source_resource_id":                    "description.Snapshot.Properties.CreationData.SourceResourceID",
	"source_unique_id":                      "description.Snapshot.Properties.CreationData.SourceUniqueID",
	"source_uri":                            "description.Snapshot.Properties.CreationData.SourceURI",
	"storage_account_id":                    "description.Snapshot.Properties.CreationData.StorageAccountID",
	"tags":                                  "description.Snapshot.Tags",
	"title":                                 "description.Snapshot.Name",
	"type":                                  "description.Snapshot.Type",
	"unique_id":                             "description.Snapshot.Properties.UniqueID",
	"upload_size_bytes":                     "description.Snapshot.Properties.CreationData.UploadSizeBytes",
}

func GetComputeSnapshots(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeSnapshots")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeSnapshotsPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeSnapshotsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeSnapshots =============================

// ==========================  START: ComputeAvailabilitySet =============================

type ComputeAvailabilitySet struct {
	Description   azure.ComputeAvailabilitySetDescription `json:"description"`
	Metadata      azure.Metadata                          `json:"metadata"`
	ResourceJobID int                                     `json:"resource_job_id"`
	SourceJobID   int                                     `json:"source_job_id"`
	ResourceType  string                                  `json:"resource_type"`
	SourceType    string                                  `json:"source_type"`
	ID            string                                  `json:"id"`
	ARN           string                                  `json:"arn"`
	SourceID      string                                  `json:"source_id"`
}

func (r *ComputeAvailabilitySet) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeAvailabilitySetDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeAvailabilitySetHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  ComputeAvailabilitySet `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type ComputeAvailabilitySetHits struct {
	Total essdk.SearchTotal           `json:"total"`
	Hits  []ComputeAvailabilitySetHit `json:"hits"`
}

type ComputeAvailabilitySetSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  ComputeAvailabilitySetHits `json:"hits"`
}

type ComputeAvailabilitySetPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeAvailabilitySetPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeAvailabilitySetPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_availabilitysets", filters, limit)
	if err != nil {
		return ComputeAvailabilitySetPaginator{}, err
	}

	p := ComputeAvailabilitySetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeAvailabilitySetPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeAvailabilitySetPaginator) NextPage(ctx context.Context) ([]ComputeAvailabilitySet, error) {
	var response ComputeAvailabilitySetSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeAvailabilitySet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeAvailabilitySetFilters = map[string]string{
	"id":                           "description.AvailabilitySet.ID",
	"kaytu_account_id":             "metadata.SourceID",
	"name":                         "description.AvailabilitySet.Name",
	"platform_fault_domain_count":  "description.AvailabilitySet.Properties.PlatformFaultDomainCount",
	"platform_update_domain_count": "description.AvailabilitySet.Properties.PlatformUpdateDomainCount",
	"proximity_placement_group_id": "description.AvailabilitySet.Properties.ProximityPlacementGroup.ID",
	"resource_group":               "description.ResourceGroup",
	"sku_capacity":                 "description.AvailabilitySet.SKU.Capacity",
	"sku_name":                     "description.AvailabilitySet.SKU.Name",
	"sku_tier":                     "description.AvailabilitySet.SKU.Tier",
	"status":                       "description.AvailabilitySet.Properties.Statuses",
	"tags":                         "description.AvailabilitySet.Tags",
	"title":                        "description.AvailabilitySet.Name",
	"type":                         "description.AvailabilitySet.Type",
	"virtual_machines":             "description.AvailabilitySet.Properties.VirtualMachines",
}

func ListComputeAvailabilitySet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeAvailabilitySet")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeAvailabilitySetPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeAvailabilitySetFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeAvailabilitySetFilters = map[string]string{
	"id":                           "description.AvailabilitySet.ID",
	"kaytu_account_id":             "metadata.SourceID",
	"name":                         "description.AvailabilitySet.Name",
	"platform_fault_domain_count":  "description.AvailabilitySet.Properties.PlatformFaultDomainCount",
	"platform_update_domain_count": "description.AvailabilitySet.Properties.PlatformUpdateDomainCount",
	"proximity_placement_group_id": "description.AvailabilitySet.Properties.ProximityPlacementGroup.ID",
	"resource_group":               "description.ResourceGroup",
	"sku_capacity":                 "description.AvailabilitySet.SKU.Capacity",
	"sku_name":                     "description.AvailabilitySet.SKU.Name",
	"sku_tier":                     "description.AvailabilitySet.SKU.Tier",
	"status":                       "description.AvailabilitySet.Properties.Statuses",
	"tags":                         "description.AvailabilitySet.Tags",
	"title":                        "description.AvailabilitySet.Name",
	"type":                         "description.AvailabilitySet.Type",
	"virtual_machines":             "description.AvailabilitySet.Properties.VirtualMachines",
}

func GetComputeAvailabilitySet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeAvailabilitySet")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeAvailabilitySetPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeAvailabilitySetFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeAvailabilitySet =============================

// ==========================  START: ComputeDiskEncryptionSet =============================

type ComputeDiskEncryptionSet struct {
	Description   azure.ComputeDiskEncryptionSetDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

func (r *ComputeDiskEncryptionSet) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeDiskEncryptionSetDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeDiskEncryptionSetHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  ComputeDiskEncryptionSet `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type ComputeDiskEncryptionSetHits struct {
	Total essdk.SearchTotal             `json:"total"`
	Hits  []ComputeDiskEncryptionSetHit `json:"hits"`
}

type ComputeDiskEncryptionSetSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  ComputeDiskEncryptionSetHits `json:"hits"`
}

type ComputeDiskEncryptionSetPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeDiskEncryptionSetPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeDiskEncryptionSetPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_diskencryptionsets", filters, limit)
	if err != nil {
		return ComputeDiskEncryptionSetPaginator{}, err
	}

	p := ComputeDiskEncryptionSetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskEncryptionSetPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeDiskEncryptionSetPaginator) NextPage(ctx context.Context) ([]ComputeDiskEncryptionSet, error) {
	var response ComputeDiskEncryptionSetSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskEncryptionSet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskEncryptionSetFilters = map[string]string{
	"active_key_source_vault_id": "description.DiskEncryptionSet.Properties.ActiveKey.SourceVault.ID",
	"active_key_url":             "description.DiskEncryptionSet.Properties.ActiveKey.KeyURL",
	"encryption_type":            "description.DiskEncryptionSet.Properties.EncryptionType",
	"id":                         "description.DiskEncryptionSet.ID",
	"identity_principal_id":      "description.DiskEncryptionSet.Identity.PrincipalID",
	"identity_tenant_id":         "description.DiskEncryptionSet.Identity.TenantID",
	"identity_type":              "description.DiskEncryptionSet.Identity.Type",
	"kaytu_account_id":           "metadata.SourceID",
	"name":                       "description.DiskEncryptionSet.Name",
	"previous_keys":              "description.DiskEncryptionSet.Properties.PreviousKeys",
	"provisioning_state":         "description.DiskEncryptionSet.Properties.ProvisioningState",
	"resource_group":             "description.ResourceGroup",
	"tags":                       "description.DiskEncryptionSet.Tags",
	"title":                      "description.DiskEncryptionSet.Name",
	"type":                       "description.DiskEncryptionSet.Type",
}

func ListComputeDiskEncryptionSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskEncryptionSet")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeDiskEncryptionSetPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeDiskEncryptionSetFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskEncryptionSetFilters = map[string]string{
	"active_key_source_vault_id": "description.DiskEncryptionSet.Properties.ActiveKey.SourceVault.ID",
	"active_key_url":             "description.DiskEncryptionSet.Properties.ActiveKey.KeyURL",
	"encryption_type":            "description.DiskEncryptionSet.Properties.EncryptionType",
	"id":                         "description.DiskEncryptionSet.ID",
	"identity_principal_id":      "description.DiskEncryptionSet.Identity.PrincipalID",
	"identity_tenant_id":         "description.DiskEncryptionSet.Identity.TenantID",
	"identity_type":              "description.DiskEncryptionSet.Identity.Type",
	"kaytu_account_id":           "metadata.SourceID",
	"name":                       "description.DiskEncryptionSet.Name",
	"previous_keys":              "description.DiskEncryptionSet.Properties.PreviousKeys",
	"provisioning_state":         "description.DiskEncryptionSet.Properties.ProvisioningState",
	"resource_group":             "description.ResourceGroup",
	"tags":                       "description.DiskEncryptionSet.Tags",
	"title":                      "description.DiskEncryptionSet.Name",
	"type":                       "description.DiskEncryptionSet.Type",
}

func GetComputeDiskEncryptionSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskEncryptionSet")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeDiskEncryptionSetPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeDiskEncryptionSetFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskEncryptionSet =============================

// ==========================  START: ComputeImageGallery =============================

type ComputeImageGallery struct {
	Description   azure.ComputeImageGalleryDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

func (r *ComputeImageGallery) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeImageGalleryDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeImageGalleryHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  ComputeImageGallery `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type ComputeImageGalleryHits struct {
	Total essdk.SearchTotal        `json:"total"`
	Hits  []ComputeImageGalleryHit `json:"hits"`
}

type ComputeImageGallerySearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  ComputeImageGalleryHits `json:"hits"`
}

type ComputeImageGalleryPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeImageGalleryPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeImageGalleryPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_galleries", filters, limit)
	if err != nil {
		return ComputeImageGalleryPaginator{}, err
	}

	p := ComputeImageGalleryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeImageGalleryPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeImageGalleryPaginator) NextPage(ctx context.Context) ([]ComputeImageGallery, error) {
	var response ComputeImageGallerySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeImageGallery
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeImageGalleryFilters = map[string]string{
	"id":               "description.ImageGallery.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.ImageGallery.Name",
	"tags":             "description.ImageGallery.Tags",
	"title":            "description.ImageGallery.Name",
}

func ListComputeImageGallery(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeImageGallery")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeImageGalleryPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeImageGalleryFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeImageGalleryFilters = map[string]string{
	"id":               "description.ImageGallery.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.ImageGallery.Name",
	"resource_group":   "description.ResourceGroup",
	"tags":             "description.ImageGallery.Tags",
	"title":            "description.ImageGallery.Name",
}

func GetComputeImageGallery(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeImageGallery")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeImageGalleryPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeImageGalleryFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeImageGallery =============================

// ==========================  START: ComputeImage =============================

type ComputeImage struct {
	Description   azure.ComputeImageDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

func (r *ComputeImage) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeImageDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeImageHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ComputeImage  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ComputeImageHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []ComputeImageHit `json:"hits"`
}

type ComputeImageSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  ComputeImageHits `json:"hits"`
}

type ComputeImagePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeImagePaginator(filters []essdk.BoolFilter, limit *int64) (ComputeImagePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_images", filters, limit)
	if err != nil {
		return ComputeImagePaginator{}, err
	}

	p := ComputeImagePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeImagePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeImagePaginator) NextPage(ctx context.Context) ([]ComputeImage, error) {
	var response ComputeImageSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeImage
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeImageFilters = map[string]string{
	"hyper_v_generation":                           "description.Image.Properties.HyperVGeneration",
	"id":                                           "description.Image.ID",
	"kaytu_account_id":                             "metadata.SourceID",
	"name":                                         "description.Image.Name",
	"provisioning_state":                           "description.Image.Properties.ProvisioningState",
	"resource_group":                               "description.ResourceGroup",
	"source_virtual_machine_id":                    "description.Image.Properties.SourceVirtualMachine.ID",
	"storage_profile_data_disks":                   "description.Image.Properties.StorageProfile.DataDisks",
	"storage_profile_os_disk_blob_uri":             "description.Image.Properties.StorageProfile.OSDisk.BlobURI",
	"storage_profile_os_disk_caching":              "description.Image.Properties.StorageProfile.OSDisk.Caching",
	"storage_profile_os_disk_encryption_set":       "description.Image.Properties.StorageProfile.OSDisk.DiskEncryptionSet.ID",
	"storage_profile_os_disk_managed_disk_id":      "description.Image.Properties.StorageProfile.OSDisk.ManagedDisk.ID",
	"storage_profile_os_disk_size_gb":              "description.Image.Properties.StorageProfile.OSDisk.DiskSizeGB",
	"storage_profile_os_disk_snapshot_id":          "description.Image.Properties.StorageProfile.OSDisk.Snapshot.ID",
	"storage_profile_os_disk_state":                "description.Image.Properties.StorageProfile.OSDisk.OSState",
	"storage_profile_os_disk_storage_account_type": "description.Image.Properties.StorageProfile.OSDisk.StorageAccountType",
	"storage_profile_os_disk_type":                 "description.Image.Properties.StorageProfile.OSDisk.OSType",
	"storage_profile_zone_resilient":               "description.Image.Properties.StorageProfile.ZoneResilient",
	"tags":                                         "description.Image.Tags",
	"title":                                        "description.Image.Name",
	"type":                                         "description.Image.Type",
}

func ListComputeImage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeImage")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeImagePaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeImageFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeImageFilters = map[string]string{
	"hyper_v_generation":                           "description.Image.Properties.HyperVGeneration",
	"id":                                           "description.Image.ID",
	"kaytu_account_id":                             "metadata.SourceID",
	"name":                                         "Description.Image.Name",
	"provisioning_state":                           "description.Image.Properties.ProvisioningState",
	"resource_group":                               "Description.Image.ResourceGroup",
	"source_virtual_machine_id":                    "description.Image.Properties.SourceVirtualMachine.ID",
	"storage_profile_data_disks":                   "description.Image.Properties.StorageProfile.DataDisks",
	"storage_profile_os_disk_blob_uri":             "description.Image.Properties.StorageProfile.OSDisk.BlobURI",
	"storage_profile_os_disk_caching":              "description.Image.Properties.StorageProfile.OSDisk.Caching",
	"storage_profile_os_disk_encryption_set":       "description.Image.Properties.StorageProfile.OSDisk.DiskEncryptionSet.ID",
	"storage_profile_os_disk_managed_disk_id":      "description.Image.Properties.StorageProfile.OSDisk.ManagedDisk.ID",
	"storage_profile_os_disk_size_gb":              "description.Image.Properties.StorageProfile.OSDisk.DiskSizeGB",
	"storage_profile_os_disk_snapshot_id":          "description.Image.Properties.StorageProfile.OSDisk.Snapshot.ID",
	"storage_profile_os_disk_state":                "description.Image.Properties.StorageProfile.OSDisk.OSState",
	"storage_profile_os_disk_storage_account_type": "description.Image.Properties.StorageProfile.OSDisk.StorageAccountType",
	"storage_profile_os_disk_type":                 "description.Image.Properties.StorageProfile.OSDisk.OSType",
	"storage_profile_zone_resilient":               "description.Image.Properties.StorageProfile.ZoneResilient",
	"tags":                                         "description.Image.Tags",
	"title":                                        "description.Image.Name",
	"type":                                         "description.Image.Type",
}

func GetComputeImage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeImage")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeImagePaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeImageFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeImage =============================

// ==========================  START: ComputeHostGroup =============================

type ComputeHostGroup struct {
	Description   azure.ComputeHostGroupDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *ComputeHostGroup) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeHostGroupDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeHostGroupHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  ComputeHostGroup `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type ComputeHostGroupHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []ComputeHostGroupHit `json:"hits"`
}

type ComputeHostGroupSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  ComputeHostGroupHits `json:"hits"`
}

type ComputeHostGroupPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeHostGroupPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeHostGroupPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_hostgroups", filters, limit)
	if err != nil {
		return ComputeHostGroupPaginator{}, err
	}

	p := ComputeHostGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeHostGroupPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeHostGroupPaginator) NextPage(ctx context.Context) ([]ComputeHostGroup, error) {
	var response ComputeHostGroupSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeHostGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeHostGroupFilters = map[string]string{
	"id":    "description.HostGroup.ID",
	"name":  "description.HostGroup.Name",
	"tags":  "description.HostGroup.Tags",
	"title": "description.HostGroup.Name",
}

func ListComputeHostGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeHostGroup")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeHostGroupPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeHostGroupFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeHostGroupFilters = map[string]string{
	"id":    "description.HostGroup.ID",
	"name":  "description.HostGroup.Name",
	"tags":  "description.HostGroup.Tags",
	"title": "description.HostGroup.Name",
}

func GetComputeHostGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeHostGroup")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeHostGroupPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeHostGroupFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeHostGroup =============================

// ==========================  START: ComputeHostGroupHost =============================

type ComputeHostGroupHost struct {
	Description   azure.ComputeHostGroupHostDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

func (r *ComputeHostGroupHost) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeHostGroupHostDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeHostGroupHostHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  ComputeHostGroupHost `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type ComputeHostGroupHostHits struct {
	Total essdk.SearchTotal         `json:"total"`
	Hits  []ComputeHostGroupHostHit `json:"hits"`
}

type ComputeHostGroupHostSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  ComputeHostGroupHostHits `json:"hits"`
}

type ComputeHostGroupHostPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeHostGroupHostPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeHostGroupHostPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_hostgroups_hosts", filters, limit)
	if err != nil {
		return ComputeHostGroupHostPaginator{}, err
	}

	p := ComputeHostGroupHostPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeHostGroupHostPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeHostGroupHostPaginator) NextPage(ctx context.Context) ([]ComputeHostGroupHost, error) {
	var response ComputeHostGroupHostSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeHostGroupHost
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeHostGroupHostFilters = map[string]string{
	"id":    "description.Host.ID",
	"name":  "description.Host.Name",
	"tags":  "description.Host.Tags",
	"title": "description.Host.Name",
}

func ListComputeHostGroupHost(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeHostGroupHost")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeHostGroupHostPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeHostGroupHostFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeHostGroupHostFilters = map[string]string{
	"id":    "description.Host.ID",
	"name":  "description.Host.Name",
	"tags":  "description.Host.Tags",
	"title": "description.Host.Name",
}

func GetComputeHostGroupHost(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeHostGroupHost")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeHostGroupHostPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeHostGroupHostFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeHostGroupHost =============================

// ==========================  START: ComputeRestorePointCollection =============================

type ComputeRestorePointCollection struct {
	Description   azure.ComputeRestorePointCollectionDescription `json:"description"`
	Metadata      azure.Metadata                                 `json:"metadata"`
	ResourceJobID int                                            `json:"resource_job_id"`
	SourceJobID   int                                            `json:"source_job_id"`
	ResourceType  string                                         `json:"resource_type"`
	SourceType    string                                         `json:"source_type"`
	ID            string                                         `json:"id"`
	ARN           string                                         `json:"arn"`
	SourceID      string                                         `json:"source_id"`
}

func (r *ComputeRestorePointCollection) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeRestorePointCollectionDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeRestorePointCollectionHit struct {
	ID      string                        `json:"_id"`
	Score   float64                       `json:"_score"`
	Index   string                        `json:"_index"`
	Type    string                        `json:"_type"`
	Version int64                         `json:"_version,omitempty"`
	Source  ComputeRestorePointCollection `json:"_source"`
	Sort    []interface{}                 `json:"sort"`
}

type ComputeRestorePointCollectionHits struct {
	Total essdk.SearchTotal                  `json:"total"`
	Hits  []ComputeRestorePointCollectionHit `json:"hits"`
}

type ComputeRestorePointCollectionSearchResponse struct {
	PitID string                            `json:"pit_id"`
	Hits  ComputeRestorePointCollectionHits `json:"hits"`
}

type ComputeRestorePointCollectionPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeRestorePointCollectionPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeRestorePointCollectionPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_restorepointcollections", filters, limit)
	if err != nil {
		return ComputeRestorePointCollectionPaginator{}, err
	}

	p := ComputeRestorePointCollectionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeRestorePointCollectionPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeRestorePointCollectionPaginator) NextPage(ctx context.Context) ([]ComputeRestorePointCollection, error) {
	var response ComputeRestorePointCollectionSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeRestorePointCollection
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeRestorePointCollectionFilters = map[string]string{
	"id":    "description.RestorePointCollection.ID",
	"name":  "description.RestorePointCollection.Name",
	"tags":  "description.RestorePointCollection.Tags",
	"title": "description.RestorePointCollection.Name",
}

func ListComputeRestorePointCollection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeRestorePointCollection")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeRestorePointCollectionPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeRestorePointCollectionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeRestorePointCollectionFilters = map[string]string{
	"id":    "description.RestorePointCollection.ID",
	"name":  "description.RestorePointCollection.Name",
	"tags":  "description.RestorePointCollection.Tags",
	"title": "description.RestorePointCollection.Name",
}

func GetComputeRestorePointCollection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeRestorePointCollection")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeRestorePointCollectionPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeRestorePointCollectionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeRestorePointCollection =============================

// ==========================  START: ComputeSSHPublicKey =============================

type ComputeSSHPublicKey struct {
	Description   azure.ComputeSSHPublicKeyDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

func (r *ComputeSSHPublicKey) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeSSHPublicKeyDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeSSHPublicKeyHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  ComputeSSHPublicKey `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type ComputeSSHPublicKeyHits struct {
	Total essdk.SearchTotal        `json:"total"`
	Hits  []ComputeSSHPublicKeyHit `json:"hits"`
}

type ComputeSSHPublicKeySearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  ComputeSSHPublicKeyHits `json:"hits"`
}

type ComputeSSHPublicKeyPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeSSHPublicKeyPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeSSHPublicKeyPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_sshpublickeys", filters, limit)
	if err != nil {
		return ComputeSSHPublicKeyPaginator{}, err
	}

	p := ComputeSSHPublicKeyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeSSHPublicKeyPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeSSHPublicKeyPaginator) NextPage(ctx context.Context) ([]ComputeSSHPublicKey, error) {
	var response ComputeSSHPublicKeySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeSSHPublicKey
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeSSHPublicKeyFilters = map[string]string{
	"id":             "description.SSHPublicKey.ID",
	"name":           "description.SSHPublicKey.Name",
	"public_key":     "description.SSHPublicKey.Properties.PublicKey",
	"resource_group": "description.ResourceGroup",
	"tags":           "description.SSHPublicKey.Tags",
	"title":          "description.SSHPublicKey.Name",
	"type":           "description.SSHPublicKey.Type",
}

func ListComputeSSHPublicKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeSSHPublicKey")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeSSHPublicKeyPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeSSHPublicKeyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeSSHPublicKeyFilters = map[string]string{
	"id":             "description.SSHPublicKey.ID",
	"name":           "description.SSHPublicKey.Name",
	"public_key":     "description.SSHPublicKey.Properties.PublicKey",
	"resource_group": "description.ResourceGroup",
	"tags":           "description.SSHPublicKey.Tags",
	"title":          "description.SSHPublicKey.Name",
	"type":           "description.SSHPublicKey.Type",
}

func GetComputeSSHPublicKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeSSHPublicKey")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeSSHPublicKeyPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeSSHPublicKeyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeSSHPublicKey =============================

// ==========================  START: DataboxEdgeDevice =============================

type DataboxEdgeDevice struct {
	Description   azure.DataboxEdgeDeviceDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

func (r *DataboxEdgeDevice) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DataboxEdgeDeviceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DataboxEdgeDeviceHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  DataboxEdgeDevice `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type DataboxEdgeDeviceHits struct {
	Total essdk.SearchTotal      `json:"total"`
	Hits  []DataboxEdgeDeviceHit `json:"hits"`
}

type DataboxEdgeDeviceSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  DataboxEdgeDeviceHits `json:"hits"`
}

type DataboxEdgeDevicePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDataboxEdgeDevicePaginator(filters []essdk.BoolFilter, limit *int64) (DataboxEdgeDevicePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_databoxedge_databoxedgedevices", filters, limit)
	if err != nil {
		return DataboxEdgeDevicePaginator{}, err
	}

	p := DataboxEdgeDevicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DataboxEdgeDevicePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DataboxEdgeDevicePaginator) NextPage(ctx context.Context) ([]DataboxEdgeDevice, error) {
	var response DataboxEdgeDeviceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DataboxEdgeDevice
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDataboxEdgeDeviceFilters = map[string]string{
	"configured_role_types":       "description.Device.Properties.ConfiguredRoleTypes",
	"culture":                     "description.Device.Properties.Culture",
	"data_box_edge_device_status": "description.Device.Properties.DataBoxEdgeDeviceStatus",
	"description":                 "description.Device.Properties.Description",
	"device_hcs_version":          "description.Device.Properties.DeviceHcsVersion",
	"device_local_capacity":       "description.Device.Properties.DeviceLocalCapacity",
	"device_model":                "description.Device.Properties.DeviceModel",
	"device_software_version":     "description.Device.Properties.DeviceSoftwareVersion",
	"device_type":                 "description.Device.Properties.DeviceType",
	"etag":                        "description.Device.Etag",
	"friendly_name":               "description.Device.Properties.FriendlyName",
	"id":                          "description.Device.ID",
	"kaytu_account_id":            "metadata.SourceID",
	"location":                    "description.Device.Location",
	"model_description":           "description.Device.Properties.ModelDescription",
	"name":                        "description.Device.Name",
	"node_count":                  "description.Device.Properties.NodeCount",
	"resource_group":              "description.ResourceGroup",
	"serial_number":               "description.Device.Properties.SerialNumber",
	"sku_name":                    "description.Device.SKU.Name",
	"sku_tier":                    "description.Device.SKU.Tier",
	"tags":                        "description.Device.Tags",
	"time_zone":                   "description.Device.Properties.TimeZone",
	"title":                       "description.Device.Name",
	"type":                        "description.Device.Type",
}

func ListDataboxEdgeDevice(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDataboxEdgeDevice")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDataboxEdgeDevicePaginator(essdk.BuildFilter(ctx, d.QueryContext, listDataboxEdgeDeviceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDataboxEdgeDeviceFilters = map[string]string{
	"configured_role_types":       "description.Device.Properties.ConfiguredRoleTypes",
	"culture":                     "description.Device.Properties.Culture",
	"data_box_edge_device_status": "description.Device.Properties.DataBoxEdgeDeviceStatus",
	"description":                 "description.Device.Properties.Description",
	"device_hcs_version":          "description.Device.Properties.DeviceHcsVersion",
	"device_local_capacity":       "description.Device.Properties.DeviceLocalCapacity",
	"device_model":                "description.Device.Properties.DeviceModel",
	"device_software_version":     "description.Device.Properties.DeviceSoftwareVersion",
	"device_type":                 "description.Device.Properties.DeviceType",
	"etag":                        "description.Device.Etag",
	"friendly_name":               "description.Device.Properties.FriendlyName",
	"id":                          "description.Device.ID",
	"kaytu_account_id":            "metadata.SourceID",
	"location":                    "description.Device.Location",
	"model_description":           "description.Device.Properties.ModelDescription",
	"name":                        "description.Device.name",
	"node_count":                  "description.Device.Properties.NodeCount",
	"resource_group":              "description.ResourceGroup",
	"serial_number":               "description.Device.Properties.SerialNumber",
	"sku_name":                    "description.Device.SKU.Name",
	"sku_tier":                    "description.Device.SKU.Tier",
	"tags":                        "description.Device.Tags",
	"time_zone":                   "description.Device.Properties.TimeZone",
	"title":                       "description.Device.Name",
	"type":                        "description.Device.Type",
}

func GetDataboxEdgeDevice(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDataboxEdgeDevice")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDataboxEdgeDevicePaginator(essdk.BuildFilter(ctx, d.QueryContext, getDataboxEdgeDeviceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DataboxEdgeDevice =============================

// ==========================  START: HealthcareService =============================

type HealthcareService struct {
	Description   azure.HealthcareServiceDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

func (r *HealthcareService) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.HealthcareServiceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type HealthcareServiceHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  HealthcareService `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type HealthcareServiceHits struct {
	Total essdk.SearchTotal      `json:"total"`
	Hits  []HealthcareServiceHit `json:"hits"`
}

type HealthcareServiceSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  HealthcareServiceHits `json:"hits"`
}

type HealthcareServicePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewHealthcareServicePaginator(filters []essdk.BoolFilter, limit *int64) (HealthcareServicePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_healthcareapis_services", filters, limit)
	if err != nil {
		return HealthcareServicePaginator{}, err
	}

	p := HealthcareServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p HealthcareServicePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p HealthcareServicePaginator) NextPage(ctx context.Context) ([]HealthcareService, error) {
	var response HealthcareServiceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []HealthcareService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listHealthcareServiceFilters = map[string]string{
	"access_policies":              "description.ServicesDescription.Properties.AccessPolicies",
	"allow_credentials":            "description.ServicesDescription.Properties.CorsConfiguration.AllowCredentials",
	"audience":                     "description.ServicesDescription.Properties.AuthenticationConfiguration.Audience",
	"authority":                    "description.ServicesDescription.Properties.AuthenticationConfiguration.Authority",
	"cosmos_db_configuration":      "description.ServicesDescription.Properties.CosmosDbConfiguration",
	"diagnostic_settings":          "description.DiagnosticSettingsResources",
	"etag":                         "description.ServicesDescription.Etag",
	"headers":                      "description.ServicesDescription.Properties.CorsConfiguration.Origins",
	"id":                           "description.ServicesDescription.ID",
	"kaytu_account_id":             "metadata.SourceID",
	"kind":                         "description.ServicesDescription.Kind",
	"location":                     "description.ServicesDescription.Location",
	"max_age":                      "description.ServicesDescription.Properties.CorsConfiguration.MaxAge",
	"methods":                      "description.ServicesDescription.Properties.CorsConfiguration.Methods",
	"name":                         "description.ServicesDescription.Name",
	"origins":                      "description.ServicesDescription.Properties.CorsConfiguration.Origins",
	"private_endpoint_connections": "description.ServicesDescription.Properties.PrivateEndpointConnections",
	"provisioning_state":           "description.ServicesDescription.Properties.ProvisioningState",
	"resource_group":               "description.ResourceGroup",
	"smart_proxy_enabled":          "description.ServicesDescription.Properties.AuthenticationConfiguration.SmartProxyEnabled",
	"tags":                         "description.ServicesDescription.Tags",
	"title":                        "description.ServicesDescription.Name",
	"type":                         "description.ServicesDescription.Type",
}

func ListHealthcareService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListHealthcareService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewHealthcareServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, listHealthcareServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getHealthcareServiceFilters = map[string]string{
	"access_policies":              "description.ServicesDescription.Properties.AccessPolicies",
	"allow_credentials":            "description.ServicesDescription.Properties.CorsConfiguration.AllowCredentials",
	"audience":                     "description.ServicesDescription.Properties.AuthenticationConfiguration.Audience",
	"authority":                    "description.ServicesDescription.Properties.AuthenticationConfiguration.Authority",
	"cosmos_db_configuration":      "description.ServicesDescription.Properties.CosmosDbConfiguration",
	"diagnostic_settings":          "description.DiagnosticSettingsResources",
	"etag":                         "description.ServicesDescription.Etag",
	"headers":                      "description.ServicesDescription.Properties.CorsConfiguration.Origins",
	"id":                           "description.ServicesDescription.ID",
	"kaytu_account_id":             "metadata.SourceID",
	"kind":                         "description.ServicesDescription.Kind",
	"location":                     "description.ServicesDescription.Location",
	"max_age":                      "description.ServicesDescription.Properties.CorsConfiguration.MaxAge",
	"methods":                      "description.ServicesDescription.Properties.CorsConfiguration.Methods",
	"name":                         "description.ServicesDescription.name",
	"origins":                      "description.ServicesDescription.Properties.CorsConfiguration.Origins",
	"private_endpoint_connections": "description.ServicesDescription.Properties.PrivateEndpointConnections",
	"provisioning_state":           "description.ServicesDescription.Properties.ProvisioningState",
	"resource_group":               "description.ResourceGroup",
	"smart_proxy_enabled":          "description.ServicesDescription.Properties.AuthenticationConfiguration.SmartProxyEnabled",
	"tags":                         "description.ServicesDescription.Tags",
	"title":                        "description.ServicesDescription.Name",
	"type":                         "description.ServicesDescription.Type",
}

func GetHealthcareService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetHealthcareService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewHealthcareServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, getHealthcareServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: HealthcareService =============================

// ==========================  START: HpcCache =============================

type HpcCache struct {
	Description   azure.HpcCacheDescription `json:"description"`
	Metadata      azure.Metadata            `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

func (r *HpcCache) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.HpcCacheDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type HpcCacheHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  HpcCache      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type HpcCacheHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []HpcCacheHit     `json:"hits"`
}

type HpcCacheSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  HpcCacheHits `json:"hits"`
}

type HpcCachePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewHpcCachePaginator(filters []essdk.BoolFilter, limit *int64) (HpcCachePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_storagecache_caches", filters, limit)
	if err != nil {
		return HpcCachePaginator{}, err
	}

	p := HpcCachePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p HpcCachePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p HpcCachePaginator) NextPage(ctx context.Context) ([]HpcCache, error) {
	var response HpcCacheSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []HpcCache
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listHpcCacheFilters = map[string]string{
	"cache_size_gb":               "description.Cache.Properties.CacheSizeGB",
	"directory_services_settings": "description.Cache.Properties.DirectoryServicesSettings",
	"encryption_settings":         "description.Cache.Properties.EncryptionSettings",
	"health":                      "description.Cache.Properties.Health",
	"id":                          "description.Cache.ID",
	"identity":                    "description.Cache.Identity",
	"kaytu_account_id":            "metadata.SourceID",
	"mount_addresses":             "description.Cache.Properties.MountAddresses",
	"name":                        "description.Cache.Name",
	"provisioning_state":          "description.Cache.Properties.ProvisioningState",
	"resource_group":              "description.ResourceGroup",
	"security_settings":           "description.Cache.Properties.SecuritySettings",
	"sku_name":                    "description.Cache.SKU.Name",
	"subnet":                      "description.Cache.Properties.Subnet",
	"system_data":                 "description.Cache.SystemData",
	"tags":                        "description.Cache.Tags",
	"title":                       "description.Cache.Name",
	"type":                        "description.Cache.Type",
}

func ListHpcCache(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListHpcCache")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewHpcCachePaginator(essdk.BuildFilter(ctx, d.QueryContext, listHpcCacheFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getHpcCacheFilters = map[string]string{
	"cache_size_gb":               "description.Cache.Properties.CacheSizeGB",
	"directory_services_settings": "description.Cache.Properties.DirectoryServicesSettings",
	"encryption_settings":         "description.Cache.Properties.EncryptionSettings",
	"health":                      "description.Cache.Properties.Health",
	"id":                          "description.Cache.ID",
	"identity":                    "description.Cache.Identity",
	"kaytu_account_id":            "metadata.SourceID",
	"mount_addresses":             "description.Cache.Properties.MountAddresses",
	"name":                        "description.Cache.name",
	"provisioning_state":          "description.Cache.Properties.ProvisioningState",
	"resource_group":              "description.ResourceGroup",
	"security_settings":           "description.Cache.Properties.SecuritySettings",
	"sku_name":                    "description.Cache.SKU.Name",
	"subnet":                      "description.Cache.Properties.Subnet",
	"system_data":                 "description.Cache.SystemData",
	"tags":                        "description.Cache.Tags",
	"title":                       "description.Cache.Name",
	"type":                        "description.Cache.Type",
}

func GetHpcCache(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetHpcCache")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewHpcCachePaginator(essdk.BuildFilter(ctx, d.QueryContext, getHpcCacheFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: HpcCache =============================

// ==========================  START: KeyVaultKey =============================

type KeyVaultKey struct {
	Description   azure.KeyVaultKeyDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

func (r *KeyVaultKey) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.KeyVaultKeyDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type KeyVaultKeyHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  KeyVaultKey   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type KeyVaultKeyHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []KeyVaultKeyHit  `json:"hits"`
}

type KeyVaultKeySearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  KeyVaultKeyHits `json:"hits"`
}

type KeyVaultKeyPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewKeyVaultKeyPaginator(filters []essdk.BoolFilter, limit *int64) (KeyVaultKeyPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_keyvault_vaults_keys", filters, limit)
	if err != nil {
		return KeyVaultKeyPaginator{}, err
	}

	p := KeyVaultKeyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KeyVaultKeyPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p KeyVaultKeyPaginator) NextPage(ctx context.Context) ([]KeyVaultKey, error) {
	var response KeyVaultKeySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KeyVaultKey
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listKeyVaultKeyFilters = map[string]string{
	"curve_name":           "description.Key.Properties.CurveName",
	"enabled":              "description.Key.Properties.Attributes.Enabled",
	"id":                   "description.Key.ID",
	"kaytu_account_id":     "metadata.SourceID",
	"key_ops":              "description.Key.Properties.KeyOps",
	"key_size":             "description.Key.Properties.KeySize",
	"key_type":             "description.Key.Properties.Kty",
	"key_uri":              "description.Key.Properties.KeyURI",
	"key_uri_with_version": "description.Key.Properties.KeyURIWithVersion",
	"location":             "description.Key.Location",
	"name":                 "description.Key.Name",
	"recovery_level":       "description.Key.Properties.Attributes.RecoveryLevel",
	"resource_group":       "description.ResourceGroup",
	"tags":                 "description.Key.Tags",
	"title":                "description.Key.Name",
	"type":                 "description.Key.Type",
}

func ListKeyVaultKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKeyVaultKey")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewKeyVaultKeyPaginator(essdk.BuildFilter(ctx, d.QueryContext, listKeyVaultKeyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKeyVaultKeyFilters = map[string]string{
	"curve_name":           "description.Key.Properties.CurveName",
	"enabled":              "description.Key.Properties.Attributes.Enabled",
	"id":                   "description.Key.ID",
	"kaytu_account_id":     "metadata.SourceID",
	"key_ops":              "description.Key.Properties.KeyOps",
	"key_size":             "description.Key.Properties.KeySize",
	"key_type":             "description.Key.Properties.Kty",
	"key_uri":              "description.Key.Properties.KeyURI",
	"key_uri_with_version": "description.Key.Properties.KeyURIWithVersion",
	"location":             "description.Key.Location",
	"name":                 "description.Key.name",
	"recovery_level":       "description.Key.Properties.Attributes.RecoveryLevel",
	"resource_group":       "description.ResourceGroup",
	"tags":                 "description.Key.Tags",
	"title":                "description.Key.Name",
	"type":                 "description.Key.Type",
	"vault_name":           "description.Vault.name",
}

func GetKeyVaultKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKeyVaultKey")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewKeyVaultKeyPaginator(essdk.BuildFilter(ctx, d.QueryContext, getKeyVaultKeyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KeyVaultKey =============================

// ==========================  START: KeyVaultKeyVersion =============================

type KeyVaultKeyVersion struct {
	Description   azure.KeyVaultKeyVersionDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

func (r *KeyVaultKeyVersion) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.KeyVaultKeyVersionDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type KeyVaultKeyVersionHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  KeyVaultKeyVersion `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type KeyVaultKeyVersionHits struct {
	Total essdk.SearchTotal       `json:"total"`
	Hits  []KeyVaultKeyVersionHit `json:"hits"`
}

type KeyVaultKeyVersionSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  KeyVaultKeyVersionHits `json:"hits"`
}

type KeyVaultKeyVersionPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewKeyVaultKeyVersionPaginator(filters []essdk.BoolFilter, limit *int64) (KeyVaultKeyVersionPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_keyvault_vaults_keys_versions", filters, limit)
	if err != nil {
		return KeyVaultKeyVersionPaginator{}, err
	}

	p := KeyVaultKeyVersionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KeyVaultKeyVersionPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p KeyVaultKeyVersionPaginator) NextPage(ctx context.Context) ([]KeyVaultKeyVersion, error) {
	var response KeyVaultKeyVersionSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KeyVaultKeyVersion
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listKeyVaultKeyVersionFilters = map[string]string{
	"curve_name":           "description.Version.Properties.CurveName",
	"enabled":              "description.Version.Properties.Attributes.Enabled",
	"id":                   "description.Version.ID",
	"kaytu_account_id":     "metadata.SourceID",
	"key_id":               "description.Key.ID",
	"key_name":             "description.Key.Name",
	"key_ops":              "description.Version.Properties.JSONWebKeyOperation",
	"key_size":             "description.Version.Properties.KeySize",
	"key_type":             "description.Version.Properties.Kty",
	"key_uri":              "description.Version.Properties.KeyURI",
	"key_uri_with_version": "description.Version.Properties.KeyURIWithVersion",
	"location":             "description.Version.Location",
	"name":                 "description.Version.Name",
	"recovery_level":       "description.Version.Properties.Attributes.RecoveryLevel",
	"resource_group":       "description.ResourceGroup",
	"tags":                 "description.Version.Tags",
	"title":                "description.Version.Name",
	"type":                 "description.Version.Type",
	"vault_name":           "description.Vault.Name",
}

func ListKeyVaultKeyVersion(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKeyVaultKeyVersion")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewKeyVaultKeyVersionPaginator(essdk.BuildFilter(ctx, d.QueryContext, listKeyVaultKeyVersionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKeyVaultKeyVersionFilters = map[string]string{
	"curve_name":           "description.Version.Properties.CurveName",
	"enabled":              "description.Version.Properties.Attributes.Enabled",
	"id":                   "description.Version.ID",
	"kaytu_account_id":     "metadata.SourceID",
	"key_id":               "description.Key.ID",
	"key_name":             "description.Key.Name",
	"key_ops":              "description.Version.Properties.JSONWebKeyOperation",
	"key_size":             "description.Version.Properties.KeySize",
	"key_type":             "description.Version.Properties.Kty",
	"key_uri":              "description.Version.Properties.KeyURI",
	"key_uri_with_version": "description.Version.Properties.KeyURIWithVersion",
	"location":             "description.Version.Location",
	"name":                 "description.Version.name",
	"recovery_level":       "description.Version.Properties.Attributes.RecoveryLevel",
	"resource_group":       "description.ResourceGroup",
	"tags":                 "description.Version.Tags",
	"title":                "description.Version.Name",
	"type":                 "description.Version.Type",
	"vault_name":           "description.Vault.name",
}

func GetKeyVaultKeyVersion(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKeyVaultKeyVersion")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewKeyVaultKeyVersionPaginator(essdk.BuildFilter(ctx, d.QueryContext, getKeyVaultKeyVersionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KeyVaultKeyVersion =============================

// ==========================  START: KubernetesCluster =============================

type KubernetesCluster struct {
	Description   azure.KubernetesClusterDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

func (r *KubernetesCluster) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.KubernetesClusterDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type KubernetesClusterHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  KubernetesCluster `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type KubernetesClusterHits struct {
	Total essdk.SearchTotal      `json:"total"`
	Hits  []KubernetesClusterHit `json:"hits"`
}

type KubernetesClusterSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  KubernetesClusterHits `json:"hits"`
}

type KubernetesClusterPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewKubernetesClusterPaginator(filters []essdk.BoolFilter, limit *int64) (KubernetesClusterPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_containerservice_managedclusters", filters, limit)
	if err != nil {
		return KubernetesClusterPaginator{}, err
	}

	p := KubernetesClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KubernetesClusterPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p KubernetesClusterPaginator) NextPage(ctx context.Context) ([]KubernetesCluster, error) {
	var response KubernetesClusterSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KubernetesCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listKubernetesClusterFilters = map[string]string{
	"aad_profile":                "description.ManagedCluster.Properties.AADProfile",
	"addon_profiles":             "description.ManagedCluster.Properties.AddonProfiles",
	"agent_pool_profiles":        "description.ManagedCluster.Properties.AgentPoolProfiles",
	"api_server_access_profile":  "description.ManagedCluster.Properties.APIServerAccessProfile",
	"auto_scaler_profile":        "description.ManagedCluster.Properties.AutoScalerProfile",
	"auto_upgrade_profile":       "description.ManagedCluster.Properties.AutoUpgradeProfile",
	"azure_portal_fqdn":          "description.ManagedCluster.Properties.AzurePortalFQDN",
	"disk_encryption_set_id":     "description.ManagedCluster.Properties.DiskEncryptionSetID",
	"dns_prefix":                 "description.ManagedCluster.Properties.DNSPrefix",
	"enable_pod_security_policy": "description.ManagedCluster.Properties.EnablePodSecurityPolicy",
	"enable_rbac":                "description.ManagedCluster.Properties.EnableRBAC",
	"fqdn":                       "description.ManagedCluster.Properties.Fqdn",
	"fqdn_subdomain":             "description.ManagedCluster.Properties.FqdnSubdomain",
	"id":                         "description.ManagedCluster.ID",
	"identity":                   "description.ManagedCluster.Identity",
	"identity_profile":           "description.ManagedCluster.Properties.IdentityProfile",
	"kaytu_account_id":           "metadata.SourceID",
	"kubernetes_version":         "description.ManagedCluster.Properties.KubernetesVersion",
	"linux_profile":              "description.ManagedCluster.Properties.LinuxProfile",
	"location":                   "description.ManagedCluster.Location",
	"max_agent_pools":            "description.ManagedCluster.Properties.MaxAgentPools",
	"name":                       "description.ManagedCluster.Name",
	"network_profile":            "description.ManagedCluster.Properties.NetworkProfile",
	"node_resource_group":        "description.ManagedCluster.Properties.NodeResourceGroup",
	"pod_identity_profile":       "description.ManagedCluster.Properties.PodIdentityProfile",
	"power_state":                "description.ManagedCluster.Properties.PowerState",
	"private_fqdn":               "description.ManagedCluster.Properties.PrivateFQDN",
	"provisioning_state":         "description.ManagedCluster.Properties.ProvisioningState",
	"resource_group":             "description.ResourceGroup",
	"service_principal_profile":  "description.ManagedCluster.Properties.ServicePrincipalProfile",
	"sku":                        "description.ManagedCluster.SKU",
	"tags":                       "description.ManagedCluster.Tags",
	"title":                      "description.ManagedCluster.Name",
	"type":                       "description.ManagedCluster.Type",
	"windows_profile":            "description.ManagedCluster.Properties.WindowsProfile",
}

func ListKubernetesCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKubernetesCluster")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewKubernetesClusterPaginator(essdk.BuildFilter(ctx, d.QueryContext, listKubernetesClusterFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKubernetesClusterFilters = map[string]string{
	"aad_profile":                "description.ManagedCluster.Properties.AADProfile",
	"addon_profiles":             "description.ManagedCluster.Properties.AddonProfiles",
	"agent_pool_profiles":        "description.ManagedCluster.Properties.AgentPoolProfiles",
	"api_server_access_profile":  "description.ManagedCluster.Properties.APIServerAccessProfile",
	"auto_scaler_profile":        "description.ManagedCluster.Properties.AutoScalerProfile",
	"auto_upgrade_profile":       "description.ManagedCluster.Properties.AutoUpgradeProfile",
	"azure_portal_fqdn":          "description.ManagedCluster.Properties.AzurePortalFQDN",
	"disk_encryption_set_id":     "description.ManagedCluster.Properties.DiskEncryptionSetID",
	"dns_prefix":                 "description.ManagedCluster.Properties.DNSPrefix",
	"enable_pod_security_policy": "description.ManagedCluster.Properties.EnablePodSecurityPolicy",
	"enable_rbac":                "description.ManagedCluster.Properties.EnableRBAC",
	"fqdn":                       "description.ManagedCluster.Properties.Fqdn",
	"fqdn_subdomain":             "description.ManagedCluster.Properties.FqdnSubdomain",
	"id":                         "description.ManagedCluster.ID",
	"identity":                   "description.ManagedCluster.Identity",
	"identity_profile":           "description.ManagedCluster.Properties.IdentityProfile",
	"kaytu_account_id":           "metadata.SourceID",
	"kubernetes_version":         "description.ManagedCluster.Properties.KubernetesVersion",
	"linux_profile":              "description.ManagedCluster.Properties.LinuxProfile",
	"location":                   "description.ManagedCluster.Location",
	"max_agent_pools":            "description.ManagedCluster.Properties.MaxAgentPools",
	"name":                       "description.ManagedCluster.name",
	"network_profile":            "description.ManagedCluster.Properties.NetworkProfile",
	"node_resource_group":        "description.ManagedCluster.Properties.NodeResourceGroup",
	"pod_identity_profile":       "description.ManagedCluster.Properties.PodIdentityProfile",
	"power_state":                "description.ManagedCluster.Properties.PowerState",
	"private_fqdn":               "description.ManagedCluster.Properties.PrivateFQDN",
	"provisioning_state":         "description.ManagedCluster.Properties.ProvisioningState",
	"resource_group":             "description.ResourceGroup",
	"service_principal_profile":  "description.ManagedCluster.Properties.ServicePrincipalProfile",
	"sku":                        "description.ManagedCluster.SKU",
	"tags":                       "description.ManagedCluster.Tags",
	"title":                      "description.ManagedCluster.Name",
	"type":                       "description.ManagedCluster.Type",
	"windows_profile":            "description.ManagedCluster.Properties.WindowsProfile",
}

func GetKubernetesCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKubernetesCluster")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewKubernetesClusterPaginator(essdk.BuildFilter(ctx, d.QueryContext, getKubernetesClusterFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KubernetesCluster =============================

// ==========================  START: KubernetesServiceVersion =============================

type KubernetesServiceVersion struct {
	Description   azure.KubernetesServiceVersionDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

func (r *KubernetesServiceVersion) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.KubernetesServiceVersionDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type KubernetesServiceVersionHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  KubernetesServiceVersion `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type KubernetesServiceVersionHits struct {
	Total essdk.SearchTotal             `json:"total"`
	Hits  []KubernetesServiceVersionHit `json:"hits"`
}

type KubernetesServiceVersionSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  KubernetesServiceVersionHits `json:"hits"`
}

type KubernetesServiceVersionPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewKubernetesServiceVersionPaginator(filters []essdk.BoolFilter, limit *int64) (KubernetesServiceVersionPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_hybridcontainerservice_customlocations_orchestrators", filters, limit)
	if err != nil {
		return KubernetesServiceVersionPaginator{}, err
	}

	p := KubernetesServiceVersionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KubernetesServiceVersionPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p KubernetesServiceVersionPaginator) NextPage(ctx context.Context) ([]KubernetesServiceVersion, error) {
	var response KubernetesServiceVersionSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KubernetesServiceVersion
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listKubernetesServiceVersionFilters = map[string]string{
	"default":              "description.Orchestrator.Default",
	"id":                   "ID",
	"is_preview":           "description.Orchestrator.IsPreview",
	"kaytu_account_id":     "metadata.SourceID",
	"name":                 "Name",
	"orchestrator_type":    "description.Orchestrator.OrchestratorType",
	"orchestrator_version": "description.Orchestrator.OrchestratorVersion",
	"title":                "Name",
	"type":                 "Type",
	"upgrades":             "description.Orchestrator.Upgrades",
}

func ListKubernetesServiceVersion(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKubernetesServiceVersion")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewKubernetesServiceVersionPaginator(essdk.BuildFilter(ctx, d.QueryContext, listKubernetesServiceVersionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKubernetesServiceVersionFilters = map[string]string{
	"default":              "description.Orchestrator.Default",
	"id":                   "ID",
	"is_preview":           "description.Orchestrator.IsPreview",
	"kaytu_account_id":     "metadata.SourceID",
	"name":                 "description.Orchestrator.name",
	"orchestrator_type":    "description.Orchestrator.OrchestratorType",
	"orchestrator_version": "description.Orchestrator.OrchestratorVersion",
	"resource_group":       "description.ResourceGroup",
	"title":                "Name",
	"type":                 "Type",
	"upgrades":             "description.Orchestrator.Upgrades",
}

func GetKubernetesServiceVersion(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKubernetesServiceVersion")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewKubernetesServiceVersionPaginator(essdk.BuildFilter(ctx, d.QueryContext, getKubernetesServiceVersionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KubernetesServiceVersion =============================

// ==========================  START: ContainerInstanceContainerGroup =============================

type ContainerInstanceContainerGroup struct {
	Description   azure.ContainerInstanceContainerGroupDescription `json:"description"`
	Metadata      azure.Metadata                                   `json:"metadata"`
	ResourceJobID int                                              `json:"resource_job_id"`
	SourceJobID   int                                              `json:"source_job_id"`
	ResourceType  string                                           `json:"resource_type"`
	SourceType    string                                           `json:"source_type"`
	ID            string                                           `json:"id"`
	ARN           string                                           `json:"arn"`
	SourceID      string                                           `json:"source_id"`
}

func (r *ContainerInstanceContainerGroup) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ContainerInstanceContainerGroupDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ContainerInstanceContainerGroupHit struct {
	ID      string                          `json:"_id"`
	Score   float64                         `json:"_score"`
	Index   string                          `json:"_index"`
	Type    string                          `json:"_type"`
	Version int64                           `json:"_version,omitempty"`
	Source  ContainerInstanceContainerGroup `json:"_source"`
	Sort    []interface{}                   `json:"sort"`
}

type ContainerInstanceContainerGroupHits struct {
	Total essdk.SearchTotal                    `json:"total"`
	Hits  []ContainerInstanceContainerGroupHit `json:"hits"`
}

type ContainerInstanceContainerGroupSearchResponse struct {
	PitID string                              `json:"pit_id"`
	Hits  ContainerInstanceContainerGroupHits `json:"hits"`
}

type ContainerInstanceContainerGroupPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewContainerInstanceContainerGroupPaginator(filters []essdk.BoolFilter, limit *int64) (ContainerInstanceContainerGroupPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_containerinstance_containergroups", filters, limit)
	if err != nil {
		return ContainerInstanceContainerGroupPaginator{}, err
	}

	p := ContainerInstanceContainerGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ContainerInstanceContainerGroupPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ContainerInstanceContainerGroupPaginator) NextPage(ctx context.Context) ([]ContainerInstanceContainerGroup, error) {
	var response ContainerInstanceContainerGroupSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ContainerInstanceContainerGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listContainerInstanceContainerGroupFilters = map[string]string{
	"containers":                 "description.ContainerGroup.Properties.Containers",
	"diagnostics":                "description.ContainerGroup.Properties.Diagnostics",
	"dns_config":                 "description.ContainerGroup.Properties.DNSConfig",
	"encryption_properties":      "description.ContainerGroup.Properties.EncryptionProperties",
	"id":                         "description.ContainerGroup.ID",
	"identity":                   "description.ContainerGroup.Identity",
	"image_registry_credentials": "description.ContainerGroup.Properties.ImageRegistryCredentials",
	"init_containers":            "description.ContainerGroup.Properties.InitContainers",
	"instance_view":              "description.ContainerGroup.Properties.InstanceView",
	"ip_address":                 "description.ContainerGroup.Properties.IPAddress",
	"kaytu_account_id":           "metadata.SourceID",
	"name":                       "description.ContainerGroup.Name",
	"os_type":                    "description.ContainerGroup.Properties.OSType",
	"provisioning_state":         "description.ContainerGroup.Properties.ProvisioningState",
	"resource_group":             "description.ResourceGroup",
	"restart_policy":             "description.ContainerGroup.Properties.RestartPolicy",
	"sku":                        "description.ContainerGroup.Properties.SKU",
	"subnet_ids":                 "description.ContainerGroup.Properties.SubnetIDs",
	"tags":                       "description.ContainerGroup.Tags",
	"title":                      "description.ContainerGroup.Name",
	"type":                       "description.ContainerGroup.Type",
	"volumes":                    "description.ContainerGroup.Properties.Volumes",
}

func ListContainerInstanceContainerGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListContainerInstanceContainerGroup")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewContainerInstanceContainerGroupPaginator(essdk.BuildFilter(ctx, d.QueryContext, listContainerInstanceContainerGroupFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getContainerInstanceContainerGroupFilters = map[string]string{
	"containers":                 "description.ContainerGroup.Properties.Containers",
	"diagnostics":                "description.ContainerGroup.Properties.Diagnostics",
	"dns_config":                 "description.ContainerGroup.Properties.DNSConfig",
	"encryption_properties":      "description.ContainerGroup.Properties.EncryptionProperties",
	"id":                         "description.ContainerGroup.ID",
	"identity":                   "description.ContainerGroup.Identity",
	"image_registry_credentials": "description.ContainerGroup.Properties.ImageRegistryCredentials",
	"init_containers":            "description.ContainerGroup.Properties.InitContainers",
	"instance_view":              "description.ContainerGroup.Properties.InstanceView",
	"ip_address":                 "description.ContainerGroup.Properties.IPAddress",
	"kaytu_account_id":           "metadata.SourceID",
	"name":                       "description.ContainerGroup.Name",
	"os_type":                    "description.ContainerGroup.Properties.OSType",
	"provisioning_state":         "description.ContainerGroup.Properties.ProvisioningState",
	"resource_group":             "description.ResourceGroup",
	"restart_policy":             "description.ContainerGroup.Properties.RestartPolicy",
	"sku":                        "description.ContainerGroup.Properties.SKU",
	"subnet_ids":                 "description.ContainerGroup.Properties.SubnetIDs",
	"tags":                       "description.ContainerGroup.Tags",
	"title":                      "description.ContainerGroup.Name",
	"type":                       "description.ContainerGroup.Type",
	"volumes":                    "description.ContainerGroup.Properties.Volumes",
}

func GetContainerInstanceContainerGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetContainerInstanceContainerGroup")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewContainerInstanceContainerGroupPaginator(essdk.BuildFilter(ctx, d.QueryContext, getContainerInstanceContainerGroupFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ContainerInstanceContainerGroup =============================

// ==========================  START: CDNProfile =============================

type CDNProfile struct {
	Description   azure.CDNProfileDescription `json:"description"`
	Metadata      azure.Metadata              `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

func (r *CDNProfile) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.CDNProfileDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type CDNProfileHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  CDNProfile    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type CDNProfileHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []CDNProfileHit   `json:"hits"`
}

type CDNProfileSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  CDNProfileHits `json:"hits"`
}

type CDNProfilePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewCDNProfilePaginator(filters []essdk.BoolFilter, limit *int64) (CDNProfilePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_cdn_profiles", filters, limit)
	if err != nil {
		return CDNProfilePaginator{}, err
	}

	p := CDNProfilePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CDNProfilePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p CDNProfilePaginator) NextPage(ctx context.Context) ([]CDNProfile, error) {
	var response CDNProfileSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CDNProfile
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listCDNProfileFilters = map[string]string{
	"id":               "description.Profiles.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Profile.Name",
	"tags":             "description.Profile.Tags",
	"title":            "description.Profile.Name",
}

func ListCDNProfile(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCDNProfile")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewCDNProfilePaginator(essdk.BuildFilter(ctx, d.QueryContext, listCDNProfileFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCDNProfileFilters = map[string]string{
	"id":               "description.Profiles.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Profile.Name",
	"tags":             "description.Profile.Tags",
	"title":            "description.Profile.Name",
}

func GetCDNProfile(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCDNProfile")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewCDNProfilePaginator(essdk.BuildFilter(ctx, d.QueryContext, getCDNProfileFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CDNProfile =============================

// ==========================  START: CDNEndpoint =============================

type CDNEndpoint struct {
	Description   azure.CDNEndpointDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

func (r *CDNEndpoint) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.CDNEndpointDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type CDNEndpointHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  CDNEndpoint   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type CDNEndpointHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []CDNEndpointHit  `json:"hits"`
}

type CDNEndpointSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  CDNEndpointHits `json:"hits"`
}

type CDNEndpointPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewCDNEndpointPaginator(filters []essdk.BoolFilter, limit *int64) (CDNEndpointPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_cdn_profiles_endpoints", filters, limit)
	if err != nil {
		return CDNEndpointPaginator{}, err
	}

	p := CDNEndpointPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CDNEndpointPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p CDNEndpointPaginator) NextPage(ctx context.Context) ([]CDNEndpoint, error) {
	var response CDNEndpointSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CDNEndpoint
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listCDNEndpointFilters = map[string]string{
	"id":    "description.Endpoint.ID",
	"name":  "description.Endpoint.Name",
	"tags":  "description.Endpoint.Tags",
	"title": "description.Endpoint.Name",
}

func ListCDNEndpoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCDNEndpoint")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewCDNEndpointPaginator(essdk.BuildFilter(ctx, d.QueryContext, listCDNEndpointFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCDNEndpointFilters = map[string]string{
	"id":    "description.Endpoint.ID",
	"name":  "description.Endpoint.Name",
	"tags":  "description.Endpoint.Tags",
	"title": "description.Endpoint.Name",
}

func GetCDNEndpoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCDNEndpoint")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewCDNEndpointPaginator(essdk.BuildFilter(ctx, d.QueryContext, getCDNEndpointFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CDNEndpoint =============================

// ==========================  START: NetworkInterface =============================

type NetworkInterface struct {
	Description   azure.NetworkInterfaceDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *NetworkInterface) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.NetworkInterfaceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type NetworkInterfaceHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  NetworkInterface `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type NetworkInterfaceHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []NetworkInterfaceHit `json:"hits"`
}

type NetworkInterfaceSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  NetworkInterfaceHits `json:"hits"`
}

type NetworkInterfacePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewNetworkInterfacePaginator(filters []essdk.BoolFilter, limit *int64) (NetworkInterfacePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_networkinterfaces", filters, limit)
	if err != nil {
		return NetworkInterfacePaginator{}, err
	}

	p := NetworkInterfacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkInterfacePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p NetworkInterfacePaginator) NextPage(ctx context.Context) ([]NetworkInterface, error) {
	var response NetworkInterfaceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkInterface
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkInterfaceFilters = map[string]string{
	"applied_dns_servers":           "description.Interface.Properties.DNSSettings.AppliedDNSServers",
	"dns_servers":                   "description.Interface.Properties.DNSSettings.DNSServers",
	"enable_accelerated_networking": "description.Interface.Properties.EnableAcceleratedNetworking",
	"enable_ip_forwarding":          "description.Interface.Properties.EnableIPForwarding",
	"etag":                          "description.Interface.Etag",
	"hosted_workloads":              "description.Interface.Properties.HostedWorkloads",
	"id":                            "description.Interface.ID",
	"internal_dns_name_label":       "description.Interface.Properties.DNSSettings.InternalDNSNameLabel",
	"internal_domain_name_suffix":   "description.Interface.Properties.DNSSettings.InternalDomainNameSuffix",
	"internal_fqdn":                 "description.Interface.Properties.DNSSettings.InternalFqdn",
	"ip_configurations":             "description.Interface.Properties.IPConfigurations",
	"is_primary":                    "description.Interface.Properties.Primary",
	"kaytu_account_id":              "metadata.SourceID",
	"mac_address":                   "description.Interface.Properties.MacAddress",
	"name":                          "description.Interface.Name",
	"network_security_group_id":     "description.Interface.Properties.NetworkSecurityGroup.ID",
	"provisioning_state":            "description.Interface.Properties.ProvisioningState",
	"resource_group":                "description.ResourceGroup",
	"resource_guid":                 "description.Interface.Properties.ResourceGUID",
	"tags":                          "description.Interface.Tags",
	"tap_configurations":            "description.Interface.Properties.TapConfigurations",
	"title":                         "description.Interface.Name",
	"type":                          "description.Interface.Type",
	"virtual_machine_id":            "description.Interface.Properties.VirtualMachine.ID",
}

func ListNetworkInterface(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkInterface")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewNetworkInterfacePaginator(essdk.BuildFilter(ctx, d.QueryContext, listNetworkInterfaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkInterfaceFilters = map[string]string{
	"applied_dns_servers":           "description.Interface.Properties.DNSSettings.AppliedDNSServers",
	"dns_servers":                   "description.Interface.Properties.DNSSettings.DNSServers",
	"enable_accelerated_networking": "description.Interface.Properties.EnableAcceleratedNetworking",
	"enable_ip_forwarding":          "description.Interface.Properties.EnableIPForwarding",
	"etag":                          "description.Interface.Etag",
	"hosted_workloads":              "description.Interface.Properties.HostedWorkloads",
	"id":                            "description.Interface.ID",
	"internal_dns_name_label":       "description.Interface.Properties.DNSSettings.InternalDNSNameLabel",
	"internal_domain_name_suffix":   "description.Interface.Properties.DNSSettings.InternalDomainNameSuffix",
	"internal_fqdn":                 "description.Interface.Properties.DNSSettings.InternalFqdn",
	"ip_configurations":             "description.Interface.Properties.IPConfigurations",
	"is_primary":                    "description.Interface.Properties.Primary",
	"kaytu_account_id":              "metadata.SourceID",
	"mac_address":                   "description.Interface.Properties.MacAddress",
	"name":                          "description.Interface.name",
	"network_security_group_id":     "description.Interface.Properties.NetworkSecurityGroup.ID",
	"provisioning_state":            "description.Interface.Properties.ProvisioningState",
	"resource_group":                "description.ResourceGroup",
	"resource_guid":                 "description.Interface.Properties.ResourceGUID",
	"tags":                          "description.Interface.Tags",
	"tap_configurations":            "description.Interface.Properties.TapConfigurations",
	"title":                         "description.Interface.Name",
	"type":                          "description.Interface.Type",
	"virtual_machine_id":            "description.Interface.Properties.VirtualMachine.ID",
}

func GetNetworkInterface(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkInterface")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewNetworkInterfacePaginator(essdk.BuildFilter(ctx, d.QueryContext, getNetworkInterfaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkInterface =============================

// ==========================  START: NetworkWatcherFlowLog =============================

type NetworkWatcherFlowLog struct {
	Description   azure.NetworkWatcherFlowLogDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

func (r *NetworkWatcherFlowLog) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.NetworkWatcherFlowLogDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type NetworkWatcherFlowLogHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  NetworkWatcherFlowLog `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type NetworkWatcherFlowLogHits struct {
	Total essdk.SearchTotal          `json:"total"`
	Hits  []NetworkWatcherFlowLogHit `json:"hits"`
}

type NetworkWatcherFlowLogSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  NetworkWatcherFlowLogHits `json:"hits"`
}

type NetworkWatcherFlowLogPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewNetworkWatcherFlowLogPaginator(filters []essdk.BoolFilter, limit *int64) (NetworkWatcherFlowLogPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_networkwatchers_flowlogs", filters, limit)
	if err != nil {
		return NetworkWatcherFlowLogPaginator{}, err
	}

	p := NetworkWatcherFlowLogPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkWatcherFlowLogPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p NetworkWatcherFlowLogPaginator) NextPage(ctx context.Context) ([]NetworkWatcherFlowLog, error) {
	var response NetworkWatcherFlowLogSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkWatcherFlowLog
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkWatcherFlowLogFilters = map[string]string{
	"enabled":                  "description.FlowLog.Properties.Enabled",
	"etag":                     "description.FlowLog.Etag",
	"file_type":                "description.FlowLog.Properties.Format.Type",
	"id":                       "description.FlowLog.ID",
	"kaytu_account_id":         "metadata.SourceID",
	"name":                     "description.FlowLog.Name",
	"network_watcher_name":     "description.NetworkWatcherName",
	"provisioning_state":       "description.FlowLog.Properties.ProvisioningState",
	"resource_group":           "description.ResourceGroup",
	"retention_policy_days":    "description.FlowLog.Properties.RetentionPolicy.Days",
	"retention_policy_enabled": "description.FlowLog.Properties.RetentionPolicy.Enabled",
	"storage_id":               "description.FlowLog.Properties.StorageID",
	"tags":                     "description.FlowLog.Tags",
	"target_resource_guid":     "description.FlowLog.Properties.TargetResourceGUID",
	"target_resource_id":       "description.FlowLog.Properties.TargetResourceID",
	"title":                    "description.FlowLog.Name",
	"traffic_analytics":        "description.FlowLog.Properties.FlowAnalyticsConfiguration.NetworkWatcherFlowAnalyticsConfiguration",
	"type":                     "description.FlowLog.Type",
	"version":                  "description.FlowLog.Properties.Format.Version",
}

func ListNetworkWatcherFlowLog(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkWatcherFlowLog")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewNetworkWatcherFlowLogPaginator(essdk.BuildFilter(ctx, d.QueryContext, listNetworkWatcherFlowLogFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkWatcherFlowLogFilters = map[string]string{
	"enabled":                  "description.FlowLog.Properties.Enabled",
	"etag":                     "description.FlowLog.Etag",
	"file_type":                "description.FlowLog.Properties.Format.Type",
	"id":                       "description.FlowLog.ID",
	"kaytu_account_id":         "metadata.SourceID",
	"name":                     "description.ManagedCluster.name",
	"network_watcher_name":     "description.NetworkWatcherName",
	"provisioning_state":       "description.FlowLog.Properties.ProvisioningState",
	"resource_group":           "description.ResourceGroup",
	"retention_policy_days":    "description.FlowLog.Properties.RetentionPolicy.Days",
	"retention_policy_enabled": "description.FlowLog.Properties.RetentionPolicy.Enabled",
	"storage_id":               "description.FlowLog.Properties.StorageID",
	"tags":                     "description.FlowLog.Tags",
	"target_resource_guid":     "description.FlowLog.Properties.TargetResourceGUID",
	"target_resource_id":       "description.FlowLog.Properties.TargetResourceID",
	"title":                    "description.FlowLog.Name",
	"traffic_analytics":        "description.FlowLog.Properties.FlowAnalyticsConfiguration.NetworkWatcherFlowAnalyticsConfiguration",
	"type":                     "description.FlowLog.Type",
	"version":                  "description.FlowLog.Properties.Format.Version",
}

func GetNetworkWatcherFlowLog(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkWatcherFlowLog")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewNetworkWatcherFlowLogPaginator(essdk.BuildFilter(ctx, d.QueryContext, getNetworkWatcherFlowLogFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkWatcherFlowLog =============================

// ==========================  START: RouteTables =============================

type RouteTables struct {
	Description   azure.RouteTablesDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

func (r *RouteTables) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.RouteTablesDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type RouteTablesHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  RouteTables   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type RouteTablesHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []RouteTablesHit  `json:"hits"`
}

type RouteTablesSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  RouteTablesHits `json:"hits"`
}

type RouteTablesPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewRouteTablesPaginator(filters []essdk.BoolFilter, limit *int64) (RouteTablesPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_routetables", filters, limit)
	if err != nil {
		return RouteTablesPaginator{}, err
	}

	p := RouteTablesPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RouteTablesPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p RouteTablesPaginator) NextPage(ctx context.Context) ([]RouteTables, error) {
	var response RouteTablesSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RouteTables
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listRouteTablesFilters = map[string]string{
	"disable_bgp_route_propagation": "description.RouteTable.Properties.DisableBgpRoutePropagation",
	"etag":                          "description.RouteTable.Etag",
	"kaytu_account_id":              "metadata.SourceID",
	"name":                          "description.RouteTable.Name",
	"provisioning_state":            "description.RouteTable.Properties.ProvisioningState",
	"routes":                        "description.RouteTable.Properties.Routes",
	"subnets":                       "description.RouteTable.Properties.Subnets",
	"tags":                          "description.RouteTable.Tags",
	"title":                         "description.RouteTable.Name",
	"type":                          "description.RouteTable.Type",
}

func ListRouteTables(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRouteTables")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewRouteTablesPaginator(essdk.BuildFilter(ctx, d.QueryContext, listRouteTablesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRouteTablesFilters = map[string]string{
	"disable_bgp_route_propagation": "description.RouteTable.Properties.DisableBgpRoutePropagation",
	"etag":                          "description.RouteTable.Etag",
	"kaytu_account_id":              "metadata.SourceID",
	"name":                          "description.RouteTable.Name",
	"provisioning_state":            "description.RouteTable.Properties.ProvisioningState",
	"resource_group":                "description.ResourceGroup",
	"routes":                        "description.RouteTable.Properties.Routes",
	"subnets":                       "description.RouteTable.Properties.Subnets",
	"tags":                          "description.RouteTable.Tags",
	"title":                         "description.RouteTable.Name",
	"type":                          "description.RouteTable.Type",
}

func GetRouteTables(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRouteTables")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewRouteTablesPaginator(essdk.BuildFilter(ctx, d.QueryContext, getRouteTablesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RouteTables =============================

// ==========================  START: NetworkApplicationSecurityGroups =============================

type NetworkApplicationSecurityGroups struct {
	Description   azure.NetworkApplicationSecurityGroupsDescription `json:"description"`
	Metadata      azure.Metadata                                    `json:"metadata"`
	ResourceJobID int                                               `json:"resource_job_id"`
	SourceJobID   int                                               `json:"source_job_id"`
	ResourceType  string                                            `json:"resource_type"`
	SourceType    string                                            `json:"source_type"`
	ID            string                                            `json:"id"`
	ARN           string                                            `json:"arn"`
	SourceID      string                                            `json:"source_id"`
}

func (r *NetworkApplicationSecurityGroups) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.NetworkApplicationSecurityGroupsDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type NetworkApplicationSecurityGroupsHit struct {
	ID      string                           `json:"_id"`
	Score   float64                          `json:"_score"`
	Index   string                           `json:"_index"`
	Type    string                           `json:"_type"`
	Version int64                            `json:"_version,omitempty"`
	Source  NetworkApplicationSecurityGroups `json:"_source"`
	Sort    []interface{}                    `json:"sort"`
}

type NetworkApplicationSecurityGroupsHits struct {
	Total essdk.SearchTotal                     `json:"total"`
	Hits  []NetworkApplicationSecurityGroupsHit `json:"hits"`
}

type NetworkApplicationSecurityGroupsSearchResponse struct {
	PitID string                               `json:"pit_id"`
	Hits  NetworkApplicationSecurityGroupsHits `json:"hits"`
}

type NetworkApplicationSecurityGroupsPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewNetworkApplicationSecurityGroupsPaginator(filters []essdk.BoolFilter, limit *int64) (NetworkApplicationSecurityGroupsPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_applicationsecuritygroups", filters, limit)
	if err != nil {
		return NetworkApplicationSecurityGroupsPaginator{}, err
	}

	p := NetworkApplicationSecurityGroupsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkApplicationSecurityGroupsPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p NetworkApplicationSecurityGroupsPaginator) NextPage(ctx context.Context) ([]NetworkApplicationSecurityGroups, error) {
	var response NetworkApplicationSecurityGroupsSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkApplicationSecurityGroups
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkApplicationSecurityGroupsFilters = map[string]string{
	"etag":               "description.ApplicationSecurityGroup.Etag",
	"kaytu_account_id":   "metadata.SourceID",
	"name":               "description.ApplicationSecurityGroup.Name",
	"provisioning_state": "description.ApplicationSecurityGroup.Properties.ProvisioningState",
	"resource_group":     "description.ResourceGroup",
	"resource_guid":      "description.ApplicationSecurityGroup.Properties.ResourceGUID",
	"tags":               "description.ApplicationSecurityGroup.Tags",
	"title":              "description.ApplicationSecurityGroup.Name",
	"type":               "description.ApplicationSecurityGroup.Type",
}

func ListNetworkApplicationSecurityGroups(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkApplicationSecurityGroups")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewNetworkApplicationSecurityGroupsPaginator(essdk.BuildFilter(ctx, d.QueryContext, listNetworkApplicationSecurityGroupsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkApplicationSecurityGroupsFilters = map[string]string{
	"etag":               "description.ApplicationSecurityGroup.Etag",
	"kaytu_account_id":   "metadata.SourceID",
	"name":               "description.ApplicationSecurityGroup.Name",
	"provisioning_state": "description.ApplicationSecurityGroup.Properties.ProvisioningState",
	"resource_group":     "description.ResourceGroup",
	"resource_guid":      "description.ApplicationSecurityGroup.Properties.ResourceGUID",
	"tags":               "description.ApplicationSecurityGroup.Tags",
	"title":              "description.ApplicationSecurityGroup.Name",
	"type":               "description.ApplicationSecurityGroup.Type",
}

func GetNetworkApplicationSecurityGroups(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkApplicationSecurityGroups")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewNetworkApplicationSecurityGroupsPaginator(essdk.BuildFilter(ctx, d.QueryContext, getNetworkApplicationSecurityGroupsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkApplicationSecurityGroups =============================

// ==========================  START: NetworkAzureFirewall =============================

type NetworkAzureFirewall struct {
	Description   azure.NetworkAzureFirewallDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

func (r *NetworkAzureFirewall) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.NetworkAzureFirewallDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type NetworkAzureFirewallHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  NetworkAzureFirewall `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type NetworkAzureFirewallHits struct {
	Total essdk.SearchTotal         `json:"total"`
	Hits  []NetworkAzureFirewallHit `json:"hits"`
}

type NetworkAzureFirewallSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  NetworkAzureFirewallHits `json:"hits"`
}

type NetworkAzureFirewallPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewNetworkAzureFirewallPaginator(filters []essdk.BoolFilter, limit *int64) (NetworkAzureFirewallPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_azurefirewalls", filters, limit)
	if err != nil {
		return NetworkAzureFirewallPaginator{}, err
	}

	p := NetworkAzureFirewallPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkAzureFirewallPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p NetworkAzureFirewallPaginator) NextPage(ctx context.Context) ([]NetworkAzureFirewall, error) {
	var response NetworkAzureFirewallSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkAzureFirewall
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkAzureFirewallFilters = map[string]string{
	"additional_properties":        "description.AzureFirewall.Properties.AdditionalProperties",
	"application_rule_collections": "description.AzureFirewall.Properties.ApplicationRuleCollections",
	"availability_zones":           "description.AzureFirewall.Zones",
	"etag":                         "description.AzureFirewall.Etag",
	"firewall_policy_id":           "description.AzureFirewall.Properties.FirewallPolicy.ID",
	"hub_private_ip_address":       "description.AzureFirewall.Properties.HubIPAddresses.PrivateIPAddress",
	"hub_public_ip_address_count":  "description.AzureFirewall.Properties.HubIPAddresses.PublicIPs.Count",
	"hub_public_ip_addresses":      "description.AzureFirewall.Properties.HubIPAddresses.PublicIPs.Addresses",
	"id":                           "description.AzureFirewall.ID",
	"ip_groups":                    "description.AzureFirewall.Properties.IPGroups",
	"kaytu_account_id":             "metadata.SourceID",
	"name":                         "description.AzureFirewall.Name",
	"nat_rule_collections":         "description.AzureFirewall.Properties.NatRuleCollections",
	"network_rule_collections":     "description.AzureFirewall.Properties.NetworkRuleCollections",
	"provisioning_state":           "description.AzureFirewall.Properties.ProvisioningState",
	"resource_group":               "description.ResourceGroup",
	"sku_name":                     "description.AzureFirewall.Properties.SKU.Name",
	"sku_tier":                     "description.AzureFirewall.Properties.SKU.Tier",
	"tags":                         "description.AzureFirewall.Tags",
	"threat_intel_mode":            "description.AzureFirewall.Properties.ThreatIntelMode",
	"title":                        "description.AzureFirewall.Name",
	"type":                         "description.AzureFirewall.Type",
	"virtual_hub_id":               "description.AzureFirewall.Properties.VirtualHub.ID",
}

func ListNetworkAzureFirewall(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkAzureFirewall")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewNetworkAzureFirewallPaginator(essdk.BuildFilter(ctx, d.QueryContext, listNetworkAzureFirewallFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkAzureFirewallFilters = map[string]string{
	"additional_properties":        "description.AzureFirewall.Properties.AdditionalProperties",
	"application_rule_collections": "description.AzureFirewall.Properties.ApplicationRuleCollections",
	"availability_zones":           "description.AzureFirewall.Zones",
	"etag":                         "description.AzureFirewall.Etag",
	"firewall_policy_id":           "description.AzureFirewall.Properties.FirewallPolicy.ID",
	"hub_private_ip_address":       "description.AzureFirewall.Properties.HubIPAddresses.PrivateIPAddress",
	"hub_public_ip_address_count":  "description.AzureFirewall.Properties.HubIPAddresses.PublicIPs.Count",
	"hub_public_ip_addresses":      "description.AzureFirewall.Properties.HubIPAddresses.PublicIPs.Addresses",
	"id":                           "description.AzureFirewall.ID",
	"ip_groups":                    "description.AzureFirewall.Properties.IPGroups",
	"kaytu_account_id":             "metadata.SourceID",
	"name":                         "description.AzureFirewall.Name",
	"nat_rule_collections":         "description.AzureFirewall.Properties.NatRuleCollections",
	"network_rule_collections":     "description.AzureFirewall.Properties.NetworkRuleCollections",
	"provisioning_state":           "description.AzureFirewall.Properties.ProvisioningState",
	"resource_group":               "description.ResourceGroup",
	"sku_name":                     "description.AzureFirewall.Properties.SKU.Name",
	"sku_tier":                     "description.AzureFirewall.Properties.SKU.Tier",
	"tags":                         "description.AzureFirewall.Tags",
	"threat_intel_mode":            "description.AzureFirewall.Properties.ThreatIntelMode",
	"title":                        "description.AzureFirewall.Name",
	"type":                         "description.AzureFirewall.Type",
	"virtual_hub_id":               "description.AzureFirewall.Properties.VirtualHub.ID",
}

func GetNetworkAzureFirewall(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkAzureFirewall")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewNetworkAzureFirewallPaginator(essdk.BuildFilter(ctx, d.QueryContext, getNetworkAzureFirewallFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkAzureFirewall =============================

// ==========================  START: ExpressRouteCircuit =============================

type ExpressRouteCircuit struct {
	Description   azure.ExpressRouteCircuitDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

func (r *ExpressRouteCircuit) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ExpressRouteCircuitDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ExpressRouteCircuitHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  ExpressRouteCircuit `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type ExpressRouteCircuitHits struct {
	Total essdk.SearchTotal        `json:"total"`
	Hits  []ExpressRouteCircuitHit `json:"hits"`
}

type ExpressRouteCircuitSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  ExpressRouteCircuitHits `json:"hits"`
}

type ExpressRouteCircuitPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewExpressRouteCircuitPaginator(filters []essdk.BoolFilter, limit *int64) (ExpressRouteCircuitPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_expressroutecircuits", filters, limit)
	if err != nil {
		return ExpressRouteCircuitPaginator{}, err
	}

	p := ExpressRouteCircuitPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ExpressRouteCircuitPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ExpressRouteCircuitPaginator) NextPage(ctx context.Context) ([]ExpressRouteCircuit, error) {
	var response ExpressRouteCircuitSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ExpressRouteCircuit
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listExpressRouteCircuitFilters = map[string]string{
	"allow_classic_operations":            "description.ExpressRouteCircuit.Properties.AllowClassicOperations",
	"authorizations":                      "description.ExpressRouteCircuit.Properties.Authorizations",
	"bandwidth_in_gbps":                   "description.ExpressRouteCircuit.Properties.BandwidthInGbps",
	"circuit_provisioning_state":          "description.ExpressRouteCircuit.Properties.CircuitProvisioningState",
	"etag":                                "description.ExpressRouteCircuit.Etag",
	"express_route_port":                  "description.ExpressRouteCircuit.Properties.ExpressRoutePort",
	"global_reach_enabled":                "description.ExpressRouteCircuit.Properties.GlobalReachEnabled",
	"id":                                  "description.ExpressRouteCircuit.ID",
	"kaytu_account_id":                    "metadata.SourceID",
	"name":                                "description.ExpressRouteCircuit.Name",
	"peerings":                            "description.ExpressRouteCircuit.Properties.Peerings",
	"provisioning_state":                  "description.ExpressRouteCircuit.Properties.ProvisioningState",
	"resource_group":                      "description.ResourceGroup",
	"service_key":                         "description.ExpressRouteCircuit.Properties.ServiceKey",
	"service_provider_notes":              "description.ExpressRouteCircuit.Properties.ServiceProviderNotes",
	"service_provider_properties":         "description.ExpressRouteCircuit.Properties.ServiceProviderProperties",
	"service_provider_provisioning_state": "description.ExpressRouteCircuit.Properties.ServiceProviderProvisioningState",
	"sku_family":                          "description.ExpressRouteCircuit.SKU.Family",
	"sku_name":                            "description.ExpressRouteCircuit.SKU.Name",
	"sku_tier":                            "description.ExpressRouteCircuit.SKU.Tier",
	"tags":                                "description.ExpressRouteCircuit.Tags",
	"title":                               "description.ExpressRouteCircuit.Name",
}

func ListExpressRouteCircuit(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListExpressRouteCircuit")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewExpressRouteCircuitPaginator(essdk.BuildFilter(ctx, d.QueryContext, listExpressRouteCircuitFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getExpressRouteCircuitFilters = map[string]string{
	"allow_classic_operations":            "description.ExpressRouteCircuit.Properties.AllowClassicOperations",
	"authorizations":                      "description.ExpressRouteCircuit.Properties.Authorizations",
	"bandwidth_in_gbps":                   "description.ExpressRouteCircuit.Properties.BandwidthInGbps",
	"circuit_provisioning_state":          "description.ExpressRouteCircuit.Properties.CircuitProvisioningState",
	"etag":                                "description.ExpressRouteCircuit.Etag",
	"express_route_port":                  "description.ExpressRouteCircuit.Properties.ExpressRoutePort",
	"global_reach_enabled":                "description.ExpressRouteCircuit.Properties.GlobalReachEnabled",
	"id":                                  "description.ExpressRouteCircuit.ID",
	"kaytu_account_id":                    "metadata.SourceID",
	"name":                                "description.ExpressRouteCircuit.name",
	"peerings":                            "description.ExpressRouteCircuit.Properties.Peerings",
	"provisioning_state":                  "description.ExpressRouteCircuit.Properties.ProvisioningState",
	"resource_group":                      "description.ResourceGroup",
	"service_key":                         "description.ExpressRouteCircuit.Properties.ServiceKey",
	"service_provider_notes":              "description.ExpressRouteCircuit.Properties.ServiceProviderNotes",
	"service_provider_properties":         "description.ExpressRouteCircuit.Properties.ServiceProviderProperties",
	"service_provider_provisioning_state": "description.ExpressRouteCircuit.Properties.ServiceProviderProvisioningState",
	"sku_family":                          "description.ExpressRouteCircuit.SKU.Family",
	"sku_name":                            "description.ExpressRouteCircuit.SKU.Name",
	"sku_tier":                            "description.ExpressRouteCircuit.SKU.Tier",
	"tags":                                "description.ExpressRouteCircuit.Tags",
	"title":                               "description.ExpressRouteCircuit.Name",
}

func GetExpressRouteCircuit(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetExpressRouteCircuit")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewExpressRouteCircuitPaginator(essdk.BuildFilter(ctx, d.QueryContext, getExpressRouteCircuitFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ExpressRouteCircuit =============================

// ==========================  START: VirtualNetworkGateway =============================

type VirtualNetworkGateway struct {
	Description   azure.VirtualNetworkGatewayDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

func (r *VirtualNetworkGateway) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.VirtualNetworkGatewayDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type VirtualNetworkGatewayHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  VirtualNetworkGateway `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type VirtualNetworkGatewayHits struct {
	Total essdk.SearchTotal          `json:"total"`
	Hits  []VirtualNetworkGatewayHit `json:"hits"`
}

type VirtualNetworkGatewaySearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  VirtualNetworkGatewayHits `json:"hits"`
}

type VirtualNetworkGatewayPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewVirtualNetworkGatewayPaginator(filters []essdk.BoolFilter, limit *int64) (VirtualNetworkGatewayPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_virtualnetworkgateways", filters, limit)
	if err != nil {
		return VirtualNetworkGatewayPaginator{}, err
	}

	p := VirtualNetworkGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p VirtualNetworkGatewayPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p VirtualNetworkGatewayPaginator) NextPage(ctx context.Context) ([]VirtualNetworkGateway, error) {
	var response VirtualNetworkGatewaySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []VirtualNetworkGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listVirtualNetworkGatewayFilters = map[string]string{
	"active_active":                   "description.VirtualNetworkGateway.Properties.Active",
	"bgp_settings":                    "description.VirtualNetworkGateway.Properties.BgpSettings",
	"custom_routes_address_prefixes":  "description.VirtualNetworkGateway.Properties.CustomRoutes.AddressPrefixes",
	"enable_bgp":                      "description.VirtualNetworkGateway.Properties.EnableBgp",
	"enable_dns_forwarding":           "description.VirtualNetworkGateway.Properties.EnableDNSForwarding",
	"enable_private_ip_address":       "description.VirtualNetworkGateway.Properties.EnablePrivateIPAddress",
	"etag":                            "description.VirtualNetworkGateway.Etag",
	"gateway_connections":             "description.VirtualNetworkGatewayConnection",
	"gateway_default_site":            "description.VirtualNetworkGateway.Properties.GatewayDefaultSite.ID",
	"gateway_type":                    "description.VirtualNetworkGateway.Properties.GatewayType",
	"id":                              "description.VirtualNetworkGateway.ID",
	"inbound_dns_forwarding_endpoint": "description.VirtualNetworkGateway.Properties.InboundDNSForwardingEndpoint",
	"ip_configurations":               "description.VirtualNetworkGateway.Properties.IPConfigurations",
	"kaytu_account_id":                "metadata.SourceID",
	"name":                            "description.VirtualNetworkGateway.Name",
	"provisioning_state":              "description.VirtualNetworkGateway.Properties.ProvisioningState",
	"resource_group":                  "description.ResourceGroup",
	"resource_guid":                   "description.VirtualNetworkGateway.Properties.ResourceGUID",
	"sku_capacity":                    "description.VirtualNetworkGateway.Properties.SKU.Capacity",
	"sku_name":                        "description.VirtualNetworkGateway.Properties.SKU.Name",
	"sku_tier":                        "description.VirtualNetworkGateway.Properties.SKU.Tier",
	"tags":                            "description.VirtualNetworkGateway.Tags",
	"title":                           "description.VirtualNetworkGateway.Name",
	"type":                            "description.VirtualNetworkGateway.Type",
	"vpn_client_configuration":        "description.VirtualNetworkGateway.Properties.VPNClientConfiguration",
	"vpn_gateway_generation":          "description.VirtualNetworkGateway.Properties.VPNGatewayGeneration",
	"vpn_type":                        "description.VirtualNetworkGateway.Properties.VPNType",
}

func ListVirtualNetworkGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListVirtualNetworkGateway")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewVirtualNetworkGatewayPaginator(essdk.BuildFilter(ctx, d.QueryContext, listVirtualNetworkGatewayFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getVirtualNetworkGatewayFilters = map[string]string{
	"active_active":                   "description.VirtualNetworkGateway.Properties.Active",
	"bgp_settings":                    "description.VirtualNetworkGateway.Properties.BgpSettings",
	"custom_routes_address_prefixes":  "description.VirtualNetworkGateway.Properties.CustomRoutes.AddressPrefixes",
	"enable_bgp":                      "description.VirtualNetworkGateway.Properties.EnableBgp",
	"enable_dns_forwarding":           "description.VirtualNetworkGateway.Properties.EnableDNSForwarding",
	"enable_private_ip_address":       "description.VirtualNetworkGateway.Properties.EnablePrivateIPAddress",
	"etag":                            "description.VirtualNetworkGateway.Etag",
	"gateway_connections":             "description.VirtualNetworkGatewayConnection",
	"gateway_default_site":            "description.VirtualNetworkGateway.Properties.GatewayDefaultSite.ID",
	"gateway_type":                    "description.VirtualNetworkGateway.Properties.GatewayType",
	"id":                              "description.VirtualNetworkGateway.ID",
	"inbound_dns_forwarding_endpoint": "description.VirtualNetworkGateway.Properties.InboundDNSForwardingEndpoint",
	"ip_configurations":               "description.VirtualNetworkGateway.Properties.IPConfigurations",
	"kaytu_account_id":                "metadata.SourceID",
	"name":                            "description.VirtualNetworkGateway.Name",
	"provisioning_state":              "description.VirtualNetworkGateway.Properties.ProvisioningState",
	"resource_group":                  "description.ResourceGroup",
	"resource_guid":                   "description.VirtualNetworkGateway.Properties.ResourceGUID",
	"sku_capacity":                    "description.VirtualNetworkGateway.Properties.SKU.Capacity",
	"sku_name":                        "description.VirtualNetworkGateway.Properties.SKU.Name",
	"sku_tier":                        "description.VirtualNetworkGateway.Properties.SKU.Tier",
	"tags":                            "description.VirtualNetworkGateway.Tags",
	"title":                           "description.VirtualNetworkGateway.Name",
	"type":                            "description.VirtualNetworkGateway.Type",
	"vpn_client_configuration":        "description.VirtualNetworkGateway.Properties.VPNClientConfiguration",
	"vpn_gateway_generation":          "description.VirtualNetworkGateway.Properties.VPNGatewayGeneration",
	"vpn_type":                        "description.VirtualNetworkGateway.Properties.VPNType",
}

func GetVirtualNetworkGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetVirtualNetworkGateway")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewVirtualNetworkGatewayPaginator(essdk.BuildFilter(ctx, d.QueryContext, getVirtualNetworkGatewayFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: VirtualNetworkGateway =============================

// ==========================  START: FirewallPolicy =============================

type FirewallPolicy struct {
	Description   azure.FirewallPolicyDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

func (r *FirewallPolicy) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.FirewallPolicyDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type FirewallPolicyHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  FirewallPolicy `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type FirewallPolicyHits struct {
	Total essdk.SearchTotal   `json:"total"`
	Hits  []FirewallPolicyHit `json:"hits"`
}

type FirewallPolicySearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  FirewallPolicyHits `json:"hits"`
}

type FirewallPolicyPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewFirewallPolicyPaginator(filters []essdk.BoolFilter, limit *int64) (FirewallPolicyPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_firewallpolicies", filters, limit)
	if err != nil {
		return FirewallPolicyPaginator{}, err
	}

	p := FirewallPolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p FirewallPolicyPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p FirewallPolicyPaginator) NextPage(ctx context.Context) ([]FirewallPolicy, error) {
	var response FirewallPolicySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []FirewallPolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listFirewallPolicyFilters = map[string]string{
	"base_policy":                         "description.FirewallPolicies.Properties.BasePolicy",
	"child_policies":                      "description.FirewallPolicies.Properties.ChildPolicies",
	"dns_settings":                        "description.FirewallPolicies.Properties.DNSSettings",
	"etag":                                "description.FirewallPolicies.Etag",
	"firewalls":                           "description.FirewallPolicies.Properties.Firewalls",
	"id":                                  "description.FirewallPolicy.ID",
	"identity":                            "description.FirewallPolicies.Identity",
	"intrusion_detection_configuration":   "description.FirewallPolicies.Properties.IntrusionDetection.Configuration",
	"intrusion_detection_mode":            "description.FirewallPolicies.Properties.IntrusionDetection.Mode",
	"kaytu_account_id":                    "metadata.SourceID",
	"name":                                "description.FirewallPolicy.Name",
	"provisioning_state":                  "description.FirewallPolicies.Properties.ProvisioningState",
	"resource_group":                      "description.ResourceGroup",
	"rule_collection_groups":              "description.FirewallPolicies.Properties.RuleCollectionGroups",
	"sku_tier":                            "description.FirewallPolicies.Properties.SKU.Tier",
	"tags":                                "description.FirewallPolicy.Tags",
	"threat_intel_mode":                   "description.FirewallPolicies.Properties.ThreatIntelMode",
	"threat_intel_whitelist_fqdns":        "description.FirewallPolicies.Properties.ThreatIntelWhitelist.Fqdns",
	"threat_intel_whitelist_ip_addresses": "description.FirewallPolicies.Properties.ThreatIntelWhitelist.IPAddresses",
	"title":                               "description.FirewallPolicy.Name",
	"transport_security_certificate_authority": "description.FirewallPolicies.Properties.TransportSecurity.CertificateAuthority",
	"type": "description.FirewallPolicies.Type",
}

func ListFirewallPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListFirewallPolicy")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewFirewallPolicyPaginator(essdk.BuildFilter(ctx, d.QueryContext, listFirewallPolicyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getFirewallPolicyFilters = map[string]string{
	"base_policy":                         "description.FirewallPolicies.Properties.BasePolicy",
	"child_policies":                      "description.FirewallPolicies.Properties.ChildPolicies",
	"dns_settings":                        "description.FirewallPolicies.Properties.DNSSettings",
	"etag":                                "description.FirewallPolicies.Etag",
	"firewalls":                           "description.FirewallPolicies.Properties.Firewalls",
	"id":                                  "description.FirewallPolicy.ID",
	"identity":                            "description.FirewallPolicies.Identity",
	"intrusion_detection_configuration":   "description.FirewallPolicies.Properties.IntrusionDetection.Configuration",
	"intrusion_detection_mode":            "description.FirewallPolicies.Properties.IntrusionDetection.Mode",
	"kaytu_account_id":                    "metadata.SourceID",
	"name":                                "description.FirewallPolicy.Name",
	"provisioning_state":                  "description.FirewallPolicies.Properties.ProvisioningState",
	"resource_group":                      "description.ResourceGroup",
	"rule_collection_groups":              "description.FirewallPolicies.Properties.RuleCollectionGroups",
	"sku_tier":                            "description.FirewallPolicies.Properties.SKU.Tier",
	"tags":                                "description.FirewallPolicy.Tags",
	"threat_intel_mode":                   "description.FirewallPolicies.Properties.ThreatIntelMode",
	"threat_intel_whitelist_fqdns":        "description.FirewallPolicies.Properties.ThreatIntelWhitelist.Fqdns",
	"threat_intel_whitelist_ip_addresses": "description.FirewallPolicies.Properties.ThreatIntelWhitelist.IPAddresses",
	"title":                               "description.FirewallPolicy.Name",
	"transport_security_certificate_authority": "description.FirewallPolicies.Properties.TransportSecurity.CertificateAuthority",
	"type": "description.FirewallPolicies.Type",
}

func GetFirewallPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetFirewallPolicy")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewFirewallPolicyPaginator(essdk.BuildFilter(ctx, d.QueryContext, getFirewallPolicyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: FirewallPolicy =============================

// ==========================  START: LocalNetworkGateway =============================

type LocalNetworkGateway struct {
	Description   azure.LocalNetworkGatewayDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

func (r *LocalNetworkGateway) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.LocalNetworkGatewayDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type LocalNetworkGatewayHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  LocalNetworkGateway `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type LocalNetworkGatewayHits struct {
	Total essdk.SearchTotal        `json:"total"`
	Hits  []LocalNetworkGatewayHit `json:"hits"`
}

type LocalNetworkGatewaySearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  LocalNetworkGatewayHits `json:"hits"`
}

type LocalNetworkGatewayPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewLocalNetworkGatewayPaginator(filters []essdk.BoolFilter, limit *int64) (LocalNetworkGatewayPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_localnetworkgateways", filters, limit)
	if err != nil {
		return LocalNetworkGatewayPaginator{}, err
	}

	p := LocalNetworkGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LocalNetworkGatewayPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p LocalNetworkGatewayPaginator) NextPage(ctx context.Context) ([]LocalNetworkGateway, error) {
	var response LocalNetworkGatewaySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LocalNetworkGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listLocalNetworkGatewayFilters = map[string]string{
	"id":               "description.LocalNetworkGateways.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.LocalNetworkGateway.Name",
	"tags":             "description.LocalNetworkGateway.Tags",
	"title":            "description.LocalNetworkGateway.Name",
}

func ListLocalNetworkGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLocalNetworkGateway")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewLocalNetworkGatewayPaginator(essdk.BuildFilter(ctx, d.QueryContext, listLocalNetworkGatewayFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLocalNetworkGatewayFilters = map[string]string{
	"id":               "description.LocalNetworkGateways.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.LocalNetworkGateway.Name",
	"resource_group":   "description.ResourceGroup",
	"tags":             "description.LocalNetworkGateway.Tags",
	"title":            "description.LocalNetworkGateway.Name",
}

func GetLocalNetworkGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLocalNetworkGateway")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewLocalNetworkGatewayPaginator(essdk.BuildFilter(ctx, d.QueryContext, getLocalNetworkGatewayFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LocalNetworkGateway =============================

// ==========================  START: NatGateway =============================

type NatGateway struct {
	Description   azure.NatGatewayDescription `json:"description"`
	Metadata      azure.Metadata              `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

func (r *NatGateway) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.NatGatewayDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type NatGatewayHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  NatGateway    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type NatGatewayHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []NatGatewayHit   `json:"hits"`
}

type NatGatewaySearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  NatGatewayHits `json:"hits"`
}

type NatGatewayPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewNatGatewayPaginator(filters []essdk.BoolFilter, limit *int64) (NatGatewayPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_natgateways", filters, limit)
	if err != nil {
		return NatGatewayPaginator{}, err
	}

	p := NatGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NatGatewayPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p NatGatewayPaginator) NextPage(ctx context.Context) ([]NatGateway, error) {
	var response NatGatewaySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NatGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listNatGatewayFilters = map[string]string{
	"etag":             "description.NatGateway.Etag",
	"id":               "description.NatGateway.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.NatGateway.Name",
	"resource_group":   "description.ResourceGroup",
	"sku_name":         "description.NatGateway.SKU.Name",
	"tags":             "description.NatGateway.Tags",
	"title":            "description.NatGateway.Name",
	"type":             "description.NatGateway.Type",
	"zones":            "description.NatGateway.Zones",
}

func ListNatGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNatGateway")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewNatGatewayPaginator(essdk.BuildFilter(ctx, d.QueryContext, listNatGatewayFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNatGatewayFilters = map[string]string{
	"etag":             "description.NatGateway.Etag",
	"id":               "description.NatGateway.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.NatGateway.Name",
	"resource_group":   "description.ResourceGroup",
	"sku_name":         "description.NatGateway.SKU.Name",
	"tags":             "description.NatGateway.Tags",
	"title":            "description.NatGateway.Name",
	"type":             "description.NatGateway.Type",
	"zones":            "description.NatGateway.Zones",
}

func GetNatGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNatGateway")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewNatGatewayPaginator(essdk.BuildFilter(ctx, d.QueryContext, getNatGatewayFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NatGateway =============================

// ==========================  START: PrivateLinkService =============================

type PrivateLinkService struct {
	Description   azure.PrivateLinkServiceDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

func (r *PrivateLinkService) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.PrivateLinkServiceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type PrivateLinkServiceHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  PrivateLinkService `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type PrivateLinkServiceHits struct {
	Total essdk.SearchTotal       `json:"total"`
	Hits  []PrivateLinkServiceHit `json:"hits"`
}

type PrivateLinkServiceSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  PrivateLinkServiceHits `json:"hits"`
}

type PrivateLinkServicePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewPrivateLinkServicePaginator(filters []essdk.BoolFilter, limit *int64) (PrivateLinkServicePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_privatelinkservices", filters, limit)
	if err != nil {
		return PrivateLinkServicePaginator{}, err
	}

	p := PrivateLinkServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PrivateLinkServicePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p PrivateLinkServicePaginator) NextPage(ctx context.Context) ([]PrivateLinkService, error) {
	var response PrivateLinkServiceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PrivateLinkService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listPrivateLinkServiceFilters = map[string]string{
	"id":               "description.PrivateLinkServices.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.PrivateLinkService.Name",
	"tags":             "description.PrivateLinkService.Tags",
	"title":            "description.PrivateLinkService.Name",
}

func ListPrivateLinkService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPrivateLinkService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewPrivateLinkServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, listPrivateLinkServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPrivateLinkServiceFilters = map[string]string{
	"id":               "description.PrivateLinkServices.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.PrivateLinkService.Name",
	"resource_group":   "description.ResourceGroup",
	"tags":             "description.PrivateLinkService.Tags",
	"title":            "description.PrivateLinkService.Name",
}

func GetPrivateLinkService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPrivateLinkService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewPrivateLinkServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, getPrivateLinkServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PrivateLinkService =============================

// ==========================  START: VpnGateway =============================

type VpnGateway struct {
	Description   azure.VpnGatewayDescription `json:"description"`
	Metadata      azure.Metadata              `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

func (r *VpnGateway) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.VpnGatewayDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type VpnGatewayHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  VpnGateway    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type VpnGatewayHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []VpnGatewayHit   `json:"hits"`
}

type VpnGatewaySearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  VpnGatewayHits `json:"hits"`
}

type VpnGatewayPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewVpnGatewayPaginator(filters []essdk.BoolFilter, limit *int64) (VpnGatewayPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_vpngateways", filters, limit)
	if err != nil {
		return VpnGatewayPaginator{}, err
	}

	p := VpnGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p VpnGatewayPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p VpnGatewayPaginator) NextPage(ctx context.Context) ([]VpnGateway, error) {
	var response VpnGatewaySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []VpnGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listVpnGatewayFilters = map[string]string{
	"id":               "description.VPNGateways.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.VpnGateway.Name",
	"tags":             "description.VpnGateway.Tags",
	"title":            "description.VpnGateway.Name",
}

func ListVpnGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListVpnGateway")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewVpnGatewayPaginator(essdk.BuildFilter(ctx, d.QueryContext, listVpnGatewayFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getVpnGatewayFilters = map[string]string{
	"id":               "description.VPNGateways.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.VpnGateway.Name",
	"resource_group":   "description.ResourceGroup",
	"tags":             "description.VpnGateway.Tags",
	"title":            "description.VpnGateway.Name",
}

func GetVpnGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetVpnGateway")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewVpnGatewayPaginator(essdk.BuildFilter(ctx, d.QueryContext, getVpnGatewayFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: VpnGateway =============================

// ==========================  START: VpnGatewayVpnConnection =============================

type VpnGatewayVpnConnection struct {
	Description   azure.VpnGatewayVpnConnectionDescription `json:"description"`
	Metadata      azure.Metadata                           `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

func (r *VpnGatewayVpnConnection) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.VpnGatewayVpnConnectionDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type VpnGatewayVpnConnectionHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  VpnGatewayVpnConnection `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type VpnGatewayVpnConnectionHits struct {
	Total essdk.SearchTotal            `json:"total"`
	Hits  []VpnGatewayVpnConnectionHit `json:"hits"`
}

type VpnGatewayVpnConnectionSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  VpnGatewayVpnConnectionHits `json:"hits"`
}

type VpnGatewayVpnConnectionPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewVpnGatewayVpnConnectionPaginator(filters []essdk.BoolFilter, limit *int64) (VpnGatewayVpnConnectionPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_vpngateways_vpnconnections", filters, limit)
	if err != nil {
		return VpnGatewayVpnConnectionPaginator{}, err
	}

	p := VpnGatewayVpnConnectionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p VpnGatewayVpnConnectionPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p VpnGatewayVpnConnectionPaginator) NextPage(ctx context.Context) ([]VpnGatewayVpnConnection, error) {
	var response VpnGatewayVpnConnectionSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []VpnGatewayVpnConnection
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listVpnGatewayVpnConnectionFilters = map[string]string{
	"id":               "description.VPNConnections.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.VpnConnection.Name",
	"tags":             "description.VpnConnection.Etag",
	"title":            "description.VpnConnection.Name",
}

func ListVpnGatewayVpnConnection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListVpnGatewayVpnConnection")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewVpnGatewayVpnConnectionPaginator(essdk.BuildFilter(ctx, d.QueryContext, listVpnGatewayVpnConnectionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getVpnGatewayVpnConnectionFilters = map[string]string{
	"id":               "description.VPNConnections.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.VpnConnection.Name",
	"tags":             "description.VpnConnection.Etag",
	"title":            "description.VpnConnection.Name",
}

func GetVpnGatewayVpnConnection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetVpnGatewayVpnConnection")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewVpnGatewayVpnConnectionPaginator(essdk.BuildFilter(ctx, d.QueryContext, getVpnGatewayVpnConnectionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: VpnGatewayVpnConnection =============================

// ==========================  START: VpnSite =============================

type VpnSite struct {
	Description   azure.VpnSiteDescription `json:"description"`
	Metadata      azure.Metadata           `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	ARN           string                   `json:"arn"`
	SourceID      string                   `json:"source_id"`
}

func (r *VpnSite) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.VpnSiteDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type VpnSiteHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  VpnSite       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type VpnSiteHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []VpnSiteHit      `json:"hits"`
}

type VpnSiteSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  VpnSiteHits `json:"hits"`
}

type VpnSitePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewVpnSitePaginator(filters []essdk.BoolFilter, limit *int64) (VpnSitePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_vpnsites", filters, limit)
	if err != nil {
		return VpnSitePaginator{}, err
	}

	p := VpnSitePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p VpnSitePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p VpnSitePaginator) NextPage(ctx context.Context) ([]VpnSite, error) {
	var response VpnSiteSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []VpnSite
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listVpnSiteFilters = map[string]string{
	"id":               "description.VPNSites.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.VpnSite.Name",
	"tags":             "description.VpnSite.Tags",
	"title":            "description.VpnSite.Name",
}

func ListVpnSite(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListVpnSite")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewVpnSitePaginator(essdk.BuildFilter(ctx, d.QueryContext, listVpnSiteFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getVpnSiteFilters = map[string]string{
	"id":               "description.VPNSites.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.VpnSite.Name",
	"tags":             "description.VpnSite.Tags",
	"title":            "description.VpnSite.Name",
}

func GetVpnSite(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetVpnSite")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewVpnSitePaginator(essdk.BuildFilter(ctx, d.QueryContext, getVpnSiteFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: VpnSite =============================

// ==========================  START: PublicIPAddress =============================

type PublicIPAddress struct {
	Description   azure.PublicIPAddressDescription `json:"description"`
	Metadata      azure.Metadata                   `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

func (r *PublicIPAddress) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.PublicIPAddressDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type PublicIPAddressHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  PublicIPAddress `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type PublicIPAddressHits struct {
	Total essdk.SearchTotal    `json:"total"`
	Hits  []PublicIPAddressHit `json:"hits"`
}

type PublicIPAddressSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  PublicIPAddressHits `json:"hits"`
}

type PublicIPAddressPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewPublicIPAddressPaginator(filters []essdk.BoolFilter, limit *int64) (PublicIPAddressPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_publicipaddresses", filters, limit)
	if err != nil {
		return PublicIPAddressPaginator{}, err
	}

	p := PublicIPAddressPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PublicIPAddressPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p PublicIPAddressPaginator) NextPage(ctx context.Context) ([]PublicIPAddress, error) {
	var response PublicIPAddressSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PublicIPAddress
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listPublicIPAddressFilters = map[string]string{
	"ddos_custom_policy_id":             "description.PublicIPAddress.Properties.DdosSettings.DdosCustomPolicy.ID",
	"ddos_settings_protected_ip":        "description.PublicIPAddress.Properties.DdosSettings.ProtectedIP",
	"ddos_settings_protection_coverage": "description.PublicIPAddress.Properties.DdosSettings.ProtectionCoverage",
	"dns_settings_domain_name_label":    "description.PublicIPAddress.Properties.DNSSettings.DomainNameLabel",
	"dns_settings_fqdn":                 "description.PublicIPAddress.Properties.DNSSettings.Fqdn",
	"dns_settings_reverse_fqdn":         "description.PublicIPAddress.Properties.DNSSettings.ReverseFqdn",
	"etag":                              "description.PublicIPAddress.Etag",
	"id":                                "description.PublicIPAddress.ID",
	"idle_timeout_in_minutes":           "description.PublicIPAddress.Properties.IdleTimeoutInMinutes",
	"ip_address":                        "description.PublicIPAddress.Properties.IPAddress",
	"ip_configuration_id":               "description.PublicIPAddress.Properties.IPConfiguration.ID",
	"ip_tags":                           "description.PublicIPAddress.PublicIPAddressPropertiesFormat.IPTags",
	"kaytu_account_id":                  "metadata.SourceID",
	"name":                              "description.PublicIPAddress.Name",
	"provisioning_state":                "description.PublicIPAddress.Properties.ProvisioningState",
	"public_ip_address_version":         "description.PublicIPAddress.Properties.PublicIPAddressVersion",
	"public_ip_allocation_method":       "description.PublicIPAddress.Properties.PublicIPAllocationMethod",
	"public_ip_prefix_id":               "description.PublicIPAddress.Properties.PublicIPPrefix.ID",
	"resource_group":                    "description.ResourceGroup",
	"resource_guid":                     "description.PublicIPAddress.Properties.ResourceGUID",
	"sku_name":                          "description.PublicIPAddress.SKU.Name",
	"tags":                              "description.PublicIPAddress.Tags",
	"title":                             "description.PublicIPAddress.Name",
	"type":                              "description.PublicIPAddress.Type",
	"zones":                             "description.PublicIPAddress.Zones",
}

func ListPublicIPAddress(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPublicIPAddress")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewPublicIPAddressPaginator(essdk.BuildFilter(ctx, d.QueryContext, listPublicIPAddressFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPublicIPAddressFilters = map[string]string{
	"ddos_custom_policy_id":             "description.PublicIPAddress.Properties.DdosSettings.DdosCustomPolicy.ID",
	"ddos_settings_protected_ip":        "description.PublicIPAddress.Properties.DdosSettings.ProtectedIP",
	"ddos_settings_protection_coverage": "description.PublicIPAddress.Properties.DdosSettings.ProtectionCoverage",
	"dns_settings_domain_name_label":    "description.PublicIPAddress.Properties.DNSSettings.DomainNameLabel",
	"dns_settings_fqdn":                 "description.PublicIPAddress.Properties.DNSSettings.Fqdn",
	"dns_settings_reverse_fqdn":         "description.PublicIPAddress.Properties.DNSSettings.ReverseFqdn",
	"etag":                              "description.PublicIPAddress.Etag",
	"id":                                "description.PublicIPAddress.ID",
	"idle_timeout_in_minutes":           "description.PublicIPAddress.Properties.IdleTimeoutInMinutes",
	"ip_address":                        "description.PublicIPAddress.Properties.IPAddress",
	"ip_configuration_id":               "description.PublicIPAddress.Properties.IPConfiguration.ID",
	"ip_tags":                           "description.PublicIPAddress.PublicIPAddressPropertiesFormat.IPTags",
	"kaytu_account_id":                  "metadata.SourceID",
	"name":                              "description.PublicIPAddress.Name",
	"provisioning_state":                "description.PublicIPAddress.Properties.ProvisioningState",
	"public_ip_address_version":         "description.PublicIPAddress.Properties.PublicIPAddressVersion",
	"public_ip_allocation_method":       "description.PublicIPAddress.Properties.PublicIPAllocationMethod",
	"public_ip_prefix_id":               "description.PublicIPAddress.Properties.PublicIPPrefix.ID",
	"resource_group":                    "description.ResourceGroup",
	"resource_guid":                     "description.PublicIPAddress.Properties.ResourceGUID",
	"sku_name":                          "description.PublicIPAddress.SKU.Name",
	"tags":                              "description.PublicIPAddress.Tags",
	"title":                             "description.PublicIPAddress.Name",
	"type":                              "description.PublicIPAddress.Type",
	"zones":                             "description.PublicIPAddress.Zones",
}

func GetPublicIPAddress(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPublicIPAddress")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewPublicIPAddressPaginator(essdk.BuildFilter(ctx, d.QueryContext, getPublicIPAddressFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PublicIPAddress =============================

// ==========================  START: PublicIPPrefix =============================

type PublicIPPrefix struct {
	Description   azure.PublicIPPrefixDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

func (r *PublicIPPrefix) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.PublicIPPrefixDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type PublicIPPrefixHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  PublicIPPrefix `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type PublicIPPrefixHits struct {
	Total essdk.SearchTotal   `json:"total"`
	Hits  []PublicIPPrefixHit `json:"hits"`
}

type PublicIPPrefixSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  PublicIPPrefixHits `json:"hits"`
}

type PublicIPPrefixPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewPublicIPPrefixPaginator(filters []essdk.BoolFilter, limit *int64) (PublicIPPrefixPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_publicipprefixes", filters, limit)
	if err != nil {
		return PublicIPPrefixPaginator{}, err
	}

	p := PublicIPPrefixPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PublicIPPrefixPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p PublicIPPrefixPaginator) NextPage(ctx context.Context) ([]PublicIPPrefix, error) {
	var response PublicIPPrefixSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PublicIPPrefix
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listPublicIPPrefixFilters = map[string]string{
	"id":               "description.PublicIPPrefixes.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.PublicIPPrefix.Name",
	"tags":             "description.PublicIPPrefix.Tags",
	"title":            "description.PublicIPPrefix.Name",
}

func ListPublicIPPrefix(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPublicIPPrefix")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewPublicIPPrefixPaginator(essdk.BuildFilter(ctx, d.QueryContext, listPublicIPPrefixFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPublicIPPrefixFilters = map[string]string{
	"id":               "description.PublicIPPrefixes.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.PublicIPPrefix.Name",
	"tags":             "description.PublicIPPrefix.Tags",
	"title":            "description.PublicIPPrefix.Name",
}

func GetPublicIPPrefix(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPublicIPPrefix")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewPublicIPPrefixPaginator(essdk.BuildFilter(ctx, d.QueryContext, getPublicIPPrefixFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PublicIPPrefix =============================

// ==========================  START: DNSZones =============================

type DNSZones struct {
	Description   azure.DNSZonesDescription `json:"description"`
	Metadata      azure.Metadata            `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

func (r *DNSZones) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DNSZonesDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DNSZonesHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  DNSZones      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type DNSZonesHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []DNSZonesHit     `json:"hits"`
}

type DNSZonesSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  DNSZonesHits `json:"hits"`
}

type DNSZonesPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDNSZonesPaginator(filters []essdk.BoolFilter, limit *int64) (DNSZonesPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_dnszones", filters, limit)
	if err != nil {
		return DNSZonesPaginator{}, err
	}

	p := DNSZonesPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DNSZonesPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DNSZonesPaginator) NextPage(ctx context.Context) ([]DNSZones, error) {
	var response DNSZonesSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DNSZones
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDNSZonesFilters = map[string]string{
	"etag":                                 "description.Zone.Etag",
	"id":                                   "description.Zone.ID",
	"kaytu_account_id":                     "metadata.SourceID",
	"max_number_of_record_sets":            "description.Zone.Properties.MaxNumberOfRecordSets",
	"max_number_of_records_per_record_set": "description.Zone.Properties.MaxNumberOfRecordsPerRecordSet",
	"name":                                 "description.Zone.Name",
	"name_servers":                         "description.Zone.Properties.NameServers",
	"number_of_record_sets":                "description.Zone.Properties.NumberOfRecordSets",
	"registration_virtual_networks":        "description.Zone.Properties.RegistrationVirtualNetworks",
	"resolution_virtual_networks":          "description.Zone.Properties.ResolutionVirtualNetworks",
	"resource_group":                       "description.ResourceGroup",
	"tags":                                 "description.Zone.Tags",
	"title":                                "description.Zone.Name",
	"type":                                 "description.Zone.Type",
	"zone_type":                            "description.Zone.Properties.ZoneType",
}

func ListDNSZones(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDNSZones")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDNSZonesPaginator(essdk.BuildFilter(ctx, d.QueryContext, listDNSZonesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDNSZonesFilters = map[string]string{
	"etag":                                 "description.Zone.Etag",
	"id":                                   "description.Zone.ID",
	"kaytu_account_id":                     "metadata.SourceID",
	"max_number_of_record_sets":            "description.Zone.Properties.MaxNumberOfRecordSets",
	"max_number_of_records_per_record_set": "description.Zone.Properties.MaxNumberOfRecordsPerRecordSet",
	"name":                                 "description.Zone.Name",
	"name_servers":                         "description.Zone.Properties.NameServers",
	"number_of_record_sets":                "description.Zone.Properties.NumberOfRecordSets",
	"registration_virtual_networks":        "description.Zone.Properties.RegistrationVirtualNetworks",
	"resolution_virtual_networks":          "description.Zone.Properties.ResolutionVirtualNetworks",
	"resource_group":                       "description.ResourceGroup",
	"tags":                                 "description.Zone.Tags",
	"title":                                "description.Zone.Name",
	"type":                                 "description.Zone.Type",
	"zone_type":                            "description.Zone.Properties.ZoneType",
}

func GetDNSZones(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDNSZones")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDNSZonesPaginator(essdk.BuildFilter(ctx, d.QueryContext, getDNSZonesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DNSZones =============================

// ==========================  START: BastionHosts =============================

type BastionHosts struct {
	Description   azure.BastionHostsDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

func (r *BastionHosts) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.BastionHostsDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type BastionHostsHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  BastionHosts  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type BastionHostsHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []BastionHostsHit `json:"hits"`
}

type BastionHostsSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  BastionHostsHits `json:"hits"`
}

type BastionHostsPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewBastionHostsPaginator(filters []essdk.BoolFilter, limit *int64) (BastionHostsPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_bastionhosts", filters, limit)
	if err != nil {
		return BastionHostsPaginator{}, err
	}

	p := BastionHostsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BastionHostsPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p BastionHostsPaginator) NextPage(ctx context.Context) ([]BastionHosts, error) {
	var response BastionHostsSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BastionHosts
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listBastionHostsFilters = map[string]string{
	"dns_name":           "description.BastianHost.Properties.DNSName",
	"etag":               "description.BastianHost.Etag",
	"id":                 "description.BastianHost.ID",
	"ip_configurations":  "description.BastianHost.Properties.IPConfigurations",
	"kaytu_account_id":   "metadata.SourceID",
	"name":               "description.BastianHost.Name",
	"provisioning_state": "description.BastianHost.Properties.ProvisioningState",
	"region":             "description.BastianHost.Location",
	"resource_group":     "description.ResourceGroup",
	"tags":               "description.BastianHost.Tags",
	"title":              "description.BastianHost.Name",
	"type":               "description.BastianHost.Type",
}

func ListBastionHosts(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBastionHosts")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewBastionHostsPaginator(essdk.BuildFilter(ctx, d.QueryContext, listBastionHostsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBastionHostsFilters = map[string]string{
	"dns_name":           "description.BastianHost.Properties.DNSName",
	"etag":               "description.BastianHost.Etag",
	"id":                 "description.BastianHost.ID",
	"ip_configurations":  "description.BastianHost.Properties.IPConfigurations",
	"kaytu_account_id":   "metadata.SourceID",
	"name":               "description.BastianHost.Name",
	"provisioning_state": "description.BastianHost.Properties.ProvisioningState",
	"region":             "description.BastianHost.Location",
	"resource_group":     "description.ResourceGroup",
	"tags":               "description.BastianHost.Tags",
	"title":              "description.BastianHost.Name",
	"type":               "description.BastianHost.Type",
}

func GetBastionHosts(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBastionHosts")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewBastionHostsPaginator(essdk.BuildFilter(ctx, d.QueryContext, getBastionHostsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BastionHosts =============================

// ==========================  START: Connection =============================

type Connection struct {
	Description   azure.ConnectionDescription `json:"description"`
	Metadata      azure.Metadata              `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

func (r *Connection) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ConnectionDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ConnectionHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  Connection    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ConnectionHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []ConnectionHit   `json:"hits"`
}

type ConnectionSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  ConnectionHits `json:"hits"`
}

type ConnectionPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewConnectionPaginator(filters []essdk.BoolFilter, limit *int64) (ConnectionPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_connections", filters, limit)
	if err != nil {
		return ConnectionPaginator{}, err
	}

	p := ConnectionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ConnectionPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ConnectionPaginator) NextPage(ctx context.Context) ([]Connection, error) {
	var response ConnectionSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []Connection
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listConnectionFilters = map[string]string{
	"id":               "description.Connection.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Connection.Name",
	"tags":             "description.Connection.Tags",
	"title":            "description.Connection.Name",
}

func ListConnection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListConnection")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewConnectionPaginator(essdk.BuildFilter(ctx, d.QueryContext, listConnectionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getConnectionFilters = map[string]string{
	"id":               "description.Connection.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Connection.Name",
	"tags":             "description.Connection.Tags",
	"title":            "description.Connection.Name",
}

func GetConnection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetConnection")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewConnectionPaginator(essdk.BuildFilter(ctx, d.QueryContext, getConnectionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: Connection =============================

// ==========================  START: VirtualHubs =============================

type VirtualHubs struct {
	Description   azure.VirtualHubsDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

func (r *VirtualHubs) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.VirtualHubsDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type VirtualHubsHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  VirtualHubs   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type VirtualHubsHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []VirtualHubsHit  `json:"hits"`
}

type VirtualHubsSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  VirtualHubsHits `json:"hits"`
}

type VirtualHubsPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewVirtualHubsPaginator(filters []essdk.BoolFilter, limit *int64) (VirtualHubsPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_virtualhubs", filters, limit)
	if err != nil {
		return VirtualHubsPaginator{}, err
	}

	p := VirtualHubsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p VirtualHubsPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p VirtualHubsPaginator) NextPage(ctx context.Context) ([]VirtualHubs, error) {
	var response VirtualHubsSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []VirtualHubs
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listVirtualHubsFilters = map[string]string{
	"id":               "description.VirtualHubs.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.VirtualHub.Name",
	"tags":             "description.VirtualHub.Tags",
	"title":            "description.VirtualHub.Name",
}

func ListVirtualHubs(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListVirtualHubs")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewVirtualHubsPaginator(essdk.BuildFilter(ctx, d.QueryContext, listVirtualHubsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getVirtualHubsFilters = map[string]string{
	"id":               "description.VirtualHubs.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.VirtualHub.Name",
	"tags":             "description.VirtualHub.Tags",
	"title":            "description.VirtualHub.Name",
}

func GetVirtualHubs(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetVirtualHubs")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewVirtualHubsPaginator(essdk.BuildFilter(ctx, d.QueryContext, getVirtualHubsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: VirtualHubs =============================

// ==========================  START: VirtualWans =============================

type VirtualWans struct {
	Description   azure.VirtualWansDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

func (r *VirtualWans) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.VirtualWansDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type VirtualWansHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  VirtualWans   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type VirtualWansHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []VirtualWansHit  `json:"hits"`
}

type VirtualWansSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  VirtualWansHits `json:"hits"`
}

type VirtualWansPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewVirtualWansPaginator(filters []essdk.BoolFilter, limit *int64) (VirtualWansPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_virtualwans", filters, limit)
	if err != nil {
		return VirtualWansPaginator{}, err
	}

	p := VirtualWansPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p VirtualWansPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p VirtualWansPaginator) NextPage(ctx context.Context) ([]VirtualWans, error) {
	var response VirtualWansSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []VirtualWans
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listVirtualWansFilters = map[string]string{
	"id":               "description.VirtualWans.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.VirtualWan.Name",
	"tags":             "description.VirtualWan.Tags",
	"title":            "description.VirtualWan.Name",
}

func ListVirtualWans(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListVirtualWans")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewVirtualWansPaginator(essdk.BuildFilter(ctx, d.QueryContext, listVirtualWansFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getVirtualWansFilters = map[string]string{
	"id":               "description.VirtualWans.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.VirtualWan.Name",
	"tags":             "description.VirtualWan.Tags",
	"title":            "description.VirtualWan.Name",
}

func GetVirtualWans(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetVirtualWans")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewVirtualWansPaginator(essdk.BuildFilter(ctx, d.QueryContext, getVirtualWansFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: VirtualWans =============================

// ==========================  START: DNSResolver =============================

type DNSResolver struct {
	Description   azure.DNSResolverDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

func (r *DNSResolver) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DNSResolverDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DNSResolverHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  DNSResolver   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type DNSResolverHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []DNSResolverHit  `json:"hits"`
}

type DNSResolverSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  DNSResolverHits `json:"hits"`
}

type DNSResolverPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDNSResolverPaginator(filters []essdk.BoolFilter, limit *int64) (DNSResolverPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_dnsresolvers", filters, limit)
	if err != nil {
		return DNSResolverPaginator{}, err
	}

	p := DNSResolverPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DNSResolverPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DNSResolverPaginator) NextPage(ctx context.Context) ([]DNSResolver, error) {
	var response DNSResolverSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DNSResolver
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDNSResolverFilters = map[string]string{
	"id":               "description.DNSResolver.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.DNSResolver.Name",
	"tags":             "description.DNSResolver.Tags",
	"title":            "description.DNSResolver.Name",
}

func ListDNSResolver(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDNSResolver")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDNSResolverPaginator(essdk.BuildFilter(ctx, d.QueryContext, listDNSResolverFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDNSResolverFilters = map[string]string{
	"id":               "description.DNSResolver.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.DNSResolver.Name",
	"tags":             "description.DNSResolver.Tags",
	"title":            "description.DNSResolver.Name",
}

func GetDNSResolver(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDNSResolver")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDNSResolverPaginator(essdk.BuildFilter(ctx, d.QueryContext, getDNSResolverFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DNSResolver =============================

// ==========================  START: TrafficManagerProfile =============================

type TrafficManagerProfile struct {
	Description   azure.TrafficManagerProfileDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

func (r *TrafficManagerProfile) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.TrafficManagerProfileDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type TrafficManagerProfileHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  TrafficManagerProfile `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type TrafficManagerProfileHits struct {
	Total essdk.SearchTotal          `json:"total"`
	Hits  []TrafficManagerProfileHit `json:"hits"`
}

type TrafficManagerProfileSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  TrafficManagerProfileHits `json:"hits"`
}

type TrafficManagerProfilePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewTrafficManagerProfilePaginator(filters []essdk.BoolFilter, limit *int64) (TrafficManagerProfilePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_trafficmanagerprofiles", filters, limit)
	if err != nil {
		return TrafficManagerProfilePaginator{}, err
	}

	p := TrafficManagerProfilePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p TrafficManagerProfilePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p TrafficManagerProfilePaginator) NextPage(ctx context.Context) ([]TrafficManagerProfile, error) {
	var response TrafficManagerProfileSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []TrafficManagerProfile
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listTrafficManagerProfileFilters = map[string]string{
	"id":    "description.Profile.ID",
	"name":  "description.Profile.Name",
	"tags":  "description.Profile.Tags",
	"title": "description.Profile.Name",
}

func ListTrafficManagerProfile(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListTrafficManagerProfile")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewTrafficManagerProfilePaginator(essdk.BuildFilter(ctx, d.QueryContext, listTrafficManagerProfileFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getTrafficManagerProfileFilters = map[string]string{
	"id":    "description.Profile.ID",
	"name":  "description.Profile.Name",
	"tags":  "description.Profile.Tags",
	"title": "description.Profile.Name",
}

func GetTrafficManagerProfile(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetTrafficManagerProfile")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewTrafficManagerProfilePaginator(essdk.BuildFilter(ctx, d.QueryContext, getTrafficManagerProfileFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: TrafficManagerProfile =============================

// ==========================  START: PrivateDNSZones =============================

type PrivateDNSZones struct {
	Description   azure.PrivateDNSZonesDescription `json:"description"`
	Metadata      azure.Metadata                   `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

func (r *PrivateDNSZones) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.PrivateDNSZonesDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type PrivateDNSZonesHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  PrivateDNSZones `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type PrivateDNSZonesHits struct {
	Total essdk.SearchTotal    `json:"total"`
	Hits  []PrivateDNSZonesHit `json:"hits"`
}

type PrivateDNSZonesSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  PrivateDNSZonesHits `json:"hits"`
}

type PrivateDNSZonesPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewPrivateDNSZonesPaginator(filters []essdk.BoolFilter, limit *int64) (PrivateDNSZonesPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_privatednszones", filters, limit)
	if err != nil {
		return PrivateDNSZonesPaginator{}, err
	}

	p := PrivateDNSZonesPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PrivateDNSZonesPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p PrivateDNSZonesPaginator) NextPage(ctx context.Context) ([]PrivateDNSZones, error) {
	var response PrivateDNSZonesSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PrivateDNSZones
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listPrivateDNSZonesFilters = map[string]string{
	"etag":                                "description.PrivateZone.Etag",
	"id":                                  "description.PrivateZone.ID",
	"kaytu_account_id":                    "metadata.SourceID",
	"max_number_of_record_sets":           "description.PrivateZone.Properties.MaxNumberOfRecordSets",
	"max_number_of_virtual_network_links": "description.PrivateZone.Properties.MaxNumberOfVirtualNetworkLinks",
	"max_number_of_virtual_network_links_with_registration": "description.PrivateZone.Properties.MaxNumberOfVirtualNetworkLinksWithRegistration",
	"name":                            "description.PrivateZone.Name",
	"number_of_record_sets":           "description.PrivateZone.Properties.NumberOfRecordSets",
	"number_of_virtual_network_links": "description.PrivateZone.Properties.NumberOfVirtualNetworkLinks",
	"number_of_virtual_network_links_with_registration": "description.PrivateZone.Properties.NumberOfVirtualNetworkLinksWithRegistration",
	"provisioning_state": "description.PrivateZone.Properties.ProvisioningState",
	"resource_group":     "description.ResourceGroup",
	"tags":               "description.PrivateZone.Tags",
	"title":              "description.PrivateZone.Name",
	"type":               "description.PrivateZone.Type",
}

func ListPrivateDNSZones(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPrivateDNSZones")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewPrivateDNSZonesPaginator(essdk.BuildFilter(ctx, d.QueryContext, listPrivateDNSZonesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPrivateDNSZonesFilters = map[string]string{
	"etag":                                "description.PrivateZone.Etag",
	"id":                                  "description.PrivateZone.ID",
	"kaytu_account_id":                    "metadata.SourceID",
	"max_number_of_record_sets":           "description.PrivateZone.Properties.MaxNumberOfRecordSets",
	"max_number_of_virtual_network_links": "description.PrivateZone.Properties.MaxNumberOfVirtualNetworkLinks",
	"max_number_of_virtual_network_links_with_registration": "description.PrivateZone.Properties.MaxNumberOfVirtualNetworkLinksWithRegistration",
	"name":                            "description.PrivateZone.Name",
	"number_of_record_sets":           "description.PrivateZone.Properties.NumberOfRecordSets",
	"number_of_virtual_network_links": "description.PrivateZone.Properties.NumberOfVirtualNetworkLinks",
	"number_of_virtual_network_links_with_registration": "description.PrivateZone.Properties.NumberOfVirtualNetworkLinksWithRegistration",
	"provisioning_state": "description.PrivateZone.Properties.ProvisioningState",
	"resource_group":     "description.ResourceGroup",
	"tags":               "description.PrivateZone.Tags",
	"title":              "description.PrivateZone.Name",
	"type":               "description.PrivateZone.Type",
}

func GetPrivateDNSZones(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPrivateDNSZones")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewPrivateDNSZonesPaginator(essdk.BuildFilter(ctx, d.QueryContext, getPrivateDNSZonesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PrivateDNSZones =============================

// ==========================  START: PrivateEndpoint =============================

type PrivateEndpoint struct {
	Description   azure.PrivateEndpointDescription `json:"description"`
	Metadata      azure.Metadata                   `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

func (r *PrivateEndpoint) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.PrivateEndpointDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type PrivateEndpointHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  PrivateEndpoint `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type PrivateEndpointHits struct {
	Total essdk.SearchTotal    `json:"total"`
	Hits  []PrivateEndpointHit `json:"hits"`
}

type PrivateEndpointSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  PrivateEndpointHits `json:"hits"`
}

type PrivateEndpointPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewPrivateEndpointPaginator(filters []essdk.BoolFilter, limit *int64) (PrivateEndpointPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_privateendpoints", filters, limit)
	if err != nil {
		return PrivateEndpointPaginator{}, err
	}

	p := PrivateEndpointPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PrivateEndpointPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p PrivateEndpointPaginator) NextPage(ctx context.Context) ([]PrivateEndpoint, error) {
	var response PrivateEndpointSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PrivateEndpoint
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listPrivateEndpointFilters = map[string]string{
	"id":               "description.PrivateEndpoints.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.PrivateEndpoint.Name",
	"tags":             "description.PrivateEndpoint.Tags",
	"title":            "description.PrivateEndpoint.Name",
}

func ListPrivateEndpoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPrivateEndpoint")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewPrivateEndpointPaginator(essdk.BuildFilter(ctx, d.QueryContext, listPrivateEndpointFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPrivateEndpointFilters = map[string]string{
	"id":               "description.PrivateEndpoints.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.PrivateEndpoint.Name",
	"tags":             "description.PrivateEndpoint.Tags",
	"title":            "description.PrivateEndpoint.Name",
}

func GetPrivateEndpoint(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPrivateEndpoint")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewPrivateEndpointPaginator(essdk.BuildFilter(ctx, d.QueryContext, getPrivateEndpointFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PrivateEndpoint =============================

// ==========================  START: NetworkDDoSProtectionPlan =============================

type NetworkDDoSProtectionPlan struct {
	Description   azure.NetworkDDoSProtectionPlanDescription `json:"description"`
	Metadata      azure.Metadata                             `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

func (r *NetworkDDoSProtectionPlan) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.NetworkDDoSProtectionPlanDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type NetworkDDoSProtectionPlanHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  NetworkDDoSProtectionPlan `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type NetworkDDoSProtectionPlanHits struct {
	Total essdk.SearchTotal              `json:"total"`
	Hits  []NetworkDDoSProtectionPlanHit `json:"hits"`
}

type NetworkDDoSProtectionPlanSearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  NetworkDDoSProtectionPlanHits `json:"hits"`
}

type NetworkDDoSProtectionPlanPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewNetworkDDoSProtectionPlanPaginator(filters []essdk.BoolFilter, limit *int64) (NetworkDDoSProtectionPlanPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_ddosprotectionplans", filters, limit)
	if err != nil {
		return NetworkDDoSProtectionPlanPaginator{}, err
	}

	p := NetworkDDoSProtectionPlanPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkDDoSProtectionPlanPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p NetworkDDoSProtectionPlanPaginator) NextPage(ctx context.Context) ([]NetworkDDoSProtectionPlan, error) {
	var response NetworkDDoSProtectionPlanSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkDDoSProtectionPlan
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkDDoSProtectionPlanFilters = map[string]string{
	"id":    "description.DDoSProtectionPlan.ID",
	"name":  "description.DDoSProtectionPlan.Name",
	"tags":  "description.DDoSProtectionPlan.Tags",
	"title": "description.DDoSProtectionPlan.Name",
}

func ListNetworkDDoSProtectionPlan(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkDDoSProtectionPlan")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewNetworkDDoSProtectionPlanPaginator(essdk.BuildFilter(ctx, d.QueryContext, listNetworkDDoSProtectionPlanFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkDDoSProtectionPlanFilters = map[string]string{
	"id":    "description.DDoSProtectionPlan.ID",
	"name":  "description.DDoSProtectionPlan.Name",
	"tags":  "description.DDoSProtectionPlan.Tags",
	"title": "description.DDoSProtectionPlan.Name",
}

func GetNetworkDDoSProtectionPlan(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkDDoSProtectionPlan")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewNetworkDDoSProtectionPlanPaginator(essdk.BuildFilter(ctx, d.QueryContext, getNetworkDDoSProtectionPlanFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkDDoSProtectionPlan =============================

// ==========================  START: PolicyAssignment =============================

type PolicyAssignment struct {
	Description   azure.PolicyAssignmentDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *PolicyAssignment) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.PolicyAssignmentDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type PolicyAssignmentHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  PolicyAssignment `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type PolicyAssignmentHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []PolicyAssignmentHit `json:"hits"`
}

type PolicyAssignmentSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  PolicyAssignmentHits `json:"hits"`
}

type PolicyAssignmentPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewPolicyAssignmentPaginator(filters []essdk.BoolFilter, limit *int64) (PolicyAssignmentPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_authorization_policyassignments", filters, limit)
	if err != nil {
		return PolicyAssignmentPaginator{}, err
	}

	p := PolicyAssignmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PolicyAssignmentPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p PolicyAssignmentPaginator) NextPage(ctx context.Context) ([]PolicyAssignment, error) {
	var response PolicyAssignmentSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PolicyAssignment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listPolicyAssignmentFilters = map[string]string{
	"description":          "description.Assignment.Properties.Description",
	"display_name":         "description.Assignment.Properties.DisplayName",
	"enforcement_mode":     "description.Assignment.Properties.EnforcementMode",
	"id":                   "description.Assignment.ID",
	"identity":             "description.Assignment.Identity",
	"kaytu_account_id":     "metadata.SourceID",
	"metadata":             "description.Assignment.Properties.Metadata",
	"name":                 "description.Assignment.Name",
	"not_scopes":           "description.Assignment.Properties.NotScopes",
	"parameters":           "description.Assignment.Properties.Parameters",
	"policy_definition_id": "description.Assignment.Properties.PolicyDefinitionID",
	"scope":                "description.Assignment.Properties.Scope",
	"sku_name":             "description.Resource.SKU.Name",
	"sku_tier":             "description.Resource.SKU.Tier",
	"title":                "description.Assignment.Name",
	"type":                 "description.Assignment.Type",
}

func ListPolicyAssignment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPolicyAssignment")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewPolicyAssignmentPaginator(essdk.BuildFilter(ctx, d.QueryContext, listPolicyAssignmentFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPolicyAssignmentFilters = map[string]string{
	"description":          "description.Assignment.Properties.Description",
	"display_name":         "description.Assignment.Properties.DisplayName",
	"enforcement_mode":     "description.Assignment.Properties.EnforcementMode",
	"id":                   "description.Assignment.ID",
	"identity":             "description.Assignment.Identity",
	"kaytu_account_id":     "metadata.SourceID",
	"metadata":             "description.Assignment.Properties.Metadata",
	"name":                 "description.Assignment.name",
	"not_scopes":           "description.Assignment.Properties.NotScopes",
	"parameters":           "description.Assignment.Properties.Parameters",
	"policy_definition_id": "description.Assignment.Properties.PolicyDefinitionID",
	"scope":                "description.Assignment.Properties.Scope",
	"sku_name":             "description.Resource.SKU.Name",
	"sku_tier":             "description.Resource.SKU.Tier",
	"title":                "description.Assignment.Name",
	"type":                 "description.Assignment.Type",
}

func GetPolicyAssignment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPolicyAssignment")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewPolicyAssignmentPaginator(essdk.BuildFilter(ctx, d.QueryContext, getPolicyAssignmentFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PolicyAssignment =============================

// ==========================  START: RedisCache =============================

type RedisCache struct {
	Description   azure.RedisCacheDescription `json:"description"`
	Metadata      azure.Metadata              `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

func (r *RedisCache) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.RedisCacheDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type RedisCacheHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  RedisCache    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type RedisCacheHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []RedisCacheHit   `json:"hits"`
}

type RedisCacheSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  RedisCacheHits `json:"hits"`
}

type RedisCachePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewRedisCachePaginator(filters []essdk.BoolFilter, limit *int64) (RedisCachePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_cache_redis", filters, limit)
	if err != nil {
		return RedisCachePaginator{}, err
	}

	p := RedisCachePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RedisCachePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p RedisCachePaginator) NextPage(ctx context.Context) ([]RedisCache, error) {
	var response RedisCacheSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RedisCache
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listRedisCacheFilters = map[string]string{
	"access_keys":                  "description.ResourceInfo.Properties.AccessKeys",
	"enable_non_ssl_port":          "description.ResourceInfo.Properties.EnableNonSSLPort",
	"host_name":                    "description.ResourceInfo.Properties.HostName",
	"id":                           "description.ResourceInfo.ID",
	"instances":                    "description.ResourceInfo.Properties.Instances",
	"kaytu_account_id":             "metadata.SourceID",
	"linked_servers":               "description.ResourceInfo.Properties.LinkedServers",
	"name":                         "description.ResourceInfo.Name",
	"port":                         "description.ResourceInfo.Properties.Port",
	"private_endpoint_connections": "description.ResourceInfo.Properties.PrivateEndpointConnections",
	"provisioning_state":           "description.ResourceInfo.Properties.ProvisioningState",
	"public_network_access":        "description.ResourceInfo.Properties.PublicNetworkAccess",
	"redis_configuration":          "description.ResourceInfo.Properties.RedisConfiguration",
	"redis_version":                "description.ResourceInfo.Properties.RedisVersion",
	"replicas_per_master":          "description.ResourceInfo.Properties.ReplicasPerMaster",
	"resource_group":               "description.ResourceGroup",
	"shard_count":                  "description.ResourceInfo.Properties.ShardCount",
	"sku_capacity":                 "description.ResourceInfo.Properties.SKU.Capacity",
	"sku_family":                   "description.ResourceInfo.Properties.SKU.Family",
	"sku_name":                     "description.ResourceInfo.Properties.SKU.Name",
	"ssl_port":                     "description.ResourceInfo.Properties.SSLPort",
	"static_ip":                    "description.ResourceInfo.Properties.StaticIP",
	"subnet_id":                    "description.ResourceInfo.Properties.SubnetID",
	"tags":                         "description.ResourceInfo.Tags",
	"tenant_settings":              "description.ResourceInfo.Properties.TenantSettings",
	"title":                        "description.ResourceInfo.Name",
	"type":                         "description.ResourceInfo.Type",
	"zones":                        "description.ResourceInfo.Zones",
}

func ListRedisCache(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRedisCache")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewRedisCachePaginator(essdk.BuildFilter(ctx, d.QueryContext, listRedisCacheFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRedisCacheFilters = map[string]string{
	"access_keys":                  "description.ResourceInfo.Properties.AccessKeys",
	"enable_non_ssl_port":          "description.ResourceInfo.Properties.EnableNonSSLPort",
	"host_name":                    "description.ResourceInfo.Properties.HostName",
	"id":                           "description.ResourceInfo.ID",
	"instances":                    "description.ResourceInfo.Properties.Instances",
	"kaytu_account_id":             "metadata.SourceID",
	"linked_servers":               "description.ResourceInfo.Properties.LinkedServers",
	"name":                         "description.ResourceType.name",
	"port":                         "description.ResourceInfo.Properties.Port",
	"private_endpoint_connections": "description.ResourceInfo.Properties.PrivateEndpointConnections",
	"provisioning_state":           "description.ResourceInfo.Properties.ProvisioningState",
	"public_network_access":        "description.ResourceInfo.Properties.PublicNetworkAccess",
	"redis_configuration":          "description.ResourceInfo.Properties.RedisConfiguration",
	"redis_version":                "description.ResourceInfo.Properties.RedisVersion",
	"replicas_per_master":          "description.ResourceInfo.Properties.ReplicasPerMaster",
	"resource_group":               "description.ResourceGroup",
	"shard_count":                  "description.ResourceInfo.Properties.ShardCount",
	"sku_capacity":                 "description.ResourceInfo.Properties.SKU.Capacity",
	"sku_family":                   "description.ResourceInfo.Properties.SKU.Family",
	"sku_name":                     "description.ResourceInfo.Properties.SKU.Name",
	"ssl_port":                     "description.ResourceInfo.Properties.SSLPort",
	"static_ip":                    "description.ResourceInfo.Properties.StaticIP",
	"subnet_id":                    "description.ResourceInfo.Properties.SubnetID",
	"tags":                         "description.ResourceInfo.Tags",
	"tenant_settings":              "description.ResourceInfo.Properties.TenantSettings",
	"title":                        "description.ResourceInfo.Name",
	"type":                         "description.ResourceInfo.Type",
	"zones":                        "description.ResourceInfo.Zones",
}

func GetRedisCache(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRedisCache")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewRedisCachePaginator(essdk.BuildFilter(ctx, d.QueryContext, getRedisCacheFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RedisCache =============================

// ==========================  START: RedisEnterpriseCache =============================

type RedisEnterpriseCache struct {
	Description   azure.RedisEnterpriseCacheDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

func (r *RedisEnterpriseCache) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.RedisEnterpriseCacheDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type RedisEnterpriseCacheHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  RedisEnterpriseCache `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type RedisEnterpriseCacheHits struct {
	Total essdk.SearchTotal         `json:"total"`
	Hits  []RedisEnterpriseCacheHit `json:"hits"`
}

type RedisEnterpriseCacheSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  RedisEnterpriseCacheHits `json:"hits"`
}

type RedisEnterpriseCachePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewRedisEnterpriseCachePaginator(filters []essdk.BoolFilter, limit *int64) (RedisEnterpriseCachePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_cache_redisenterprise", filters, limit)
	if err != nil {
		return RedisEnterpriseCachePaginator{}, err
	}

	p := RedisEnterpriseCachePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RedisEnterpriseCachePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p RedisEnterpriseCachePaginator) NextPage(ctx context.Context) ([]RedisEnterpriseCache, error) {
	var response RedisEnterpriseCacheSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RedisEnterpriseCache
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listRedisEnterpriseCacheFilters = map[string]string{
	"id":               "description.RedisEnterprise.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.RedisEnterprise.Name",
	"tags":             "description.RedisEnterprise.Tags",
	"title":            "description.RedisEnterprise.Name",
}

func ListRedisEnterpriseCache(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRedisEnterpriseCache")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewRedisEnterpriseCachePaginator(essdk.BuildFilter(ctx, d.QueryContext, listRedisEnterpriseCacheFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRedisEnterpriseCacheFilters = map[string]string{
	"id":               "description.RedisEnterprise.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.RedisEnterprise.Name",
	"tags":             "description.RedisEnterprise.Tags",
	"title":            "description.RedisEnterprise.Name",
}

func GetRedisEnterpriseCache(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRedisEnterpriseCache")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewRedisEnterpriseCachePaginator(essdk.BuildFilter(ctx, d.QueryContext, getRedisEnterpriseCacheFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RedisEnterpriseCache =============================

// ==========================  START: ResourceLink =============================

type ResourceLink struct {
	Description   azure.ResourceLinkDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

func (r *ResourceLink) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ResourceLinkDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ResourceLinkHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ResourceLink  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ResourceLinkHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []ResourceLinkHit `json:"hits"`
}

type ResourceLinkSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  ResourceLinkHits `json:"hits"`
}

type ResourceLinkPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewResourceLinkPaginator(filters []essdk.BoolFilter, limit *int64) (ResourceLinkPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_resources_links", filters, limit)
	if err != nil {
		return ResourceLinkPaginator{}, err
	}

	p := ResourceLinkPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ResourceLinkPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ResourceLinkPaginator) NextPage(ctx context.Context) ([]ResourceLink, error) {
	var response ResourceLinkSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ResourceLink
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listResourceLinkFilters = map[string]string{
	"id":               "description.ResourceLink.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.ResourceLink.Name",
	"notes":            "description.ResourceLink.Properties.Notes",
	"resource_group":   "description.ResourceLink.Properties.SourceID",
	"source_id":        "description.ResourceLink.Properties.SourceID",
	"target_id":        "description.ResourceLink.Properties.TargetID",
	"title":            "description.ResourceLink.Name",
	"type":             "description.ResourceLink.Type",
}

func ListResourceLink(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListResourceLink")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewResourceLinkPaginator(essdk.BuildFilter(ctx, d.QueryContext, listResourceLinkFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getResourceLinkFilters = map[string]string{
	"id":               "description.ResourceLink.id",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.ResourceLink.Name",
	"notes":            "description.ResourceLink.Properties.Notes",
	"resource_group":   "description.ResourceLink.Properties.SourceID",
	"source_id":        "description.ResourceLink.Properties.SourceID",
	"target_id":        "description.ResourceLink.Properties.TargetID",
	"title":            "description.ResourceLink.Name",
	"type":             "description.ResourceLink.Type",
}

func GetResourceLink(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetResourceLink")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewResourceLinkPaginator(essdk.BuildFilter(ctx, d.QueryContext, getResourceLinkFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ResourceLink =============================

// ==========================  START: RoleAssignment =============================

type RoleAssignment struct {
	Description   azure.RoleAssignmentDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

func (r *RoleAssignment) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.RoleAssignmentDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type RoleAssignmentHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  RoleAssignment `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type RoleAssignmentHits struct {
	Total essdk.SearchTotal   `json:"total"`
	Hits  []RoleAssignmentHit `json:"hits"`
}

type RoleAssignmentSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  RoleAssignmentHits `json:"hits"`
}

type RoleAssignmentPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewRoleAssignmentPaginator(filters []essdk.BoolFilter, limit *int64) (RoleAssignmentPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_authorization_roleassignment", filters, limit)
	if err != nil {
		return RoleAssignmentPaginator{}, err
	}

	p := RoleAssignmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RoleAssignmentPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p RoleAssignmentPaginator) NextPage(ctx context.Context) ([]RoleAssignment, error) {
	var response RoleAssignmentSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RoleAssignment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listRoleAssignmentFilters = map[string]string{
	"id":                 "description.RoleAssignment.ID",
	"kaytu_account_id":   "metadata.SourceID",
	"name":               "description.RoleAssignment.Name",
	"principal_id":       "description.RoleAssignment.Properties.PrincipalID",
	"principal_type":     "description.RoleAssignment.Properties.PrincipalType",
	"role_definition_id": "description.RoleAssignment.Properties.RoleDefinitionID",
	"scope":              "description.RoleAssignment.Properties.Scope",
	"title":              "description.RoleAssignment.Name",
	"type":               "description.RoleAssignment.Type",
}

func ListRoleAssignment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRoleAssignment")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewRoleAssignmentPaginator(essdk.BuildFilter(ctx, d.QueryContext, listRoleAssignmentFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRoleAssignmentFilters = map[string]string{
	"id":                 "description.RoleAssignment.id",
	"kaytu_account_id":   "metadata.SourceID",
	"name":               "description.RoleAssignment.Name",
	"principal_id":       "description.RoleAssignment.Properties.PrincipalID",
	"principal_type":     "description.RoleAssignment.Properties.PrincipalType",
	"role_definition_id": "description.RoleAssignment.Properties.RoleDefinitionID",
	"scope":              "description.RoleAssignment.Properties.Scope",
	"title":              "description.RoleAssignment.Name",
	"type":               "description.RoleAssignment.Type",
}

func GetRoleAssignment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRoleAssignment")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewRoleAssignmentPaginator(essdk.BuildFilter(ctx, d.QueryContext, getRoleAssignmentFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RoleAssignment =============================

// ==========================  START: RoleDefinition =============================

type RoleDefinition struct {
	Description   azure.RoleDefinitionDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

func (r *RoleDefinition) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.RoleDefinitionDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type RoleDefinitionHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  RoleDefinition `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type RoleDefinitionHits struct {
	Total essdk.SearchTotal   `json:"total"`
	Hits  []RoleDefinitionHit `json:"hits"`
}

type RoleDefinitionSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  RoleDefinitionHits `json:"hits"`
}

type RoleDefinitionPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewRoleDefinitionPaginator(filters []essdk.BoolFilter, limit *int64) (RoleDefinitionPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_authorization_roledefinitions", filters, limit)
	if err != nil {
		return RoleDefinitionPaginator{}, err
	}

	p := RoleDefinitionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RoleDefinitionPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p RoleDefinitionPaginator) NextPage(ctx context.Context) ([]RoleDefinition, error) {
	var response RoleDefinitionSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RoleDefinition
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listRoleDefinitionFilters = map[string]string{
	"assignable_scopes": "description.RoleDefinition.Properties.AssignableScopes",
	"description":       "description.RoleDefinition.Properties.Description",
	"id":                "description.RoleDefinition.ID",
	"kaytu_account_id":  "metadata.SourceID",
	"name":              "description.RoleDefinition.Name",
	"permissions":       "description.RoleDefinition.Properties.Permissions",
	"role_name":         "description.RoleDefinition.Properties.RoleName",
	"role_type":         "description.RoleDefinition.Properties.RoleType",
	"type":              "description.RoleDefinition.Type",
}

func ListRoleDefinition(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRoleDefinition")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewRoleDefinitionPaginator(essdk.BuildFilter(ctx, d.QueryContext, listRoleDefinitionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRoleDefinitionFilters = map[string]string{
	"assignable_scopes": "description.RoleDefinition.Properties.AssignableScopes",
	"description":       "description.RoleDefinition.Properties.Description",
	"id":                "description.RoleDefinition.ID",
	"kaytu_account_id":  "metadata.SourceID",
	"name":              "description.RoleDefinition.name",
	"permissions":       "description.RoleDefinition.Properties.Permissions",
	"role_name":         "description.RoleDefinition.Properties.RoleName",
	"role_type":         "description.RoleDefinition.Properties.RoleType",
	"type":              "description.RoleDefinition.Type",
}

func GetRoleDefinition(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRoleDefinition")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewRoleDefinitionPaginator(essdk.BuildFilter(ctx, d.QueryContext, getRoleDefinitionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RoleDefinition =============================

// ==========================  START: PolicyDefinition =============================

type PolicyDefinition struct {
	Description   azure.PolicyDefinitionDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *PolicyDefinition) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.PolicyDefinitionDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type PolicyDefinitionHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  PolicyDefinition `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type PolicyDefinitionHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []PolicyDefinitionHit `json:"hits"`
}

type PolicyDefinitionSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  PolicyDefinitionHits `json:"hits"`
}

type PolicyDefinitionPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewPolicyDefinitionPaginator(filters []essdk.BoolFilter, limit *int64) (PolicyDefinitionPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_authorization_policydefinitions", filters, limit)
	if err != nil {
		return PolicyDefinitionPaginator{}, err
	}

	p := PolicyDefinitionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PolicyDefinitionPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p PolicyDefinitionPaginator) NextPage(ctx context.Context) ([]PolicyDefinition, error) {
	var response PolicyDefinitionSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PolicyDefinition
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listPolicyDefinitionFilters = map[string]string{
	"akas":             "description.TurboData.Akas",
	"description":      "description.Definition.Properties.Description",
	"display_name":     "description.Definition.Properties.DisplayName",
	"id":               "ID",
	"kaytu_account_id": "metadata.SourceID",
	"metadata":         "description.Definition.Properties.Metadata",
	"mode":             "description.Definition.Properties.Mode",
	"name":             "description.Definition.Name",
	"parameters":       "description.Definition.Properties.Parameters",
	"policy_rule":      "description.Definition.Properties.PolicyRule",
	"policy_type":      "description.Definition.Properties.PolicyType",
	"title":            "description.Definition.Properties.DisplayName",
	"type":             "description.Definition.Type",
}

func ListPolicyDefinition(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPolicyDefinition")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewPolicyDefinitionPaginator(essdk.BuildFilter(ctx, d.QueryContext, listPolicyDefinitionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPolicyDefinitionFilters = map[string]string{
	"akas":             "description.TurboData.Akas",
	"description":      "description.Definition.Properties.Description",
	"display_name":     "description.Definition.Properties.DisplayName",
	"id":               "ID",
	"kaytu_account_id": "metadata.SourceID",
	"metadata":         "description.Definition.Properties.Metadata",
	"mode":             "description.Definition.Properties.Mode",
	"name":             "description.Definition.Name",
	"parameters":       "description.Definition.Properties.Parameters",
	"policy_rule":      "description.Definition.Properties.PolicyRule",
	"policy_type":      "description.Definition.Properties.PolicyType",
	"title":            "description.Definition.Properties.DisplayName",
	"type":             "description.Definition.Type",
}

func GetPolicyDefinition(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPolicyDefinition")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewPolicyDefinitionPaginator(essdk.BuildFilter(ctx, d.QueryContext, getPolicyDefinitionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PolicyDefinition =============================

// ==========================  START: SecurityCenterAutoProvisioning =============================

type SecurityCenterAutoProvisioning struct {
	Description   azure.SecurityCenterAutoProvisioningDescription `json:"description"`
	Metadata      azure.Metadata                                  `json:"metadata"`
	ResourceJobID int                                             `json:"resource_job_id"`
	SourceJobID   int                                             `json:"source_job_id"`
	ResourceType  string                                          `json:"resource_type"`
	SourceType    string                                          `json:"source_type"`
	ID            string                                          `json:"id"`
	ARN           string                                          `json:"arn"`
	SourceID      string                                          `json:"source_id"`
}

func (r *SecurityCenterAutoProvisioning) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SecurityCenterAutoProvisioningDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SecurityCenterAutoProvisioningHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  SecurityCenterAutoProvisioning `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type SecurityCenterAutoProvisioningHits struct {
	Total essdk.SearchTotal                   `json:"total"`
	Hits  []SecurityCenterAutoProvisioningHit `json:"hits"`
}

type SecurityCenterAutoProvisioningSearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  SecurityCenterAutoProvisioningHits `json:"hits"`
}

type SecurityCenterAutoProvisioningPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSecurityCenterAutoProvisioningPaginator(filters []essdk.BoolFilter, limit *int64) (SecurityCenterAutoProvisioningPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_security_autoprovisioningsettings", filters, limit)
	if err != nil {
		return SecurityCenterAutoProvisioningPaginator{}, err
	}

	p := SecurityCenterAutoProvisioningPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityCenterAutoProvisioningPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SecurityCenterAutoProvisioningPaginator) NextPage(ctx context.Context) ([]SecurityCenterAutoProvisioning, error) {
	var response SecurityCenterAutoProvisioningSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityCenterAutoProvisioning
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityCenterAutoProvisioningFilters = map[string]string{
	"auto_provision":   "description.AutoProvisioningSetting.Properties.AutoProvision",
	"id":               "description.AutoProvisioningSetting.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.AutoProvisioningSetting.Name",
	"title":            "description.AutoProvisioningSetting.Name",
	"type":             "description.AutoProvisioningSetting.Type",
}

func ListSecurityCenterAutoProvisioning(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityCenterAutoProvisioning")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSecurityCenterAutoProvisioningPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSecurityCenterAutoProvisioningFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityCenterAutoProvisioningFilters = map[string]string{
	"auto_provision":   "description.AutoProvisioningSetting.Properties.AutoProvision",
	"id":               "description.AutoProvisioningSetting.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.AutoProvisioningSetting.name",
	"title":            "description.AutoProvisioningSetting.Name",
	"type":             "description.AutoProvisioningSetting.Type",
}

func GetSecurityCenterAutoProvisioning(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityCenterAutoProvisioning")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSecurityCenterAutoProvisioningPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSecurityCenterAutoProvisioningFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityCenterAutoProvisioning =============================

// ==========================  START: SecurityCenterContact =============================

type SecurityCenterContact struct {
	Description   azure.SecurityCenterContactDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

func (r *SecurityCenterContact) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SecurityCenterContactDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SecurityCenterContactHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  SecurityCenterContact `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type SecurityCenterContactHits struct {
	Total essdk.SearchTotal          `json:"total"`
	Hits  []SecurityCenterContactHit `json:"hits"`
}

type SecurityCenterContactSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  SecurityCenterContactHits `json:"hits"`
}

type SecurityCenterContactPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSecurityCenterContactPaginator(filters []essdk.BoolFilter, limit *int64) (SecurityCenterContactPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_security_securitycontacts", filters, limit)
	if err != nil {
		return SecurityCenterContactPaginator{}, err
	}

	p := SecurityCenterContactPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityCenterContactPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SecurityCenterContactPaginator) NextPage(ctx context.Context) ([]SecurityCenterContact, error) {
	var response SecurityCenterContactSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityCenterContact
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityCenterContactFilters = map[string]string{
	"alert_notifications": "description.Contact.Properties.AlertNotifications",
	"alerts_to_admins":    "description.Contact.Properties.AlertNotifications",
	"email":               "description.Contact.Properties.Emails",
	"id":                  "description.Contact.ID",
	"kaytu_account_id":    "metadata.SourceID",
	"name":                "description.Contact.Name",
	"phone":               "description.Contact.Properties.Phone",
	"title":               "description.Contact.Name",
	"type":                "description.Contact.Type",
}

func ListSecurityCenterContact(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityCenterContact")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSecurityCenterContactPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSecurityCenterContactFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityCenterContactFilters = map[string]string{
	"alert_notifications": "description.Contact.Properties.AlertNotifications",
	"alerts_to_admins":    "description.Contact.Properties.AlertNotifications",
	"email":               "description.Contact.Properties.Emails",
	"id":                  "description.Contact.ID",
	"kaytu_account_id":    "metadata.SourceID",
	"name":                "description.Contact.name",
	"phone":               "description.Contact.Properties.Phone",
	"title":               "description.Contact.Name",
	"type":                "description.Contact.Type",
}

func GetSecurityCenterContact(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityCenterContact")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSecurityCenterContactPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSecurityCenterContactFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityCenterContact =============================

// ==========================  START: SecurityCenterJitNetworkAccessPolicy =============================

type SecurityCenterJitNetworkAccessPolicy struct {
	Description   azure.SecurityCenterJitNetworkAccessPolicyDescription `json:"description"`
	Metadata      azure.Metadata                                        `json:"metadata"`
	ResourceJobID int                                                   `json:"resource_job_id"`
	SourceJobID   int                                                   `json:"source_job_id"`
	ResourceType  string                                                `json:"resource_type"`
	SourceType    string                                                `json:"source_type"`
	ID            string                                                `json:"id"`
	ARN           string                                                `json:"arn"`
	SourceID      string                                                `json:"source_id"`
}

func (r *SecurityCenterJitNetworkAccessPolicy) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SecurityCenterJitNetworkAccessPolicyDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SecurityCenterJitNetworkAccessPolicyHit struct {
	ID      string                               `json:"_id"`
	Score   float64                              `json:"_score"`
	Index   string                               `json:"_index"`
	Type    string                               `json:"_type"`
	Version int64                                `json:"_version,omitempty"`
	Source  SecurityCenterJitNetworkAccessPolicy `json:"_source"`
	Sort    []interface{}                        `json:"sort"`
}

type SecurityCenterJitNetworkAccessPolicyHits struct {
	Total essdk.SearchTotal                         `json:"total"`
	Hits  []SecurityCenterJitNetworkAccessPolicyHit `json:"hits"`
}

type SecurityCenterJitNetworkAccessPolicySearchResponse struct {
	PitID string                                   `json:"pit_id"`
	Hits  SecurityCenterJitNetworkAccessPolicyHits `json:"hits"`
}

type SecurityCenterJitNetworkAccessPolicyPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSecurityCenterJitNetworkAccessPolicyPaginator(filters []essdk.BoolFilter, limit *int64) (SecurityCenterJitNetworkAccessPolicyPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_security_locations_jitnetworkaccesspolicies", filters, limit)
	if err != nil {
		return SecurityCenterJitNetworkAccessPolicyPaginator{}, err
	}

	p := SecurityCenterJitNetworkAccessPolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityCenterJitNetworkAccessPolicyPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SecurityCenterJitNetworkAccessPolicyPaginator) NextPage(ctx context.Context) ([]SecurityCenterJitNetworkAccessPolicy, error) {
	var response SecurityCenterJitNetworkAccessPolicySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityCenterJitNetworkAccessPolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityCenterJitNetworkAccessPolicyFilters = map[string]string{
	"id":                 "description.JitNetworkAccessPolicy.ID",
	"kaytu_account_id":   "metadata.SourceID",
	"kind":               "description.JitNetworkAccessPolicy.Kind",
	"name":               "description.JitNetworkAccessPolicy.Name",
	"provisioning_state": "description.JitNetworkAccessPolicy.Properties.ProvisioningState",
	"title":              "description.JitNetworkAccessPolicy.Name",
	"type":               "description.JitNetworkAccessPolicy.Type",
	"virtual_machines":   "description.JitNetworkAccessPolicy.Properties.VirtualMachines",
}

func ListSecurityCenterJitNetworkAccessPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityCenterJitNetworkAccessPolicy")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSecurityCenterJitNetworkAccessPolicyPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSecurityCenterJitNetworkAccessPolicyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityCenterJitNetworkAccessPolicyFilters = map[string]string{
	"id":                 "description.JitNetworkAccessPolicy.ID",
	"kaytu_account_id":   "metadata.SourceID",
	"kind":               "description.JitNetworkAccessPolicy.Kind",
	"name":               "description.JitNetworkAccessPolicy.Name",
	"provisioning_state": "description.JitNetworkAccessPolicy.Properties.ProvisioningState",
	"title":              "description.JitNetworkAccessPolicy.Name",
	"type":               "description.JitNetworkAccessPolicy.Type",
	"virtual_machines":   "description.JitNetworkAccessPolicy.Properties.VirtualMachines",
}

func GetSecurityCenterJitNetworkAccessPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityCenterJitNetworkAccessPolicy")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSecurityCenterJitNetworkAccessPolicyPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSecurityCenterJitNetworkAccessPolicyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityCenterJitNetworkAccessPolicy =============================

// ==========================  START: SecurityCenterSetting =============================

type SecurityCenterSetting struct {
	Description   azure.SecurityCenterSettingDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

func (r *SecurityCenterSetting) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SecurityCenterSettingDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SecurityCenterSettingHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  SecurityCenterSetting `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type SecurityCenterSettingHits struct {
	Total essdk.SearchTotal          `json:"total"`
	Hits  []SecurityCenterSettingHit `json:"hits"`
}

type SecurityCenterSettingSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  SecurityCenterSettingHits `json:"hits"`
}

type SecurityCenterSettingPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSecurityCenterSettingPaginator(filters []essdk.BoolFilter, limit *int64) (SecurityCenterSettingPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_security_settings", filters, limit)
	if err != nil {
		return SecurityCenterSettingPaginator{}, err
	}

	p := SecurityCenterSettingPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityCenterSettingPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SecurityCenterSettingPaginator) NextPage(ctx context.Context) ([]SecurityCenterSetting, error) {
	var response SecurityCenterSettingSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityCenterSetting
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityCenterSettingFilters = map[string]string{
	"enabled":          "description.ExportSettingStatus",
	"id":               "description.Setting.ID",
	"kaytu_account_id": "metadata.SourceID",
	"kind":             "description.Setting.Kind",
	"name":             "description.Setting.Name",
	"title":            "description.Setting.Name",
	"type":             "description.Setting.Type",
}

func ListSecurityCenterSetting(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityCenterSetting")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSecurityCenterSettingPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSecurityCenterSettingFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityCenterSettingFilters = map[string]string{
	"enabled":          "description.ExportSettingStatus",
	"id":               "description.Setting.ID",
	"kaytu_account_id": "metadata.SourceID",
	"kind":             "description.Setting.Kind",
	"name":             "description.Setting.name",
	"title":            "description.Setting.Name",
	"type":             "description.Setting.Type",
}

func GetSecurityCenterSetting(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityCenterSetting")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSecurityCenterSettingPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSecurityCenterSettingFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityCenterSetting =============================

// ==========================  START: SecurityCenterSubscriptionPricing =============================

type SecurityCenterSubscriptionPricing struct {
	Description   azure.SecurityCenterSubscriptionPricingDescription `json:"description"`
	Metadata      azure.Metadata                                     `json:"metadata"`
	ResourceJobID int                                                `json:"resource_job_id"`
	SourceJobID   int                                                `json:"source_job_id"`
	ResourceType  string                                             `json:"resource_type"`
	SourceType    string                                             `json:"source_type"`
	ID            string                                             `json:"id"`
	ARN           string                                             `json:"arn"`
	SourceID      string                                             `json:"source_id"`
}

func (r *SecurityCenterSubscriptionPricing) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SecurityCenterSubscriptionPricingDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SecurityCenterSubscriptionPricingHit struct {
	ID      string                            `json:"_id"`
	Score   float64                           `json:"_score"`
	Index   string                            `json:"_index"`
	Type    string                            `json:"_type"`
	Version int64                             `json:"_version,omitempty"`
	Source  SecurityCenterSubscriptionPricing `json:"_source"`
	Sort    []interface{}                     `json:"sort"`
}

type SecurityCenterSubscriptionPricingHits struct {
	Total essdk.SearchTotal                      `json:"total"`
	Hits  []SecurityCenterSubscriptionPricingHit `json:"hits"`
}

type SecurityCenterSubscriptionPricingSearchResponse struct {
	PitID string                                `json:"pit_id"`
	Hits  SecurityCenterSubscriptionPricingHits `json:"hits"`
}

type SecurityCenterSubscriptionPricingPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSecurityCenterSubscriptionPricingPaginator(filters []essdk.BoolFilter, limit *int64) (SecurityCenterSubscriptionPricingPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_security_pricings", filters, limit)
	if err != nil {
		return SecurityCenterSubscriptionPricingPaginator{}, err
	}

	p := SecurityCenterSubscriptionPricingPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityCenterSubscriptionPricingPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SecurityCenterSubscriptionPricingPaginator) NextPage(ctx context.Context) ([]SecurityCenterSubscriptionPricing, error) {
	var response SecurityCenterSubscriptionPricingSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityCenterSubscriptionPricing
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityCenterSubscriptionPricingFilters = map[string]string{
	"free_trial_remaining_time": "description.Pricing.Properties.FreeTrialRemainingTime",
	"id":                        "description.Pricing.ID",
	"kaytu_account_id":          "metadata.SourceID",
	"name":                      "description.Pricing.Name",
	"pricing_tier":              "description.Pricing.Properties.PricingTier",
	"title":                     "description.Pricing.Name",
	"type":                      "description.Pricing.Type",
}

func ListSecurityCenterSubscriptionPricing(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityCenterSubscriptionPricing")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSecurityCenterSubscriptionPricingPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSecurityCenterSubscriptionPricingFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityCenterSubscriptionPricingFilters = map[string]string{
	"free_trial_remaining_time": "description.Pricing.Properties.FreeTrialRemainingTime",
	"id":                        "description.Pricing.ID",
	"kaytu_account_id":          "metadata.SourceID",
	"name":                      "description.Pricing.Name",
	"pricing_tier":              "description.Pricing.Properties.PricingTier",
	"title":                     "description.Pricing.Name",
	"type":                      "description.Pricing.Type",
}

func GetSecurityCenterSubscriptionPricing(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityCenterSubscriptionPricing")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSecurityCenterSubscriptionPricingPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSecurityCenterSubscriptionPricingFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityCenterSubscriptionPricing =============================

// ==========================  START: SecurityCenterAutomation =============================

type SecurityCenterAutomation struct {
	Description   azure.SecurityCenterAutomationDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

func (r *SecurityCenterAutomation) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SecurityCenterAutomationDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SecurityCenterAutomationHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  SecurityCenterAutomation `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type SecurityCenterAutomationHits struct {
	Total essdk.SearchTotal             `json:"total"`
	Hits  []SecurityCenterAutomationHit `json:"hits"`
}

type SecurityCenterAutomationSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  SecurityCenterAutomationHits `json:"hits"`
}

type SecurityCenterAutomationPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSecurityCenterAutomationPaginator(filters []essdk.BoolFilter, limit *int64) (SecurityCenterAutomationPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_security_automations", filters, limit)
	if err != nil {
		return SecurityCenterAutomationPaginator{}, err
	}

	p := SecurityCenterAutomationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityCenterAutomationPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SecurityCenterAutomationPaginator) NextPage(ctx context.Context) ([]SecurityCenterAutomation, error) {
	var response SecurityCenterAutomationSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityCenterAutomation
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityCenterAutomationFilters = map[string]string{
	"actions":          "description.Automation.Properties.Actions",
	"description":      "description.Automation.Properties.Description",
	"etag":             "description.Automation.Etag",
	"id":               "description.Automation.ID",
	"is_enabled":       "description.Automation.Properties.IsEnabled",
	"kaytu_account_id": "metadata.SourceID",
	"kind":             "description.Automation.Kind",
	"name":             "description.Automation.Name",
	"resource_group":   "description.ResourceGroup",
	"scopes":           "description.Automation.Properties.Scopes",
	"sources":          "description.Automation.Properties.Sources",
	"tags":             "description.Automation.Tags",
	"title":            "description.Automation.Name",
	"type":             "description.Automation.Type",
}

func ListSecurityCenterAutomation(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityCenterAutomation")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSecurityCenterAutomationPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSecurityCenterAutomationFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityCenterAutomationFilters = map[string]string{
	"actions":          "description.Automation.Properties.Actions",
	"description":      "description.Automation.Properties.Description",
	"etag":             "description.Automation.Etag",
	"id":               "description.Automation.ID",
	"is_enabled":       "description.Automation.Properties.IsEnabled",
	"kaytu_account_id": "metadata.SourceID",
	"kind":             "description.Automation.Kind",
	"name":             "description.Automation.name",
	"resource_group":   "description.ResourceGroup",
	"scopes":           "description.Automation.Properties.Scopes",
	"sources":          "description.Automation.Properties.Sources",
	"tags":             "description.Automation.Tags",
	"title":            "description.Automation.Name",
	"type":             "description.Automation.Type",
}

func GetSecurityCenterAutomation(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityCenterAutomation")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSecurityCenterAutomationPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSecurityCenterAutomationFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityCenterAutomation =============================

// ==========================  START: SecurityCenterSubAssessment =============================

type SecurityCenterSubAssessment struct {
	Description   azure.SecurityCenterSubAssessmentDescription `json:"description"`
	Metadata      azure.Metadata                               `json:"metadata"`
	ResourceJobID int                                          `json:"resource_job_id"`
	SourceJobID   int                                          `json:"source_job_id"`
	ResourceType  string                                       `json:"resource_type"`
	SourceType    string                                       `json:"source_type"`
	ID            string                                       `json:"id"`
	ARN           string                                       `json:"arn"`
	SourceID      string                                       `json:"source_id"`
}

func (r *SecurityCenterSubAssessment) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SecurityCenterSubAssessmentDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SecurityCenterSubAssessmentHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  SecurityCenterSubAssessment `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type SecurityCenterSubAssessmentHits struct {
	Total essdk.SearchTotal                `json:"total"`
	Hits  []SecurityCenterSubAssessmentHit `json:"hits"`
}

type SecurityCenterSubAssessmentSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  SecurityCenterSubAssessmentHits `json:"hits"`
}

type SecurityCenterSubAssessmentPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSecurityCenterSubAssessmentPaginator(filters []essdk.BoolFilter, limit *int64) (SecurityCenterSubAssessmentPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_security_subassessments", filters, limit)
	if err != nil {
		return SecurityCenterSubAssessmentPaginator{}, err
	}

	p := SecurityCenterSubAssessmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityCenterSubAssessmentPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SecurityCenterSubAssessmentPaginator) NextPage(ctx context.Context) ([]SecurityCenterSubAssessment, error) {
	var response SecurityCenterSubAssessmentSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityCenterSubAssessment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityCenterSubAssessmentFilters = map[string]string{
	"category":         "description.SubAssessment.Properties.Category",
	"description":      "description.SubAssessment.Properties.Description",
	"display_name":     "description.SubAssessment.Properties.DisplayName",
	"id":               "description.SubAssessment.ID",
	"impact":           "description.SubAssessment.Properties.Impact",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.SubAssessment.Name",
	"remediation":      "description.SubAssessment.Properties.Remediation",
	"resource_group":   "description.ResourceGroup",
	"time_generated":   "description.SubAssessment.Properties.TimeGenerated",
	"title":            "description.SubAssessment.Name",
	"type":             "description.SubAssessment.Type",
}

func ListSecurityCenterSubAssessment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityCenterSubAssessment")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSecurityCenterSubAssessmentPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSecurityCenterSubAssessmentFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityCenterSubAssessmentFilters = map[string]string{
	"category":         "description.SubAssessment.Properties.Category",
	"description":      "description.SubAssessment.Properties.Description",
	"display_name":     "description.SubAssessment.Properties.DisplayName",
	"id":               "description.SubAssessment.ID",
	"impact":           "description.SubAssessment.Properties.Impact",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.SubAssessment.Name",
	"remediation":      "description.SubAssessment.Properties.Remediation",
	"resource_group":   "description.ResourceGroup",
	"time_generated":   "description.SubAssessment.Properties.TimeGenerated",
	"title":            "description.SubAssessment.Name",
	"type":             "description.SubAssessment.Type",
}

func GetSecurityCenterSubAssessment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityCenterSubAssessment")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSecurityCenterSubAssessmentPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSecurityCenterSubAssessmentFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityCenterSubAssessment =============================

// ==========================  START: StorageContainer =============================

type StorageContainer struct {
	Description   azure.StorageContainerDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *StorageContainer) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.StorageContainerDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type StorageContainerHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  StorageContainer `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type StorageContainerHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []StorageContainerHit `json:"hits"`
}

type StorageContainerSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  StorageContainerHits `json:"hits"`
}

type StorageContainerPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewStorageContainerPaginator(filters []essdk.BoolFilter, limit *int64) (StorageContainerPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_storage_storageaccounts_blobservices_containers", filters, limit)
	if err != nil {
		return StorageContainerPaginator{}, err
	}

	p := StorageContainerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageContainerPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p StorageContainerPaginator) NextPage(ctx context.Context) ([]StorageContainer, error) {
	var response StorageContainerSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageContainer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listStorageContainerFilters = map[string]string{
	"account_name":                   "description.AccountName",
	"default_encryption_scope":       "description.ListContainerItem.Properties.DefaultEncryptionScope",
	"deleted":                        "description.ListContainerItem.Properties.Deleted",
	"deny_encryption_scope_override": "description.ListContainerItem.Properties.DenyEncryptionScopeOverride",
	"has_immutability_policy":        "description.ListContainerItem.Properties.HasImmutabilityPolicy",
	"has_legal_hold":                 "description.ListContainerItem.Properties.HasLegalHold",
	"id":                             "description.ListContainerItem.ID",
	"immutability_policy":            "description.ImmutabilityPolicy",
	"kaytu_account_id":               "metadata.SourceID",
	"lease_duration":                 "description.ListContainerItem.Properties.LeaseDuration",
	"lease_state":                    "description.ListContainerItem.Properties.LeaseState",
	"lease_status":                   "description.ListContainerItem.Properties.LeaseStatus",
	"legal_hold":                     "description.ListContainerItem.Properties.LegalHold",
	"metadata":                       "description.ListContainerItem.Properties.Metadata",
	"name":                           "description.ListContainerItem.Name",
	"public_access":                  "description.ListContainerItem.Properties.PublicAccess",
	"remaining_retention_days":       "description.ListContainerItem.Properties.RemainingRetentionDays",
	"resource_group":                 "description.ResourceGroup",
	"title":                          "description.ListContainerItem.Name",
	"type":                           "description.ListContainerItem.Type",
	"version":                        "description.ListContainerItem.Properties.Version",
}

func ListStorageContainer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageContainer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewStorageContainerPaginator(essdk.BuildFilter(ctx, d.QueryContext, listStorageContainerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageContainerFilters = map[string]string{
	"account_name":                   "description.AccountName",
	"default_encryption_scope":       "description.ListContainerItem.Properties.DefaultEncryptionScope",
	"deleted":                        "description.ListContainerItem.Properties.Deleted",
	"deny_encryption_scope_override": "description.ListContainerItem.Properties.DenyEncryptionScopeOverride",
	"has_immutability_policy":        "description.ListContainerItem.Properties.HasImmutabilityPolicy",
	"has_legal_hold":                 "description.ListContainerItem.Properties.HasLegalHold",
	"id":                             "description.ListContainerItem.ID",
	"immutability_policy":            "description.ImmutabilityPolicy",
	"kaytu_account_id":               "metadata.SourceID",
	"lease_duration":                 "description.ListContainerItem.Properties.LeaseDuration",
	"lease_state":                    "description.ListContainerItem.Properties.LeaseState",
	"lease_status":                   "description.ListContainerItem.Properties.LeaseStatus",
	"legal_hold":                     "description.ListContainerItem.Properties.LegalHold",
	"metadata":                       "description.ListContainerItem.Properties.Metadata",
	"name":                           "description.ListContainerItem.name",
	"public_access":                  "description.ListContainerItem.Properties.PublicAccess",
	"remaining_retention_days":       "description.ListContainerItem.Properties.RemainingRetentionDays",
	"resource_group":                 "description.ResourceGroup",
	"title":                          "description.ListContainerItem.Name",
	"type":                           "description.ListContainerItem.Type",
	"version":                        "description.ListContainerItem.Properties.Version",
}

func GetStorageContainer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageContainer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewStorageContainerPaginator(essdk.BuildFilter(ctx, d.QueryContext, getStorageContainerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageContainer =============================

// ==========================  START: StorageBlob =============================

type StorageBlob struct {
	Description   azure.StorageBlobDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

func (r *StorageBlob) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.StorageBlobDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type StorageBlobHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  StorageBlob   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type StorageBlobHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []StorageBlobHit  `json:"hits"`
}

type StorageBlobSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  StorageBlobHits `json:"hits"`
}

type StorageBlobPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewStorageBlobPaginator(filters []essdk.BoolFilter, limit *int64) (StorageBlobPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_storage_blobs", filters, limit)
	if err != nil {
		return StorageBlobPaginator{}, err
	}

	p := StorageBlobPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageBlobPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p StorageBlobPaginator) NextPage(ctx context.Context) ([]StorageBlob, error) {
	var response StorageBlobSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageBlob
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listStorageBlobFilters = map[string]string{
	"access_tier":              "description.Blob.Properties.AccessTier",
	"access_tier_change_time":  "description.Blob.Properties.AccessTierChangeTime",
	"access_tier_inferred":     "description.Blob.Properties.AccessTierInferred",
	"archive_status":           "description.Blob.Properties.ArchiveStatus",
	"blob_sequence_number":     "description.Blob.Properties.BlobSequenceNumber",
	"blob_tag_set":             "description.Blob.BlobTags.BlobTagSet",
	"cache_control":            "description.Blob.Properties.CacheControl",
	"container_name":           "description.ContainerName",
	"content_disposition":      "description.Blob.Properties.ContentDisposition",
	"content_encoding":         "description.Blob.Properties.ContentEncoding",
	"content_language":         "description.Blob.Properties.ContentLanguage",
	"content_length":           "description.Blob.Properties.ContentLength",
	"content_md5":              "description.Blob.Properties.ContentMD5",
	"content_type":             "description.Blob.Properties.ContentType",
	"copy_completion_time":     "description.Blob.Properties.CopyCompletionTime",
	"copy_id":                  "description.Blob.Properties.CopyID",
	"copy_progress":            "description.Blob.Properties.CopyProgress",
	"copy_source":              "description.Blob.Properties.CopySource",
	"copy_status":              "description.Blob.Properties.CopyStatus",
	"copy_status_description":  "description.Blob.Properties.CopyStatusDescription",
	"creation_time":            "description.Blob.Properties.CreationTime",
	"deleted":                  "description.Blob.Deleted",
	"deleted_time":             "description.Blob.Properties.DeletedTime",
	"destination_snapshot":     "description.Blob.Properties.DestinationSnapshot",
	"encryption_key_sha256":    "description.Blob.Properties.CustomerProvidedKeySha256",
	"encryption_scope":         "description.Blob.Properties.EncryptionScope",
	"etag":                     "description.Blob.Properties.Etag",
	"incremental_copy":         "description.Blob.Properties.IncrementalCopy",
	"is_current_version":       "description.Blob.IsCurrentVersion",
	"is_sealed":                "description.Blob.Properties.IsSealed",
	"is_snapshot":              "description.IsSnapshot",
	"kaytu_account_id":         "metadata.SourceID",
	"last_modified":            "description.Blob.Properties.LastModified",
	"lease_duration":           "description.Blob.Properties.LeaseDuration",
	"lease_state":              "description.Blob.Properties.LeaseState",
	"lease_status":             "description.Blob.Properties.LeaseStatus",
	"metadata":                 "description.Blob.Metadata",
	"name":                     "description.Blob.Name",
	"remaining_retention_days": "description.Blob.Properties.RemainingRetentionDays",
	"resource_group":           "description.ResourceGroup",
	"server_encrypted":         "description.Blob.Properties.ServerEncrypted",
	"snapshot":                 "description.Blob.Snapshot",
	"storage_account_name":     "description.AccountName",
	"title":                    "description.Blob.Name",
	"type":                     "description.Blob.Properties.BlobType",
	"version_id":               "description.Blob.VersionID",
}

func ListStorageBlob(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageBlob")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewStorageBlobPaginator(essdk.BuildFilter(ctx, d.QueryContext, listStorageBlobFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageBlobFilters = map[string]string{
	"access_tier":              "description.Blob.Properties.AccessTier",
	"access_tier_change_time":  "description.Blob.Properties.AccessTierChangeTime",
	"access_tier_inferred":     "description.Blob.Properties.AccessTierInferred",
	"archive_status":           "description.Blob.Properties.ArchiveStatus",
	"blob_sequence_number":     "description.Blob.Properties.BlobSequenceNumber",
	"blob_tag_set":             "description.Blob.BlobTags.BlobTagSet",
	"cache_control":            "description.Blob.Properties.CacheControl",
	"container_name":           "description.ContainerName",
	"content_disposition":      "description.Blob.Properties.ContentDisposition",
	"content_encoding":         "description.Blob.Properties.ContentEncoding",
	"content_language":         "description.Blob.Properties.ContentLanguage",
	"content_length":           "description.Blob.Properties.ContentLength",
	"content_md5":              "description.Blob.Properties.ContentMD5",
	"content_type":             "description.Blob.Properties.ContentType",
	"copy_completion_time":     "description.Blob.Properties.CopyCompletionTime",
	"copy_id":                  "description.Blob.Properties.CopyID",
	"copy_progress":            "description.Blob.Properties.CopyProgress",
	"copy_source":              "description.Blob.Properties.CopySource",
	"copy_status":              "description.Blob.Properties.CopyStatus",
	"copy_status_description":  "description.Blob.Properties.CopyStatusDescription",
	"creation_time":            "description.Blob.Properties.CreationTime",
	"deleted":                  "description.Blob.Deleted",
	"deleted_time":             "description.Blob.Properties.DeletedTime",
	"destination_snapshot":     "description.Blob.Properties.DestinationSnapshot",
	"encryption_key_sha256":    "description.Blob.Properties.CustomerProvidedKeySha256",
	"encryption_scope":         "description.Blob.Properties.EncryptionScope",
	"etag":                     "description.Blob.Properties.Etag",
	"incremental_copy":         "description.Blob.Properties.IncrementalCopy",
	"is_current_version":       "description.Blob.IsCurrentVersion",
	"is_sealed":                "description.Blob.Properties.IsSealed",
	"is_snapshot":              "description.IsSnapshot",
	"kaytu_account_id":         "metadata.SourceID",
	"last_modified":            "description.Blob.Properties.LastModified",
	"lease_duration":           "description.Blob.Properties.LeaseDuration",
	"lease_state":              "description.Blob.Properties.LeaseState",
	"lease_status":             "description.Blob.Properties.LeaseStatus",
	"metadata":                 "description.Blob.Metadata",
	"name":                     "description.Blob.Name",
	"remaining_retention_days": "description.Blob.Properties.RemainingRetentionDays",
	"server_encrypted":         "description.Blob.Properties.ServerEncrypted",
	"snapshot":                 "description.Blob.Snapshot",
	"storage_account_name":     "description.AccountName",
	"title":                    "description.Blob.Name",
	"type":                     "description.Blob.Properties.BlobType",
	"version_id":               "description.Blob.VersionID",
}

func GetStorageBlob(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageBlob")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewStorageBlobPaginator(essdk.BuildFilter(ctx, d.QueryContext, getStorageBlobFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageBlob =============================

// ==========================  START: StorageBlobService =============================

type StorageBlobService struct {
	Description   azure.StorageBlobServiceDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

func (r *StorageBlobService) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.StorageBlobServiceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type StorageBlobServiceHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  StorageBlobService `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type StorageBlobServiceHits struct {
	Total essdk.SearchTotal       `json:"total"`
	Hits  []StorageBlobServiceHit `json:"hits"`
}

type StorageBlobServiceSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  StorageBlobServiceHits `json:"hits"`
}

type StorageBlobServicePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewStorageBlobServicePaginator(filters []essdk.BoolFilter, limit *int64) (StorageBlobServicePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_storage_blobservives", filters, limit)
	if err != nil {
		return StorageBlobServicePaginator{}, err
	}

	p := StorageBlobServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageBlobServicePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p StorageBlobServicePaginator) NextPage(ctx context.Context) ([]StorageBlobService, error) {
	var response StorageBlobServiceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageBlobService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listStorageBlobServiceFilters = map[string]string{
	"automatic_snapshot_policy_enabled": "description.BlobService.BlobServiceProperties.AutomaticSnapshotPolicyEnabled",
	"change_feed_enabled":               "description.BlobService.BlobServiceProperties.ChangeFeed.Enabled",
	"container_delete_retention_policy": "description.BlobService.BlobServiceProperties.ContainerDeleteRetentionPolicy",
	"cors_rules":                        "description.BlobService.BlobServiceProperties.Cors.CorsRules",
	"default_service_version":           "description.BlobService.BlobServiceProperties.DefaultServiceVersion",
	"delete_retention_policy":           "description.BlobService.BlobServiceProperties.ContainerDeleteRetentionPolicy",
	"id":                                "description.BlobService.ID",
	"is_versioning_enabled":             "description.BlobService.BlobServiceProperties.IsVersioningEnabled",
	"kaytu_account_id":                  "metadata.SourceID",
	"name":                              "description.BlobService.Name",
	"resource_group":                    "description.ResourceGroup",
	"restore_policy":                    "description.BlobService.BlobServiceProperties.RestorePolicy",
	"sku_name":                          "description.BlobService.SKU.Name",
	"sku_tier":                          "description.BlobService.SKU.Tier",
	"storage_account_name":              "description.AccountName",
	"title":                             "description.BlobService.Name",
	"type":                              "description.BlobService.Type",
}

func ListStorageBlobService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageBlobService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewStorageBlobServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, listStorageBlobServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageBlobServiceFilters = map[string]string{
	"automatic_snapshot_policy_enabled": "description.BlobService.BlobServiceProperties.AutomaticSnapshotPolicyEnabled",
	"change_feed_enabled":               "description.BlobService.BlobServiceProperties.ChangeFeed.Enabled",
	"container_delete_retention_policy": "description.BlobService.BlobServiceProperties.ContainerDeleteRetentionPolicy",
	"cors_rules":                        "description.BlobService.BlobServiceProperties.Cors.CorsRules",
	"default_service_version":           "description.BlobService.BlobServiceProperties.DefaultServiceVersion",
	"delete_retention_policy":           "description.BlobService.BlobServiceProperties.ContainerDeleteRetentionPolicy",
	"id":                                "description.BlobService.ID",
	"is_versioning_enabled":             "description.BlobService.BlobServiceProperties.IsVersioningEnabled",
	"kaytu_account_id":                  "metadata.SourceID",
	"name":                              "description.BlobService.Name",
	"resource_group":                    "description.ResourceGroup",
	"restore_policy":                    "description.BlobService.BlobServiceProperties.RestorePolicy",
	"sku_name":                          "description.BlobService.SKU.Name",
	"sku_tier":                          "description.BlobService.SKU.Tier",
	"storage_account_name":              "description.AccountName",
	"title":                             "description.BlobService.Name",
	"type":                              "description.BlobService.Type",
}

func GetStorageBlobService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageBlobService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewStorageBlobServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, getStorageBlobServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageBlobService =============================

// ==========================  START: StorageQueue =============================

type StorageQueue struct {
	Description   azure.StorageQueueDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

func (r *StorageQueue) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.StorageQueueDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type StorageQueueHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  StorageQueue  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type StorageQueueHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []StorageQueueHit `json:"hits"`
}

type StorageQueueSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  StorageQueueHits `json:"hits"`
}

type StorageQueuePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewStorageQueuePaginator(filters []essdk.BoolFilter, limit *int64) (StorageQueuePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_storage_queues", filters, limit)
	if err != nil {
		return StorageQueuePaginator{}, err
	}

	p := StorageQueuePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageQueuePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p StorageQueuePaginator) NextPage(ctx context.Context) ([]StorageQueue, error) {
	var response StorageQueueSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageQueue
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listStorageQueueFilters = map[string]string{
	"id":                   "description.Queue.ID",
	"kaytu_account_id":     "metadata.SourceID",
	"metadata":             "description.Queue.QueueProperties.Metadata",
	"name":                 "description.Queue.Name",
	"resource_group":       "description.ResourceGroup",
	"storage_account_name": "description.AccountName",
	"title":                "description.Queue.Name",
	"type":                 "description.Queue.Type",
}

func ListStorageQueue(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageQueue")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewStorageQueuePaginator(essdk.BuildFilter(ctx, d.QueryContext, listStorageQueueFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageQueueFilters = map[string]string{
	"id":                   "description.Queue.ID",
	"kaytu_account_id":     "metadata.SourceID",
	"metadata":             "description.Queue.QueueProperties.Metadata",
	"name":                 "description.Queue.Name",
	"resource_group":       "description.ResourceGroup",
	"storage_account_name": "description.AccountName",
	"title":                "description.Queue.Name",
	"type":                 "description.Queue.Type",
}

func GetStorageQueue(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageQueue")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewStorageQueuePaginator(essdk.BuildFilter(ctx, d.QueryContext, getStorageQueueFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageQueue =============================

// ==========================  START: StorageFileShare =============================

type StorageFileShare struct {
	Description   azure.StorageFileShareDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *StorageFileShare) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.StorageFileShareDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type StorageFileShareHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  StorageFileShare `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type StorageFileShareHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []StorageFileShareHit `json:"hits"`
}

type StorageFileShareSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  StorageFileShareHits `json:"hits"`
}

type StorageFileSharePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewStorageFileSharePaginator(filters []essdk.BoolFilter, limit *int64) (StorageFileSharePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_storage_fileshares", filters, limit)
	if err != nil {
		return StorageFileSharePaginator{}, err
	}

	p := StorageFileSharePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageFileSharePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p StorageFileSharePaginator) NextPage(ctx context.Context) ([]StorageFileShare, error) {
	var response StorageFileShareSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageFileShare
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listStorageFileShareFilters = map[string]string{
	"access_tier":              "description.FileShare.Properties.AccessTier",
	"access_tier_status":       "description.FileShare.Properties.AccessTierStatus",
	"deleted":                  "description.FileShare.Properties.Deleted",
	"enabled_protocols":        "description.FileShare.Properties.EnabledProtocols",
	"id":                       "description.FileShare.ID",
	"kaytu_account_id":         "metadata.SourceID",
	"metadata":                 "description.FileShare.Properties.Metadata",
	"name":                     "description.FileShare.Name",
	"remaining_retention_days": "description.FileShare.Properties.RemainingRetentionDays",
	"resource_group":           "description.ResourceGroup",
	"root_squash":              "description.FileShare.Properties.RootSquash",
	"share_quota":              "description.FileShare.Properties.ShareQuota",
	"share_usage_bytes":        "description.FileShare.Properties.ShareUsageBytes",
	"storage_account_name":     "description.AccountName",
	"title":                    "description.FileShare.Name",
	"type":                     "description.FileShare.Type",
	"version":                  "description.FileShare.Properties.Version",
}

func ListStorageFileShare(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageFileShare")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewStorageFileSharePaginator(essdk.BuildFilter(ctx, d.QueryContext, listStorageFileShareFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageFileShareFilters = map[string]string{
	"access_tier":              "description.FileShare.Properties.AccessTier",
	"access_tier_status":       "description.FileShare.Properties.AccessTierStatus",
	"deleted":                  "description.FileShare.Properties.Deleted",
	"enabled_protocols":        "description.FileShare.Properties.EnabledProtocols",
	"id":                       "description.FileShare.ID",
	"kaytu_account_id":         "metadata.SourceID",
	"metadata":                 "description.FileShare.Properties.Metadata",
	"name":                     "description.FileShare.Name",
	"remaining_retention_days": "description.FileShare.Properties.RemainingRetentionDays",
	"root_squash":              "description.FileShare.Properties.RootSquash",
	"share_quota":              "description.FileShare.Properties.ShareQuota",
	"share_usage_bytes":        "description.FileShare.Properties.ShareUsageBytes",
	"storage_account_name":     "description.AccountName",
	"title":                    "description.FileShare.Name",
	"type":                     "description.FileShare.Type",
	"version":                  "description.FileShare.Properties.Version",
}

func GetStorageFileShare(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageFileShare")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewStorageFileSharePaginator(essdk.BuildFilter(ctx, d.QueryContext, getStorageFileShareFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageFileShare =============================

// ==========================  START: StorageTable =============================

type StorageTable struct {
	Description   azure.StorageTableDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

func (r *StorageTable) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.StorageTableDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type StorageTableHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  StorageTable  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type StorageTableHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []StorageTableHit `json:"hits"`
}

type StorageTableSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  StorageTableHits `json:"hits"`
}

type StorageTablePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewStorageTablePaginator(filters []essdk.BoolFilter, limit *int64) (StorageTablePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_storage_tables", filters, limit)
	if err != nil {
		return StorageTablePaginator{}, err
	}

	p := StorageTablePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageTablePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p StorageTablePaginator) NextPage(ctx context.Context) ([]StorageTable, error) {
	var response StorageTableSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageTable
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listStorageTableFilters = map[string]string{
	"id":                   "description.Table.ID",
	"kaytu_account_id":     "metadata.SourceID",
	"name":                 "description.Table.Name",
	"resource_group":       "description.ResourceGroup",
	"storage_account_name": "description.AccountName",
	"title":                "description.Table.Name",
	"type":                 "description.Table.Type",
}

func ListStorageTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageTable")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewStorageTablePaginator(essdk.BuildFilter(ctx, d.QueryContext, listStorageTableFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageTableFilters = map[string]string{
	"id":                   "description.Table.ID",
	"kaytu_account_id":     "metadata.SourceID",
	"name":                 "description.Table.Name",
	"storage_account_name": "description.AccountName",
	"title":                "description.Table.Name",
	"type":                 "description.Table.Type",
}

func GetStorageTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageTable")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewStorageTablePaginator(essdk.BuildFilter(ctx, d.QueryContext, getStorageTableFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageTable =============================

// ==========================  START: StorageTableService =============================

type StorageTableService struct {
	Description   azure.StorageTableServiceDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

func (r *StorageTableService) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.StorageTableServiceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type StorageTableServiceHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  StorageTableService `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type StorageTableServiceHits struct {
	Total essdk.SearchTotal        `json:"total"`
	Hits  []StorageTableServiceHit `json:"hits"`
}

type StorageTableServiceSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  StorageTableServiceHits `json:"hits"`
}

type StorageTableServicePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewStorageTableServicePaginator(filters []essdk.BoolFilter, limit *int64) (StorageTableServicePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_storage_tableservices", filters, limit)
	if err != nil {
		return StorageTableServicePaginator{}, err
	}

	p := StorageTableServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageTableServicePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p StorageTableServicePaginator) NextPage(ctx context.Context) ([]StorageTableService, error) {
	var response StorageTableServiceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageTableService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listStorageTableServiceFilters = map[string]string{
	"cors_rules":           "description.TableService.TableServiceProperties.Cors.CorsRules",
	"id":                   "description.TableService.ID",
	"kaytu_account_id":     "metadata.SourceID",
	"name":                 "description.TableService.Name",
	"resource_group":       "description.ResourceGroup",
	"storage_account_name": "description.AccountName",
	"title":                "description.TableService.Name",
	"type":                 "description.TableService.Type",
}

func ListStorageTableService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageTableService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewStorageTableServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, listStorageTableServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageTableServiceFilters = map[string]string{
	"cors_rules":           "description.TableService.TableServiceProperties.Cors.CorsRules",
	"id":                   "description.TableService.ID",
	"kaytu_account_id":     "metadata.SourceID",
	"name":                 "description.TableService.Name",
	"storage_account_name": "description.AccountName",
	"title":                "description.TableService.Name",
	"type":                 "description.TableService.Type",
}

func GetStorageTableService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageTableService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewStorageTableServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, getStorageTableServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageTableService =============================

// ==========================  START: Subnet =============================

type Subnet struct {
	Description   azure.SubnetDescription `json:"description"`
	Metadata      azure.Metadata          `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

func (r *Subnet) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SubnetDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SubnetHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  Subnet        `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type SubnetHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []SubnetHit       `json:"hits"`
}

type SubnetSearchResponse struct {
	PitID string     `json:"pit_id"`
	Hits  SubnetHits `json:"hits"`
}

type SubnetPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSubnetPaginator(filters []essdk.BoolFilter, limit *int64) (SubnetPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_virtualnetworks_subnets", filters, limit)
	if err != nil {
		return SubnetPaginator{}, err
	}

	p := SubnetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SubnetPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SubnetPaginator) NextPage(ctx context.Context) ([]Subnet, error) {
	var response SubnetSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []Subnet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSubnetFilters = map[string]string{
	"address_prefix":                        "description.Subnet.Properties.AddressPrefix",
	"delegations":                           "description.Subnet.Properties.Delegations",
	"etag":                                  "description.Subnet.Etag",
	"id":                                    "description.Subnet.ID",
	"kaytu_account_id":                      "metadata.SourceID",
	"name":                                  "description.Subnet.Name",
	"nat_gateway_id":                        "description.Subnet.Properties.NatGateway.ID",
	"network_security_group_id":             "description.Subnet.Properties.NetworkSecurityGroup.ID",
	"private_endpoint_network_policies":     "description.Subnet.Properties.PrivateEndpointNetworkPolicies",
	"private_link_service_network_policies": "description.Subnet.Properties.PrivateLinkServiceNetworkPolicies",
	"provisioning_state":                    "description.Subnet.Properties.ProvisioningState",
	"route_table_id":                        "description.Subnet.Properties.RouteTable.ID",
	"service_endpoint_policies":             "description.Subnet.Properties.ServiceEndpointPolicies",
	"service_endpoints":                     "description.Subnet.Properties.ServiceEndpoints",
	"title":                                 "description.Subnet.Name",
	"type":                                  "description.Subnet.Properties.RouteTable.Type",
	"virtual_network_name":                  "description.VirtualNetworkName",
}

func ListSubnet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSubnet")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSubnetPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSubnetFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSubnetFilters = map[string]string{
	"address_prefix":                        "description.Subnet.Properties.AddressPrefix",
	"delegations":                           "description.Subnet.Properties.Delegations",
	"etag":                                  "description.Subnet.Etag",
	"id":                                    "description.Subnet.ID",
	"kaytu_account_id":                      "metadata.SourceID",
	"name":                                  "description.Subnet.name",
	"nat_gateway_id":                        "description.Subnet.Properties.NatGateway.ID",
	"network_security_group_id":             "description.Subnet.Properties.NetworkSecurityGroup.ID",
	"private_endpoint_network_policies":     "description.Subnet.Properties.PrivateEndpointNetworkPolicies",
	"private_link_service_network_policies": "description.Subnet.Properties.PrivateLinkServiceNetworkPolicies",
	"provisioning_state":                    "description.Subnet.Properties.ProvisioningState",
	"resource_group":                        "description.ResourceGroup",
	"route_table_id":                        "description.Subnet.Properties.RouteTable.ID",
	"service_endpoint_policies":             "description.Subnet.Properties.ServiceEndpointPolicies",
	"service_endpoints":                     "description.Subnet.Properties.ServiceEndpoints",
	"title":                                 "description.Subnet.Name",
	"type":                                  "description.Subnet.Properties.RouteTable.Type",
	"virtual_network_name":                  "description.VirtualNetworkName",
}

func GetSubnet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSubnet")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSubnetPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSubnetFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: Subnet =============================

// ==========================  START: VirtualNetwork =============================

type VirtualNetwork struct {
	Description   azure.VirtualNetworkDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

func (r *VirtualNetwork) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.VirtualNetworkDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type VirtualNetworkHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  VirtualNetwork `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type VirtualNetworkHits struct {
	Total essdk.SearchTotal   `json:"total"`
	Hits  []VirtualNetworkHit `json:"hits"`
}

type VirtualNetworkSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  VirtualNetworkHits `json:"hits"`
}

type VirtualNetworkPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewVirtualNetworkPaginator(filters []essdk.BoolFilter, limit *int64) (VirtualNetworkPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_virtualnetworks", filters, limit)
	if err != nil {
		return VirtualNetworkPaginator{}, err
	}

	p := VirtualNetworkPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p VirtualNetworkPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p VirtualNetworkPaginator) NextPage(ctx context.Context) ([]VirtualNetwork, error) {
	var response VirtualNetworkSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []VirtualNetwork
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listVirtualNetworkFilters = map[string]string{
	"address_prefixes":       "description.VirtualNetwork.Properties.AddressSpace.AddressPrefixes",
	"enable_ddos_protection": "description.VirtualNetwork.Properties.EnableDdosProtection",
	"enable_vm_protection":   "description.VirtualNetwork.Properties.EnableVMProtection",
	"etag":                   "description.VirtualNetwork.Etag",
	"id":                     "description.VirtualNetwork.ID",
	"kaytu_account_id":       "metadata.SourceID",
	"name":                   "description.VirtualNetwork.Name",
	"network_peerings":       "description.VirtualNetwork.Properties.VirtualNetworkPeerings",
	"provisioning_state":     "description.VirtualNetwork.Properties.ProvisioningState",
	"resource_group":         "description.ResourceGroup",
	"resource_guid":          "description.VirtualNetwork.Properties.ResourceGUID",
	"subnets":                "description.VirtualNetwork.Properties.Subnets",
	"tags":                   "description.VirtualNetwork.Tags",
	"title":                  "description.VirtualNetwork.Name",
	"type":                   "description.VirtualNetwork.Type",
}

func ListVirtualNetwork(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListVirtualNetwork")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewVirtualNetworkPaginator(essdk.BuildFilter(ctx, d.QueryContext, listVirtualNetworkFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getVirtualNetworkFilters = map[string]string{
	"address_prefixes":       "description.VirtualNetwork.Properties.AddressSpace.AddressPrefixes",
	"enable_ddos_protection": "description.VirtualNetwork.Properties.EnableDdosProtection",
	"enable_vm_protection":   "description.VirtualNetwork.Properties.EnableVMProtection",
	"etag":                   "description.VirtualNetwork.Etag",
	"id":                     "description.VirtualNetwork.ID",
	"kaytu_account_id":       "metadata.SourceID",
	"name":                   "description.VirtualNetwork.name",
	"network_peerings":       "description.VirtualNetwork.Properties.VirtualNetworkPeerings",
	"provisioning_state":     "description.VirtualNetwork.Properties.ProvisioningState",
	"resource_group":         "description.ResourceGroup",
	"resource_guid":          "description.VirtualNetwork.Properties.ResourceGUID",
	"subnets":                "description.VirtualNetwork.Properties.Subnets",
	"tags":                   "description.VirtualNetwork.Tags",
	"title":                  "description.VirtualNetwork.Name",
	"type":                   "description.VirtualNetwork.Type",
}

func GetVirtualNetwork(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetVirtualNetwork")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewVirtualNetworkPaginator(essdk.BuildFilter(ctx, d.QueryContext, getVirtualNetworkFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: VirtualNetwork =============================

// ==========================  START: Tenant =============================

type Tenant struct {
	Description   azure.TenantDescription `json:"description"`
	Metadata      azure.Metadata          `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

func (r *Tenant) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.TenantDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type TenantHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  Tenant        `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type TenantHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []TenantHit       `json:"hits"`
}

type TenantSearchResponse struct {
	PitID string     `json:"pit_id"`
	Hits  TenantHits `json:"hits"`
}

type TenantPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewTenantPaginator(filters []essdk.BoolFilter, limit *int64) (TenantPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_resources_tenants", filters, limit)
	if err != nil {
		return TenantPaginator{}, err
	}

	p := TenantPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p TenantPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p TenantPaginator) NextPage(ctx context.Context) ([]Tenant, error) {
	var response TenantSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []Tenant
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listTenantFilters = map[string]string{
	"display_name":     "description.TenantIDDescription.Name",
	"id":               "description.TenantIDDescription.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.TenantIDDescription.Name",
	"tenant_category":  "TenantCategory",
	"tenant_id":        "description.TenantIDDescription.TenantID",
	"title":            "description.TenantIDDescription.Name",
}

func ListTenant(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListTenant")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewTenantPaginator(essdk.BuildFilter(ctx, d.QueryContext, listTenantFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getTenantFilters = map[string]string{
	"display_name":     "description.TenantIDDescription.Name",
	"id":               "description.TenantIDDescription.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.TenantIDDescription.Name",
	"tenant_category":  "TenantCategory",
	"tenant_id":        "description.TenantIDDescription.TenantID",
	"title":            "description.TenantIDDescription.Name",
}

func GetTenant(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetTenant")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewTenantPaginator(essdk.BuildFilter(ctx, d.QueryContext, getTenantFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: Tenant =============================

// ==========================  START: Subscription =============================

type Subscription struct {
	Description   azure.SubscriptionDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

func (r *Subscription) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SubscriptionDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SubscriptionHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  Subscription  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type SubscriptionHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []SubscriptionHit `json:"hits"`
}

type SubscriptionSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  SubscriptionHits `json:"hits"`
}

type SubscriptionPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSubscriptionPaginator(filters []essdk.BoolFilter, limit *int64) (SubscriptionPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_resources_subscriptions", filters, limit)
	if err != nil {
		return SubscriptionPaginator{}, err
	}

	p := SubscriptionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SubscriptionPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SubscriptionPaginator) NextPage(ctx context.Context) ([]Subscription, error) {
	var response SubscriptionSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []Subscription
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSubscriptionFilters = map[string]string{
	"authorization_source":  "description.Subscription.AuthorizationSource",
	"cloud_environment":     "description.Subscription.SubscriptionPolicies",
	"display_name":          "description.Subscription.DisplayName",
	"id":                    "description.Subscription.ID",
	"kaytu_account_id":      "metadata.SourceID",
	"state":                 "description.Subscription.State",
	"subscription_id":       "description.Subscription.SubscriptionID",
	"subscription_policies": "description.Subscription.SubscriptionPolicies",
	"tenant_id":             "TenantID",
	"title":                 "description.Subscription.DisplayName",
}

func ListSubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSubscription")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSubscriptionPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSubscriptionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSubscriptionFilters = map[string]string{
	"authorization_source":  "description.Subscription.AuthorizationSource",
	"cloud_environment":     "description.Subscription.SubscriptionPolicies",
	"display_name":          "description.Subscription.DisplayName",
	"id":                    "description.Subscription.ID",
	"kaytu_account_id":      "metadata.SourceID",
	"state":                 "description.Subscription.State",
	"subscription_id":       "description.Subscription.SubscriptionID",
	"subscription_policies": "description.Subscription.SubscriptionPolicies",
	"tenant_id":             "TenantID",
	"title":                 "description.Subscription.DisplayName",
}

func GetSubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSubscription")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSubscriptionPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSubscriptionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: Subscription =============================

// ==========================  START: ApplicationGateway =============================

type ApplicationGateway struct {
	Description   azure.ApplicationGatewayDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

func (r *ApplicationGateway) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ApplicationGatewayDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ApplicationGatewayHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  ApplicationGateway `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type ApplicationGatewayHits struct {
	Total essdk.SearchTotal       `json:"total"`
	Hits  []ApplicationGatewayHit `json:"hits"`
}

type ApplicationGatewaySearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  ApplicationGatewayHits `json:"hits"`
}

type ApplicationGatewayPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewApplicationGatewayPaginator(filters []essdk.BoolFilter, limit *int64) (ApplicationGatewayPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_applicationgateways", filters, limit)
	if err != nil {
		return ApplicationGatewayPaginator{}, err
	}

	p := ApplicationGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApplicationGatewayPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ApplicationGatewayPaginator) NextPage(ctx context.Context) ([]ApplicationGateway, error) {
	var response ApplicationGatewaySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApplicationGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listApplicationGatewayFilters = map[string]string{
	"autoscale_configuration":                "description.ApplicationGateway.Properties.AutoscaleConfiguration",
	"custom_error_configurations":            "description.ApplicationGateway.Properties.CustomErrorConfigurations",
	"diagnostic_settings":                    "description.DiagnosticSettingsResources",
	"enable_fips":                            "description.ApplicationGateway.Properties.EnableFips",
	"enable_http2":                           "description.ApplicationGateway.Properties.EnableHTTP2",
	"etag":                                   "description.ApplicationGateway.Etag",
	"firewall_policy":                        "description.ApplicationGateway.Properties.FirewallPolicy",
	"force_firewall_policy_association":      "description.ApplicationGateway.Properties.ForceFirewallPolicyAssociation",
	"id":                                     "description.ApplicationGateway.ID",
	"identity":                               "description.ApplicationGateway.Identity",
	"kaytu_account_id":                       "metadata.SourceID",
	"name":                                   "description.ApplicationGateway.Name",
	"operational_state":                      "description.ApplicationGateway.Properties.OperationalState",
	"provisioning_state":                     "description.ApplicationGateway.Properties.ProvisioningState",
	"redirect_configurations":                "description.ApplicationGateway.Properties.RedirectConfigurations",
	"resource_group":                         "description.ResourceGroup",
	"resource_guid":                          "description.ApplicationGateway.Properties.ResourceGUID",
	"sku":                                    "description.ApplicationGateway.Properties.SKU",
	"ssl_policy":                             "description.ApplicationGateway.Properties.SSLPolicy",
	"tags":                                   "description.ApplicationGateway.Tags",
	"title":                                  "description.ApplicationGateway.Name",
	"type":                                   "description.ApplicationGateway.Type",
	"web_application_firewall_configuration": "description.ApplicationGateway.Properties.WebApplicationFirewallConfiguration",
	"zones":                                  "description.ApplicationGateway.Zones",
}

func ListApplicationGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApplicationGateway")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewApplicationGatewayPaginator(essdk.BuildFilter(ctx, d.QueryContext, listApplicationGatewayFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApplicationGatewayFilters = map[string]string{
	"autoscale_configuration":                "description.ApplicationGateway.Properties.AutoscaleConfiguration",
	"custom_error_configurations":            "description.ApplicationGateway.Properties.CustomErrorConfigurations",
	"diagnostic_settings":                    "description.DiagnosticSettingsResources",
	"enable_fips":                            "description.ApplicationGateway.Properties.EnableFips",
	"enable_http2":                           "description.ApplicationGateway.Properties.EnableHTTP2",
	"etag":                                   "description.ApplicationGateway.Etag",
	"firewall_policy":                        "description.ApplicationGateway.Properties.FirewallPolicy",
	"force_firewall_policy_association":      "description.ApplicationGateway.Properties.ForceFirewallPolicyAssociation",
	"id":                                     "description.ApplicationGateway.ID",
	"identity":                               "description.ApplicationGateway.Identity",
	"kaytu_account_id":                       "metadata.SourceID",
	"name":                                   "description.ApplicationGateway.name",
	"operational_state":                      "description.ApplicationGateway.Properties.OperationalState",
	"provisioning_state":                     "description.ApplicationGateway.Properties.ProvisioningState",
	"redirect_configurations":                "description.ApplicationGateway.Properties.RedirectConfigurations",
	"resource_group":                         "description.ResourceGroup",
	"resource_guid":                          "description.ApplicationGateway.Properties.ResourceGUID",
	"sku":                                    "description.ApplicationGateway.Properties.SKU",
	"ssl_policy":                             "description.ApplicationGateway.Properties.SSLPolicy",
	"tags":                                   "description.ApplicationGateway.Tags",
	"title":                                  "description.ApplicationGateway.Name",
	"type":                                   "description.ApplicationGateway.Type",
	"web_application_firewall_configuration": "description.ApplicationGateway.Properties.WebApplicationFirewallConfiguration",
	"zones":                                  "description.ApplicationGateway.Zones",
}

func GetApplicationGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApplicationGateway")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewApplicationGatewayPaginator(essdk.BuildFilter(ctx, d.QueryContext, getApplicationGatewayFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApplicationGateway =============================

// ==========================  START: BatchAccount =============================

type BatchAccount struct {
	Description   azure.BatchAccountDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

func (r *BatchAccount) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.BatchAccountDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type BatchAccountHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  BatchAccount  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type BatchAccountHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []BatchAccountHit `json:"hits"`
}

type BatchAccountSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  BatchAccountHits `json:"hits"`
}

type BatchAccountPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewBatchAccountPaginator(filters []essdk.BoolFilter, limit *int64) (BatchAccountPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_batch_batchaccounts", filters, limit)
	if err != nil {
		return BatchAccountPaginator{}, err
	}

	p := BatchAccountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BatchAccountPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p BatchAccountPaginator) NextPage(ctx context.Context) ([]BatchAccount, error) {
	var response BatchAccountSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BatchAccount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listBatchAccountFilters = map[string]string{
	"account_endpoint":                            "description.Account.Properties.AccountEndpoint",
	"active_job_and_job_schedule_quota":           "description.Account.Properties.ActiveJobAndJobScheduleQuota",
	"auto_storage":                                "description.Account.Properties.AutoStorage",
	"dedicated_core_quota":                        "description.Account.Properties.DedicatedCoreQuota",
	"dedicated_core_quota_per_vm_family":          "description.Account.Properties.DedicatedCoreQuotaPerVMFamily",
	"dedicated_core_quota_per_vm_family_enforced": "description.Account.Properties.DedicatedCoreQuotaPerVMFamilyEnforced",
	"diagnostic_settings":                         "description.DiagnosticSettingsResources",
	"encryption":                                  "description.Account.Properties.Encryption",
	"id":                                          "description.Account.ID",
	"identity":                                    "description.Account.Identity",
	"kaytu_account_id":                            "metadata.SourceID",
	"key_vault_reference":                         "description.Account.Properties.KeyVaultReference",
	"low_priority_core_quota":                     "description.Account.Properties.LowPriorityCoreQuota",
	"name":                                        "description.Account.Name",
	"pool_allocation_mode":                        "description.Account.Properties.PoolAllocationMode",
	"pool_quota":                                  "description.Account.Properties.PoolQuota",
	"private_endpoint_connections":                "description.Account.Properties.PrivateEndpointConnections",
	"provisioning_state":                          "description.Account.Properties.ProvisioningState",
	"public_network_access":                       "description.Account.Properties.PublicNetworkAccess",
	"resource_group":                              "description.ResourceGroup",
	"tags":                                        "description.Account.Tags",
	"title":                                       "description.Account.Name",
	"type":                                        "description.Account.Type",
}

func ListBatchAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBatchAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewBatchAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, listBatchAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBatchAccountFilters = map[string]string{
	"account_endpoint":                            "description.Account.Properties.AccountEndpoint",
	"active_job_and_job_schedule_quota":           "description.Account.Properties.ActiveJobAndJobScheduleQuota",
	"auto_storage":                                "description.Account.Properties.AutoStorage",
	"dedicated_core_quota":                        "description.Account.Properties.DedicatedCoreQuota",
	"dedicated_core_quota_per_vm_family":          "description.Account.Properties.DedicatedCoreQuotaPerVMFamily",
	"dedicated_core_quota_per_vm_family_enforced": "description.Account.Properties.DedicatedCoreQuotaPerVMFamilyEnforced",
	"diagnostic_settings":                         "description.DiagnosticSettingsResources",
	"encryption":                                  "description.Account.Properties.Encryption",
	"id":                                          "description.Account.ID",
	"identity":                                    "description.Account.Identity",
	"kaytu_account_id":                            "metadata.SourceID",
	"key_vault_reference":                         "description.Account.Properties.KeyVaultReference",
	"low_priority_core_quota":                     "description.Account.Properties.LowPriorityCoreQuota",
	"name":                                        "description.Account.name",
	"pool_allocation_mode":                        "description.Account.Properties.PoolAllocationMode",
	"pool_quota":                                  "description.Account.Properties.PoolQuota",
	"private_endpoint_connections":                "description.Account.Properties.PrivateEndpointConnections",
	"provisioning_state":                          "description.Account.Properties.ProvisioningState",
	"public_network_access":                       "description.Account.Properties.PublicNetworkAccess",
	"resource_group":                              "description.ResourceGroup",
	"tags":                                        "description.Account.Tags",
	"title":                                       "description.Account.Name",
	"type":                                        "description.Account.Type",
}

func GetBatchAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBatchAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewBatchAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, getBatchAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BatchAccount =============================

// ==========================  START: CognitiveAccount =============================

type CognitiveAccount struct {
	Description   azure.CognitiveAccountDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *CognitiveAccount) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.CognitiveAccountDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type CognitiveAccountHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  CognitiveAccount `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type CognitiveAccountHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []CognitiveAccountHit `json:"hits"`
}

type CognitiveAccountSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  CognitiveAccountHits `json:"hits"`
}

type CognitiveAccountPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewCognitiveAccountPaginator(filters []essdk.BoolFilter, limit *int64) (CognitiveAccountPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_cognitiveservices_accounts", filters, limit)
	if err != nil {
		return CognitiveAccountPaginator{}, err
	}

	p := CognitiveAccountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CognitiveAccountPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p CognitiveAccountPaginator) NextPage(ctx context.Context) ([]CognitiveAccount, error) {
	var response CognitiveAccountSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CognitiveAccount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listCognitiveAccountFilters = map[string]string{
	"allowed_fqdn_list":                "description.Account.Properties.AllowedFqdnList",
	"api_properties":                   "description.Account.Properties.APIProperties",
	"call_rate_limit":                  "description.Account.Properties.CallRateLimit",
	"capabilities":                     "description.Account.Properties.Capabilities",
	"custom_sub_domain_name":           "description.Account.Properties.CustomSubDomainName",
	"date_created":                     "description.Account.Properties.DateCreated",
	"diagnostic_settings":              "description.DiagnosticSettingsResources",
	"disable_local_auth":               "description.Account.Properties.DisableLocalAuth",
	"encryption":                       "description.Account.Properties.Encryption",
	"endpoint":                         "description.Account.Properties.Endpoint",
	"endpoints":                        "description.Account.Properties.Endpoints",
	"etag":                             "description.Account.Etag",
	"id":                               "description.Account.ID",
	"identity":                         "description.Account.Identity",
	"is_migrated":                      "description.Account.Properties.IsMigrated",
	"kaytu_account_id":                 "metadata.SourceID",
	"kind":                             "description.Account.Kind",
	"migration_token":                  "description.Account.Properties.MigrationToken",
	"name":                             "description.Account.Name",
	"network_acls":                     "description.Account.Properties.NetworkACLs",
	"provisioning_state":               "description.Account.Properties.ProvisioningState",
	"public_network_access":            "description.Account.Properties.PublicNetworkAccess",
	"quota_limit":                      "description.Account.Properties.QuotaLimit",
	"resource_group":                   "description.ResourceGroup",
	"restore":                          "description.Account.Properties.Restore",
	"restrict_outbound_network_access": "description.Account.Properties.RestrictOutboundNetworkAccess",
	"sku":                              "description.Account.SKU",
	"sku_change_info":                  "description.Account.Properties.SKUChangeInfo",
	"system_data":                      "description.Account.SystemData",
	"tags":                             "description.Account.Tags",
	"title":                            "description.Account.Name",
	"type":                             "description.Account.Type",
	"user_owned_storage":               "description.Account.Properties.UserOwnedStorage",
}

func ListCognitiveAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCognitiveAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewCognitiveAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, listCognitiveAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCognitiveAccountFilters = map[string]string{
	"allowed_fqdn_list":                "description.Account.Properties.AllowedFqdnList",
	"api_properties":                   "description.Account.Properties.APIProperties",
	"call_rate_limit":                  "description.Account.Properties.CallRateLimit",
	"capabilities":                     "description.Account.Properties.Capabilities",
	"custom_sub_domain_name":           "description.Account.Properties.CustomSubDomainName",
	"date_created":                     "description.Account.Properties.DateCreated",
	"diagnostic_settings":              "description.DiagnosticSettingsResources",
	"disable_local_auth":               "description.Account.Properties.DisableLocalAuth",
	"encryption":                       "description.Account.Properties.Encryption",
	"endpoint":                         "description.Account.Properties.Endpoint",
	"endpoints":                        "description.Account.Properties.Endpoints",
	"etag":                             "description.Account.Etag",
	"id":                               "description.Account.ID",
	"identity":                         "description.Account.Identity",
	"is_migrated":                      "description.Account.Properties.IsMigrated",
	"kaytu_account_id":                 "metadata.SourceID",
	"kind":                             "description.Account.Kind",
	"migration_token":                  "description.Account.Properties.MigrationToken",
	"name":                             "description.Account.name",
	"network_acls":                     "description.Account.Properties.NetworkACLs",
	"provisioning_state":               "description.Account.Properties.ProvisioningState",
	"public_network_access":            "description.Account.Properties.PublicNetworkAccess",
	"quota_limit":                      "description.Account.Properties.QuotaLimit",
	"resource_group":                   "description.ResourceGroup",
	"restore":                          "description.Account.Properties.Restore",
	"restrict_outbound_network_access": "description.Account.Properties.RestrictOutboundNetworkAccess",
	"sku":                              "description.Account.SKU",
	"sku_change_info":                  "description.Account.Properties.SKUChangeInfo",
	"system_data":                      "description.Account.SystemData",
	"tags":                             "description.Account.Tags",
	"title":                            "description.Account.Name",
	"type":                             "description.Account.Type",
	"user_owned_storage":               "description.Account.Properties.UserOwnedStorage",
}

func GetCognitiveAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCognitiveAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewCognitiveAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, getCognitiveAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CognitiveAccount =============================

// ==========================  START: ComputeVirtualMachine =============================

type ComputeVirtualMachine struct {
	Description   azure.ComputeVirtualMachineDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

func (r *ComputeVirtualMachine) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeVirtualMachineDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeVirtualMachineHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  ComputeVirtualMachine `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type ComputeVirtualMachineHits struct {
	Total essdk.SearchTotal          `json:"total"`
	Hits  []ComputeVirtualMachineHit `json:"hits"`
}

type ComputeVirtualMachineSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  ComputeVirtualMachineHits `json:"hits"`
}

type ComputeVirtualMachinePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeVirtualMachinePaginator(filters []essdk.BoolFilter, limit *int64) (ComputeVirtualMachinePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_virtualmachines", filters, limit)
	if err != nil {
		return ComputeVirtualMachinePaginator{}, err
	}

	p := ComputeVirtualMachinePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeVirtualMachinePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeVirtualMachinePaginator) NextPage(ctx context.Context) ([]ComputeVirtualMachine, error) {
	var response ComputeVirtualMachineSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeVirtualMachine
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeVirtualMachineFilters = map[string]string{
	"additional_unattend_content":         "description.VirtualMachine.Properties.OSProfile.WindowsConfiguration.AdditionalUnattendContent",
	"admin_user_name":                     "description.VirtualMachine.Properties.OSProfile.AdminUsername",
	"allow_extension_operations":          "description.VirtualMachine.Properties.OSProfile.AllowExtensionOperations",
	"availability_set_id":                 "description.VirtualMachine.Properties.AvailabilitySet.ID",
	"billing_profile_max_price":           "description.VirtualMachine.Properties.BillingProfile.MaxPrice",
	"boot_diagnostics_enabled":            "description.VirtualMachine.Properties.DiagnosticsProfile.BootDiagnostics.Enabled",
	"boot_diagnostics_storage_uri":        "description.VirtualMachine.Properties.DiagnosticsProfile.BootDiagnostics.StorageURI",
	"computer_name":                       "description.VirtualMachine.Properties.OSProfile.ComputerName",
	"data_disks":                          "description.VirtualMachine.Properties.StorageProfile.DataDisks",
	"disable_password_authentication":     "description.VirtualMachine.Properties.OSProfile.LinuxConfiguration.DisablePasswordAuthentication",
	"enable_automatic_updates":            "description.VirtualMachine.Properties.OSProfile.WindowsConfiguration.EnableAutomaticUpdates",
	"eviction_policy":                     "description.VirtualMachine.Properties.EvictionPolicy",
	"extensions":                          "description.VirtualMachineInstanceView.Extensions",
	"guest_configuration_assignments":     "description.Assignments",
	"id":                                  "description.VirtualMachine.ID",
	"identity":                            "description.VirtualMachine.Identity",
	"image_exact_version":                 "description.VirtualMachine.Properties.StorageProfile.ImageReference.ExactVersion",
	"image_id":                            "description.VirtualMachine.Properties.StorageProfile.ImageReference.ID",
	"image_offer":                         "description.VirtualMachine.Properties.StorageProfile.ImageReference.Offer",
	"image_publisher":                     "description.VirtualMachine.Properties.StorageProfile.ImageReference.Publisher",
	"image_sku":                           "description.VirtualMachine.Properties.StorageProfile.ImageReference.SKU",
	"image_version":                       "description.VirtualMachine.Properties.StorageProfile.ImageReference.Version",
	"kaytu_account_id":                    "metadata.SourceID",
	"linux_configuration_ssh_public_keys": "description.VirtualMachine.Properties.OSProfile.LinuxConfiguration.SSH.PublicKeys",
	"managed_disk_id":                     "description.VirtualMachine.Properties.StorageProfile.OSDisk.ManagedDisk.ID",
	"name":                                "description.VirtualMachine.Name",
	"network_interfaces":                  "description.VirtualMachine.Properties.NetworkProfile.NetworkInterfaces",
	"os_disk_caching":                     "description.VirtualMachine.Properties.StorageProfile.OSDisk.Caching",
	"os_disk_create_option":               "description.VirtualMachine.Properties.StorageProfile.OSDisk.CreateOption",
	"os_disk_name":                        "description.VirtualMachine.Properties.StorageProfile.OSDisk.Name",
	"os_disk_vhd_uri":                     "description.VirtualMachine.Properties.StorageProfile.OSDisk.Vhd.URI",
	"os_name":                             "description.VirtualMachineInstanceView.OSName",
	"os_type":                             "description.VirtualMachine.Properties.StorageProfile.OSDisk.OSType",
	"os_version":                          "description.VirtualMachineInstanceView.OSVersion",
	"patch_settings":                      "description.VirtualMachine.Properties.OSProfile.WindowsConfiguration.PatchSettings",
	"priority":                            "description.VirtualMachine.Properties.Priority",
	"provision_vm_agent":                  "description.VirtualMachine.Properties.OSProfile.LinuxConfiguration.ProvisionVMAgent",
	"provision_vm_agent_windows":          "description.VirtualMachine.Properties.OSProfile.WindowsConfiguration.ProvisionVMAgent",
	"provisioning_state":                  "description.VirtualMachine.Properties.ProvisioningState",
	"public_ips":                          "description.PublicIPs",
	"require_guest_provision_signal":      "description.VirtualMachine.Properties.OSProfile.RequireGuestProvisionSignal",
	"resource_group":                      "description.ResourceGroup",
	"secrets":                             "description.VirtualMachine.Properties.OSProfile.Secrets",
	"security_profile":                    "description.VirtualMachine.Properties.SecurityProfile",
	"size":                                "description.VirtualMachine.Properties.HardwareProfile.VMSize",
	"statuses":                            "description.VirtualMachineInstanceView.Statuses",
	"tags":                                "description.VirtualMachine.Tags",
	"time_zone":                           "description.VirtualMachine.Properties.OSProfile.WindowsConfiguration.TimeZone",
	"title":                               "description.VirtualMachine.Name",
	"type":                                "description.VirtualMachine.Type",
	"ultra_ssd_enabled":                   "description.VirtualMachine.Properties.AdditionalCapabilities.UltraSSDEnabled",
	"vm_id":                               "description.VirtualMachine.Properties.VMID",
	"win_rm":                              "description.VirtualMachine.Properties.OSProfile.WindowsConfiguration.WinRM",
	"zones":                               "description.VirtualMachine.Zones",
}

func ListComputeVirtualMachine(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeVirtualMachine")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeVirtualMachinePaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeVirtualMachineFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeVirtualMachineFilters = map[string]string{
	"additional_unattend_content":         "description.VirtualMachine.Properties.OSProfile.WindowsConfiguration.AdditionalUnattendContent",
	"admin_user_name":                     "description.VirtualMachine.Properties.OSProfile.AdminUsername",
	"allow_extension_operations":          "description.VirtualMachine.Properties.OSProfile.AllowExtensionOperations",
	"availability_set_id":                 "description.VirtualMachine.Properties.AvailabilitySet.ID",
	"billing_profile_max_price":           "description.VirtualMachine.Properties.BillingProfile.MaxPrice",
	"boot_diagnostics_enabled":            "description.VirtualMachine.Properties.DiagnosticsProfile.BootDiagnostics.Enabled",
	"boot_diagnostics_storage_uri":        "description.VirtualMachine.Properties.DiagnosticsProfile.BootDiagnostics.StorageURI",
	"computer_name":                       "description.VirtualMachine.Properties.OSProfile.ComputerName",
	"data_disks":                          "description.VirtualMachine.Properties.StorageProfile.DataDisks",
	"disable_password_authentication":     "description.VirtualMachine.Properties.OSProfile.LinuxConfiguration.DisablePasswordAuthentication",
	"enable_automatic_updates":            "description.VirtualMachine.Properties.OSProfile.WindowsConfiguration.EnableAutomaticUpdates",
	"eviction_policy":                     "description.VirtualMachine.Properties.EvictionPolicy",
	"extensions":                          "description.VirtualMachineInstanceView.Extensions",
	"guest_configuration_assignments":     "description.Assignments",
	"id":                                  "description.VirtualMachine.ID",
	"identity":                            "description.VirtualMachine.Identity",
	"image_exact_version":                 "description.VirtualMachine.Properties.StorageProfile.ImageReference.ExactVersion",
	"image_id":                            "description.VirtualMachine.Properties.StorageProfile.ImageReference.ID",
	"image_offer":                         "description.VirtualMachine.Properties.StorageProfile.ImageReference.Offer",
	"image_publisher":                     "description.VirtualMachine.Properties.StorageProfile.ImageReference.Publisher",
	"image_sku":                           "description.VirtualMachine.Properties.StorageProfile.ImageReference.SKU",
	"image_version":                       "description.VirtualMachine.Properties.StorageProfile.ImageReference.Version",
	"kaytu_account_id":                    "metadata.SourceID",
	"linux_configuration_ssh_public_keys": "description.VirtualMachine.Properties.OSProfile.LinuxConfiguration.SSH.PublicKeys",
	"managed_disk_id":                     "description.VirtualMachine.Properties.StorageProfile.OSDisk.ManagedDisk.ID",
	"name":                                "description.VirtualMachine.name",
	"network_interfaces":                  "description.VirtualMachine.Properties.NetworkProfile.NetworkInterfaces",
	"os_disk_caching":                     "description.VirtualMachine.Properties.StorageProfile.OSDisk.Caching",
	"os_disk_create_option":               "description.VirtualMachine.Properties.StorageProfile.OSDisk.CreateOption",
	"os_disk_name":                        "description.VirtualMachine.Properties.StorageProfile.OSDisk.Name",
	"os_disk_vhd_uri":                     "description.VirtualMachine.Properties.StorageProfile.OSDisk.Vhd.URI",
	"os_name":                             "description.VirtualMachineInstanceView.OSName",
	"os_type":                             "description.VirtualMachine.Properties.StorageProfile.OSDisk.OSType",
	"os_version":                          "description.VirtualMachineInstanceView.OSVersion",
	"patch_settings":                      "description.VirtualMachine.Properties.OSProfile.WindowsConfiguration.PatchSettings",
	"priority":                            "description.VirtualMachine.Properties.Priority",
	"provision_vm_agent":                  "description.VirtualMachine.Properties.OSProfile.LinuxConfiguration.ProvisionVMAgent",
	"provision_vm_agent_windows":          "description.VirtualMachine.Properties.OSProfile.WindowsConfiguration.ProvisionVMAgent",
	"provisioning_state":                  "description.VirtualMachine.Properties.ProvisioningState",
	"public_ips":                          "description.PublicIPs",
	"require_guest_provision_signal":      "description.VirtualMachine.Properties.OSProfile.RequireGuestProvisionSignal",
	"resource_group":                      "description.ResourceGroup",
	"secrets":                             "description.VirtualMachine.Properties.OSProfile.Secrets",
	"security_profile":                    "description.VirtualMachine.Properties.SecurityProfile",
	"size":                                "description.VirtualMachine.Properties.HardwareProfile.VMSize",
	"statuses":                            "description.VirtualMachineInstanceView.Statuses",
	"tags":                                "description.VirtualMachine.Tags",
	"time_zone":                           "description.VirtualMachine.Properties.OSProfile.WindowsConfiguration.TimeZone",
	"title":                               "description.VirtualMachine.Name",
	"type":                                "description.VirtualMachine.Type",
	"ultra_ssd_enabled":                   "description.VirtualMachine.Properties.AdditionalCapabilities.UltraSSDEnabled",
	"vm_id":                               "description.VirtualMachine.Properties.VMID",
	"win_rm":                              "description.VirtualMachine.Properties.OSProfile.WindowsConfiguration.WinRM",
	"zones":                               "description.VirtualMachine.Zones",
}

func GetComputeVirtualMachine(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeVirtualMachine")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeVirtualMachinePaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeVirtualMachineFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeVirtualMachine =============================

// ==========================  START: ComputeResourceSKU =============================

type ComputeResourceSKU struct {
	Description   azure.ComputeResourceSKUDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

func (r *ComputeResourceSKU) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeResourceSKUDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeResourceSKUHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  ComputeResourceSKU `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type ComputeResourceSKUHits struct {
	Total essdk.SearchTotal       `json:"total"`
	Hits  []ComputeResourceSKUHit `json:"hits"`
}

type ComputeResourceSKUSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  ComputeResourceSKUHits `json:"hits"`
}

type ComputeResourceSKUPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeResourceSKUPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeResourceSKUPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_resourcesku", filters, limit)
	if err != nil {
		return ComputeResourceSKUPaginator{}, err
	}

	p := ComputeResourceSKUPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeResourceSKUPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeResourceSKUPaginator) NextPage(ctx context.Context) ([]ComputeResourceSKU, error) {
	var response ComputeResourceSKUSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeResourceSKU
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeResourceSKUFilters = map[string]string{
	"api_versions":     "description.ResourceSKU.APIVersions",
	"default_capacity": "description.ResourceSKU.Capacity.Default",
	"family":           "description.ResourceSKU.Family",
	"kaytu_account_id": "metadata.SourceID",
	"kind":             "description.ResourceSKU.Kind",
	"locations":        "description.ResourceSKU.Locations",
	"maximum_capacity": "description.ResourceSKU.Capacity.Maximum",
	"minimum_capacity": "description.ResourceSKU.Capacity.Minimum",
	"name":             "description.ResourceSKU.Name",
	"resource_type":    "description.ResourceSKU.ResourceType",
	"scale_type":       "description.ResourceSKU.Capacity.ScaleType",
	"size":             "description.ResourceSKU.Size",
	"tier":             "description.ResourceSKU.Tier",
	"title":            "description.ResourceSKU.Name",
}

func ListComputeResourceSKU(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeResourceSKU")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeResourceSKUPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeResourceSKUFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeResourceSKUFilters = map[string]string{
	"api_versions":     "description.ResourceSKU.APIVersions",
	"default_capacity": "description.ResourceSKU.Capacity.Default",
	"family":           "description.ResourceSKU.Family",
	"kaytu_account_id": "metadata.SourceID",
	"kind":             "description.ResourceSKU.Kind",
	"locations":        "description.ResourceSKU.Locations",
	"maximum_capacity": "description.ResourceSKU.Capacity.Maximum",
	"minimum_capacity": "description.ResourceSKU.Capacity.Minimum",
	"name":             "description.ResourceSKU.Name",
	"resource_type":    "description.ResourceSKU.ResourceType",
	"scale_type":       "description.ResourceSKU.Capacity.ScaleType",
	"size":             "description.ResourceSKU.Size",
	"tier":             "description.ResourceSKU.Tier",
	"title":            "description.ResourceSKU.Name",
}

func GetComputeResourceSKU(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeResourceSKU")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeResourceSKUPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeResourceSKUFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeResourceSKU =============================

// ==========================  START: ComputeVirtualMachineCpuUtilization =============================

type ComputeVirtualMachineCpuUtilization struct {
	Description   azure.ComputeVirtualMachineCpuUtilizationDescription `json:"description"`
	Metadata      azure.Metadata                                       `json:"metadata"`
	ResourceJobID int                                                  `json:"resource_job_id"`
	SourceJobID   int                                                  `json:"source_job_id"`
	ResourceType  string                                               `json:"resource_type"`
	SourceType    string                                               `json:"source_type"`
	ID            string                                               `json:"id"`
	ARN           string                                               `json:"arn"`
	SourceID      string                                               `json:"source_id"`
}

func (r *ComputeVirtualMachineCpuUtilization) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeVirtualMachineCpuUtilizationDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeVirtualMachineCpuUtilizationHit struct {
	ID      string                              `json:"_id"`
	Score   float64                             `json:"_score"`
	Index   string                              `json:"_index"`
	Type    string                              `json:"_type"`
	Version int64                               `json:"_version,omitempty"`
	Source  ComputeVirtualMachineCpuUtilization `json:"_source"`
	Sort    []interface{}                       `json:"sort"`
}

type ComputeVirtualMachineCpuUtilizationHits struct {
	Total essdk.SearchTotal                        `json:"total"`
	Hits  []ComputeVirtualMachineCpuUtilizationHit `json:"hits"`
}

type ComputeVirtualMachineCpuUtilizationSearchResponse struct {
	PitID string                                  `json:"pit_id"`
	Hits  ComputeVirtualMachineCpuUtilizationHits `json:"hits"`
}

type ComputeVirtualMachineCpuUtilizationPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeVirtualMachineCpuUtilizationPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeVirtualMachineCpuUtilizationPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_virtualmachinecpuutilization", filters, limit)
	if err != nil {
		return ComputeVirtualMachineCpuUtilizationPaginator{}, err
	}

	p := ComputeVirtualMachineCpuUtilizationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeVirtualMachineCpuUtilizationPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeVirtualMachineCpuUtilizationPaginator) NextPage(ctx context.Context) ([]ComputeVirtualMachineCpuUtilization, error) {
	var response ComputeVirtualMachineCpuUtilizationSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeVirtualMachineCpuUtilization
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeVirtualMachineCpuUtilizationFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func ListComputeVirtualMachineCpuUtilization(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeVirtualMachineCpuUtilization")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeVirtualMachineCpuUtilizationPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeVirtualMachineCpuUtilizationFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeVirtualMachineCpuUtilizationFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func GetComputeVirtualMachineCpuUtilization(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeVirtualMachineCpuUtilization")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeVirtualMachineCpuUtilizationPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeVirtualMachineCpuUtilizationFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeVirtualMachineCpuUtilization =============================

// ==========================  START: ComputeVirtualMachineCpuUtilizationDaily =============================

type ComputeVirtualMachineCpuUtilizationDaily struct {
	Description   azure.ComputeVirtualMachineCpuUtilizationDailyDescription `json:"description"`
	Metadata      azure.Metadata                                            `json:"metadata"`
	ResourceJobID int                                                       `json:"resource_job_id"`
	SourceJobID   int                                                       `json:"source_job_id"`
	ResourceType  string                                                    `json:"resource_type"`
	SourceType    string                                                    `json:"source_type"`
	ID            string                                                    `json:"id"`
	ARN           string                                                    `json:"arn"`
	SourceID      string                                                    `json:"source_id"`
}

func (r *ComputeVirtualMachineCpuUtilizationDaily) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeVirtualMachineCpuUtilizationDailyDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeVirtualMachineCpuUtilizationDailyHit struct {
	ID      string                                   `json:"_id"`
	Score   float64                                  `json:"_score"`
	Index   string                                   `json:"_index"`
	Type    string                                   `json:"_type"`
	Version int64                                    `json:"_version,omitempty"`
	Source  ComputeVirtualMachineCpuUtilizationDaily `json:"_source"`
	Sort    []interface{}                            `json:"sort"`
}

type ComputeVirtualMachineCpuUtilizationDailyHits struct {
	Total essdk.SearchTotal                             `json:"total"`
	Hits  []ComputeVirtualMachineCpuUtilizationDailyHit `json:"hits"`
}

type ComputeVirtualMachineCpuUtilizationDailySearchResponse struct {
	PitID string                                       `json:"pit_id"`
	Hits  ComputeVirtualMachineCpuUtilizationDailyHits `json:"hits"`
}

type ComputeVirtualMachineCpuUtilizationDailyPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeVirtualMachineCpuUtilizationDailyPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeVirtualMachineCpuUtilizationDailyPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_virtualmachinecpuutilizationdaily", filters, limit)
	if err != nil {
		return ComputeVirtualMachineCpuUtilizationDailyPaginator{}, err
	}

	p := ComputeVirtualMachineCpuUtilizationDailyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeVirtualMachineCpuUtilizationDailyPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeVirtualMachineCpuUtilizationDailyPaginator) NextPage(ctx context.Context) ([]ComputeVirtualMachineCpuUtilizationDaily, error) {
	var response ComputeVirtualMachineCpuUtilizationDailySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeVirtualMachineCpuUtilizationDaily
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeVirtualMachineCpuUtilizationDailyFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func ListComputeVirtualMachineCpuUtilizationDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeVirtualMachineCpuUtilizationDaily")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeVirtualMachineCpuUtilizationDailyPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeVirtualMachineCpuUtilizationDailyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeVirtualMachineCpuUtilizationDailyFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func GetComputeVirtualMachineCpuUtilizationDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeVirtualMachineCpuUtilizationDaily")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeVirtualMachineCpuUtilizationDailyPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeVirtualMachineCpuUtilizationDailyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeVirtualMachineCpuUtilizationDaily =============================

// ==========================  START: ComputeVirtualMachineCpuUtilizationHourly =============================

type ComputeVirtualMachineCpuUtilizationHourly struct {
	Description   azure.ComputeVirtualMachineCpuUtilizationHourlyDescription `json:"description"`
	Metadata      azure.Metadata                                             `json:"metadata"`
	ResourceJobID int                                                        `json:"resource_job_id"`
	SourceJobID   int                                                        `json:"source_job_id"`
	ResourceType  string                                                     `json:"resource_type"`
	SourceType    string                                                     `json:"source_type"`
	ID            string                                                     `json:"id"`
	ARN           string                                                     `json:"arn"`
	SourceID      string                                                     `json:"source_id"`
}

func (r *ComputeVirtualMachineCpuUtilizationHourly) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeVirtualMachineCpuUtilizationHourlyDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeVirtualMachineCpuUtilizationHourlyHit struct {
	ID      string                                    `json:"_id"`
	Score   float64                                   `json:"_score"`
	Index   string                                    `json:"_index"`
	Type    string                                    `json:"_type"`
	Version int64                                     `json:"_version,omitempty"`
	Source  ComputeVirtualMachineCpuUtilizationHourly `json:"_source"`
	Sort    []interface{}                             `json:"sort"`
}

type ComputeVirtualMachineCpuUtilizationHourlyHits struct {
	Total essdk.SearchTotal                              `json:"total"`
	Hits  []ComputeVirtualMachineCpuUtilizationHourlyHit `json:"hits"`
}

type ComputeVirtualMachineCpuUtilizationHourlySearchResponse struct {
	PitID string                                        `json:"pit_id"`
	Hits  ComputeVirtualMachineCpuUtilizationHourlyHits `json:"hits"`
}

type ComputeVirtualMachineCpuUtilizationHourlyPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeVirtualMachineCpuUtilizationHourlyPaginator(filters []essdk.BoolFilter, limit *int64) (ComputeVirtualMachineCpuUtilizationHourlyPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_virtualmachinecpuutilizationhourly", filters, limit)
	if err != nil {
		return ComputeVirtualMachineCpuUtilizationHourlyPaginator{}, err
	}

	p := ComputeVirtualMachineCpuUtilizationHourlyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeVirtualMachineCpuUtilizationHourlyPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeVirtualMachineCpuUtilizationHourlyPaginator) NextPage(ctx context.Context) ([]ComputeVirtualMachineCpuUtilizationHourly, error) {
	var response ComputeVirtualMachineCpuUtilizationHourlySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeVirtualMachineCpuUtilizationHourly
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeVirtualMachineCpuUtilizationHourlyFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func ListComputeVirtualMachineCpuUtilizationHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeVirtualMachineCpuUtilizationHourly")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeVirtualMachineCpuUtilizationHourlyPaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeVirtualMachineCpuUtilizationHourlyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeVirtualMachineCpuUtilizationHourlyFilters = map[string]string{
	"kaytu_account_id": "metadata.SourceID",
}

func GetComputeVirtualMachineCpuUtilizationHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeVirtualMachineCpuUtilizationHourly")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeVirtualMachineCpuUtilizationHourlyPaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeVirtualMachineCpuUtilizationHourlyFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeVirtualMachineCpuUtilizationHourly =============================

// ==========================  START: ComputeCloudService =============================

type ComputeCloudService struct {
	Description   azure.ComputeCloudServiceDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

func (r *ComputeCloudService) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ComputeCloudServiceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ComputeCloudServiceHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  ComputeCloudService `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type ComputeCloudServiceHits struct {
	Total essdk.SearchTotal        `json:"total"`
	Hits  []ComputeCloudServiceHit `json:"hits"`
}

type ComputeCloudServiceSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  ComputeCloudServiceHits `json:"hits"`
}

type ComputeCloudServicePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewComputeCloudServicePaginator(filters []essdk.BoolFilter, limit *int64) (ComputeCloudServicePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_compute_cloudservices", filters, limit)
	if err != nil {
		return ComputeCloudServicePaginator{}, err
	}

	p := ComputeCloudServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeCloudServicePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ComputeCloudServicePaginator) NextPage(ctx context.Context) ([]ComputeCloudService, error) {
	var response ComputeCloudServiceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeCloudService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listComputeCloudServiceFilters = map[string]string{
	"id":               "description.CloudServices.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.CloudService.Name",
	"tags":             "description.CloudService.Tags",
	"title":            "description.CloudService.Name",
}

func ListComputeCloudService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeCloudService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewComputeCloudServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, listComputeCloudServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeCloudServiceFilters = map[string]string{
	"id":               "description.CloudServices.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.CloudService.Name",
	"tags":             "description.CloudService.Tags",
	"title":            "description.CloudService.Name",
}

func GetComputeCloudService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeCloudService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewComputeCloudServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, getComputeCloudServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeCloudService =============================

// ==========================  START: ContainerRegistry =============================

type ContainerRegistry struct {
	Description   azure.ContainerRegistryDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

func (r *ContainerRegistry) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ContainerRegistryDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ContainerRegistryHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  ContainerRegistry `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type ContainerRegistryHits struct {
	Total essdk.SearchTotal      `json:"total"`
	Hits  []ContainerRegistryHit `json:"hits"`
}

type ContainerRegistrySearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  ContainerRegistryHits `json:"hits"`
}

type ContainerRegistryPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewContainerRegistryPaginator(filters []essdk.BoolFilter, limit *int64) (ContainerRegistryPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_containerregistry_registries", filters, limit)
	if err != nil {
		return ContainerRegistryPaginator{}, err
	}

	p := ContainerRegistryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ContainerRegistryPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ContainerRegistryPaginator) NextPage(ctx context.Context) ([]ContainerRegistry, error) {
	var response ContainerRegistrySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ContainerRegistry
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listContainerRegistryFilters = map[string]string{
	"admin_user_enabled":           "description.Registry.Properties.AdminUserEnabled",
	"data_endpoint_enabled":        "description.Registry.Properties.DataEndpointEnabled",
	"data_endpoint_host_names":     "description.Registry.Properties.DataEndpointHostNames",
	"encryption":                   "description.Registry.Properties.Encryption",
	"id":                           "description.Registry.ID",
	"identity":                     "description.Registry.Identity",
	"kaytu_account_id":             "metadata.SourceID",
	"login_credentials":            "description.RegistryListCredentialsResult",
	"login_server":                 "description.Registry.Properties.LoginServer",
	"name":                         "description.Registry.Name",
	"network_rule_bypass_options":  "description.Registry.Properties.NetworkRuleBypassOptions",
	"network_rule_set":             "description.Registry.Properties.NetworkRuleSet",
	"policies":                     "description.Registry.Properties.Policies",
	"private_endpoint_connections": "description.Registry.Properties.PrivateEndpointConnections",
	"provisioning_state":           "description.Registry.Properties.ProvisioningState",
	"public_network_access":        "description.Registry.Properties.PublicNetworkAccess",
	"resource_group":               "description.ResourceGroup",
	"sku_name":                     "description.Registry.SKU.Name",
	"sku_tier":                     "description.Registry.SKU.Tier",
	"status":                       "description.Registry.Properties.Status.DisplayStatus",
	"status_message":               "description.Registry.Properties.Status.Message",
	"storage_account_id":           "RegistryProperties.StorageAccount.ID",
	"system_data":                  "description.Registry.SystemData",
	"tags":                         "description.Registry.Tags",
	"title":                        "description.Registry.Name",
	"type":                         "description.Registry.Type",
	"usages":                       "description.RegistryUsages",
	"zone_redundancy":              "description.Registry.Properties.ZoneRedundancy",
}

func ListContainerRegistry(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListContainerRegistry")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewContainerRegistryPaginator(essdk.BuildFilter(ctx, d.QueryContext, listContainerRegistryFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getContainerRegistryFilters = map[string]string{
	"admin_user_enabled":           "description.Registry.Properties.AdminUserEnabled",
	"data_endpoint_enabled":        "description.Registry.Properties.DataEndpointEnabled",
	"data_endpoint_host_names":     "description.Registry.Properties.DataEndpointHostNames",
	"encryption":                   "description.Registry.Properties.Encryption",
	"id":                           "description.Registry.ID",
	"identity":                     "description.Registry.Identity",
	"kaytu_account_id":             "metadata.SourceID",
	"login_credentials":            "description.RegistryListCredentialsResult",
	"login_server":                 "description.Registry.Properties.LoginServer",
	"name":                         "description.Registry.name",
	"network_rule_bypass_options":  "description.Registry.Properties.NetworkRuleBypassOptions",
	"network_rule_set":             "description.Registry.Properties.NetworkRuleSet",
	"policies":                     "description.Registry.Properties.Policies",
	"private_endpoint_connections": "description.Registry.Properties.PrivateEndpointConnections",
	"provisioning_state":           "description.Registry.Properties.ProvisioningState",
	"public_network_access":        "description.Registry.Properties.PublicNetworkAccess",
	"resource_group":               "description.ResourceGroup",
	"sku_name":                     "description.Registry.SKU.Name",
	"sku_tier":                     "description.Registry.SKU.Tier",
	"status":                       "description.Registry.Properties.Status.DisplayStatus",
	"status_message":               "description.Registry.Properties.Status.Message",
	"storage_account_id":           "RegistryProperties.StorageAccount.ID",
	"system_data":                  "description.Registry.SystemData",
	"tags":                         "description.Registry.Tags",
	"title":                        "description.Registry.Name",
	"type":                         "description.Registry.Type",
	"usages":                       "description.RegistryUsages",
	"zone_redundancy":              "description.Registry.Properties.ZoneRedundancy",
}

func GetContainerRegistry(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetContainerRegistry")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewContainerRegistryPaginator(essdk.BuildFilter(ctx, d.QueryContext, getContainerRegistryFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ContainerRegistry =============================

// ==========================  START: CosmosdbAccount =============================

type CosmosdbAccount struct {
	Description   azure.CosmosdbAccountDescription `json:"description"`
	Metadata      azure.Metadata                   `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

func (r *CosmosdbAccount) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.CosmosdbAccountDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type CosmosdbAccountHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  CosmosdbAccount `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type CosmosdbAccountHits struct {
	Total essdk.SearchTotal    `json:"total"`
	Hits  []CosmosdbAccountHit `json:"hits"`
}

type CosmosdbAccountSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  CosmosdbAccountHits `json:"hits"`
}

type CosmosdbAccountPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewCosmosdbAccountPaginator(filters []essdk.BoolFilter, limit *int64) (CosmosdbAccountPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_documentdb_databaseaccounts", filters, limit)
	if err != nil {
		return CosmosdbAccountPaginator{}, err
	}

	p := CosmosdbAccountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CosmosdbAccountPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p CosmosdbAccountPaginator) NextPage(ctx context.Context) ([]CosmosdbAccount, error) {
	var response CosmosdbAccountSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CosmosdbAccount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listCosmosdbAccountFilters = map[string]string{
	"capabilities":                            "description.DatabaseAccountGetResults.Properties.Capabilities",
	"connector_offer":                         "description.DatabaseAccountGetResults.Properties.ConnectorOffer",
	"consistency_policy_max_interval":         "description.DatabaseAccountGetResults.Properties.ConsistencyPolicy.MaxIntervalInSeconds",
	"consistency_policy_max_staleness_prefix": "description.DatabaseAccountGetResults.Properties.ConsistencyPolicy.MaxStalenessPrefix",
	"cors":                                    "description.DatabaseAccountGetResults.Properties.Cors",
	"database_account_offer_type":             "description.DatabaseAccountGetResults.Properties.DatabaseAccountOfferType",
	"default_consistency_level":               "description.DatabaseAccountGetResults.Properties.ConsistencyPolicy.DefaultConsistencyLevel",
	"disable_key_based_metadata_write_access": "description.DatabaseAccountGetResults.Properties.DisableKeyBasedMetadataWriteAccess",
	"document_endpoint":                       "description.DatabaseAccountGetResults.Properties.DocumentEndpoint",
	"enable_analytical_storage":               "description.DatabaseAccountGetResults.Properties.EnableAnalyticalStorage",
	"enable_automatic_failover":               "description.DatabaseAccountGetResults.Properties.EnableAutomaticFailover",
	"enable_cassandra_connector":              "description.DatabaseAccountGetResults.Properties.EnableCassandraConnector",
	"enable_free_tier":                        "description.DatabaseAccountGetResults.Properties.EnableFreeTier",
	"enable_multiple_write_locations":         "description.DatabaseAccountGetResults.Properties.EnableMultipleWriteLocations",
	"failover_policies":                       "description.DatabaseAccountGetResults.Properties.FailoverPolicies",
	"id":                                      "description.DatabaseAccountGetResults.ID",
	"ip_rules":                                "description.DatabaseAccountGetResults.Properties.IPRules",
	"is_virtual_network_filter_enabled":       "description.DatabaseAccountGetResults.Properties.IsVirtualNetworkFilterEnabled",
	"kaytu_account_id":                        "metadata.SourceID",
	"key_vault_key_uri":                       "description.DatabaseAccountGetResults.Properties.KeyVaultKeyURI",
	"kind":                                    "description.DatabaseAccountGetResults.Kind",
	"locations":                               "description.DatabaseAccountGetResults.Properties.Locations",
	"name":                                    "description.DatabaseAccountGetResults.Name",
	"private_endpoint_connections":            "description.DatabaseAccountGetResults.Properties.PrivateEndpointConnections",
	"provisioning_state":                      "description.DatabaseAccountGetResults.Properties.ProvisioningState",
	"public_network_access":                   "description.DatabaseAccountGetResults.Properties.PublicNetworkAccess",
	"read_locations":                          "description.DatabaseAccountGetResults.Properties.ReadLocations",
	"server_version":                          "description.DatabaseAccountGetResults.Properties.APIProperties.ServerVersion",
	"tags":                                    "description.DatabaseAccountGetResults.Tags",
	"title":                                   "description.DatabaseAccountGetResults.Name",
	"type":                                    "description.DatabaseAccountGetResults.Type",
	"virtual_network_rules":                   "description.DatabaseAccountGetResults.Properties.VirtualNetworkRules",
	"write_locations":                         "description.DatabaseAccountGetResults.Properties.WriteLocations",
}

func ListCosmosdbAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCosmosdbAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewCosmosdbAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, listCosmosdbAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCosmosdbAccountFilters = map[string]string{
	"capabilities":                            "description.DatabaseAccountGetResults.Properties.Capabilities",
	"connector_offer":                         "description.DatabaseAccountGetResults.Properties.ConnectorOffer",
	"consistency_policy_max_interval":         "description.DatabaseAccountGetResults.Properties.ConsistencyPolicy.MaxIntervalInSeconds",
	"consistency_policy_max_staleness_prefix": "description.DatabaseAccountGetResults.Properties.ConsistencyPolicy.MaxStalenessPrefix",
	"cors":                                    "description.DatabaseAccountGetResults.Properties.Cors",
	"database_account_offer_type":             "description.DatabaseAccountGetResults.Properties.DatabaseAccountOfferType",
	"default_consistency_level":               "description.DatabaseAccountGetResults.Properties.ConsistencyPolicy.DefaultConsistencyLevel",
	"disable_key_based_metadata_write_access": "description.DatabaseAccountGetResults.Properties.DisableKeyBasedMetadataWriteAccess",
	"document_endpoint":                       "description.DatabaseAccountGetResults.Properties.DocumentEndpoint",
	"enable_analytical_storage":               "description.DatabaseAccountGetResults.Properties.EnableAnalyticalStorage",
	"enable_automatic_failover":               "description.DatabaseAccountGetResults.Properties.EnableAutomaticFailover",
	"enable_cassandra_connector":              "description.DatabaseAccountGetResults.Properties.EnableCassandraConnector",
	"enable_free_tier":                        "description.DatabaseAccountGetResults.Properties.EnableFreeTier",
	"enable_multiple_write_locations":         "description.DatabaseAccountGetResults.Properties.EnableMultipleWriteLocations",
	"failover_policies":                       "description.DatabaseAccountGetResults.Properties.FailoverPolicies",
	"id":                                      "description.DatabaseAccountGetResults.ID",
	"ip_rules":                                "description.DatabaseAccountGetResults.Properties.IPRules",
	"is_virtual_network_filter_enabled":       "description.DatabaseAccountGetResults.Properties.IsVirtualNetworkFilterEnabled",
	"kaytu_account_id":                        "metadata.SourceID",
	"key_vault_key_uri":                       "description.DatabaseAccountGetResults.Properties.KeyVaultKeyURI",
	"kind":                                    "description.DatabaseAccountGetResults.Kind",
	"locations":                               "description.DatabaseAccountGetResults.Properties.Locations",
	"name":                                    "description.DatabaseAccountGetResults.name",
	"private_endpoint_connections":            "description.DatabaseAccountGetResults.Properties.PrivateEndpointConnections",
	"provisioning_state":                      "description.DatabaseAccountGetResults.Properties.ProvisioningState",
	"public_network_access":                   "description.DatabaseAccountGetResults.Properties.PublicNetworkAccess",
	"read_locations":                          "description.DatabaseAccountGetResults.Properties.ReadLocations",
	"resource_group":                          "description.ResourceGroup",
	"server_version":                          "description.DatabaseAccountGetResults.Properties.APIProperties.ServerVersion",
	"tags":                                    "description.DatabaseAccountGetResults.Tags",
	"title":                                   "description.DatabaseAccountGetResults.Name",
	"type":                                    "description.DatabaseAccountGetResults.Type",
	"virtual_network_rules":                   "description.DatabaseAccountGetResults.Properties.VirtualNetworkRules",
	"write_locations":                         "description.DatabaseAccountGetResults.Properties.WriteLocations",
}

func GetCosmosdbAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCosmosdbAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewCosmosdbAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, getCosmosdbAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CosmosdbAccount =============================

// ==========================  START: CosmosdbRestorableDatabaseAccount =============================

type CosmosdbRestorableDatabaseAccount struct {
	Description   azure.CosmosdbRestorableDatabaseAccountDescription `json:"description"`
	Metadata      azure.Metadata                                     `json:"metadata"`
	ResourceJobID int                                                `json:"resource_job_id"`
	SourceJobID   int                                                `json:"source_job_id"`
	ResourceType  string                                             `json:"resource_type"`
	SourceType    string                                             `json:"source_type"`
	ID            string                                             `json:"id"`
	ARN           string                                             `json:"arn"`
	SourceID      string                                             `json:"source_id"`
}

func (r *CosmosdbRestorableDatabaseAccount) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.CosmosdbRestorableDatabaseAccountDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type CosmosdbRestorableDatabaseAccountHit struct {
	ID      string                            `json:"_id"`
	Score   float64                           `json:"_score"`
	Index   string                            `json:"_index"`
	Type    string                            `json:"_type"`
	Version int64                             `json:"_version,omitempty"`
	Source  CosmosdbRestorableDatabaseAccount `json:"_source"`
	Sort    []interface{}                     `json:"sort"`
}

type CosmosdbRestorableDatabaseAccountHits struct {
	Total essdk.SearchTotal                      `json:"total"`
	Hits  []CosmosdbRestorableDatabaseAccountHit `json:"hits"`
}

type CosmosdbRestorableDatabaseAccountSearchResponse struct {
	PitID string                                `json:"pit_id"`
	Hits  CosmosdbRestorableDatabaseAccountHits `json:"hits"`
}

type CosmosdbRestorableDatabaseAccountPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewCosmosdbRestorableDatabaseAccountPaginator(filters []essdk.BoolFilter, limit *int64) (CosmosdbRestorableDatabaseAccountPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_documentdb_restorabledatabaseaccounts", filters, limit)
	if err != nil {
		return CosmosdbRestorableDatabaseAccountPaginator{}, err
	}

	p := CosmosdbRestorableDatabaseAccountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CosmosdbRestorableDatabaseAccountPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p CosmosdbRestorableDatabaseAccountPaginator) NextPage(ctx context.Context) ([]CosmosdbRestorableDatabaseAccount, error) {
	var response CosmosdbRestorableDatabaseAccountSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CosmosdbRestorableDatabaseAccount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listCosmosdbRestorableDatabaseAccountFilters = map[string]string{
	"account_name":         "description.Account.Properties.AccountName",
	"api_type":             "description.Account.Properties.APIType",
	"creation_time":        "description.Account.Properties.CreationTime",
	"deletion_time":        "description.Account.Properties.DeletionTime",
	"id":                   "description.Account.ID",
	"kaytu_account_id":     "metadata.SourceID",
	"name":                 "description.Account.Name",
	"resource_group":       "description.ResourceGroup",
	"restorable_locations": "description.Account.Properties.RestorableLocations",
	"title":                "description.Account.Name",
	"type":                 "description.Account.Type",
}

func ListCosmosdbRestorableDatabaseAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCosmosdbRestorableDatabaseAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewCosmosdbRestorableDatabaseAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, listCosmosdbRestorableDatabaseAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCosmosdbRestorableDatabaseAccountFilters = map[string]string{
	"account_name":         "description.Account.Properties.AccountName",
	"api_type":             "description.Account.Properties.APIType",
	"creation_time":        "description.Account.Properties.CreationTime",
	"deletion_time":        "description.Account.Properties.DeletionTime",
	"id":                   "description.Account.ID",
	"kaytu_account_id":     "metadata.SourceID",
	"name":                 "description.Account.Name",
	"resource_group":       "description.ResourceGroup",
	"restorable_locations": "description.Account.Properties.RestorableLocations",
	"title":                "description.Account.Name",
	"type":                 "description.Account.Type",
}

func GetCosmosdbRestorableDatabaseAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCosmosdbRestorableDatabaseAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewCosmosdbRestorableDatabaseAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, getCosmosdbRestorableDatabaseAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CosmosdbRestorableDatabaseAccount =============================

// ==========================  START: CosmosdbMongoDatabase =============================

type CosmosdbMongoDatabase struct {
	Description   azure.CosmosdbMongoDatabaseDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

func (r *CosmosdbMongoDatabase) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.CosmosdbMongoDatabaseDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type CosmosdbMongoDatabaseHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  CosmosdbMongoDatabase `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type CosmosdbMongoDatabaseHits struct {
	Total essdk.SearchTotal          `json:"total"`
	Hits  []CosmosdbMongoDatabaseHit `json:"hits"`
}

type CosmosdbMongoDatabaseSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  CosmosdbMongoDatabaseHits `json:"hits"`
}

type CosmosdbMongoDatabasePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewCosmosdbMongoDatabasePaginator(filters []essdk.BoolFilter, limit *int64) (CosmosdbMongoDatabasePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_documentdb_mongodatabases", filters, limit)
	if err != nil {
		return CosmosdbMongoDatabasePaginator{}, err
	}

	p := CosmosdbMongoDatabasePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CosmosdbMongoDatabasePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p CosmosdbMongoDatabasePaginator) NextPage(ctx context.Context) ([]CosmosdbMongoDatabase, error) {
	var response CosmosdbMongoDatabaseSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CosmosdbMongoDatabase
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listCosmosdbMongoDatabaseFilters = map[string]string{
	"account_name":                      "description.Account.Name",
	"autoscale_settings_max_throughput": "description.MongoDatabase.Properties.Options.AutoscaleSettings.MaxThroughput",
	"database_etag":                     "description.MongoDatabase.Properties.Resource.Etag",
	"database_id":                       "description.MongoDatabase.Properties.Resource.ID",
	"database_rid":                      "description.MongoDatabase.Properties.Resource.Rid",
	"id":                                "description.MongoDatabase.ID",
	"kaytu_account_id":                  "metadata.SourceID",
	"name":                              "description.MongoDatabase.Name",
	"tags":                              "description.MongoDatabase.Tags",
	"throughput":                        "description.MongoDatabase.Properties.Options.Throughput",
	"title":                             "description.MongoDatabase.Name",
	"type":                              "description.MongoDatabase.Type",
}

func ListCosmosdbMongoDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCosmosdbMongoDatabase")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewCosmosdbMongoDatabasePaginator(essdk.BuildFilter(ctx, d.QueryContext, listCosmosdbMongoDatabaseFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCosmosdbMongoDatabaseFilters = map[string]string{
	"account_name":                      "description.Account.name",
	"autoscale_settings_max_throughput": "description.MongoDatabase.Properties.Options.AutoscaleSettings.MaxThroughput",
	"database_etag":                     "description.MongoDatabase.Properties.Resource.Etag",
	"database_id":                       "description.MongoDatabase.Properties.Resource.ID",
	"database_rid":                      "description.MongoDatabase.Properties.Resource.Rid",
	"id":                                "description.MongoDatabase.ID",
	"kaytu_account_id":                  "metadata.SourceID",
	"name":                              "description.MongoDatabase.name",
	"resource_group":                    "description.ResourceGroup",
	"tags":                              "description.MongoDatabase.Tags",
	"throughput":                        "description.MongoDatabase.Properties.Options.Throughput",
	"title":                             "description.MongoDatabase.Name",
	"type":                              "description.MongoDatabase.Type",
}

func GetCosmosdbMongoDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCosmosdbMongoDatabase")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewCosmosdbMongoDatabasePaginator(essdk.BuildFilter(ctx, d.QueryContext, getCosmosdbMongoDatabaseFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CosmosdbMongoDatabase =============================

// ==========================  START: CosmosdbMongoCollection =============================

type CosmosdbMongoCollection struct {
	Description   azure.CosmosdbMongoCollectionDescription `json:"description"`
	Metadata      azure.Metadata                           `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

func (r *CosmosdbMongoCollection) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.CosmosdbMongoCollectionDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type CosmosdbMongoCollectionHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  CosmosdbMongoCollection `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type CosmosdbMongoCollectionHits struct {
	Total essdk.SearchTotal            `json:"total"`
	Hits  []CosmosdbMongoCollectionHit `json:"hits"`
}

type CosmosdbMongoCollectionSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  CosmosdbMongoCollectionHits `json:"hits"`
}

type CosmosdbMongoCollectionPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewCosmosdbMongoCollectionPaginator(filters []essdk.BoolFilter, limit *int64) (CosmosdbMongoCollectionPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_documentdb_mongocollection", filters, limit)
	if err != nil {
		return CosmosdbMongoCollectionPaginator{}, err
	}

	p := CosmosdbMongoCollectionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CosmosdbMongoCollectionPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p CosmosdbMongoCollectionPaginator) NextPage(ctx context.Context) ([]CosmosdbMongoCollection, error) {
	var response CosmosdbMongoCollectionSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CosmosdbMongoCollection
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listCosmosdbMongoCollectionFilters = map[string]string{
	"account_name":                      "description.Account.Name",
	"analytical_storage_ttl":            "description.MongoCollection.Properties.Resource.AnalyticalStorageTTL",
	"autoscale_settings_max_throughput": "description.MongoCollection.Properties.AutoscaleSettings.MaxThroughput",
	"collection_etag":                   "description.MongoCollection.Properties.Resource.Etag",
	"collection_id":                     "description.MongoCollection.Properties.Resource.ID",
	"collection_rid":                    "description.MongoCollection.Properties.Resource.Rid",
	"database_name":                     "description.MongoDatabase.Name",
	"id":                                "description.MongoCollection.ID",
	"indexes":                           "description.MongoCollection.Properties.Resource.Indexes",
	"kaytu_account_id":                  "metadata.SourceID",
	"name":                              "description.MongoCollection.Name",
	"resource_group":                    "description.ResourceGroup",
	"shard_key":                         "description.MongoCollection.Properties.Resource.ShardKey",
	"tags":                              "description.MongoCollection.Tags",
	"throughput":                        "description.MongoCollection.Properties.Options.Throughput",
	"throughput_settings":               "description.Throughput",
	"title":                             "description.MongoCollection.Name",
	"type":                              "description.MongoCollection.Type",
}

func ListCosmosdbMongoCollection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCosmosdbMongoCollection")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewCosmosdbMongoCollectionPaginator(essdk.BuildFilter(ctx, d.QueryContext, listCosmosdbMongoCollectionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCosmosdbMongoCollectionFilters = map[string]string{
	"account_name":                      "description.Account.name",
	"analytical_storage_ttl":            "description.MongoCollection.Properties.Resource.AnalyticalStorageTTL",
	"autoscale_settings_max_throughput": "description.MongoCollection.Properties.AutoscaleSettings.MaxThroughput",
	"collection_etag":                   "description.MongoCollection.Properties.Resource.Etag",
	"collection_id":                     "description.MongoCollection.Properties.Resource.ID",
	"collection_rid":                    "description.MongoCollection.Properties.Resource.Rid",
	"database_name":                     "description.MongoDatabase.Name",
	"id":                                "description.MongoCollection.ID",
	"indexes":                           "description.MongoCollection.Properties.Resource.Indexes",
	"kaytu_account_id":                  "metadata.SourceID",
	"name":                              "description.MongoCollection.name",
	"resource_group":                    "description.ResourceGroup",
	"shard_key":                         "description.MongoCollection.Properties.Resource.ShardKey",
	"tags":                              "description.MongoCollection.Tags",
	"throughput":                        "description.MongoCollection.Properties.Options.Throughput",
	"throughput_settings":               "description.Throughput",
	"title":                             "description.MongoCollection.Name",
	"type":                              "description.MongoCollection.Type",
}

func GetCosmosdbMongoCollection(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCosmosdbMongoCollection")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewCosmosdbMongoCollectionPaginator(essdk.BuildFilter(ctx, d.QueryContext, getCosmosdbMongoCollectionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CosmosdbMongoCollection =============================

// ==========================  START: CosmosdbSqlDatabase =============================

type CosmosdbSqlDatabase struct {
	Description   azure.CosmosdbSqlDatabaseDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

func (r *CosmosdbSqlDatabase) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.CosmosdbSqlDatabaseDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type CosmosdbSqlDatabaseHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  CosmosdbSqlDatabase `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type CosmosdbSqlDatabaseHits struct {
	Total essdk.SearchTotal        `json:"total"`
	Hits  []CosmosdbSqlDatabaseHit `json:"hits"`
}

type CosmosdbSqlDatabaseSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  CosmosdbSqlDatabaseHits `json:"hits"`
}

type CosmosdbSqlDatabasePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewCosmosdbSqlDatabasePaginator(filters []essdk.BoolFilter, limit *int64) (CosmosdbSqlDatabasePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_documentdb_sqldatabases", filters, limit)
	if err != nil {
		return CosmosdbSqlDatabasePaginator{}, err
	}

	p := CosmosdbSqlDatabasePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CosmosdbSqlDatabasePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p CosmosdbSqlDatabasePaginator) NextPage(ctx context.Context) ([]CosmosdbSqlDatabase, error) {
	var response CosmosdbSqlDatabaseSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CosmosdbSqlDatabase
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listCosmosdbSqlDatabaseFilters = map[string]string{
	"account_name":                      "description.Account.Name",
	"autoscale_settings_max_throughput": "description.SqlDatabase.Properties.Options.AutoscaleSettings.MaxThroughput",
	"database_colls":                    "description.SqlDatabase.Properties.Resource.Colls",
	"database_etag":                     "description.SqlDatabase.Properties.Resource.Etag",
	"database_id":                       "description.SqlDatabase.Properties.Resource.ID",
	"database_rid":                      "description.SqlDatabase.Properties.Resource.Rid",
	"database_users":                    "description.SqlDatabase.Properties.Resource.Users",
	"id":                                "description.SqlDatabase.ID",
	"kaytu_account_id":                  "metadata.SourceID",
	"name":                              "description.SqlDatabase.Name",
	"tags":                              "description.SqlDatabase.Tags",
	"throughput":                        "description.SqlDatabase.Properties.Options.Throughput",
	"title":                             "description.SqlDatabase.Name",
	"type":                              "description.SqlDatabase.Type",
}

func ListCosmosdbSqlDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCosmosdbSqlDatabase")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewCosmosdbSqlDatabasePaginator(essdk.BuildFilter(ctx, d.QueryContext, listCosmosdbSqlDatabaseFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCosmosdbSqlDatabaseFilters = map[string]string{
	"account_name":                      "description.Account.name",
	"autoscale_settings_max_throughput": "description.SqlDatabase.Properties.Options.AutoscaleSettings.MaxThroughput",
	"database_colls":                    "description.SqlDatabase.Properties.Resource.Colls",
	"database_etag":                     "description.SqlDatabase.Properties.Resource.Etag",
	"database_id":                       "description.SqlDatabase.Properties.Resource.ID",
	"database_rid":                      "description.SqlDatabase.Properties.Resource.Rid",
	"database_users":                    "description.SqlDatabase.Properties.Resource.Users",
	"id":                                "description.SqlDatabase.ID",
	"kaytu_account_id":                  "metadata.SourceID",
	"name":                              "description.SqlDatabase.name",
	"resource_group":                    "description.ResourceGroup",
	"tags":                              "description.SqlDatabase.Tags",
	"throughput":                        "description.SqlDatabase.Properties.Options.Throughput",
	"title":                             "description.SqlDatabase.Name",
	"type":                              "description.SqlDatabase.Type",
}

func GetCosmosdbSqlDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCosmosdbSqlDatabase")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewCosmosdbSqlDatabasePaginator(essdk.BuildFilter(ctx, d.QueryContext, getCosmosdbSqlDatabaseFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CosmosdbSqlDatabase =============================

// ==========================  START: CosmosdbCassandraCluster =============================

type CosmosdbCassandraCluster struct {
	Description   azure.CosmosdbCassandraClusterDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

func (r *CosmosdbCassandraCluster) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.CosmosdbCassandraClusterDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type CosmosdbCassandraClusterHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  CosmosdbCassandraCluster `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type CosmosdbCassandraClusterHits struct {
	Total essdk.SearchTotal             `json:"total"`
	Hits  []CosmosdbCassandraClusterHit `json:"hits"`
}

type CosmosdbCassandraClusterSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  CosmosdbCassandraClusterHits `json:"hits"`
}

type CosmosdbCassandraClusterPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewCosmosdbCassandraClusterPaginator(filters []essdk.BoolFilter, limit *int64) (CosmosdbCassandraClusterPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_documentdb_cassandraclusters", filters, limit)
	if err != nil {
		return CosmosdbCassandraClusterPaginator{}, err
	}

	p := CosmosdbCassandraClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CosmosdbCassandraClusterPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p CosmosdbCassandraClusterPaginator) NextPage(ctx context.Context) ([]CosmosdbCassandraCluster, error) {
	var response CosmosdbCassandraClusterSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CosmosdbCassandraCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listCosmosdbCassandraClusterFilters = map[string]string{
	"id":    "description.CassandraCluster.ID",
	"name":  "description.CassandraCluster.Name",
	"tags":  "description.CassandraCluster.Tags",
	"title": "description.CassandraCluster.Name",
}

func ListCosmosdbCassandraCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCosmosdbCassandraCluster")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewCosmosdbCassandraClusterPaginator(essdk.BuildFilter(ctx, d.QueryContext, listCosmosdbCassandraClusterFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCosmosdbCassandraClusterFilters = map[string]string{
	"id":    "description.CassandraCluster.ID",
	"name":  "description.CassandraCluster.Name",
	"tags":  "description.CassandraCluster.Tags",
	"title": "description.CassandraCluster.Name",
}

func GetCosmosdbCassandraCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCosmosdbCassandraCluster")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewCosmosdbCassandraClusterPaginator(essdk.BuildFilter(ctx, d.QueryContext, getCosmosdbCassandraClusterFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CosmosdbCassandraCluster =============================

// ==========================  START: DatabricksWorkspace =============================

type DatabricksWorkspace struct {
	Description   azure.DatabricksWorkspaceDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

func (r *DatabricksWorkspace) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DatabricksWorkspaceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DatabricksWorkspaceHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  DatabricksWorkspace `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type DatabricksWorkspaceHits struct {
	Total essdk.SearchTotal        `json:"total"`
	Hits  []DatabricksWorkspaceHit `json:"hits"`
}

type DatabricksWorkspaceSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  DatabricksWorkspaceHits `json:"hits"`
}

type DatabricksWorkspacePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDatabricksWorkspacePaginator(filters []essdk.BoolFilter, limit *int64) (DatabricksWorkspacePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_databricks_workspaces", filters, limit)
	if err != nil {
		return DatabricksWorkspacePaginator{}, err
	}

	p := DatabricksWorkspacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DatabricksWorkspacePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DatabricksWorkspacePaginator) NextPage(ctx context.Context) ([]DatabricksWorkspace, error) {
	var response DatabricksWorkspaceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DatabricksWorkspace
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDatabricksWorkspaceFilters = map[string]string{
	"id":               "description.Workspace.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Workspace.Name",
	"tags":             "description.Workspace.Tags",
	"title":            "description.Workspace.Name",
}

func ListDatabricksWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDatabricksWorkspace")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDatabricksWorkspacePaginator(essdk.BuildFilter(ctx, d.QueryContext, listDatabricksWorkspaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDatabricksWorkspaceFilters = map[string]string{
	"id":               "description.Workspace.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Workspace.Name",
	"tags":             "description.Workspace.Tags",
	"title":            "description.Workspace.Name",
}

func GetDatabricksWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDatabricksWorkspace")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDatabricksWorkspacePaginator(essdk.BuildFilter(ctx, d.QueryContext, getDatabricksWorkspaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DatabricksWorkspace =============================

// ==========================  START: DataMigrationService =============================

type DataMigrationService struct {
	Description   azure.DataMigrationServiceDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

func (r *DataMigrationService) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DataMigrationServiceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DataMigrationServiceHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  DataMigrationService `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type DataMigrationServiceHits struct {
	Total essdk.SearchTotal         `json:"total"`
	Hits  []DataMigrationServiceHit `json:"hits"`
}

type DataMigrationServiceSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  DataMigrationServiceHits `json:"hits"`
}

type DataMigrationServicePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDataMigrationServicePaginator(filters []essdk.BoolFilter, limit *int64) (DataMigrationServicePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_datamigration_services", filters, limit)
	if err != nil {
		return DataMigrationServicePaginator{}, err
	}

	p := DataMigrationServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DataMigrationServicePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DataMigrationServicePaginator) NextPage(ctx context.Context) ([]DataMigrationService, error) {
	var response DataMigrationServiceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DataMigrationService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDataMigrationServiceFilters = map[string]string{
	"id":               "description.Service.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Service.Name",
	"tags":             "description.Service.Tags",
	"title":            "description.Service.Name",
}

func ListDataMigrationService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDataMigrationService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDataMigrationServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, listDataMigrationServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDataMigrationServiceFilters = map[string]string{
	"id":               "description.Service.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Service.Name",
	"tags":             "description.Service.Tags",
	"title":            "description.Service.Name",
}

func GetDataMigrationService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDataMigrationService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDataMigrationServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, getDataMigrationServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DataMigrationService =============================

// ==========================  START: DataProtectionBackupVaults =============================

type DataProtectionBackupVaults struct {
	Description   azure.DataProtectionBackupVaultsDescription `json:"description"`
	Metadata      azure.Metadata                              `json:"metadata"`
	ResourceJobID int                                         `json:"resource_job_id"`
	SourceJobID   int                                         `json:"source_job_id"`
	ResourceType  string                                      `json:"resource_type"`
	SourceType    string                                      `json:"source_type"`
	ID            string                                      `json:"id"`
	ARN           string                                      `json:"arn"`
	SourceID      string                                      `json:"source_id"`
}

func (r *DataProtectionBackupVaults) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DataProtectionBackupVaultsDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DataProtectionBackupVaultsHit struct {
	ID      string                     `json:"_id"`
	Score   float64                    `json:"_score"`
	Index   string                     `json:"_index"`
	Type    string                     `json:"_type"`
	Version int64                      `json:"_version,omitempty"`
	Source  DataProtectionBackupVaults `json:"_source"`
	Sort    []interface{}              `json:"sort"`
}

type DataProtectionBackupVaultsHits struct {
	Total essdk.SearchTotal               `json:"total"`
	Hits  []DataProtectionBackupVaultsHit `json:"hits"`
}

type DataProtectionBackupVaultsSearchResponse struct {
	PitID string                         `json:"pit_id"`
	Hits  DataProtectionBackupVaultsHits `json:"hits"`
}

type DataProtectionBackupVaultsPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDataProtectionBackupVaultsPaginator(filters []essdk.BoolFilter, limit *int64) (DataProtectionBackupVaultsPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_dataprotection_backupvaults", filters, limit)
	if err != nil {
		return DataProtectionBackupVaultsPaginator{}, err
	}

	p := DataProtectionBackupVaultsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DataProtectionBackupVaultsPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DataProtectionBackupVaultsPaginator) NextPage(ctx context.Context) ([]DataProtectionBackupVaults, error) {
	var response DataProtectionBackupVaultsSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DataProtectionBackupVaults
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDataProtectionBackupVaultsFilters = map[string]string{
	"id":               "description.BackupVaults.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.BackupVaults.Name",
	"tags":             "description.BackupVaults.Tags",
	"title":            "description.BackupVaults.Name",
}

func ListDataProtectionBackupVaults(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDataProtectionBackupVaults")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDataProtectionBackupVaultsPaginator(essdk.BuildFilter(ctx, d.QueryContext, listDataProtectionBackupVaultsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDataProtectionBackupVaultsFilters = map[string]string{
	"id":               "description.BackupVaults.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.BackupVaults.Name",
	"tags":             "description.BackupVaults.Tags",
	"title":            "description.BackupVaults.Name",
}

func GetDataProtectionBackupVaults(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDataProtectionBackupVaults")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDataProtectionBackupVaultsPaginator(essdk.BuildFilter(ctx, d.QueryContext, getDataProtectionBackupVaultsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DataProtectionBackupVaults =============================

// ==========================  START: DataProtectionBackupVaultsBackupPolicies =============================

type DataProtectionBackupVaultsBackupPolicies struct {
	Description   azure.DataProtectionBackupVaultsBackupPoliciesDescription `json:"description"`
	Metadata      azure.Metadata                                            `json:"metadata"`
	ResourceJobID int                                                       `json:"resource_job_id"`
	SourceJobID   int                                                       `json:"source_job_id"`
	ResourceType  string                                                    `json:"resource_type"`
	SourceType    string                                                    `json:"source_type"`
	ID            string                                                    `json:"id"`
	ARN           string                                                    `json:"arn"`
	SourceID      string                                                    `json:"source_id"`
}

func (r *DataProtectionBackupVaultsBackupPolicies) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DataProtectionBackupVaultsBackupPoliciesDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DataProtectionBackupVaultsBackupPoliciesHit struct {
	ID      string                                   `json:"_id"`
	Score   float64                                  `json:"_score"`
	Index   string                                   `json:"_index"`
	Type    string                                   `json:"_type"`
	Version int64                                    `json:"_version,omitempty"`
	Source  DataProtectionBackupVaultsBackupPolicies `json:"_source"`
	Sort    []interface{}                            `json:"sort"`
}

type DataProtectionBackupVaultsBackupPoliciesHits struct {
	Total essdk.SearchTotal                             `json:"total"`
	Hits  []DataProtectionBackupVaultsBackupPoliciesHit `json:"hits"`
}

type DataProtectionBackupVaultsBackupPoliciesSearchResponse struct {
	PitID string                                       `json:"pit_id"`
	Hits  DataProtectionBackupVaultsBackupPoliciesHits `json:"hits"`
}

type DataProtectionBackupVaultsBackupPoliciesPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDataProtectionBackupVaultsBackupPoliciesPaginator(filters []essdk.BoolFilter, limit *int64) (DataProtectionBackupVaultsBackupPoliciesPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_dataprotection_backupvaults_backuppolicies", filters, limit)
	if err != nil {
		return DataProtectionBackupVaultsBackupPoliciesPaginator{}, err
	}

	p := DataProtectionBackupVaultsBackupPoliciesPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DataProtectionBackupVaultsBackupPoliciesPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DataProtectionBackupVaultsBackupPoliciesPaginator) NextPage(ctx context.Context) ([]DataProtectionBackupVaultsBackupPolicies, error) {
	var response DataProtectionBackupVaultsBackupPoliciesSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DataProtectionBackupVaultsBackupPolicies
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDataProtectionBackupVaultsBackupPoliciesFilters = map[string]string{
	"id":               "description.BackupPolicies.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.BackupPolicies.Name",
	"tags":             "description.BackupPolicies.Name",
	"title":            "description.BackupPolicies.Name",
}

func ListDataProtectionBackupVaultsBackupPolicies(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDataProtectionBackupVaultsBackupPolicies")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDataProtectionBackupVaultsBackupPoliciesPaginator(essdk.BuildFilter(ctx, d.QueryContext, listDataProtectionBackupVaultsBackupPoliciesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDataProtectionBackupVaultsBackupPoliciesFilters = map[string]string{
	"id":               "description.BackupPolicies.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.BackupPolicies.Name",
	"tags":             "description.BackupPolicies.Name",
	"title":            "description.BackupPolicies.Name",
}

func GetDataProtectionBackupVaultsBackupPolicies(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDataProtectionBackupVaultsBackupPolicies")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDataProtectionBackupVaultsBackupPoliciesPaginator(essdk.BuildFilter(ctx, d.QueryContext, getDataProtectionBackupVaultsBackupPoliciesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DataProtectionBackupVaultsBackupPolicies =============================

// ==========================  START: DataFactory =============================

type DataFactory struct {
	Description   azure.DataFactoryDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

func (r *DataFactory) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DataFactoryDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DataFactoryHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  DataFactory   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type DataFactoryHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []DataFactoryHit  `json:"hits"`
}

type DataFactorySearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  DataFactoryHits `json:"hits"`
}

type DataFactoryPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDataFactoryPaginator(filters []essdk.BoolFilter, limit *int64) (DataFactoryPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_datafactory_factories", filters, limit)
	if err != nil {
		return DataFactoryPaginator{}, err
	}

	p := DataFactoryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DataFactoryPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DataFactoryPaginator) NextPage(ctx context.Context) ([]DataFactory, error) {
	var response DataFactorySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DataFactory
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDataFactoryFilters = map[string]string{
	"additional_properties":        "description.Factory.AdditionalProperties",
	"encryption":                   "description.Factory.Properties.Encryption",
	"etag":                         "description.Factory.ETag",
	"global_parameters":            "description.Factory.Properties.GlobalParameters",
	"id":                           "description.Factory.ID",
	"identity":                     "description.Factory.Identity",
	"kaytu_account_id":             "metadata.SourceID",
	"name":                         "description.Factory.Name",
	"private_endpoint_connections": "description.PrivateEndPointConnections",
	"provisioning_state":           "description.Factory.Properties.ProvisioningState",
	"public_network_access":        "description.Factory.Properties.PublicNetworkAccess",
	"repo_configuration":           "description.Factory.Properties.RepoConfiguration",
	"resource_group":               "description.ResourceGroup",
	"tags":                         "description.Factory.Tags",
	"title":                        "description.Factory.Name",
	"type":                         "description.Factory.Type",
	"version":                      "description.Factory.Properties.Version",
}

func ListDataFactory(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDataFactory")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDataFactoryPaginator(essdk.BuildFilter(ctx, d.QueryContext, listDataFactoryFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDataFactoryFilters = map[string]string{
	"additional_properties":        "description.Factory.AdditionalProperties",
	"encryption":                   "description.Factory.Properties.Encryption",
	"etag":                         "description.Factory.ETag",
	"global_parameters":            "description.Factory.Properties.GlobalParameters",
	"id":                           "description.Factory.ID",
	"identity":                     "description.Factory.Identity",
	"kaytu_account_id":             "metadata.SourceID",
	"name":                         "description.Factory.name",
	"private_endpoint_connections": "description.PrivateEndPointConnections",
	"provisioning_state":           "description.Factory.Properties.ProvisioningState",
	"public_network_access":        "description.Factory.Properties.PublicNetworkAccess",
	"repo_configuration":           "description.Factory.Properties.RepoConfiguration",
	"resource_group":               "description.ResourceGroup",
	"tags":                         "description.Factory.Tags",
	"title":                        "description.Factory.Name",
	"type":                         "description.Factory.Type",
	"version":                      "description.Factory.Properties.Version",
}

func GetDataFactory(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDataFactory")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDataFactoryPaginator(essdk.BuildFilter(ctx, d.QueryContext, getDataFactoryFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DataFactory =============================

// ==========================  START: DataFactoryDataset =============================

type DataFactoryDataset struct {
	Description   azure.DataFactoryDatasetDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

func (r *DataFactoryDataset) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DataFactoryDatasetDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DataFactoryDatasetHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  DataFactoryDataset `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type DataFactoryDatasetHits struct {
	Total essdk.SearchTotal       `json:"total"`
	Hits  []DataFactoryDatasetHit `json:"hits"`
}

type DataFactoryDatasetSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  DataFactoryDatasetHits `json:"hits"`
}

type DataFactoryDatasetPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDataFactoryDatasetPaginator(filters []essdk.BoolFilter, limit *int64) (DataFactoryDatasetPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_datafactory_factoriesdatasets", filters, limit)
	if err != nil {
		return DataFactoryDatasetPaginator{}, err
	}

	p := DataFactoryDatasetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DataFactoryDatasetPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DataFactoryDatasetPaginator) NextPage(ctx context.Context) ([]DataFactoryDataset, error) {
	var response DataFactoryDatasetSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DataFactoryDataset
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDataFactoryDatasetFilters = map[string]string{
	"etag":             "description.Dataset.Etag",
	"factory_name":     "description.Factory.Name",
	"id":               "description.Dataset.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Dataset.Name",
	"properties":       "description.Dataset.Properties",
	"resource_group":   "description.ResourceGroup",
	"title":            "description.Dataset.Name",
	"type":             "description.Dataset.Type",
}

func ListDataFactoryDataset(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDataFactoryDataset")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDataFactoryDatasetPaginator(essdk.BuildFilter(ctx, d.QueryContext, listDataFactoryDatasetFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDataFactoryDatasetFilters = map[string]string{
	"etag":             "description.Dataset.Etag",
	"factory_name":     "description.Factory.name",
	"id":               "description.Dataset.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Dataset.name",
	"properties":       "description.Dataset.Properties",
	"resource_group":   "description.ResourceGroup",
	"title":            "description.Dataset.Name",
	"type":             "description.Dataset.Type",
}

func GetDataFactoryDataset(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDataFactoryDataset")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDataFactoryDatasetPaginator(essdk.BuildFilter(ctx, d.QueryContext, getDataFactoryDatasetFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DataFactoryDataset =============================

// ==========================  START: DataFactoryPipeline =============================

type DataFactoryPipeline struct {
	Description   azure.DataFactoryPipelineDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

func (r *DataFactoryPipeline) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DataFactoryPipelineDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DataFactoryPipelineHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  DataFactoryPipeline `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type DataFactoryPipelineHits struct {
	Total essdk.SearchTotal        `json:"total"`
	Hits  []DataFactoryPipelineHit `json:"hits"`
}

type DataFactoryPipelineSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  DataFactoryPipelineHits `json:"hits"`
}

type DataFactoryPipelinePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDataFactoryPipelinePaginator(filters []essdk.BoolFilter, limit *int64) (DataFactoryPipelinePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_datafactory_factoriespipelines", filters, limit)
	if err != nil {
		return DataFactoryPipelinePaginator{}, err
	}

	p := DataFactoryPipelinePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DataFactoryPipelinePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DataFactoryPipelinePaginator) NextPage(ctx context.Context) ([]DataFactoryPipeline, error) {
	var response DataFactoryPipelineSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DataFactoryPipeline
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDataFactoryPipelineFilters = map[string]string{
	"activities":       "description.Pipeline.Properties.Activities",
	"annotations":      "description.Pipeline.Properties.Annotations",
	"concurrency":      "description.Pipeline.Properties.Concurrency",
	"description":      "description.Pipeline.Properties.Description",
	"etag":             "description.Pipeline.Etag",
	"factory_name":     "description.Factory.Name",
	"id":               "description.Pipeline.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Pipeline.Name",
	"parameters":       "description.Pipeline.Properties.Parameters",
	"pipeline_folder":  "description.Pipeline.Properties.Folder.Name",
	"pipeline_policy":  "description.Pipeline.Properties.Policy",
	"resource_group":   "description.ResourceGroup",
	"run_dimensions":   "description.Pipeline.Properties.RunDimensions",
	"title":            "description.Pipeline.Name",
	"type":             "description.Pipeline.Type",
	"variables":        "description.Pipeline.Properties.Variables",
}

func ListDataFactoryPipeline(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDataFactoryPipeline")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDataFactoryPipelinePaginator(essdk.BuildFilter(ctx, d.QueryContext, listDataFactoryPipelineFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDataFactoryPipelineFilters = map[string]string{
	"activities":       "description.Pipeline.Properties.Activities",
	"annotations":      "description.Pipeline.Properties.Annotations",
	"concurrency":      "description.Pipeline.Properties.Concurrency",
	"description":      "description.Pipeline.Properties.Description",
	"etag":             "description.Pipeline.Etag",
	"factory_name":     "description.Factory.name",
	"id":               "description.Pipeline.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Pipeline.name",
	"parameters":       "description.Pipeline.Properties.Parameters",
	"pipeline_folder":  "description.Pipeline.Properties.Folder.Name",
	"pipeline_policy":  "description.Pipeline.Properties.Policy",
	"resource_group":   "description.ResourceGroup",
	"run_dimensions":   "description.Pipeline.Properties.RunDimensions",
	"title":            "description.Pipeline.Name",
	"type":             "description.Pipeline.Type",
	"variables":        "description.Pipeline.Properties.Variables",
}

func GetDataFactoryPipeline(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDataFactoryPipeline")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDataFactoryPipelinePaginator(essdk.BuildFilter(ctx, d.QueryContext, getDataFactoryPipelineFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DataFactoryPipeline =============================

// ==========================  START: DataLakeAnalyticsAccount =============================

type DataLakeAnalyticsAccount struct {
	Description   azure.DataLakeAnalyticsAccountDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

func (r *DataLakeAnalyticsAccount) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DataLakeAnalyticsAccountDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DataLakeAnalyticsAccountHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  DataLakeAnalyticsAccount `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type DataLakeAnalyticsAccountHits struct {
	Total essdk.SearchTotal             `json:"total"`
	Hits  []DataLakeAnalyticsAccountHit `json:"hits"`
}

type DataLakeAnalyticsAccountSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  DataLakeAnalyticsAccountHits `json:"hits"`
}

type DataLakeAnalyticsAccountPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDataLakeAnalyticsAccountPaginator(filters []essdk.BoolFilter, limit *int64) (DataLakeAnalyticsAccountPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_datalakeanalytics_accounts", filters, limit)
	if err != nil {
		return DataLakeAnalyticsAccountPaginator{}, err
	}

	p := DataLakeAnalyticsAccountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DataLakeAnalyticsAccountPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DataLakeAnalyticsAccountPaginator) NextPage(ctx context.Context) ([]DataLakeAnalyticsAccount, error) {
	var response DataLakeAnalyticsAccountSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DataLakeAnalyticsAccount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDataLakeAnalyticsAccountFilters = map[string]string{
	"account_id":                        "description.DataLakeAnalyticsAccount.Properties.AccountID",
	"compute_policies":                  "description.DataLakeAnalyticsAccount.Properties.ComputePolicies",
	"current_tier":                      "description.DataLakeAnalyticsAccount.Properties.CurrentTier",
	"data_lake_store_accounts":          "description.DataLakeAnalyticsAccount.Properties.DataLakeStoreAccounts",
	"default_data_lake_store_account":   "description.DataLakeAnalyticsAccount.Properties.DefaultDataLakeStoreAccount",
	"diagnostic_settings":               "description.DiagnosticSettingsResource",
	"endpoint":                          "description.DataLakeAnalyticsAccount.Properties.Endpoint",
	"firewall_allow_azure_ips":          "description.DataLakeAnalyticsAccount.Properties.FirewallAllowAzureIPs",
	"firewall_rules":                    "description.DataLakeAnalyticsAccount.Properties.FirewallRules",
	"firewall_state":                    "description.DataLakeAnalyticsAccount.Properties.FirewallState",
	"id":                                "description.DataLakeAnalyticsAccount.ID",
	"kaytu_account_id":                  "metadata.SourceID",
	"max_degree_of_parallelism":         "description.DataLakeAnalyticsAccount.Properties.MaxDegreeOfParallelism",
	"max_degree_of_parallelism_per_job": "description.DataLakeAnalyticsAccount.Properties.MaxDegreeOfParallelismPerJob",
	"max_job_count":                     "description.DataLakeAnalyticsAccount.Properties.MaxJobCount",
	"min_priority_per_job":              "description.DataLakeAnalyticsAccount.Properties.MinPriorityPerJob",
	"name":                              "description.DataLakeAnalyticsAccount.Name",
	"new_tier":                          "description.DataLakeAnalyticsAccount.Properties.NewTier",
	"provisioning_state":                "description.DataLakeAnalyticsAccount.Properties.ProvisioningState",
	"query_store_retention":             "description.DataLakeAnalyticsAccount.Properties.QueryStoreRetention",
	"resource_group":                    "description.ResourceGroup",
	"state":                             "description.DataLakeAnalyticsAccount.Properties.State",
	"storage_accounts":                  "description.DataLakeAnalyticsAccount.Properties.StorageAccounts",
	"system_max_degree_of_parallelism":  "description.DataLakeAnalyticsAccount.Properties.SystemMaxDegreeOfParallelism",
	"system_max_job_count":              "description.DataLakeAnalyticsAccount.Properties.SystemMaxJobCount",
	"tags":                              "description.DataLakeAnalyticsAccount.Tags",
	"title":                             "description.DataLakeAnalyticsAccount.Name",
	"type":                              "description.DataLakeAnalyticsAccount.Type",
}

func ListDataLakeAnalyticsAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDataLakeAnalyticsAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDataLakeAnalyticsAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, listDataLakeAnalyticsAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDataLakeAnalyticsAccountFilters = map[string]string{
	"account_id":                        "description.DataLakeAnalyticsAccount.Properties.AccountID",
	"compute_policies":                  "description.DataLakeAnalyticsAccount.Properties.ComputePolicies",
	"current_tier":                      "description.DataLakeAnalyticsAccount.Properties.CurrentTier",
	"data_lake_store_accounts":          "description.DataLakeAnalyticsAccount.Properties.DataLakeStoreAccounts",
	"default_data_lake_store_account":   "description.DataLakeAnalyticsAccount.Properties.DefaultDataLakeStoreAccount",
	"diagnostic_settings":               "description.DiagnosticSettingsResource",
	"endpoint":                          "description.DataLakeAnalyticsAccount.Properties.Endpoint",
	"firewall_allow_azure_ips":          "description.DataLakeAnalyticsAccount.Properties.FirewallAllowAzureIPs",
	"firewall_rules":                    "description.DataLakeAnalyticsAccount.Properties.FirewallRules",
	"firewall_state":                    "description.DataLakeAnalyticsAccount.Properties.FirewallState",
	"id":                                "description.DataLakeAnalyticsAccount.ID",
	"kaytu_account_id":                  "metadata.SourceID",
	"max_degree_of_parallelism":         "description.DataLakeAnalyticsAccount.Properties.MaxDegreeOfParallelism",
	"max_degree_of_parallelism_per_job": "description.DataLakeAnalyticsAccount.Properties.MaxDegreeOfParallelismPerJob",
	"max_job_count":                     "description.DataLakeAnalyticsAccount.Properties.MaxJobCount",
	"min_priority_per_job":              "description.DataLakeAnalyticsAccount.Properties.MinPriorityPerJob",
	"name":                              "description.DataLakeAnalyticsAccount.name",
	"new_tier":                          "description.DataLakeAnalyticsAccount.Properties.NewTier",
	"provisioning_state":                "description.DataLakeAnalyticsAccount.Properties.ProvisioningState",
	"query_store_retention":             "description.DataLakeAnalyticsAccount.Properties.QueryStoreRetention",
	"resource_group":                    "description.ResourceGroup",
	"state":                             "description.DataLakeAnalyticsAccount.Properties.State",
	"storage_accounts":                  "description.DataLakeAnalyticsAccount.Properties.StorageAccounts",
	"system_max_degree_of_parallelism":  "description.DataLakeAnalyticsAccount.Properties.SystemMaxDegreeOfParallelism",
	"system_max_job_count":              "description.DataLakeAnalyticsAccount.Properties.SystemMaxJobCount",
	"tags":                              "description.DataLakeAnalyticsAccount.Tags",
	"title":                             "description.DataLakeAnalyticsAccount.Name",
	"type":                              "description.DataLakeAnalyticsAccount.Type",
}

func GetDataLakeAnalyticsAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDataLakeAnalyticsAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDataLakeAnalyticsAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, getDataLakeAnalyticsAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DataLakeAnalyticsAccount =============================

// ==========================  START: DataLakeStore =============================

type DataLakeStore struct {
	Description   azure.DataLakeStoreDescription `json:"description"`
	Metadata      azure.Metadata                 `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

func (r *DataLakeStore) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DataLakeStoreDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DataLakeStoreHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  DataLakeStore `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type DataLakeStoreHits struct {
	Total essdk.SearchTotal  `json:"total"`
	Hits  []DataLakeStoreHit `json:"hits"`
}

type DataLakeStoreSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  DataLakeStoreHits `json:"hits"`
}

type DataLakeStorePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDataLakeStorePaginator(filters []essdk.BoolFilter, limit *int64) (DataLakeStorePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_datalakestore_accounts", filters, limit)
	if err != nil {
		return DataLakeStorePaginator{}, err
	}

	p := DataLakeStorePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DataLakeStorePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DataLakeStorePaginator) NextPage(ctx context.Context) ([]DataLakeStore, error) {
	var response DataLakeStoreSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DataLakeStore
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDataLakeStoreFilters = map[string]string{
	"account_id":                    "description.DataLakeStoreAccount.Properties.AccountID",
	"current_tier":                  "description.DataLakeStoreAccount.Properties.CurrentTier",
	"default_group":                 "description.DataLakeStoreAccount.Properties.DefaultGroup",
	"diagnostic_settings":           "description.DiagnosticSettingsResource",
	"encryption_config":             "description.DataLakeStoreAccount.Properties.EncryptionConfig",
	"encryption_provisioning_state": "description.DataLakeStoreAccount.Properties.EncryptionProvisioningState",
	"encryption_state":              "description.DataLakeStoreAccount.Properties.EncryptionState",
	"endpoint":                      "description.DataLakeStoreAccount.Properties.Endpoint",
	"firewall_allow_azure_ips":      "description.DataLakeStoreAccount.Properties.FirewallAllowAzureIPs",
	"firewall_rules":                "description.DataLakeStoreAccount.Properties.FirewallRules",
	"firewall_state":                "description.DataLakeStoreAccount.Properties.FirewallState",
	"id":                            "description.DataLakeStoreAccount.ID",
	"identity":                      "description.DataLakeStoreAccount.Identity",
	"kaytu_account_id":              "metadata.SourceID",
	"name":                          "description.DataLakeStoreAccount.Name",
	"new_tier":                      "description.DataLakeStoreAccount.Properties.NewTier",
	"provisioning_state":            "description.DataLakeStoreAccount.Properties.ProvisioningState",
	"resource_group":                "description.ResourceGroup",
	"state":                         "description.DataLakeStoreAccount.Properties.State",
	"tags":                          "description.DataLakeStoreAccount.Tags",
	"title":                         "description.DataLakeStoreAccount.Name",
	"trusted_id_provider_state":     "description.DataLakeStoreAccount.Properties.TrustedIDProviderState",
	"trusted_id_providers":          "description.DataLakeStoreAccount.Properties.TrustedIDProviders",
	"type":                          "description.DataLakeStoreAccount.Type",
	"virtual_network_rules":         "description.DataLakeStoreAccount.Properties.VirtualNetworkRules",
}

func ListDataLakeStore(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDataLakeStore")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDataLakeStorePaginator(essdk.BuildFilter(ctx, d.QueryContext, listDataLakeStoreFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDataLakeStoreFilters = map[string]string{
	"account_id":                    "description.DataLakeStoreAccount.Properties.AccountID",
	"current_tier":                  "description.DataLakeStoreAccount.Properties.CurrentTier",
	"default_group":                 "description.DataLakeStoreAccount.Properties.DefaultGroup",
	"diagnostic_settings":           "description.DiagnosticSettingsResource",
	"encryption_config":             "description.DataLakeStoreAccount.Properties.EncryptionConfig",
	"encryption_provisioning_state": "description.DataLakeStoreAccount.Properties.EncryptionProvisioningState",
	"encryption_state":              "description.DataLakeStoreAccount.Properties.EncryptionState",
	"endpoint":                      "description.DataLakeStoreAccount.Properties.Endpoint",
	"firewall_allow_azure_ips":      "description.DataLakeStoreAccount.Properties.FirewallAllowAzureIPs",
	"firewall_rules":                "description.DataLakeStoreAccount.Properties.FirewallRules",
	"firewall_state":                "description.DataLakeStoreAccount.Properties.FirewallState",
	"id":                            "description.DataLakeStoreAccount.ID",
	"identity":                      "description.DataLakeStoreAccount.Identity",
	"kaytu_account_id":              "metadata.SourceID",
	"name":                          "description.DataLakeStoreAccount.name",
	"new_tier":                      "description.DataLakeStoreAccount.Properties.NewTier",
	"provisioning_state":            "description.DataLakeStoreAccount.Properties.ProvisioningState",
	"resource_group":                "description.ResourceGroup",
	"state":                         "description.DataLakeStoreAccount.Properties.State",
	"tags":                          "description.DataLakeStoreAccount.Tags",
	"title":                         "description.DataLakeStoreAccount.Name",
	"trusted_id_provider_state":     "description.DataLakeStoreAccount.Properties.TrustedIDProviderState",
	"trusted_id_providers":          "description.DataLakeStoreAccount.Properties.TrustedIDProviders",
	"type":                          "description.DataLakeStoreAccount.Type",
	"virtual_network_rules":         "description.DataLakeStoreAccount.Properties.VirtualNetworkRules",
}

func GetDataLakeStore(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDataLakeStore")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDataLakeStorePaginator(essdk.BuildFilter(ctx, d.QueryContext, getDataLakeStoreFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DataLakeStore =============================

// ==========================  START: DiagnosticSetting =============================

type DiagnosticSetting struct {
	Description   azure.DiagnosticSettingDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

func (r *DiagnosticSetting) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DiagnosticSettingDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DiagnosticSettingHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  DiagnosticSetting `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type DiagnosticSettingHits struct {
	Total essdk.SearchTotal      `json:"total"`
	Hits  []DiagnosticSettingHit `json:"hits"`
}

type DiagnosticSettingSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  DiagnosticSettingHits `json:"hits"`
}

type DiagnosticSettingPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDiagnosticSettingPaginator(filters []essdk.BoolFilter, limit *int64) (DiagnosticSettingPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_insights_guestdiagnosticsettings", filters, limit)
	if err != nil {
		return DiagnosticSettingPaginator{}, err
	}

	p := DiagnosticSettingPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DiagnosticSettingPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DiagnosticSettingPaginator) NextPage(ctx context.Context) ([]DiagnosticSetting, error) {
	var response DiagnosticSettingSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DiagnosticSetting
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDiagnosticSettingFilters = map[string]string{
	"event_hub_authorization_rule_id": "description.DiagnosticSettingsResource.Properties.EventHubAuthorizationRuleID",
	"event_hub_name":                  "description.DiagnosticSettingsResource.Properties.EventHubName",
	"id":                              "description.DiagnosticSettingsResource.ID",
	"kaytu_account_id":                "metadata.SourceID",
	"log_analytics_destination_type":  "description.DiagnosticSettingsResource.Properties.LogAnalyticsDestinationType",
	"logs":                            "description.DiagnosticSettingsResource.Properties.Logs",
	"metrics":                         "description.DiagnosticSettingsResource.Properties.Metrics",
	"name":                            "description.DiagnosticSettingsResource.Name",
	"resource_group":                  "description.ResourceGroup",
	"service_bus_rule_id":             "description.DiagnosticSettingsResource.Properties.ServiceBusRuleID",
	"storage_account_id":              "description.DiagnosticSettingsResource.Properties.StorageAccountID",
	"title":                           "description.DiagnosticSettingsResource.Name",
	"type":                            "description.DiagnosticSettingsResource.Type",
	"workspace_id":                    "description.DiagnosticSettingsResource.Properties.WorkspaceID",
}

func ListDiagnosticSetting(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDiagnosticSetting")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDiagnosticSettingPaginator(essdk.BuildFilter(ctx, d.QueryContext, listDiagnosticSettingFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDiagnosticSettingFilters = map[string]string{
	"event_hub_authorization_rule_id": "description.DiagnosticSettingsResource.Properties.EventHubAuthorizationRuleID",
	"event_hub_name":                  "description.DiagnosticSettingsResource.Properties.EventHubName",
	"id":                              "description.DiagnosticSettingsResource.ID",
	"kaytu_account_id":                "metadata.SourceID",
	"log_analytics_destination_type":  "description.DiagnosticSettingsResource.Properties.LogAnalyticsDestinationType",
	"logs":                            "description.DiagnosticSettingsResource.Properties.Logs",
	"metrics":                         "description.DiagnosticSettingsResource.Properties.Metrics",
	"name":                            "description.DiagnosticSettingsResource.name",
	"resource_group":                  "description.ResourceGroup",
	"service_bus_rule_id":             "description.DiagnosticSettingsResource.Properties.ServiceBusRuleID",
	"storage_account_id":              "description.DiagnosticSettingsResource.Properties.StorageAccountID",
	"title":                           "description.DiagnosticSettingsResource.Name",
	"type":                            "description.DiagnosticSettingsResource.Type",
	"workspace_id":                    "description.DiagnosticSettingsResource.Properties.WorkspaceID",
}

func GetDiagnosticSetting(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDiagnosticSetting")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDiagnosticSettingPaginator(essdk.BuildFilter(ctx, d.QueryContext, getDiagnosticSettingFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DiagnosticSetting =============================

// ==========================  START: EventGridDomain =============================

type EventGridDomain struct {
	Description   azure.EventGridDomainDescription `json:"description"`
	Metadata      azure.Metadata                   `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

func (r *EventGridDomain) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.EventGridDomainDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type EventGridDomainHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  EventGridDomain `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type EventGridDomainHits struct {
	Total essdk.SearchTotal    `json:"total"`
	Hits  []EventGridDomainHit `json:"hits"`
}

type EventGridDomainSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  EventGridDomainHits `json:"hits"`
}

type EventGridDomainPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewEventGridDomainPaginator(filters []essdk.BoolFilter, limit *int64) (EventGridDomainPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_eventgrid_domains", filters, limit)
	if err != nil {
		return EventGridDomainPaginator{}, err
	}

	p := EventGridDomainPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EventGridDomainPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p EventGridDomainPaginator) NextPage(ctx context.Context) ([]EventGridDomain, error) {
	var response EventGridDomainSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EventGridDomain
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listEventGridDomainFilters = map[string]string{
	"auto_create_topic_with_first_subscription": "description.Domain.Properties.AutoCreateTopicWithFirstSubscription",
	"auto_delete_topic_with_last_subscription":  "description.Domain.Properties.AutoDeleteTopicWithLastSubscription",
	"created_by":               "description.Domain.SystemData.CreatedBy",
	"created_by_type":          "description.Domain.SystemData.CreatedByType",
	"diagnostic_settings":      "description.DiagnosticSettingsResources",
	"disable_local_auth":       "description.Domain.Properties.DisableLocalAuth",
	"endpoint":                 "description.Domain.Properties.Endpoint",
	"id":                       "description.Domain.ID",
	"identity_type":            "description.Domain.Identity.Type",
	"inbound_ip_rules":         "description.Domain.Properties.InboundIPRules",
	"input_schema":             "description.Domain.Properties.InputSchema",
	"input_schema_mapping":     "description.Domain.Properties.InputSchemaMapping",
	"kaytu_account_id":         "metadata.SourceID",
	"last_modified_by":         "description.Domain.SystemData.LastModifiedBy",
	"last_modified_by_type":    "description.Domain.SystemData.LastModifiedByType",
	"location":                 "description.Domain.Location",
	"name":                     "description.Domain.Name",
	"principal_id":             "description.Domain.Identity.PrincipalID",
	"provisioning_state":       "description.Domain.Properties.ProvisioningState",
	"public_network_access":    "description.Domain.Properties.PublicNetworkAccess",
	"resource_group":           "description.ResourceGroup",
	"sku_name":                 "description.Domain.Name",
	"tags":                     "description.Domain.Tags",
	"title":                    "description.Domain.Name",
	"type":                     "description.Domain.Type",
	"user_assigned_identities": "description.Domain.Identity.UserAssignedIdentities",
}

func ListEventGridDomain(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEventGridDomain")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewEventGridDomainPaginator(essdk.BuildFilter(ctx, d.QueryContext, listEventGridDomainFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEventGridDomainFilters = map[string]string{
	"auto_create_topic_with_first_subscription": "description.Domain.Properties.AutoCreateTopicWithFirstSubscription",
	"auto_delete_topic_with_last_subscription":  "description.Domain.Properties.AutoDeleteTopicWithLastSubscription",
	"created_by":               "description.Domain.SystemData.CreatedBy",
	"created_by_type":          "description.Domain.SystemData.CreatedByType",
	"diagnostic_settings":      "description.DiagnosticSettingsResources",
	"disable_local_auth":       "description.Domain.Properties.DisableLocalAuth",
	"endpoint":                 "description.Domain.Properties.Endpoint",
	"id":                       "description.Domain.ID",
	"identity_type":            "description.Domain.Identity.Type",
	"inbound_ip_rules":         "description.Domain.Properties.InboundIPRules",
	"input_schema":             "description.Domain.Properties.InputSchema",
	"input_schema_mapping":     "description.Domain.Properties.InputSchemaMapping",
	"kaytu_account_id":         "metadata.SourceID",
	"last_modified_by":         "description.Domain.SystemData.LastModifiedBy",
	"last_modified_by_type":    "description.Domain.SystemData.LastModifiedByType",
	"location":                 "description.Domain.Location",
	"name":                     "description.Domain.name",
	"principal_id":             "description.Domain.Identity.PrincipalID",
	"provisioning_state":       "description.Domain.Properties.ProvisioningState",
	"public_network_access":    "description.Domain.Properties.PublicNetworkAccess",
	"resource_group":           "description.ResourceGroup",
	"sku_name":                 "description.Domain.Name",
	"tags":                     "description.Domain.Tags",
	"title":                    "description.Domain.Name",
	"type":                     "description.Domain.Type",
	"user_assigned_identities": "description.Domain.Identity.UserAssignedIdentities",
}

func GetEventGridDomain(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEventGridDomain")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewEventGridDomainPaginator(essdk.BuildFilter(ctx, d.QueryContext, getEventGridDomainFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EventGridDomain =============================

// ==========================  START: EventGridTopic =============================

type EventGridTopic struct {
	Description   azure.EventGridTopicDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

func (r *EventGridTopic) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.EventGridTopicDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type EventGridTopicHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  EventGridTopic `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type EventGridTopicHits struct {
	Total essdk.SearchTotal   `json:"total"`
	Hits  []EventGridTopicHit `json:"hits"`
}

type EventGridTopicSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  EventGridTopicHits `json:"hits"`
}

type EventGridTopicPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewEventGridTopicPaginator(filters []essdk.BoolFilter, limit *int64) (EventGridTopicPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_eventgrid_topics", filters, limit)
	if err != nil {
		return EventGridTopicPaginator{}, err
	}

	p := EventGridTopicPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EventGridTopicPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p EventGridTopicPaginator) NextPage(ctx context.Context) ([]EventGridTopic, error) {
	var response EventGridTopicSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EventGridTopic
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listEventGridTopicFilters = map[string]string{
	"created_by":            "description.Topic.SystemData.CreatedBy",
	"created_by_type":       "description.Topic.SystemData.CreatedByType",
	"diagnostic_settings":   "description.DiagnosticSettingsResources",
	"disable_local_auth":    "description.Topic.Properties.DisableLocalAuth",
	"endpoint":              "description.Topic.Properties.Endpoint",
	"extended_location":     "description.Topic.Location",
	"id":                    "description.Topic.ID",
	"identity":              "description.Topic.Identity",
	"inbound_ip_rules":      "description.Topic.Properties.InboundIPRules",
	"input_schema":          "description.Topic.Properties.InputSchema",
	"input_schema_mapping":  "description.Topic.Properties.InputSchemaMapping",
	"kaytu_account_id":      "metadata.SourceID",
	"kind":                  "description.Topic.Type",
	"last_modified_by":      "description.Topic.SystemData.LastModifiedBy",
	"last_modified_by_type": "description.Topic.SystemData.LastModifiedByType",
	"location":              "description.Topic.Location",
	"name":                  "description.Topic.Name",
	"provisioning_state":    "description.Topic.Properties.ProvisioningState",
	"public_network_access": "description.Topic.Properties.PublicNetworkAccess",
	"resource_group":        "description.ResourceGroup",
	"sku_name":              "description.Topic.Name",
	"tags":                  "description.Topic.Tags",
	"title":                 "description.Topic.Name",
	"type":                  "description.Topic.Type",
}

func ListEventGridTopic(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEventGridTopic")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewEventGridTopicPaginator(essdk.BuildFilter(ctx, d.QueryContext, listEventGridTopicFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEventGridTopicFilters = map[string]string{
	"created_by":            "description.Topic.SystemData.CreatedBy",
	"created_by_type":       "description.Topic.SystemData.CreatedByType",
	"diagnostic_settings":   "description.DiagnosticSettingsResources",
	"disable_local_auth":    "description.Topic.Properties.DisableLocalAuth",
	"endpoint":              "description.Topic.Properties.Endpoint",
	"extended_location":     "description.Topic.Location",
	"id":                    "description.Topic.ID",
	"identity":              "description.Topic.Identity",
	"inbound_ip_rules":      "description.Topic.Properties.InboundIPRules",
	"input_schema":          "description.Topic.Properties.InputSchema",
	"input_schema_mapping":  "description.Topic.Properties.InputSchemaMapping",
	"kaytu_account_id":      "metadata.SourceID",
	"kind":                  "description.Topic.Type",
	"last_modified_by":      "description.Topic.SystemData.LastModifiedBy",
	"last_modified_by_type": "description.Topic.SystemData.LastModifiedByType",
	"location":              "description.Topic.Location",
	"name":                  "description.Topic.name",
	"provisioning_state":    "description.Topic.Properties.ProvisioningState",
	"public_network_access": "description.Topic.Properties.PublicNetworkAccess",
	"resource_group":        "description.ResourceGroup",
	"sku_name":              "description.Topic.Name",
	"tags":                  "description.Topic.Tags",
	"title":                 "description.Topic.Name",
	"type":                  "description.Topic.Type",
}

func GetEventGridTopic(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEventGridTopic")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewEventGridTopicPaginator(essdk.BuildFilter(ctx, d.QueryContext, getEventGridTopicFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EventGridTopic =============================

// ==========================  START: EventhubNamespace =============================

type EventhubNamespace struct {
	Description   azure.EventhubNamespaceDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

func (r *EventhubNamespace) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.EventhubNamespaceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type EventhubNamespaceHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  EventhubNamespace `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type EventhubNamespaceHits struct {
	Total essdk.SearchTotal      `json:"total"`
	Hits  []EventhubNamespaceHit `json:"hits"`
}

type EventhubNamespaceSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  EventhubNamespaceHits `json:"hits"`
}

type EventhubNamespacePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewEventhubNamespacePaginator(filters []essdk.BoolFilter, limit *int64) (EventhubNamespacePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_eventhub_namespaces", filters, limit)
	if err != nil {
		return EventhubNamespacePaginator{}, err
	}

	p := EventhubNamespacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EventhubNamespacePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p EventhubNamespacePaginator) NextPage(ctx context.Context) ([]EventhubNamespace, error) {
	var response EventhubNamespaceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EventhubNamespace
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listEventhubNamespaceFilters = map[string]string{
	"cluster_arm_id":               "description.EHNamespace.Properties.ClusterArmID",
	"diagnostic_settings":          "description.DiagnosticSettingsResources",
	"encryption":                   "description.EHNamespace.Properties.Encryption",
	"id":                           "description.EHNamespace.ID",
	"identity":                     "description.EHNamespace.Properties.Encryption",
	"is_auto_inflate_enabled":      "description.EHNamespace.Properties.IsAutoInflateEnabled",
	"kafka_enabled":                "description.EHNamespace.Properties.KafkaEnabled",
	"kaytu_account_id":             "metadata.SourceID",
	"maximum_throughput_units":     "description.EHNamespace.Properties.MaximumThroughputUnits",
	"metric_id":                    "description.EHNamespace.Properties.MetricID",
	"name":                         "description.EHNamespace.Name",
	"network_rule_set":             "description.NetworkRuleSet",
	"private_endpoint_connections": "description.EHNamespace.Properties.PrivateEndpointConnections",
	"provisioning_state":           "description.EHNamespace.Properties.ProvisioningState",
	"resource_group":               "description.ResourceGroup",
	"service_bus_endpoint":         "description.EHNamespace.Properties.ServiceBusEndpoint",
	"sku_capacity":                 "description.EHNamespace.SKU.Capacity",
	"sku_name":                     "description.EHNamespace.SKU.Name",
	"sku_tier":                     "description.EHNamespace.SKU.Tier",
	"tags":                         "description.EHNamespace.Tags",
	"title":                        "description.EHNamespace.Name",
	"type":                         "description.EHNamespace.Type",
	"zone_redundant":               "description.EHNamespace.Properties.ZoneRedundant",
}

func ListEventhubNamespace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEventhubNamespace")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewEventhubNamespacePaginator(essdk.BuildFilter(ctx, d.QueryContext, listEventhubNamespaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEventhubNamespaceFilters = map[string]string{
	"cluster_arm_id":               "description.EHNamespace.Properties.ClusterArmID",
	"diagnostic_settings":          "description.DiagnosticSettingsResources",
	"encryption":                   "description.EHNamespace.Properties.Encryption",
	"id":                           "description.EHNamespace.ID",
	"identity":                     "description.EHNamespace.Properties.Encryption",
	"is_auto_inflate_enabled":      "description.EHNamespace.Properties.IsAutoInflateEnabled",
	"kafka_enabled":                "description.EHNamespace.Properties.KafkaEnabled",
	"kaytu_account_id":             "metadata.SourceID",
	"maximum_throughput_units":     "description.EHNamespace.Properties.MaximumThroughputUnits",
	"metric_id":                    "description.EHNamespace.Properties.MetricID",
	"name":                         "description.EHNamespace.name",
	"network_rule_set":             "description.NetworkRuleSet",
	"private_endpoint_connections": "description.EHNamespace.Properties.PrivateEndpointConnections",
	"provisioning_state":           "description.EHNamespace.Properties.ProvisioningState",
	"resource_group":               "description.ResourceGroup",
	"service_bus_endpoint":         "description.EHNamespace.Properties.ServiceBusEndpoint",
	"sku_capacity":                 "description.EHNamespace.SKU.Capacity",
	"sku_name":                     "description.EHNamespace.SKU.Name",
	"sku_tier":                     "description.EHNamespace.SKU.Tier",
	"tags":                         "description.EHNamespace.Tags",
	"title":                        "description.EHNamespace.Name",
	"type":                         "description.EHNamespace.Type",
	"zone_redundant":               "description.EHNamespace.Properties.ZoneRedundant",
}

func GetEventhubNamespace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEventhubNamespace")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewEventhubNamespacePaginator(essdk.BuildFilter(ctx, d.QueryContext, getEventhubNamespaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EventhubNamespace =============================

// ==========================  START: EventhubNamespaceEventhub =============================

type EventhubNamespaceEventhub struct {
	Description   azure.EventhubNamespaceEventhubDescription `json:"description"`
	Metadata      azure.Metadata                             `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

func (r *EventhubNamespaceEventhub) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.EventhubNamespaceEventhubDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type EventhubNamespaceEventhubHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  EventhubNamespaceEventhub `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type EventhubNamespaceEventhubHits struct {
	Total essdk.SearchTotal              `json:"total"`
	Hits  []EventhubNamespaceEventhubHit `json:"hits"`
}

type EventhubNamespaceEventhubSearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  EventhubNamespaceEventhubHits `json:"hits"`
}

type EventhubNamespaceEventhubPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewEventhubNamespaceEventhubPaginator(filters []essdk.BoolFilter, limit *int64) (EventhubNamespaceEventhubPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_eventhub_namespaces_eventhubs", filters, limit)
	if err != nil {
		return EventhubNamespaceEventhubPaginator{}, err
	}

	p := EventhubNamespaceEventhubPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EventhubNamespaceEventhubPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p EventhubNamespaceEventhubPaginator) NextPage(ctx context.Context) ([]EventhubNamespaceEventhub, error) {
	var response EventhubNamespaceEventhubSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EventhubNamespaceEventhub
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listEventhubNamespaceEventhubFilters = map[string]string{
	"id":               "description.EventHub.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.EHNamespace.Name",
	"tags":             "description.EHNamespace.Tags",
	"title":            "description.EHNamespace.Identity.Type",
}

func ListEventhubNamespaceEventhub(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEventhubNamespaceEventhub")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewEventhubNamespaceEventhubPaginator(essdk.BuildFilter(ctx, d.QueryContext, listEventhubNamespaceEventhubFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEventhubNamespaceEventhubFilters = map[string]string{
	"id":               "description.EventHub.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.EHNamespace.Name",
	"tags":             "description.EHNamespace.Tags",
	"title":            "description.EHNamespace.Identity.Type",
}

func GetEventhubNamespaceEventhub(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEventhubNamespaceEventhub")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewEventhubNamespaceEventhubPaginator(essdk.BuildFilter(ctx, d.QueryContext, getEventhubNamespaceEventhubFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EventhubNamespaceEventhub =============================

// ==========================  START: Frontdoor =============================

type Frontdoor struct {
	Description   azure.FrontdoorDescription `json:"description"`
	Metadata      azure.Metadata             `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

func (r *Frontdoor) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.FrontdoorDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type FrontdoorHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  Frontdoor     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type FrontdoorHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []FrontdoorHit    `json:"hits"`
}

type FrontdoorSearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  FrontdoorHits `json:"hits"`
}

type FrontdoorPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewFrontdoorPaginator(filters []essdk.BoolFilter, limit *int64) (FrontdoorPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_frontdoors", filters, limit)
	if err != nil {
		return FrontdoorPaginator{}, err
	}

	p := FrontdoorPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p FrontdoorPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p FrontdoorPaginator) NextPage(ctx context.Context) ([]Frontdoor, error) {
	var response FrontdoorSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []Frontdoor
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listFrontdoorFilters = map[string]string{
	"backend_pools":           "description.FrontDoor.Properties.BackendPools",
	"backend_pools_settings":  "description.FrontDoor.Properties.BackendPoolsSettings",
	"diagnostic_settings":     "description.DiagnosticSettingsResources",
	"enabled_state":           "description.FrontDoor.Properties.EnabledState",
	"friendly_name":           "description.FrontDoor.Properties.FriendlyName",
	"front_door_id":           "description.FrontDoor.Properties.FrontdoorID",
	"frontend_endpoints":      "description.FrontDoor.Properties.FrontendEndpoints",
	"health_probe_settings":   "description.FrontDoor.Properties.HealthProbeSettings",
	"id":                      "description.FrontDoor.ID",
	"kaytu_account_id":        "metadata.SourceID",
	"load_balancing_settings": "description.FrontDoor.Properties.LoadBalancingSettings",
	"name":                    "description.FrontDoor.Name",
	"provisioning_state":      "description.FrontDoor.Properties.ProvisioningState",
	"resource_group":          "description.ResourceGroup",
	"resource_state":          "description.FrontDoor.Properties.ResourceState",
	"routing_rules":           "description.FrontDoor.Properties.RoutingRules",
	"rules_engines":           "description.FrontDoor.Properties.RulesEngines",
	"tags":                    "description.FrontDoor.Tags",
	"title":                   "description.FrontDoor.Name",
	"type":                    "description.FrontDoor.Type",
}

func ListFrontdoor(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListFrontdoor")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewFrontdoorPaginator(essdk.BuildFilter(ctx, d.QueryContext, listFrontdoorFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getFrontdoorFilters = map[string]string{
	"backend_pools":           "description.FrontDoor.Properties.BackendPools",
	"backend_pools_settings":  "description.FrontDoor.Properties.BackendPoolsSettings",
	"diagnostic_settings":     "description.DiagnosticSettingsResources",
	"enabled_state":           "description.FrontDoor.Properties.EnabledState",
	"friendly_name":           "description.FrontDoor.Properties.FriendlyName",
	"front_door_id":           "description.FrontDoor.Properties.FrontdoorID",
	"frontend_endpoints":      "description.FrontDoor.Properties.FrontendEndpoints",
	"health_probe_settings":   "description.FrontDoor.Properties.HealthProbeSettings",
	"id":                      "description.FrontDoor.ID",
	"kaytu_account_id":        "metadata.SourceID",
	"load_balancing_settings": "description.FrontDoor.Properties.LoadBalancingSettings",
	"name":                    "description.FrontDoor.name",
	"provisioning_state":      "description.FrontDoor.Properties.ProvisioningState",
	"resource_group":          "description.ResourceGroup",
	"resource_state":          "description.FrontDoor.Properties.ResourceState",
	"routing_rules":           "description.FrontDoor.Properties.RoutingRules",
	"rules_engines":           "description.FrontDoor.Properties.RulesEngines",
	"tags":                    "description.FrontDoor.Tags",
	"title":                   "description.FrontDoor.Name",
	"type":                    "description.FrontDoor.Type",
}

func GetFrontdoor(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetFrontdoor")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewFrontdoorPaginator(essdk.BuildFilter(ctx, d.QueryContext, getFrontdoorFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: Frontdoor =============================

// ==========================  START: HdinsightCluster =============================

type HdinsightCluster struct {
	Description   azure.HdinsightClusterDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *HdinsightCluster) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.HdinsightClusterDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type HdinsightClusterHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  HdinsightCluster `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type HdinsightClusterHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []HdinsightClusterHit `json:"hits"`
}

type HdinsightClusterSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  HdinsightClusterHits `json:"hits"`
}

type HdinsightClusterPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewHdinsightClusterPaginator(filters []essdk.BoolFilter, limit *int64) (HdinsightClusterPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_hdinsight_clusters", filters, limit)
	if err != nil {
		return HdinsightClusterPaginator{}, err
	}

	p := HdinsightClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p HdinsightClusterPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p HdinsightClusterPaginator) NextPage(ctx context.Context) ([]HdinsightCluster, error) {
	var response HdinsightClusterSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []HdinsightCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listHdinsightClusterFilters = map[string]string{
	"cluster_definition":               "description.Cluster.Properties.ClusterDefinition",
	"cluster_hdp_version":              "description.Cluster.Properties.ClusterHdpVersion",
	"cluster_id":                       "description.Cluster.Properties.ClusterID",
	"cluster_state":                    "description.Cluster.Properties.ClusterState",
	"cluster_version":                  "description.Cluster.Properties.ClusterVersion",
	"compute_isolation_properties":     "description.Cluster.Properties.ComputeIsolationProperties",
	"compute_profile":                  "description.Cluster.Properties.ComputeProfile",
	"connectivity_endpoints":           "description.Cluster.Properties.ConnectivityEndpoints",
	"created_date":                     "description.Cluster.Properties.CreatedDate",
	"diagnostic_settings":              "description.DiagnosticSettingsResources",
	"disk_encryption_properties":       "description.Cluster.Properties.DiskEncryptionProperties",
	"encryption_in_transit_properties": "description.Cluster.Properties.EncryptionInTransitProperties",
	"errors":                           "description.Cluster.Properties.Errors",
	"etag":                             "description.Cluster.Etag",
	"excluded_services_config":         "description.Cluster.Properties.ExcludedServicesConfig",
	"id":                               "description.Cluster.ID",
	"identity":                         "description.Cluster.Identity",
	"kafka_rest_properties":            "description.Cluster.Properties.KafkaRestProperties",
	"kaytu_account_id":                 "metadata.SourceID",
	"min_supported_tls_version":        "description.Cluster.Properties.MinSupportedTLSVersion",
	"name":                             "description.Cluster.Name",
	"network_properties":               "description.Cluster.Properties.NetworkProperties",
	"os_type":                          "description.Cluster.Properties.OSType",
	"provisioning_state":               "description.Cluster.Properties.ProvisioningState",
	"quota_info":                       "description.Cluster.Properties.QuotaInfo",
	"resource_group":                   "description.ResourceGroup",
	"security_profile":                 "description.Cluster.Properties.SecurityProfile",
	"storage_profile":                  "description.Cluster.Properties.StorageProfile",
	"tags":                             "description.Cluster.Tags",
	"tier":                             "description.Cluster.Properties.Tier",
	"title":                            "description.Cluster.Name",
	"type":                             "description.Cluster.Type",
}

func ListHdinsightCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListHdinsightCluster")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewHdinsightClusterPaginator(essdk.BuildFilter(ctx, d.QueryContext, listHdinsightClusterFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getHdinsightClusterFilters = map[string]string{
	"cluster_definition":               "description.Cluster.Properties.ClusterDefinition",
	"cluster_hdp_version":              "description.Cluster.Properties.ClusterHdpVersion",
	"cluster_id":                       "description.Cluster.Properties.ClusterID",
	"cluster_state":                    "description.Cluster.Properties.ClusterState",
	"cluster_version":                  "description.Cluster.Properties.ClusterVersion",
	"compute_isolation_properties":     "description.Cluster.Properties.ComputeIsolationProperties",
	"compute_profile":                  "description.Cluster.Properties.ComputeProfile",
	"connectivity_endpoints":           "description.Cluster.Properties.ConnectivityEndpoints",
	"created_date":                     "description.Cluster.Properties.CreatedDate",
	"diagnostic_settings":              "description.DiagnosticSettingsResources",
	"disk_encryption_properties":       "description.Cluster.Properties.DiskEncryptionProperties",
	"encryption_in_transit_properties": "description.Cluster.Properties.EncryptionInTransitProperties",
	"errors":                           "description.Cluster.Properties.Errors",
	"etag":                             "description.Cluster.Etag",
	"excluded_services_config":         "description.Cluster.Properties.ExcludedServicesConfig",
	"id":                               "description.Cluster.ID",
	"identity":                         "description.Cluster.Identity",
	"kafka_rest_properties":            "description.Cluster.Properties.KafkaRestProperties",
	"kaytu_account_id":                 "metadata.SourceID",
	"min_supported_tls_version":        "description.Cluster.Properties.MinSupportedTLSVersion",
	"name":                             "description.Cluster.name",
	"network_properties":               "description.Cluster.Properties.NetworkProperties",
	"os_type":                          "description.Cluster.Properties.OSType",
	"provisioning_state":               "description.Cluster.Properties.ProvisioningState",
	"quota_info":                       "description.Cluster.Properties.QuotaInfo",
	"resource_group":                   "description.ResourceGroup",
	"security_profile":                 "description.Cluster.Properties.SecurityProfile",
	"storage_profile":                  "description.Cluster.Properties.StorageProfile",
	"tags":                             "description.Cluster.Tags",
	"tier":                             "description.Cluster.Properties.Tier",
	"title":                            "description.Cluster.Name",
	"type":                             "description.Cluster.Type",
}

func GetHdinsightCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetHdinsightCluster")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewHdinsightClusterPaginator(essdk.BuildFilter(ctx, d.QueryContext, getHdinsightClusterFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: HdinsightCluster =============================

// ==========================  START: HybridComputeMachine =============================

type HybridComputeMachine struct {
	Description   azure.HybridComputeMachineDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

func (r *HybridComputeMachine) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.HybridComputeMachineDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type HybridComputeMachineHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  HybridComputeMachine `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type HybridComputeMachineHits struct {
	Total essdk.SearchTotal         `json:"total"`
	Hits  []HybridComputeMachineHit `json:"hits"`
}

type HybridComputeMachineSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  HybridComputeMachineHits `json:"hits"`
}

type HybridComputeMachinePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewHybridComputeMachinePaginator(filters []essdk.BoolFilter, limit *int64) (HybridComputeMachinePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_hybridcompute_machines", filters, limit)
	if err != nil {
		return HybridComputeMachinePaginator{}, err
	}

	p := HybridComputeMachinePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p HybridComputeMachinePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p HybridComputeMachinePaginator) NextPage(ctx context.Context) ([]HybridComputeMachine, error) {
	var response HybridComputeMachineSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []HybridComputeMachine
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listHybridComputeMachineFilters = map[string]string{
	"ad_fqdn":                       "description.Machine.Properties.AdFqdn",
	"agent_version":                 "description.Machine.Properties.AgentVersion",
	"client_public_key":             "description.Machine.Properties.ClientPublicKey",
	"display_name":                  "description.Machine.Properties.DisplayName",
	"dns_fqdn":                      "description.Machine.Properties.DNSFqdn",
	"domain_name":                   "description.Machine.Properties.DomainName",
	"error_details":                 "description.Machine.Properties.ErrorDetails",
	"extensions":                    "description.MachineExtensions",
	"id":                            "description.Machine.ID",
	"identity":                      "description.Machine.Identity",
	"kaytu_account_id":              "metadata.SourceID",
	"location_data":                 "description.Machine.Properties.LocationData",
	"machine_fqdn":                  "description.Machine.Properties.MachineFqdn",
	"machine_properties_extensions": "description.Machine.Properties.Extensions",
	"name":                          "description.Machine.Name",
	"os_name":                       "description.Machine.Properties.OSName",
	"os_profile":                    "description.Machine.Properties.OSProfile",
	"os_sku":                        "description.Machine.Properties.OSSKU",
	"os_version":                    "description.Machine.Properties.OSVersion",
	"provisioning_state":            "description.Machine.Properties.ProvisioningState",
	"resource_group":                "description.ResourceGroup",
	"status":                        "description.Machine.Properties.Status",
	"tags":                          "description.Machine.Tags",
	"title":                         "description.Machine.Name",
	"type":                          "description.Machine.Type",
	"vm_id":                         "description.Machine.Properties.VMID",
	"vm_uuid":                       "description.Machine.Properties.VMUUID",
}

func ListHybridComputeMachine(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListHybridComputeMachine")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewHybridComputeMachinePaginator(essdk.BuildFilter(ctx, d.QueryContext, listHybridComputeMachineFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getHybridComputeMachineFilters = map[string]string{
	"ad_fqdn":                       "description.Machine.Properties.AdFqdn",
	"agent_version":                 "description.Machine.Properties.AgentVersion",
	"client_public_key":             "description.Machine.Properties.ClientPublicKey",
	"display_name":                  "description.Machine.Properties.DisplayName",
	"dns_fqdn":                      "description.Machine.Properties.DNSFqdn",
	"domain_name":                   "description.Machine.Properties.DomainName",
	"error_details":                 "description.Machine.Properties.ErrorDetails",
	"extensions":                    "description.MachineExtensions",
	"id":                            "description.Machine.ID",
	"identity":                      "description.Machine.Identity",
	"kaytu_account_id":              "metadata.SourceID",
	"location_data":                 "description.Machine.Properties.LocationData",
	"machine_fqdn":                  "description.Machine.Properties.MachineFqdn",
	"machine_properties_extensions": "description.Machine.Properties.Extensions",
	"name":                          "description.Machine.name",
	"os_name":                       "description.Machine.Properties.OSName",
	"os_profile":                    "description.Machine.Properties.OSProfile",
	"os_sku":                        "description.Machine.Properties.OSSKU",
	"os_version":                    "description.Machine.Properties.OSVersion",
	"provisioning_state":            "description.Machine.Properties.ProvisioningState",
	"resource_group":                "description.ResourceGroup",
	"status":                        "description.Machine.Properties.Status",
	"tags":                          "description.Machine.Tags",
	"title":                         "description.Machine.Name",
	"type":                          "description.Machine.Type",
	"vm_id":                         "description.Machine.Properties.VMID",
	"vm_uuid":                       "description.Machine.Properties.VMUUID",
}

func GetHybridComputeMachine(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetHybridComputeMachine")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewHybridComputeMachinePaginator(essdk.BuildFilter(ctx, d.QueryContext, getHybridComputeMachineFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: HybridComputeMachine =============================

// ==========================  START: IOTHub =============================

type IOTHub struct {
	Description   azure.IOTHubDescription `json:"description"`
	Metadata      azure.Metadata          `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

func (r *IOTHub) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.IOTHubDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type IOTHubHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IOTHub        `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IOTHubHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []IOTHubHit       `json:"hits"`
}

type IOTHubSearchResponse struct {
	PitID string     `json:"pit_id"`
	Hits  IOTHubHits `json:"hits"`
}

type IOTHubPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewIOTHubPaginator(filters []essdk.BoolFilter, limit *int64) (IOTHubPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_devices_iothubs", filters, limit)
	if err != nil {
		return IOTHubPaginator{}, err
	}

	p := IOTHubPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IOTHubPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p IOTHubPaginator) NextPage(ctx context.Context) ([]IOTHub, error) {
	var response IOTHubSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IOTHub
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listIOTHubFilters = map[string]string{
	"authorization_policies":           "description.IotHubDescription.Properties.AuthorizationPolicies",
	"cloud_to_device":                  "description.IotHubDescription.Properties.CloudToDevice",
	"comments":                         "description.IotHubDescription.Properties.Comments",
	"diagnostic_settings":              "description.DiagnosticSettingsResources",
	"enable_file_upload_notifications": "description.IotHubDescription.Properties.EnableFileUploadNotifications",
	"etag":                             "description.IotHubDescription.Etag",
	"event_hub_endpoints":              "description.IotHubDescription.Properties.EventHubEndpoints",
	"features":                         "description.IotHubDescription.Properties.Features",
	"host_name":                        "description.IotHubDescription.Properties.HostName",
	"id":                               "description.IotHubDescription.ID",
	"ip_filter_rules":                  "description.IotHubDescription.Properties.IPFilterRules",
	"kaytu_account_id":                 "metadata.SourceID",
	"locations":                        "description.IotHubDescription.Properties.Locations",
	"messaging_endpoints":              "description.IotHubDescription.Properties.MessagingEndpoints",
	"min_tls_version":                  "description.IotHubDescription.Properties.MinTLSVersion",
	"name":                             "description.IotHubDescription.Name",
	"private_endpoint_connections":     "description.IotHubDescription.Properties.PrivateEndpointConnections",
	"provisioning_state":               "description.IotHubDescription.Properties.ProvisioningState",
	"public_network_access":            "description.IotHubDescription.Properties.PublicNetworkAccess",
	"resource_group":                   "description.ResourceGroup",
	"routing":                          "description.IotHubDescription.Properties.Routing",
	"sku_capacity":                     "description.IotHubDescription.SKU.Capacity",
	"sku_name":                         "description.IotHubDescription.SKU.Name",
	"sku_tier":                         "description.IotHubDescription.SKU.Tier",
	"state":                            "description.IotHubDescription.Properties.State",
	"storage_endpoints":                "description.IotHubDescription.Properties.StorageEndpoints",
	"tags":                             "description.IotHubDescription.Tags",
	"title":                            "description.IotHubDescription.Name",
	"type":                             "description.IotHubDescription.Type",
}

func ListIOTHub(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIOTHub")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewIOTHubPaginator(essdk.BuildFilter(ctx, d.QueryContext, listIOTHubFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIOTHubFilters = map[string]string{
	"authorization_policies":           "description.IotHubDescription.Properties.AuthorizationPolicies",
	"cloud_to_device":                  "description.IotHubDescription.Properties.CloudToDevice",
	"comments":                         "description.IotHubDescription.Properties.Comments",
	"diagnostic_settings":              "description.DiagnosticSettingsResources",
	"enable_file_upload_notifications": "description.IotHubDescription.Properties.EnableFileUploadNotifications",
	"etag":                             "description.IotHubDescription.Etag",
	"event_hub_endpoints":              "description.IotHubDescription.Properties.EventHubEndpoints",
	"features":                         "description.IotHubDescription.Properties.Features",
	"host_name":                        "description.IotHubDescription.Properties.HostName",
	"id":                               "description.IotHubDescription.ID",
	"ip_filter_rules":                  "description.IotHubDescription.Properties.IPFilterRules",
	"kaytu_account_id":                 "metadata.SourceID",
	"locations":                        "description.IotHubDescription.Properties.Locations",
	"messaging_endpoints":              "description.IotHubDescription.Properties.MessagingEndpoints",
	"min_tls_version":                  "description.IotHubDescription.Properties.MinTLSVersion",
	"name":                             "description.IotHubDescription.name",
	"private_endpoint_connections":     "description.IotHubDescription.Properties.PrivateEndpointConnections",
	"provisioning_state":               "description.IotHubDescription.Properties.ProvisioningState",
	"public_network_access":            "description.IotHubDescription.Properties.PublicNetworkAccess",
	"resource_group":                   "description.ResourceGroup",
	"routing":                          "description.IotHubDescription.Properties.Routing",
	"sku_capacity":                     "description.IotHubDescription.SKU.Capacity",
	"sku_name":                         "description.IotHubDescription.SKU.Name",
	"sku_tier":                         "description.IotHubDescription.SKU.Tier",
	"state":                            "description.IotHubDescription.Properties.State",
	"storage_endpoints":                "description.IotHubDescription.Properties.StorageEndpoints",
	"tags":                             "description.IotHubDescription.Tags",
	"title":                            "description.IotHubDescription.Name",
	"type":                             "description.IotHubDescription.Type",
}

func GetIOTHub(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIOTHub")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewIOTHubPaginator(essdk.BuildFilter(ctx, d.QueryContext, getIOTHubFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IOTHub =============================

// ==========================  START: IOTHubDps =============================

type IOTHubDps struct {
	Description   azure.IOTHubDpsDescription `json:"description"`
	Metadata      azure.Metadata             `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

func (r *IOTHubDps) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.IOTHubDpsDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type IOTHubDpsHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IOTHubDps     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IOTHubDpsHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []IOTHubDpsHit    `json:"hits"`
}

type IOTHubDpsSearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  IOTHubDpsHits `json:"hits"`
}

type IOTHubDpsPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewIOTHubDpsPaginator(filters []essdk.BoolFilter, limit *int64) (IOTHubDpsPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_devices_iothubdpses", filters, limit)
	if err != nil {
		return IOTHubDpsPaginator{}, err
	}

	p := IOTHubDpsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IOTHubDpsPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p IOTHubDpsPaginator) NextPage(ctx context.Context) ([]IOTHubDps, error) {
	var response IOTHubDpsSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IOTHubDps
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listIOTHubDpsFilters = map[string]string{
	"allocation_policy":             "description.IotHubDps.Properties.AllocationPolicy",
	"authorization_policies":        "description.IotHubDps.Properties.AuthorizationPolicies",
	"device_provisioning_host_name": "description.IotHubDps.Properties.DeviceProvisioningHostName",
	"diagnostic_settings":           "description.DiagnosticSettingsResources",
	"etag":                          "description.IotHubDps.Etag",
	"id":                            "description.IotHubDps.ID",
	"id_scope":                      "description.IotHubDps.Properties.IDScope",
	"iot_hubs":                      "description.IotHubDps.Properties.IotHubs",
	"kaytu_account_id":              "metadata.SourceID",
	"name":                          "description.IotHubDps.Name",
	"provisioning_state":            "description.IotHubDps.Properties.ProvisioningState",
	"resource_group":                "description.ResourceGroup",
	"service_operations_host_name":  "description.IotHubDps.Properties.ServiceOperationsHostName",
	"sku_capacity":                  "description.IotHubDps.SKU.Capacity",
	"sku_name":                      "description.IotHubDps.SKU.Name",
	"sku_tier":                      "description.IotHubDps.SKU.Tier",
	"state":                         "description.IotHubDps.Properties.State",
	"tags":                          "description.IotHubDps.Tags",
	"title":                         "description.IotHubDps.Name",
	"type":                          "description.IotHubDps.Type",
}

func ListIOTHubDps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIOTHubDps")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewIOTHubDpsPaginator(essdk.BuildFilter(ctx, d.QueryContext, listIOTHubDpsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIOTHubDpsFilters = map[string]string{
	"allocation_policy":             "description.IotHubDps.Properties.AllocationPolicy",
	"authorization_policies":        "description.IotHubDps.Properties.AuthorizationPolicies",
	"device_provisioning_host_name": "description.IotHubDps.Properties.DeviceProvisioningHostName",
	"diagnostic_settings":           "description.DiagnosticSettingsResources",
	"etag":                          "description.IotHubDps.Etag",
	"id":                            "description.IotHubDps.ID",
	"id_scope":                      "description.IotHubDps.Properties.IDScope",
	"iot_hubs":                      "description.IotHubDps.Properties.IotHubs",
	"kaytu_account_id":              "metadata.SourceID",
	"name":                          "description.IotHubDps.name",
	"provisioning_state":            "description.IotHubDps.Properties.ProvisioningState",
	"resource_group":                "description.ResourceGroup",
	"service_operations_host_name":  "description.IotHubDps.Properties.ServiceOperationsHostName",
	"sku_capacity":                  "description.IotHubDps.SKU.Capacity",
	"sku_name":                      "description.IotHubDps.SKU.Name",
	"sku_tier":                      "description.IotHubDps.SKU.Tier",
	"state":                         "description.IotHubDps.Properties.State",
	"tags":                          "description.IotHubDps.Tags",
	"title":                         "description.IotHubDps.Name",
	"type":                          "description.IotHubDps.Type",
}

func GetIOTHubDps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIOTHubDps")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewIOTHubDpsPaginator(essdk.BuildFilter(ctx, d.QueryContext, getIOTHubDpsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IOTHubDps =============================

// ==========================  START: KeyVault =============================

type KeyVault struct {
	Description   azure.KeyVaultDescription `json:"description"`
	Metadata      azure.Metadata            `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

func (r *KeyVault) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.KeyVaultDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type KeyVaultHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  KeyVault      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type KeyVaultHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []KeyVaultHit     `json:"hits"`
}

type KeyVaultSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  KeyVaultHits `json:"hits"`
}

type KeyVaultPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewKeyVaultPaginator(filters []essdk.BoolFilter, limit *int64) (KeyVaultPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_keyvault_vaults", filters, limit)
	if err != nil {
		return KeyVaultPaginator{}, err
	}

	p := KeyVaultPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KeyVaultPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p KeyVaultPaginator) NextPage(ctx context.Context) ([]KeyVault, error) {
	var response KeyVaultSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KeyVault
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listKeyVaultFilters = map[string]string{
	"create_mode":                     "description.Vault.Properties.CreateMode",
	"diagnostic_settings":             "description.DiagnosticSettingsResources",
	"enable_rbac_authorization":       "description.Vault.Properties.EnableRbacAuthorization",
	"enabled_for_deployment":          "description.Vault.Properties.EnabledForDeployment",
	"enabled_for_disk_encryption":     "description.Vault.Properties.EnabledForDiskEncryption",
	"enabled_for_template_deployment": "description.Vault.Properties.EnabledForTemplateDeployment",
	"id":                              "description.Vault.ID",
	"kaytu_account_id":                "metadata.SourceID",
	"name":                            "description.Vault.Name",
	"network_acls":                    "description.Vault.Properties.NetworkACLs",
	"purge_protection_enabled":        "description.Vault.Properties.EnablePurgeProtection",
	"resource_group":                  "description.ResourceGroup",
	"sku_family":                      "description.Vault.Properties.SKU.Family",
	"sku_name":                        "description.Vault.Properties.SKU.Name",
	"soft_delete_enabled":             "description.Vault.Properties.EnableSoftDelete",
	"soft_delete_retention_in_days":   "description.Vault.Properties.SoftDeleteRetentionInDays",
	"tags":                            "description.Vault.Tags",
	"tenant_id":                       "description.Vault.Properties.TenantID",
	"title":                           "description.Vault.Name",
	"type":                            "description.Vault.Type",
	"vault_uri":                       "description.Vault.Properties.VaultURI",
}

func ListKeyVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKeyVault")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewKeyVaultPaginator(essdk.BuildFilter(ctx, d.QueryContext, listKeyVaultFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKeyVaultFilters = map[string]string{
	"create_mode":                     "description.Vault.Properties.CreateMode",
	"diagnostic_settings":             "description.DiagnosticSettingsResources",
	"enable_rbac_authorization":       "description.Vault.Properties.EnableRbacAuthorization",
	"enabled_for_deployment":          "description.Vault.Properties.EnabledForDeployment",
	"enabled_for_disk_encryption":     "description.Vault.Properties.EnabledForDiskEncryption",
	"enabled_for_template_deployment": "description.Vault.Properties.EnabledForTemplateDeployment",
	"id":                              "description.Vault.ID",
	"kaytu_account_id":                "metadata.SourceID",
	"name":                            "description.Resource.name",
	"network_acls":                    "description.Vault.Properties.NetworkACLs",
	"purge_protection_enabled":        "description.Vault.Properties.EnablePurgeProtection",
	"resource_group":                  "description.ResourceGroup",
	"sku_family":                      "description.Vault.Properties.SKU.Family",
	"sku_name":                        "description.Vault.Properties.SKU.Name",
	"soft_delete_enabled":             "description.Vault.Properties.EnableSoftDelete",
	"soft_delete_retention_in_days":   "description.Vault.Properties.SoftDeleteRetentionInDays",
	"tags":                            "description.Vault.Tags",
	"tenant_id":                       "description.Vault.Properties.TenantID",
	"title":                           "description.Vault.Name",
	"type":                            "description.Vault.Type",
	"vault_uri":                       "description.Vault.Properties.VaultURI",
}

func GetKeyVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKeyVault")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewKeyVaultPaginator(essdk.BuildFilter(ctx, d.QueryContext, getKeyVaultFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KeyVault =============================

// ==========================  START: KeyVaultDeletedVault =============================

type KeyVaultDeletedVault struct {
	Description   azure.KeyVaultDeletedVaultDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

func (r *KeyVaultDeletedVault) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.KeyVaultDeletedVaultDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type KeyVaultDeletedVaultHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  KeyVaultDeletedVault `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type KeyVaultDeletedVaultHits struct {
	Total essdk.SearchTotal         `json:"total"`
	Hits  []KeyVaultDeletedVaultHit `json:"hits"`
}

type KeyVaultDeletedVaultSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  KeyVaultDeletedVaultHits `json:"hits"`
}

type KeyVaultDeletedVaultPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewKeyVaultDeletedVaultPaginator(filters []essdk.BoolFilter, limit *int64) (KeyVaultDeletedVaultPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_keyvault_deletedvaults", filters, limit)
	if err != nil {
		return KeyVaultDeletedVaultPaginator{}, err
	}

	p := KeyVaultDeletedVaultPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KeyVaultDeletedVaultPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p KeyVaultDeletedVaultPaginator) NextPage(ctx context.Context) ([]KeyVaultDeletedVault, error) {
	var response KeyVaultDeletedVaultSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KeyVaultDeletedVault
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listKeyVaultDeletedVaultFilters = map[string]string{
	"id":               "description.Vault.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Vault.Name",
	"tags":             "description.Vault.Properties.Tags",
	"title":            "description.Vault.Name",
	"type":             "description.Vault.Type",
	"vault_id":         "description.Vault.Properties.VaultID",
}

func ListKeyVaultDeletedVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKeyVaultDeletedVault")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewKeyVaultDeletedVaultPaginator(essdk.BuildFilter(ctx, d.QueryContext, listKeyVaultDeletedVaultFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKeyVaultDeletedVaultFilters = map[string]string{
	"id":               "description.Vault.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Vault.name",
	"region":           "description.Vault.Properties.Location",
	"tags":             "description.Vault.Properties.Tags",
	"title":            "description.Vault.Name",
	"type":             "description.Vault.Type",
	"vault_id":         "description.Vault.Properties.VaultID",
}

func GetKeyVaultDeletedVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKeyVaultDeletedVault")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewKeyVaultDeletedVaultPaginator(essdk.BuildFilter(ctx, d.QueryContext, getKeyVaultDeletedVaultFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KeyVaultDeletedVault =============================

// ==========================  START: KeyVaultManagedHardwareSecurityModule =============================

type KeyVaultManagedHardwareSecurityModule struct {
	Description   azure.KeyVaultManagedHardwareSecurityModuleDescription `json:"description"`
	Metadata      azure.Metadata                                         `json:"metadata"`
	ResourceJobID int                                                    `json:"resource_job_id"`
	SourceJobID   int                                                    `json:"source_job_id"`
	ResourceType  string                                                 `json:"resource_type"`
	SourceType    string                                                 `json:"source_type"`
	ID            string                                                 `json:"id"`
	ARN           string                                                 `json:"arn"`
	SourceID      string                                                 `json:"source_id"`
}

func (r *KeyVaultManagedHardwareSecurityModule) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.KeyVaultManagedHardwareSecurityModuleDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type KeyVaultManagedHardwareSecurityModuleHit struct {
	ID      string                                `json:"_id"`
	Score   float64                               `json:"_score"`
	Index   string                                `json:"_index"`
	Type    string                                `json:"_type"`
	Version int64                                 `json:"_version,omitempty"`
	Source  KeyVaultManagedHardwareSecurityModule `json:"_source"`
	Sort    []interface{}                         `json:"sort"`
}

type KeyVaultManagedHardwareSecurityModuleHits struct {
	Total essdk.SearchTotal                          `json:"total"`
	Hits  []KeyVaultManagedHardwareSecurityModuleHit `json:"hits"`
}

type KeyVaultManagedHardwareSecurityModuleSearchResponse struct {
	PitID string                                    `json:"pit_id"`
	Hits  KeyVaultManagedHardwareSecurityModuleHits `json:"hits"`
}

type KeyVaultManagedHardwareSecurityModulePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewKeyVaultManagedHardwareSecurityModulePaginator(filters []essdk.BoolFilter, limit *int64) (KeyVaultManagedHardwareSecurityModulePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_keyvault_managedhsms", filters, limit)
	if err != nil {
		return KeyVaultManagedHardwareSecurityModulePaginator{}, err
	}

	p := KeyVaultManagedHardwareSecurityModulePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KeyVaultManagedHardwareSecurityModulePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p KeyVaultManagedHardwareSecurityModulePaginator) NextPage(ctx context.Context) ([]KeyVaultManagedHardwareSecurityModule, error) {
	var response KeyVaultManagedHardwareSecurityModuleSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KeyVaultManagedHardwareSecurityModule
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listKeyVaultManagedHardwareSecurityModuleFilters = map[string]string{
	"create_mode":                   "description.ManagedHsm.Properties.CreateMode",
	"diagnostic_settings":           "description.DiagnosticSettingsResources",
	"enable_purge_protection":       "description.ManagedHsm.Properties.EnablePurgeProtection",
	"enable_soft_delete":            "description.ManagedHsm.Properties.EnableSoftDelete",
	"hsm_uri":                       "description.ManagedHsm.Properties.HsmURI",
	"id":                            "description.ManagedHsm.ID",
	"kaytu_account_id":              "metadata.SourceID",
	"name":                          "description.ManagedHsm.Name",
	"provisioning_state":            "description.ManagedHsm.Properties.ProvisioningState",
	"resource_group":                "description.ResourceGroup",
	"sku_family":                    "description.ManagedHsm.SKU.Family",
	"sku_name":                      "description.ManagedHsm.SKU.Name",
	"soft_delete_retention_in_days": "description.ManagedHsm.Properties.SoftDeleteRetentionInDays",
	"status_message":                "description.ManagedHsm.Properties.StatusMessage",
	"tags":                          "description.ManagedHsm.Tags",
	"tenant_id":                     "description.ManagedHsm.Properties.TenantID",
	"title":                         "description.ManagedHsm.Name",
	"type":                          "description.ManagedHsm.Type",
}

func ListKeyVaultManagedHardwareSecurityModule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKeyVaultManagedHardwareSecurityModule")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewKeyVaultManagedHardwareSecurityModulePaginator(essdk.BuildFilter(ctx, d.QueryContext, listKeyVaultManagedHardwareSecurityModuleFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKeyVaultManagedHardwareSecurityModuleFilters = map[string]string{
	"create_mode":                   "description.ManagedHsm.Properties.CreateMode",
	"diagnostic_settings":           "description.DiagnosticSettingsResources",
	"enable_purge_protection":       "description.ManagedHsm.Properties.EnablePurgeProtection",
	"enable_soft_delete":            "description.ManagedHsm.Properties.EnableSoftDelete",
	"hsm_uri":                       "description.ManagedHsm.Properties.HsmURI",
	"id":                            "description.ManagedHsm.ID",
	"kaytu_account_id":              "metadata.SourceID",
	"name":                          "description.ManagedHsm.name",
	"provisioning_state":            "description.ManagedHsm.Properties.ProvisioningState",
	"resource_group":                "description.ResourceGroup",
	"sku_family":                    "description.ManagedHsm.SKU.Family",
	"sku_name":                      "description.ManagedHsm.SKU.Name",
	"soft_delete_retention_in_days": "description.ManagedHsm.Properties.SoftDeleteRetentionInDays",
	"status_message":                "description.ManagedHsm.Properties.StatusMessage",
	"tags":                          "description.ManagedHsm.Tags",
	"tenant_id":                     "description.ManagedHsm.Properties.TenantID",
	"title":                         "description.ManagedHsm.Name",
	"type":                          "description.ManagedHsm.Type",
}

func GetKeyVaultManagedHardwareSecurityModule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKeyVaultManagedHardwareSecurityModule")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewKeyVaultManagedHardwareSecurityModulePaginator(essdk.BuildFilter(ctx, d.QueryContext, getKeyVaultManagedHardwareSecurityModuleFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KeyVaultManagedHardwareSecurityModule =============================

// ==========================  START: KeyVaultSecret =============================

type KeyVaultSecret struct {
	Description   azure.KeyVaultSecretDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

func (r *KeyVaultSecret) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.KeyVaultSecretDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type KeyVaultSecretHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  KeyVaultSecret `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type KeyVaultSecretHits struct {
	Total essdk.SearchTotal   `json:"total"`
	Hits  []KeyVaultSecretHit `json:"hits"`
}

type KeyVaultSecretSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  KeyVaultSecretHits `json:"hits"`
}

type KeyVaultSecretPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewKeyVaultSecretPaginator(filters []essdk.BoolFilter, limit *int64) (KeyVaultSecretPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_keyvault_vaults_secrets", filters, limit)
	if err != nil {
		return KeyVaultSecretPaginator{}, err
	}

	p := KeyVaultSecretPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KeyVaultSecretPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p KeyVaultSecretPaginator) NextPage(ctx context.Context) ([]KeyVaultSecret, error) {
	var response KeyVaultSecretSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KeyVaultSecret
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listKeyVaultSecretFilters = map[string]string{
	"akas":             "description.TurboData.Akas",
	"content_type":     "description.SecretItem.Properties.ContentType",
	"enabled":          "description.SecretItem.Properties.Attributes.Enabled",
	"id":               "description.SecretItem.ID",
	"kaytu_account_id": "metadata.SourceID",
	"kid":              "description.SecretBundle.Kid",
	"name":             "description.SecretItem.Name",
	"recoverable_days": "description.Vault.Properties.SoftDeleteRetentionInDays",
	"resource_group":   "description.TurboData.ResourceGroup",
	"tags":             "description.SecretItem.Tags",
	"value":            "description.SecretItem.Properties.Value",
}

func ListKeyVaultSecret(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKeyVaultSecret")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewKeyVaultSecretPaginator(essdk.BuildFilter(ctx, d.QueryContext, listKeyVaultSecretFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKeyVaultSecretFilters = map[string]string{
	"akas":             "description.TurboData.Akas",
	"content_type":     "description.SecretItem.Properties.ContentType",
	"enabled":          "description.SecretItem.Properties.Attributes.Enabled",
	"id":               "description.SecretItem.ID",
	"kaytu_account_id": "metadata.SourceID",
	"kid":              "description.SecretBundle.Kid",
	"name":             "description.SecretItem.name",
	"recoverable_days": "description.Vault.Properties.SoftDeleteRetentionInDays",
	"resource_group":   "description.ResourceGroup",
	"tags":             "description.SecretItem.Tags",
	"value":            "description.SecretItem.Properties.Value",
}

func GetKeyVaultSecret(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKeyVaultSecret")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewKeyVaultSecretPaginator(essdk.BuildFilter(ctx, d.QueryContext, getKeyVaultSecretFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KeyVaultSecret =============================

// ==========================  START: KustoCluster =============================

type KustoCluster struct {
	Description   azure.KustoClusterDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

func (r *KustoCluster) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.KustoClusterDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type KustoClusterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  KustoCluster  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type KustoClusterHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []KustoClusterHit `json:"hits"`
}

type KustoClusterSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  KustoClusterHits `json:"hits"`
}

type KustoClusterPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewKustoClusterPaginator(filters []essdk.BoolFilter, limit *int64) (KustoClusterPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_kusto_clusters", filters, limit)
	if err != nil {
		return KustoClusterPaginator{}, err
	}

	p := KustoClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KustoClusterPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p KustoClusterPaginator) NextPage(ctx context.Context) ([]KustoCluster, error) {
	var response KustoClusterSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KustoCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listKustoClusterFilters = map[string]string{
	"data_ingestion_uri":            "description.Cluster.Properties.DataIngestionURI",
	"enable_disk_encryption":        "description.Cluster.Properties.EnableDiskEncryption",
	"enable_double_encryption":      "description.Cluster.Properties.EnableDoubleEncryption",
	"enable_purge":                  "description.Cluster.Properties.EnablePurge",
	"enable_streaming_ingest":       "description.Cluster.Properties.EnableStreamingIngest",
	"engine_type":                   "description.Cluster.Properties.EngineType",
	"etag":                          "description.Cluster.Etag",
	"id":                            "description.Cluster.ID",
	"kaytu_account_id":              "metadata.SourceID",
	"key_vault_properties":          "description.Cluster.Properties.KeyVaultProperties",
	"language_extensions":           "description.Cluster.Properties.LanguageExtensions",
	"location":                      "description.Cluster.Location",
	"name":                          "description.Cluster.Name",
	"optimized_autoscale":           "description.Cluster.Properties.OptimizedAutoscale",
	"provisioning_state":            "description.Cluster.Properties.ProvisioningState",
	"resource_group":                "description.ResourceGroup",
	"sku_capacity":                  "description.Cluster.SKU.Capacity",
	"sku_name":                      "description.Cluster.SKU.Name",
	"sku_tier":                      "description.Cluster.SKU.Tier",
	"state":                         "description.Cluster.Properties.State",
	"state_reason":                  "description.Cluster.Properties.StateReason",
	"tags":                          "description.Cluster.Tags",
	"title":                         "description.Cluster.Name",
	"trusted_external_tenants":      "description.Cluster.Properties.TrustedExternalTenants",
	"type":                          "description.Cluster.Type",
	"uri":                           "description.Cluster.Properties.URI",
	"virtual_network_configuration": "description.Cluster.Properties.VirtualNetworkConfiguration",
}

func ListKustoCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKustoCluster")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewKustoClusterPaginator(essdk.BuildFilter(ctx, d.QueryContext, listKustoClusterFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKustoClusterFilters = map[string]string{
	"data_ingestion_uri":            "description.Cluster.Properties.DataIngestionURI",
	"enable_disk_encryption":        "description.Cluster.Properties.EnableDiskEncryption",
	"enable_double_encryption":      "description.Cluster.Properties.EnableDoubleEncryption",
	"enable_purge":                  "description.Cluster.Properties.EnablePurge",
	"enable_streaming_ingest":       "description.Cluster.Properties.EnableStreamingIngest",
	"engine_type":                   "description.Cluster.Properties.EngineType",
	"etag":                          "description.Cluster.Etag",
	"id":                            "description.Cluster.ID",
	"kaytu_account_id":              "metadata.SourceID",
	"key_vault_properties":          "description.Cluster.Properties.KeyVaultProperties",
	"language_extensions":           "description.Cluster.Properties.LanguageExtensions",
	"location":                      "description.Cluster.Location",
	"name":                          "description.Cluster.name",
	"optimized_autoscale":           "description.Cluster.Properties.OptimizedAutoscale",
	"provisioning_state":            "description.Cluster.Properties.ProvisioningState",
	"resource_group":                "description.ResourceGroup",
	"sku_capacity":                  "description.Cluster.SKU.Capacity",
	"sku_name":                      "description.Cluster.SKU.Name",
	"sku_tier":                      "description.Cluster.SKU.Tier",
	"state":                         "description.Cluster.Properties.State",
	"state_reason":                  "description.Cluster.Properties.StateReason",
	"tags":                          "description.Cluster.Tags",
	"title":                         "description.Cluster.Name",
	"trusted_external_tenants":      "description.Cluster.Properties.TrustedExternalTenants",
	"type":                          "description.Cluster.Type",
	"uri":                           "description.Cluster.Properties.URI",
	"virtual_network_configuration": "description.Cluster.Properties.VirtualNetworkConfiguration",
}

func GetKustoCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKustoCluster")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewKustoClusterPaginator(essdk.BuildFilter(ctx, d.QueryContext, getKustoClusterFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KustoCluster =============================

// ==========================  START: LogAlert =============================

type LogAlert struct {
	Description   azure.LogAlertDescription `json:"description"`
	Metadata      azure.Metadata            `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

func (r *LogAlert) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.LogAlertDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type LogAlertHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  LogAlert      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type LogAlertHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []LogAlertHit     `json:"hits"`
}

type LogAlertSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  LogAlertHits `json:"hits"`
}

type LogAlertPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewLogAlertPaginator(filters []essdk.BoolFilter, limit *int64) (LogAlertPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_insights_activitylogalerts", filters, limit)
	if err != nil {
		return LogAlertPaginator{}, err
	}

	p := LogAlertPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LogAlertPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p LogAlertPaginator) NextPage(ctx context.Context) ([]LogAlert, error) {
	var response LogAlertSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LogAlert
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listLogAlertFilters = map[string]string{
	"actions":          "description.ActivityLogAlertResource.Properties.Actions",
	"condition":        "description.ActivityLogAlertResource.Properties.Condition",
	"description":      "description.ActivityLogAlertResource.Properties.Description",
	"enabled":          "description.ActivityLogAlertResource.Properties.Enabled",
	"id":               "description.ActivityLogAlertResource.ID",
	"kaytu_account_id": "metadata.SourceID",
	"location":         "description.ActivityLogAlertResource.Location",
	"name":             "description.ActivityLogAlertResource.Name",
	"resource_group":   "description.ResourceGroup",
	"scopes":           "description.ActivityLogAlertResource.Properties.Scopes",
	"tags":             "description.ActivityLogAlertResource.Tags",
	"title":            "description.ActivityLogAlertResource.Name",
	"type":             "description.ActivityLogAlertResource.Type",
}

func ListLogAlert(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLogAlert")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewLogAlertPaginator(essdk.BuildFilter(ctx, d.QueryContext, listLogAlertFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLogAlertFilters = map[string]string{
	"actions":          "description.ActivityLogAlertResource.Properties.Actions",
	"condition":        "description.ActivityLogAlertResource.Properties.Condition",
	"description":      "description.ActivityLogAlertResource.Properties.Description",
	"enabled":          "description.ActivityLogAlertResource.Properties.Enabled",
	"id":               "description.ActivityLogAlertResource.ID",
	"kaytu_account_id": "metadata.SourceID",
	"location":         "description.ActivityLogAlertResource.Location",
	"name":             "description.ActivityLogAlertResource.name",
	"resource_group":   "description.ResourceGroup",
	"scopes":           "description.ActivityLogAlertResource.Properties.Scopes",
	"tags":             "description.ActivityLogAlertResource.Tags",
	"title":            "description.ActivityLogAlertResource.Name",
	"type":             "description.ActivityLogAlertResource.Type",
}

func GetLogAlert(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLogAlert")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewLogAlertPaginator(essdk.BuildFilter(ctx, d.QueryContext, getLogAlertFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LogAlert =============================

// ==========================  START: LogProfile =============================

type LogProfile struct {
	Description   azure.LogProfileDescription `json:"description"`
	Metadata      azure.Metadata              `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

func (r *LogProfile) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.LogProfileDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type LogProfileHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  LogProfile    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type LogProfileHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []LogProfileHit   `json:"hits"`
}

type LogProfileSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  LogProfileHits `json:"hits"`
}

type LogProfilePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewLogProfilePaginator(filters []essdk.BoolFilter, limit *int64) (LogProfilePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_insights_logprofiles", filters, limit)
	if err != nil {
		return LogProfilePaginator{}, err
	}

	p := LogProfilePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LogProfilePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p LogProfilePaginator) NextPage(ctx context.Context) ([]LogProfile, error) {
	var response LogProfileSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LogProfile
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listLogProfileFilters = map[string]string{
	"categories":          "description.LogProfileResource.Properties.Categories",
	"id":                  "description.LogProfileResource.ID",
	"kaytu_account_id":    "metadata.SourceID",
	"location":            "description.LogProfileResource.Location",
	"log_event_location":  "description.LogProfileResource.Properties.Locations",
	"name":                "description.LogProfileResource.Name",
	"resource_group":      "description.ResourceGroup",
	"retention_policy":    "description.LogProfileResource.Properties.RetentionPolicy",
	"service_bus_rule_id": "description.LogProfileResource.Properties.ServiceBusRuleID",
	"storage_account_id":  "description.LogProfileResource.Properties.StorageAccountID",
	"tags":                "description.LogProfileResource.Tags",
	"title":               "description.LogProfileResource.Name",
	"type":                "description.LogProfileResource.Type",
}

func ListLogProfile(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLogProfile")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewLogProfilePaginator(essdk.BuildFilter(ctx, d.QueryContext, listLogProfileFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLogProfileFilters = map[string]string{
	"categories":          "description.LogProfileResource.Properties.Categories",
	"id":                  "description.LogProfileResource.ID",
	"kaytu_account_id":    "metadata.SourceID",
	"location":            "description.LogProfileResource.Location",
	"log_event_location":  "description.LogProfileResource.Properties.Locations",
	"name":                "description.LogProfileResource.name",
	"resource_group":      "description.ResourceGroup",
	"retention_policy":    "description.LogProfileResource.Properties.RetentionPolicy",
	"service_bus_rule_id": "description.LogProfileResource.Properties.ServiceBusRuleID",
	"storage_account_id":  "description.LogProfileResource.Properties.StorageAccountID",
	"tags":                "description.LogProfileResource.Tags",
	"title":               "description.LogProfileResource.Name",
	"type":                "description.LogProfileResource.Type",
}

func GetLogProfile(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLogProfile")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewLogProfilePaginator(essdk.BuildFilter(ctx, d.QueryContext, getLogProfileFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LogProfile =============================

// ==========================  START: LogicAppWorkflow =============================

type LogicAppWorkflow struct {
	Description   azure.LogicAppWorkflowDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *LogicAppWorkflow) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.LogicAppWorkflowDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type LogicAppWorkflowHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  LogicAppWorkflow `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type LogicAppWorkflowHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []LogicAppWorkflowHit `json:"hits"`
}

type LogicAppWorkflowSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  LogicAppWorkflowHits `json:"hits"`
}

type LogicAppWorkflowPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewLogicAppWorkflowPaginator(filters []essdk.BoolFilter, limit *int64) (LogicAppWorkflowPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_logic_workflows", filters, limit)
	if err != nil {
		return LogicAppWorkflowPaginator{}, err
	}

	p := LogicAppWorkflowPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LogicAppWorkflowPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p LogicAppWorkflowPaginator) NextPage(ctx context.Context) ([]LogicAppWorkflow, error) {
	var response LogicAppWorkflowSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LogicAppWorkflow
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listLogicAppWorkflowFilters = map[string]string{
	"access_control":                  "description.Workflow.Properties.AccessControl",
	"access_endpoint":                 "description.Workflow.Properties.AccessEndpoint",
	"definition":                      "description.Workflow.Properties.Definition",
	"diagnostic_settings":             "description.DiagnosticSettingsResources",
	"endpoints_configuration":         "description.Workflow.Properties.EndpointsConfiguration",
	"id":                              "description.Workflow.ID",
	"integration_account":             "description.Workflow.Properties.IntegrationAccount",
	"integration_service_environment": "description.Workflow.Properties.IntegrationServiceEnvironment",
	"kaytu_account_id":                "metadata.SourceID",
	"name":                            "description.Workflow.Name",
	"parameters":                      "description.Workflow.Properties.Parameters",
	"provisioning_state":              "description.Workflow.Properties.ProvisioningState",
	"resource_group":                  "description.ResourceGroup",
	"sku_name":                        "description.Workflow.Properties.SKU.Name",
	"sku_plan":                        "description.Workflow.Properties.SKU.Plan",
	"state":                           "description.Workflow.Properties.State",
	"tags":                            "description.Workflow.Tags",
	"title":                           "description.Workflow.Name",
	"type":                            "description.Workflow.Type",
	"version":                         "description.Workflow.Properties.Version",
}

func ListLogicAppWorkflow(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLogicAppWorkflow")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewLogicAppWorkflowPaginator(essdk.BuildFilter(ctx, d.QueryContext, listLogicAppWorkflowFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLogicAppWorkflowFilters = map[string]string{
	"access_control":                  "description.Workflow.Properties.AccessControl",
	"access_endpoint":                 "description.Workflow.Properties.AccessEndpoint",
	"definition":                      "description.Workflow.Properties.Definition",
	"diagnostic_settings":             "description.DiagnosticSettingsResources",
	"endpoints_configuration":         "description.Workflow.Properties.EndpointsConfiguration",
	"id":                              "description.Workflow.ID",
	"integration_account":             "description.Workflow.Properties.IntegrationAccount",
	"integration_service_environment": "description.Workflow.Properties.IntegrationServiceEnvironment",
	"kaytu_account_id":                "metadata.SourceID",
	"name":                            "description.Workflow.name",
	"parameters":                      "description.Workflow.Properties.Parameters",
	"provisioning_state":              "description.Workflow.Properties.ProvisioningState",
	"resource_group":                  "description.ResourceGroup",
	"sku_name":                        "description.Workflow.Properties.SKU.Name",
	"sku_plan":                        "description.Workflow.Properties.SKU.Plan",
	"state":                           "description.Workflow.Properties.State",
	"tags":                            "description.Workflow.Tags",
	"title":                           "description.Workflow.Name",
	"type":                            "description.Workflow.Type",
	"version":                         "description.Workflow.Properties.Version",
}

func GetLogicAppWorkflow(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLogicAppWorkflow")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewLogicAppWorkflowPaginator(essdk.BuildFilter(ctx, d.QueryContext, getLogicAppWorkflowFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LogicAppWorkflow =============================

// ==========================  START: LogicIntegrationAccounts =============================

type LogicIntegrationAccounts struct {
	Description   azure.LogicIntegrationAccountsDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

func (r *LogicIntegrationAccounts) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.LogicIntegrationAccountsDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type LogicIntegrationAccountsHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  LogicIntegrationAccounts `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type LogicIntegrationAccountsHits struct {
	Total essdk.SearchTotal             `json:"total"`
	Hits  []LogicIntegrationAccountsHit `json:"hits"`
}

type LogicIntegrationAccountsSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  LogicIntegrationAccountsHits `json:"hits"`
}

type LogicIntegrationAccountsPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewLogicIntegrationAccountsPaginator(filters []essdk.BoolFilter, limit *int64) (LogicIntegrationAccountsPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_logic_integrationaccounts", filters, limit)
	if err != nil {
		return LogicIntegrationAccountsPaginator{}, err
	}

	p := LogicIntegrationAccountsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LogicIntegrationAccountsPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p LogicIntegrationAccountsPaginator) NextPage(ctx context.Context) ([]LogicIntegrationAccounts, error) {
	var response LogicIntegrationAccountsSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LogicIntegrationAccounts
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listLogicIntegrationAccountsFilters = map[string]string{
	"id":               "description.IntegrationAccounts.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Account.Properties.IntegrationServiceEnvironment.Name",
	"tags":             "description.Account.Properties.IntegrationServiceEnvironment.Name",
	"title":            "description.Account.Properties.IntegrationServiceEnvironment.Name",
}

func ListLogicIntegrationAccounts(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLogicIntegrationAccounts")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewLogicIntegrationAccountsPaginator(essdk.BuildFilter(ctx, d.QueryContext, listLogicIntegrationAccountsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLogicIntegrationAccountsFilters = map[string]string{
	"id":               "description.IntegrationAccounts.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Account.Properties.IntegrationServiceEnvironment.Name",
	"tags":             "description.Account.Properties.IntegrationServiceEnvironment.Name",
	"title":            "description.Account.Properties.IntegrationServiceEnvironment.Name",
}

func GetLogicIntegrationAccounts(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLogicIntegrationAccounts")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewLogicIntegrationAccountsPaginator(essdk.BuildFilter(ctx, d.QueryContext, getLogicIntegrationAccountsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LogicIntegrationAccounts =============================

// ==========================  START: MachineLearningWorkspace =============================

type MachineLearningWorkspace struct {
	Description   azure.MachineLearningWorkspaceDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

func (r *MachineLearningWorkspace) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.MachineLearningWorkspaceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type MachineLearningWorkspaceHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  MachineLearningWorkspace `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type MachineLearningWorkspaceHits struct {
	Total essdk.SearchTotal             `json:"total"`
	Hits  []MachineLearningWorkspaceHit `json:"hits"`
}

type MachineLearningWorkspaceSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  MachineLearningWorkspaceHits `json:"hits"`
}

type MachineLearningWorkspacePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewMachineLearningWorkspacePaginator(filters []essdk.BoolFilter, limit *int64) (MachineLearningWorkspacePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_machinelearningservices_workspaces", filters, limit)
	if err != nil {
		return MachineLearningWorkspacePaginator{}, err
	}

	p := MachineLearningWorkspacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p MachineLearningWorkspacePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p MachineLearningWorkspacePaginator) NextPage(ctx context.Context) ([]MachineLearningWorkspace, error) {
	var response MachineLearningWorkspaceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []MachineLearningWorkspace
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listMachineLearningWorkspaceFilters = map[string]string{
	"application_insights":               "description.Workspace.Properties.ApplicationInsights",
	"container_registry":                 "description.Workspace.Properties.ContainerRegistry",
	"description":                        "description.Workspace.Properties.Description",
	"diagnostic_settings":                "description.DiagnosticSettingsResources",
	"discovery_url":                      "description.Workspace.Properties.DiscoveryURL",
	"encryption":                         "description.Workspace.Properties.Encryption",
	"friendly_name":                      "description.Workspace.Properties.FriendlyName",
	"hbi_workspace":                      "description.Workspace.Properties.HbiWorkspace",
	"id":                                 "description.Workspace.ID",
	"identity":                           "description.Workspace.Identity",
	"kaytu_account_id":                   "metadata.SourceID",
	"key_vault":                          "description.Workspace.Properties.KeyVault",
	"location":                           "description.Workspace.Location",
	"name":                               "description.Workspace.Name",
	"provisioning_state":                 "description.Workspace.Properties.ProvisioningState",
	"resource_group":                     "description.ResourceGroup",
	"service_provisioned_resource_group": "description.Workspace.Properties.ServiceProvisionedResourceGroup",
	"sku_name":                           "description.Workspace.SKU.Name",
	"sku_tier":                           "description.Workspace.SKU.Tier",
	"storage_account":                    "description.Workspace.Properties.StorageAccount",
	"tags":                               "description.Workspace.Tags",
	"title":                              "description.Workspace.Name",
	"type":                               "description.Workspace.Type",
	"workspace_id":                       "description.Workspace.Properties.WorkspaceID",
}

func ListMachineLearningWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListMachineLearningWorkspace")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewMachineLearningWorkspacePaginator(essdk.BuildFilter(ctx, d.QueryContext, listMachineLearningWorkspaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getMachineLearningWorkspaceFilters = map[string]string{
	"application_insights":               "description.Workspace.Properties.ApplicationInsights",
	"container_registry":                 "description.Workspace.Properties.ContainerRegistry",
	"description":                        "description.Workspace.Properties.Description",
	"diagnostic_settings":                "description.DiagnosticSettingsResources",
	"discovery_url":                      "description.Workspace.Properties.DiscoveryURL",
	"encryption":                         "description.Workspace.Properties.Encryption",
	"friendly_name":                      "description.Workspace.Properties.FriendlyName",
	"hbi_workspace":                      "description.Workspace.Properties.HbiWorkspace",
	"id":                                 "description.Workspace.ID",
	"identity":                           "description.Workspace.Identity",
	"kaytu_account_id":                   "metadata.SourceID",
	"key_vault":                          "description.Workspace.Properties.KeyVault",
	"location":                           "description.Workspace.Location",
	"name":                               "description.Workspace.name",
	"provisioning_state":                 "description.Workspace.Properties.ProvisioningState",
	"resource_group":                     "description.ResourceGroup",
	"service_provisioned_resource_group": "description.Workspace.Properties.ServiceProvisionedResourceGroup",
	"sku_name":                           "description.Workspace.SKU.Name",
	"sku_tier":                           "description.Workspace.SKU.Tier",
	"storage_account":                    "description.Workspace.Properties.StorageAccount",
	"tags":                               "description.Workspace.Tags",
	"title":                              "description.Workspace.Name",
	"type":                               "description.Workspace.Type",
	"workspace_id":                       "description.Workspace.Properties.WorkspaceID",
}

func GetMachineLearningWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetMachineLearningWorkspace")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewMachineLearningWorkspacePaginator(essdk.BuildFilter(ctx, d.QueryContext, getMachineLearningWorkspaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: MachineLearningWorkspace =============================

// ==========================  START: MariadbServer =============================

type MariadbServer struct {
	Description   azure.MariadbServerDescription `json:"description"`
	Metadata      azure.Metadata                 `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

func (r *MariadbServer) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.MariadbServerDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type MariadbServerHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  MariadbServer `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type MariadbServerHits struct {
	Total essdk.SearchTotal  `json:"total"`
	Hits  []MariadbServerHit `json:"hits"`
}

type MariadbServerSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  MariadbServerHits `json:"hits"`
}

type MariadbServerPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewMariadbServerPaginator(filters []essdk.BoolFilter, limit *int64) (MariadbServerPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_dbformariadb_servers", filters, limit)
	if err != nil {
		return MariadbServerPaginator{}, err
	}

	p := MariadbServerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p MariadbServerPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p MariadbServerPaginator) NextPage(ctx context.Context) ([]MariadbServer, error) {
	var response MariadbServerSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []MariadbServer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listMariadbServerFilters = map[string]string{
	"administrator_login":          "description.Server.Properties.AdministratorLogin",
	"auto_grow_enabled":            "description.Server.Properties.StorageProfile.StorageAutogrow",
	"backup_retention_days":        "description.Server.Properties.StorageProfile.BackupRetentionDays",
	"fully_qualified_domain_name":  "description.Server.Properties.FullyQualifiedDomainName",
	"geo_redundant_backup_enabled": "description.Server.Properties.StorageProfile.GeoRedundantBackup",
	"id":                           "description.Server.ID",
	"kaytu_account_id":             "metadata.SourceID",
	"master_service_id":            "description.Server.Properties.MasterServerID",
	"name":                         "description.Server.Name",
	"private_endpoint_connections": "description.Server.Properties.PrivateEndpointConnections",
	"public_network_access":        "description.Server.Properties.PublicNetworkAccess",
	"replica_capacity":             "description.Server.Properties.ReplicaCapacity",
	"replication_role":             "description.Server.Properties.ReplicationRole",
	"resource_group":               "description.ResourceGroup",
	"sku_capacity":                 "description.Server.SKU.Capacity",
	"sku_family":                   "description.Server.SKU.Family",
	"sku_name":                     "description.Server.SKU.Name",
	"sku_size":                     "description.Server.SKU.Size",
	"sku_tier":                     "description.Server.SKU.Tier",
	"ssl_enforcement":              "description.Server.Properties.SSLEnforcement",
	"storage_mb":                   "description.Server.Properties.StorageProfile.StorageMB",
	"tags":                         "description.Server.Tags",
	"title":                        "description.Server.Name",
	"type":                         "description.Server.Type",
	"user_visible_state":           "description.Server.Properties.UserVisibleState",
	"version":                      "description.Server.Properties.Version",
}

func ListMariadbServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListMariadbServer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewMariadbServerPaginator(essdk.BuildFilter(ctx, d.QueryContext, listMariadbServerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getMariadbServerFilters = map[string]string{
	"administrator_login":          "description.Server.Properties.AdministratorLogin",
	"auto_grow_enabled":            "description.Server.Properties.StorageProfile.StorageAutogrow",
	"backup_retention_days":        "description.Server.Properties.StorageProfile.BackupRetentionDays",
	"fully_qualified_domain_name":  "description.Server.Properties.FullyQualifiedDomainName",
	"geo_redundant_backup_enabled": "description.Server.Properties.StorageProfile.GeoRedundantBackup",
	"id":                           "description.Server.ID",
	"kaytu_account_id":             "metadata.SourceID",
	"master_service_id":            "description.Server.Properties.MasterServerID",
	"name":                         "description.Server.name",
	"private_endpoint_connections": "description.Server.Properties.PrivateEndpointConnections",
	"public_network_access":        "description.Server.Properties.PublicNetworkAccess",
	"replica_capacity":             "description.Server.Properties.ReplicaCapacity",
	"replication_role":             "description.Server.Properties.ReplicationRole",
	"resource_group":               "description.ResourceGroup",
	"sku_capacity":                 "description.Server.SKU.Capacity",
	"sku_family":                   "description.Server.SKU.Family",
	"sku_name":                     "description.Server.SKU.Name",
	"sku_size":                     "description.Server.SKU.Size",
	"sku_tier":                     "description.Server.SKU.Tier",
	"ssl_enforcement":              "description.Server.Properties.SSLEnforcement",
	"storage_mb":                   "description.Server.Properties.StorageProfile.StorageMB",
	"tags":                         "description.Server.Tags",
	"title":                        "description.Server.Name",
	"type":                         "description.Server.Type",
	"user_visible_state":           "description.Server.Properties.UserVisibleState",
	"version":                      "description.Server.Properties.Version",
}

func GetMariadbServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetMariadbServer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewMariadbServerPaginator(essdk.BuildFilter(ctx, d.QueryContext, getMariadbServerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: MariadbServer =============================

// ==========================  START: MariadbDatabase =============================

type MariadbDatabase struct {
	Description   azure.MariadbDatabaseDescription `json:"description"`
	Metadata      azure.Metadata                   `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

func (r *MariadbDatabase) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.MariadbDatabaseDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type MariadbDatabaseHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  MariadbDatabase `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type MariadbDatabaseHits struct {
	Total essdk.SearchTotal    `json:"total"`
	Hits  []MariadbDatabaseHit `json:"hits"`
}

type MariadbDatabaseSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  MariadbDatabaseHits `json:"hits"`
}

type MariadbDatabasePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewMariadbDatabasePaginator(filters []essdk.BoolFilter, limit *int64) (MariadbDatabasePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_dbformariadb_servers_databases", filters, limit)
	if err != nil {
		return MariadbDatabasePaginator{}, err
	}

	p := MariadbDatabasePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p MariadbDatabasePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p MariadbDatabasePaginator) NextPage(ctx context.Context) ([]MariadbDatabase, error) {
	var response MariadbDatabaseSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []MariadbDatabase
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listMariadbDatabaseFilters = map[string]string{
	"id":               "description.Databases.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Database.Name",
	"tags":             "description.Database.Name",
	"title":            "description.Database.Name",
}

func ListMariadbDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListMariadbDatabase")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewMariadbDatabasePaginator(essdk.BuildFilter(ctx, d.QueryContext, listMariadbDatabaseFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getMariadbDatabaseFilters = map[string]string{
	"id":               "description.Databases.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Database.Name",
	"tags":             "description.Database.Name",
	"title":            "description.Database.Name",
}

func GetMariadbDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetMariadbDatabase")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewMariadbDatabasePaginator(essdk.BuildFilter(ctx, d.QueryContext, getMariadbDatabaseFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: MariadbDatabase =============================

// ==========================  START: MysqlServer =============================

type MysqlServer struct {
	Description   azure.MysqlServerDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

func (r *MysqlServer) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.MysqlServerDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type MysqlServerHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  MysqlServer   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type MysqlServerHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []MysqlServerHit  `json:"hits"`
}

type MysqlServerSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  MysqlServerHits `json:"hits"`
}

type MysqlServerPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewMysqlServerPaginator(filters []essdk.BoolFilter, limit *int64) (MysqlServerPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_dbformysql_servers", filters, limit)
	if err != nil {
		return MysqlServerPaginator{}, err
	}

	p := MysqlServerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p MysqlServerPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p MysqlServerPaginator) NextPage(ctx context.Context) ([]MysqlServer, error) {
	var response MysqlServerSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []MysqlServer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listMysqlServerFilters = map[string]string{
	"administrator_login":         "description.Server.Properties.AdministratorLogin",
	"backup_retention_days":       "description.Server.Properties.StorageProfile.BackupRetentionDays",
	"byok_enforcement":            "description.Server.Properties.ByokEnforcement",
	"fully_qualified_domain_name": "description.Server.Properties.FullyQualifiedDomainName",
	"geo_redundant_backup":        "description.Server.Properties.StorageProfile.GeoRedundantBackup",
	"id":                          "description.Server.ID",
	"infrastructure_encryption":   "description.Server.Properties.InfrastructureEncryption",
	"kaytu_account_id":            "metadata.SourceID",
	"location":                    "description.Server.Location",
	"master_server_id":            "description.Server.Properties.MasterServerID",
	"minimal_tls_version":         "description.Server.Properties.MinimalTLSVersion",
	"name":                        "description.Server.Name",
	"public_network_access":       "description.Server.Properties.PublicNetworkAccess",
	"replica_capacity":            "description.Server.Properties.ReplicaCapacity",
	"replication_role":            "description.Server.Properties.ReplicationRole",
	"resource_group":              "description.ResourceGroup",
	"server_configurations":       "description.Configurations",
	"server_keys":                 "description.ServerKeys",
	"sku_capacity":                "description.Server.SKU.Capacity",
	"sku_family":                  "description.Server.SKU.Family",
	"sku_name":                    "description.Server.SKU.Name",
	"sku_size":                    "description.Server.SKU.Size",
	"sku_tier":                    "description.Server.SKU.Tier",
	"ssl_enforcement":             "description.Server.Properties.SSLEnforcement",
	"state":                       "description.Server.Properties.UserVisibleState",
	"storage_auto_grow":           "description.Server.Properties.StorageProfile.StorageAutogrow",
	"storage_mb":                  "description.Server.Properties.StorageProfile.StorageMB",
	"tags":                        "description.Server.Tags",
	"title":                       "description.Server.Name",
	"type":                        "description.Server.Type",
	"user_visible_state":          "description.Server.Properties.UserVisibleState",
	"version":                     "description.Server.Properties.Version",
}

func ListMysqlServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListMysqlServer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewMysqlServerPaginator(essdk.BuildFilter(ctx, d.QueryContext, listMysqlServerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getMysqlServerFilters = map[string]string{
	"administrator_login":         "description.Server.Properties.AdministratorLogin",
	"backup_retention_days":       "description.Server.Properties.StorageProfile.BackupRetentionDays",
	"byok_enforcement":            "description.Server.Properties.ByokEnforcement",
	"fully_qualified_domain_name": "description.Server.Properties.FullyQualifiedDomainName",
	"geo_redundant_backup":        "description.Server.Properties.StorageProfile.GeoRedundantBackup",
	"id":                          "description.Server.ID",
	"infrastructure_encryption":   "description.Server.Properties.InfrastructureEncryption",
	"kaytu_account_id":            "metadata.SourceID",
	"location":                    "description.Server.Location",
	"master_server_id":            "description.Server.Properties.MasterServerID",
	"minimal_tls_version":         "description.Server.Properties.MinimalTLSVersion",
	"name":                        "description.Server.name",
	"public_network_access":       "description.Server.Properties.PublicNetworkAccess",
	"replica_capacity":            "description.Server.Properties.ReplicaCapacity",
	"replication_role":            "description.Server.Properties.ReplicationRole",
	"resource_group":              "description.ResourceGroup",
	"server_configurations":       "description.Configurations",
	"server_keys":                 "description.ServerKeys",
	"sku_capacity":                "description.Server.SKU.Capacity",
	"sku_family":                  "description.Server.SKU.Family",
	"sku_name":                    "description.Server.SKU.Name",
	"sku_size":                    "description.Server.SKU.Size",
	"sku_tier":                    "description.Server.SKU.Tier",
	"ssl_enforcement":             "description.Server.Properties.SSLEnforcement",
	"state":                       "description.Server.Properties.UserVisibleState",
	"storage_auto_grow":           "description.Server.Properties.StorageProfile.StorageAutogrow",
	"storage_mb":                  "description.Server.Properties.StorageProfile.StorageMB",
	"tags":                        "description.Server.Tags",
	"title":                       "description.Server.Name",
	"type":                        "description.Server.Type",
	"user_visible_state":          "description.Server.Properties.UserVisibleState",
	"version":                     "description.Server.Properties.Version",
}

func GetMysqlServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetMysqlServer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewMysqlServerPaginator(essdk.BuildFilter(ctx, d.QueryContext, getMysqlServerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: MysqlServer =============================

// ==========================  START: MysqlFlexibleserver =============================

type MysqlFlexibleserver struct {
	Description   azure.MysqlFlexibleserverDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

func (r *MysqlFlexibleserver) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.MysqlFlexibleserverDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type MysqlFlexibleserverHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  MysqlFlexibleserver `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type MysqlFlexibleserverHits struct {
	Total essdk.SearchTotal        `json:"total"`
	Hits  []MysqlFlexibleserverHit `json:"hits"`
}

type MysqlFlexibleserverSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  MysqlFlexibleserverHits `json:"hits"`
}

type MysqlFlexibleserverPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewMysqlFlexibleserverPaginator(filters []essdk.BoolFilter, limit *int64) (MysqlFlexibleserverPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_dbformysql_flexibleservers", filters, limit)
	if err != nil {
		return MysqlFlexibleserverPaginator{}, err
	}

	p := MysqlFlexibleserverPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p MysqlFlexibleserverPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p MysqlFlexibleserverPaginator) NextPage(ctx context.Context) ([]MysqlFlexibleserver, error) {
	var response MysqlFlexibleserverSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []MysqlFlexibleserver
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listMysqlFlexibleserverFilters = map[string]string{
	"id":               "description.Server.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Server.Name",
	"tags":             "description.Server.Tags",
	"title":            "description.Server.Name",
}

func ListMysqlFlexibleserver(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListMysqlFlexibleserver")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewMysqlFlexibleserverPaginator(essdk.BuildFilter(ctx, d.QueryContext, listMysqlFlexibleserverFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getMysqlFlexibleserverFilters = map[string]string{
	"id":               "description.Server.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Server.Name",
	"tags":             "description.Server.Tags",
	"title":            "description.Server.Name",
}

func GetMysqlFlexibleserver(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetMysqlFlexibleserver")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewMysqlFlexibleserverPaginator(essdk.BuildFilter(ctx, d.QueryContext, getMysqlFlexibleserverFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: MysqlFlexibleserver =============================

// ==========================  START: NetworkSecurityGroup =============================

type NetworkSecurityGroup struct {
	Description   azure.NetworkSecurityGroupDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

func (r *NetworkSecurityGroup) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.NetworkSecurityGroupDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type NetworkSecurityGroupHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  NetworkSecurityGroup `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type NetworkSecurityGroupHits struct {
	Total essdk.SearchTotal         `json:"total"`
	Hits  []NetworkSecurityGroupHit `json:"hits"`
}

type NetworkSecurityGroupSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  NetworkSecurityGroupHits `json:"hits"`
}

type NetworkSecurityGroupPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewNetworkSecurityGroupPaginator(filters []essdk.BoolFilter, limit *int64) (NetworkSecurityGroupPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_networksecuritygroups", filters, limit)
	if err != nil {
		return NetworkSecurityGroupPaginator{}, err
	}

	p := NetworkSecurityGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkSecurityGroupPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p NetworkSecurityGroupPaginator) NextPage(ctx context.Context) ([]NetworkSecurityGroup, error) {
	var response NetworkSecurityGroupSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkSecurityGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkSecurityGroupFilters = map[string]string{
	"default_security_rules": "description.SecurityGroup.Properties.DefaultSecurityRules",
	"diagnostic_settings":    "description.DiagnosticSettingsResources",
	"etag":                   "description.SecurityGroup.Etag",
	"flow_logs":              "description.SecurityGroup.Properties.FlowLogs",
	"id":                     "description.SecurityGroup.ID",
	"kaytu_account_id":       "metadata.SourceID",
	"name":                   "description.SecurityGroup.Name",
	"network_interfaces":     "description.SecurityGroup.Properties.NetworkInterfaces",
	"provisioning_state":     "description.SecurityGroup.Properties.ProvisioningState",
	"resource_group":         "description.ResourceGroup",
	"resource_guid":          "description.SecurityGroup.Properties.ResourceGUID",
	"security_rules":         "description.SecurityGroup.Properties.SecurityRules",
	"subnets":                "description.SecurityGroup.Properties.Subnets",
	"tags":                   "description.SecurityGroup.Tags",
	"title":                  "description.SecurityGroup.Name",
	"type":                   "description.SecurityGroup.Type",
}

func ListNetworkSecurityGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkSecurityGroup")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewNetworkSecurityGroupPaginator(essdk.BuildFilter(ctx, d.QueryContext, listNetworkSecurityGroupFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkSecurityGroupFilters = map[string]string{
	"default_security_rules": "description.SecurityGroup.Properties.DefaultSecurityRules",
	"diagnostic_settings":    "description.DiagnosticSettingsResources",
	"etag":                   "description.SecurityGroup.Etag",
	"flow_logs":              "description.SecurityGroup.Properties.FlowLogs",
	"id":                     "description.SecurityGroup.ID",
	"kaytu_account_id":       "metadata.SourceID",
	"name":                   "description.SecurityGroup.name",
	"network_interfaces":     "description.SecurityGroup.Properties.NetworkInterfaces",
	"provisioning_state":     "description.SecurityGroup.Properties.ProvisioningState",
	"resource_group":         "description.ResourceGroup",
	"resource_guid":          "description.SecurityGroup.Properties.ResourceGUID",
	"security_rules":         "description.SecurityGroup.Properties.SecurityRules",
	"subnets":                "description.SecurityGroup.Properties.Subnets",
	"tags":                   "description.SecurityGroup.Tags",
	"title":                  "description.SecurityGroup.Name",
	"type":                   "description.SecurityGroup.Type",
}

func GetNetworkSecurityGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkSecurityGroup")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewNetworkSecurityGroupPaginator(essdk.BuildFilter(ctx, d.QueryContext, getNetworkSecurityGroupFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkSecurityGroup =============================

// ==========================  START: NetworkWatcher =============================

type NetworkWatcher struct {
	Description   azure.NetworkWatcherDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

func (r *NetworkWatcher) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.NetworkWatcherDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type NetworkWatcherHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  NetworkWatcher `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type NetworkWatcherHits struct {
	Total essdk.SearchTotal   `json:"total"`
	Hits  []NetworkWatcherHit `json:"hits"`
}

type NetworkWatcherSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  NetworkWatcherHits `json:"hits"`
}

type NetworkWatcherPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewNetworkWatcherPaginator(filters []essdk.BoolFilter, limit *int64) (NetworkWatcherPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_networkwatchers", filters, limit)
	if err != nil {
		return NetworkWatcherPaginator{}, err
	}

	p := NetworkWatcherPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkWatcherPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p NetworkWatcherPaginator) NextPage(ctx context.Context) ([]NetworkWatcher, error) {
	var response NetworkWatcherSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkWatcher
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkWatcherFilters = map[string]string{
	"etag":               "description.Watcher.Etag",
	"id":                 "description.Watcher.ID",
	"kaytu_account_id":   "metadata.SourceID",
	"name":               "description.Watcher.Name",
	"provisioning_state": "description.Watcher.Properties.ProvisioningState",
	"resource_group":     "description.ResourceGroup",
	"tags":               "description.Watcher.Tags",
	"title":              "description.Watcher.Name",
	"type":               "description.Watcher.Type",
}

func ListNetworkWatcher(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkWatcher")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewNetworkWatcherPaginator(essdk.BuildFilter(ctx, d.QueryContext, listNetworkWatcherFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkWatcherFilters = map[string]string{
	"etag":               "description.Watcher.Etag",
	"id":                 "description.Watcher.ID",
	"kaytu_account_id":   "metadata.SourceID",
	"name":               "description.Watcher.name",
	"provisioning_state": "description.Watcher.Properties.ProvisioningState",
	"resource_group":     "description.ResourceGroup",
	"tags":               "description.Watcher.Tags",
	"title":              "description.Watcher.Name",
	"type":               "description.Watcher.Type",
}

func GetNetworkWatcher(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkWatcher")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewNetworkWatcherPaginator(essdk.BuildFilter(ctx, d.QueryContext, getNetworkWatcherFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkWatcher =============================

// ==========================  START: SearchService =============================

type SearchService struct {
	Description   azure.SearchServiceDescription `json:"description"`
	Metadata      azure.Metadata                 `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

func (r *SearchService) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SearchServiceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SearchServiceHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  SearchService `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type SearchServiceHits struct {
	Total essdk.SearchTotal  `json:"total"`
	Hits  []SearchServiceHit `json:"hits"`
}

type SearchServiceSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  SearchServiceHits `json:"hits"`
}

type SearchServicePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSearchServicePaginator(filters []essdk.BoolFilter, limit *int64) (SearchServicePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_search_searchservices", filters, limit)
	if err != nil {
		return SearchServicePaginator{}, err
	}

	p := SearchServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SearchServicePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SearchServicePaginator) NextPage(ctx context.Context) ([]SearchService, error) {
	var response SearchServiceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SearchService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSearchServiceFilters = map[string]string{
	"diagnostic_settings":           "description.DiagnosticSettingsResources",
	"hosting_mode":                  "description.Service.Properties.HostingMode",
	"id":                            "description.Service.ID",
	"identity":                      "description.Service.Identity",
	"kaytu_account_id":              "metadata.SourceID",
	"name":                          "description.Service.Name",
	"network_rule_set":              "description.Service.Properties.NetworkRuleSet",
	"partition_count":               "description.Service.Properties.PartitionCount",
	"private_endpoint_connections":  "description.Service.Properties.PrivateEndpointConnections",
	"provisioning_state":            "description.Service.Properties.ProvisioningState",
	"public_network_access":         "description.Service.Properties.PublicNetworkAccess",
	"replica_count":                 "description.Service.Properties.ReplicaCount",
	"shared_private_link_resources": "description.Service.Properties.SharedPrivateLinkResources",
	"sku_name":                      "description.Service.SKU.Name",
	"status":                        "description.Service.Properties.Status",
	"status_details":                "description.Service.Properties.StatusDetails",
	"tags":                          "description.Service.Tags",
	"title":                         "description.Service.Name",
	"type":                          "description.Service.Type",
}

func ListSearchService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSearchService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSearchServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, listSearchServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSearchServiceFilters = map[string]string{
	"diagnostic_settings":           "description.DiagnosticSettingsResources",
	"hosting_mode":                  "description.Service.Properties.HostingMode",
	"id":                            "description.Service.ID",
	"identity":                      "description.Service.Identity",
	"kaytu_account_id":              "metadata.SourceID",
	"name":                          "description.Service.name",
	"network_rule_set":              "description.Service.Properties.NetworkRuleSet",
	"partition_count":               "description.Service.Properties.PartitionCount",
	"private_endpoint_connections":  "description.Service.Properties.PrivateEndpointConnections",
	"provisioning_state":            "description.Service.Properties.ProvisioningState",
	"public_network_access":         "description.Service.Properties.PublicNetworkAccess",
	"replica_count":                 "description.Service.Properties.ReplicaCount",
	"resource_group":                "description.ResourceGroup",
	"shared_private_link_resources": "description.Service.Properties.SharedPrivateLinkResources",
	"sku_name":                      "description.Service.SKU.Name",
	"status":                        "description.Service.Properties.Status",
	"status_details":                "description.Service.Properties.StatusDetails",
	"tags":                          "description.Service.Tags",
	"title":                         "description.Service.Name",
	"type":                          "description.Service.Type",
}

func GetSearchService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSearchService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSearchServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, getSearchServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SearchService =============================

// ==========================  START: ServiceFabricCluster =============================

type ServiceFabricCluster struct {
	Description   azure.ServiceFabricClusterDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

func (r *ServiceFabricCluster) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ServiceFabricClusterDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ServiceFabricClusterHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  ServiceFabricCluster `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type ServiceFabricClusterHits struct {
	Total essdk.SearchTotal         `json:"total"`
	Hits  []ServiceFabricClusterHit `json:"hits"`
}

type ServiceFabricClusterSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  ServiceFabricClusterHits `json:"hits"`
}

type ServiceFabricClusterPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewServiceFabricClusterPaginator(filters []essdk.BoolFilter, limit *int64) (ServiceFabricClusterPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_servicefabric_clusters", filters, limit)
	if err != nil {
		return ServiceFabricClusterPaginator{}, err
	}

	p := ServiceFabricClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ServiceFabricClusterPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ServiceFabricClusterPaginator) NextPage(ctx context.Context) ([]ServiceFabricCluster, error) {
	var response ServiceFabricClusterSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ServiceFabricCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listServiceFabricClusterFilters = map[string]string{
	"add_on_features":                        "description.Cluster.Properties.AddOnFeatures",
	"available_cluster_versions":             "description.Cluster.Properties.AvailableClusterVersions",
	"azure_active_directory":                 "description.Cluster.Properties.AzureActiveDirectory",
	"certificate":                            "description.Cluster.Properties.Certificate",
	"certificate_common_names":               "description.Cluster.Properties.CertificateCommonNames",
	"client_certificate_common_names":        "description.Cluster.Properties.ClientCertificateCommonNames",
	"client_certificate_thumbprints":         "description.Cluster.Properties.ClientCertificateThumbprints",
	"cluster_code_version":                   "description.Cluster.Properties.ClusterCodeVersion",
	"cluster_endpoint":                       "description.Cluster.Properties.ClusterEndpoint",
	"cluster_id":                             "description.Cluster.Properties.ClusterID",
	"cluster_state":                          "description.Cluster.Properties.ClusterState",
	"diagnostics_storage_account_config":     "description.Cluster.Properties.DiagnosticsStorageAccountConfig",
	"etag":                                   "description.Cluster.Etag",
	"event_store_service_enabled":            "description.Cluster.Properties.EventStoreServiceEnabled",
	"fabric_settings":                        "description.Cluster.Properties.FabricSettings",
	"id":                                     "description.Cluster.ID",
	"kaytu_account_id":                       "metadata.SourceID",
	"management_endpoint":                    "description.Cluster.Properties.ManagementEndpoint",
	"name":                                   "description.Cluster.Name",
	"node_types":                             "description.Cluster.Properties.NodeTypes",
	"provisioning_state":                     "description.Cluster.Properties.ProvisioningState",
	"reliability_level":                      "description.Cluster.Properties.ReliabilityLevel",
	"resource_group":                         "description.ResourceGroup",
	"reverse_proxy_certificate":              "description.Cluster.Properties.ReverseProxyCertificate",
	"reverse_proxy_certificate_common_names": "description.Cluster.Properties.ReverseProxyCertificateCommonNames",
	"tags":                                   "description.Cluster.Tags",
	"title":                                  "description.Cluster.Name",
	"type":                                   "description.Cluster.Type",
	"upgrade_description":                    "description.Cluster.Properties.UpgradeDescription",
	"upgrade_mode":                           "description.Cluster.Properties.UpgradeMode",
	"vm_image":                               "description.Cluster.Properties.VMImage",
}

func ListServiceFabricCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListServiceFabricCluster")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewServiceFabricClusterPaginator(essdk.BuildFilter(ctx, d.QueryContext, listServiceFabricClusterFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getServiceFabricClusterFilters = map[string]string{
	"add_on_features":                        "description.Cluster.Properties.AddOnFeatures",
	"available_cluster_versions":             "description.Cluster.Properties.AvailableClusterVersions",
	"azure_active_directory":                 "description.Cluster.Properties.AzureActiveDirectory",
	"certificate":                            "description.Cluster.Properties.Certificate",
	"certificate_common_names":               "description.Cluster.Properties.CertificateCommonNames",
	"client_certificate_common_names":        "description.Cluster.Properties.ClientCertificateCommonNames",
	"client_certificate_thumbprints":         "description.Cluster.Properties.ClientCertificateThumbprints",
	"cluster_code_version":                   "description.Cluster.Properties.ClusterCodeVersion",
	"cluster_endpoint":                       "description.Cluster.Properties.ClusterEndpoint",
	"cluster_id":                             "description.Cluster.Properties.ClusterID",
	"cluster_state":                          "description.Cluster.Properties.ClusterState",
	"diagnostics_storage_account_config":     "description.Cluster.Properties.DiagnosticsStorageAccountConfig",
	"etag":                                   "description.Cluster.Etag",
	"event_store_service_enabled":            "description.Cluster.Properties.EventStoreServiceEnabled",
	"fabric_settings":                        "description.Cluster.Properties.FabricSettings",
	"id":                                     "description.Cluster.ID",
	"kaytu_account_id":                       "metadata.SourceID",
	"management_endpoint":                    "description.Cluster.Properties.ManagementEndpoint",
	"name":                                   "description.Cluster.name",
	"node_types":                             "description.Cluster.Properties.NodeTypes",
	"provisioning_state":                     "description.Cluster.Properties.ProvisioningState",
	"reliability_level":                      "description.Cluster.Properties.ReliabilityLevel",
	"resource_group":                         "description.ResourceGroup",
	"reverse_proxy_certificate":              "description.Cluster.Properties.ReverseProxyCertificate",
	"reverse_proxy_certificate_common_names": "description.Cluster.Properties.ReverseProxyCertificateCommonNames",
	"tags":                                   "description.Cluster.Tags",
	"title":                                  "description.Cluster.Name",
	"type":                                   "description.Cluster.Type",
	"upgrade_description":                    "description.Cluster.Properties.UpgradeDescription",
	"upgrade_mode":                           "description.Cluster.Properties.UpgradeMode",
	"vm_image":                               "description.Cluster.Properties.VMImage",
}

func GetServiceFabricCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetServiceFabricCluster")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewServiceFabricClusterPaginator(essdk.BuildFilter(ctx, d.QueryContext, getServiceFabricClusterFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ServiceFabricCluster =============================

// ==========================  START: ServicebusNamespace =============================

type ServicebusNamespace struct {
	Description   azure.ServicebusNamespaceDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

func (r *ServicebusNamespace) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ServicebusNamespaceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ServicebusNamespaceHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  ServicebusNamespace `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type ServicebusNamespaceHits struct {
	Total essdk.SearchTotal        `json:"total"`
	Hits  []ServicebusNamespaceHit `json:"hits"`
}

type ServicebusNamespaceSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  ServicebusNamespaceHits `json:"hits"`
}

type ServicebusNamespacePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewServicebusNamespacePaginator(filters []essdk.BoolFilter, limit *int64) (ServicebusNamespacePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_servicebus_namespaces", filters, limit)
	if err != nil {
		return ServicebusNamespacePaginator{}, err
	}

	p := ServicebusNamespacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ServicebusNamespacePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ServicebusNamespacePaginator) NextPage(ctx context.Context) ([]ServicebusNamespace, error) {
	var response ServicebusNamespaceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ServicebusNamespace
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listServicebusNamespaceFilters = map[string]string{
	"diagnostic_settings":          "description.DiagnosticSettingsResources",
	"encryption":                   "description.SBNamespace.Properties.Encryption",
	"id":                           "description.SBNamespace.ID",
	"kaytu_account_id":             "metadata.SourceID",
	"metric_id":                    "description.SBNamespace.Properties.MetricID",
	"name":                         "description.SBNamespace.Name",
	"network_rule_set":             "description.NetworkRuleSet",
	"private_endpoint_connections": "description.SBNamespace.Properties.PrivateEndpointConnections",
	"provisioning_state":           "description.SBNamespace.Properties.ProvisioningState",
	"resource_group":               "description.ResourceGroup",
	"servicebus_endpoint":          "description.SBNamespace.Properties.ServiceBusEndpoint",
	"sku_capacity":                 "description.SBNamespace.SKU.Capacity",
	"sku_name":                     "description.SBNamespace.SKU.Name",
	"sku_tier":                     "description.SBNamespace.SKU.Tier",
	"tags":                         "description.SBNamespace.Tags",
	"title":                        "description.SBNamespace.Name",
	"type":                         "description.SBNamespace.Type",
	"zone_redundant":               "description.SBNamespace.Properties.ZoneRedundant",
}

func ListServicebusNamespace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListServicebusNamespace")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewServicebusNamespacePaginator(essdk.BuildFilter(ctx, d.QueryContext, listServicebusNamespaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getServicebusNamespaceFilters = map[string]string{
	"diagnostic_settings":          "description.DiagnosticSettingsResources",
	"encryption":                   "description.SBNamespace.Properties.Encryption",
	"id":                           "description.SBNamespace.ID",
	"kaytu_account_id":             "metadata.SourceID",
	"metric_id":                    "description.SBNamespace.Properties.MetricID",
	"name":                         "description.SBNamespace.name",
	"network_rule_set":             "description.NetworkRuleSet",
	"private_endpoint_connections": "description.SBNamespace.Properties.PrivateEndpointConnections",
	"provisioning_state":           "description.SBNamespace.Properties.ProvisioningState",
	"resource_group":               "description.ResourceGroup",
	"servicebus_endpoint":          "description.SBNamespace.Properties.ServiceBusEndpoint",
	"sku_capacity":                 "description.SBNamespace.SKU.Capacity",
	"sku_name":                     "description.SBNamespace.SKU.Name",
	"sku_tier":                     "description.SBNamespace.SKU.Tier",
	"tags":                         "description.SBNamespace.Tags",
	"title":                        "description.SBNamespace.Name",
	"type":                         "description.SBNamespace.Type",
	"zone_redundant":               "description.SBNamespace.Properties.ZoneRedundant",
}

func GetServicebusNamespace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetServicebusNamespace")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewServicebusNamespacePaginator(essdk.BuildFilter(ctx, d.QueryContext, getServicebusNamespaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ServicebusNamespace =============================

// ==========================  START: SignalrService =============================

type SignalrService struct {
	Description   azure.SignalrServiceDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

func (r *SignalrService) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SignalrServiceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SignalrServiceHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  SignalrService `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type SignalrServiceHits struct {
	Total essdk.SearchTotal   `json:"total"`
	Hits  []SignalrServiceHit `json:"hits"`
}

type SignalrServiceSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  SignalrServiceHits `json:"hits"`
}

type SignalrServicePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSignalrServicePaginator(filters []essdk.BoolFilter, limit *int64) (SignalrServicePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_signalrservice_signalr", filters, limit)
	if err != nil {
		return SignalrServicePaginator{}, err
	}

	p := SignalrServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SignalrServicePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SignalrServicePaginator) NextPage(ctx context.Context) ([]SignalrService, error) {
	var response SignalrServiceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SignalrService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSignalrServiceFilters = map[string]string{
	"cors":                "description.ResourceInfo.Properties.Cors",
	"diagnostic_settings": "description.DiagnosticSettingsResources",
	"external_ip":         "description.ResourceInfo.Properties.ExternalIP",
	"features":            "description.ResourceInfo.Properties.Features",
	"host_name":           "description.ResourceInfo.Properties.HostName",
	"host_name_prefix":    "description.ResourceInfo.Properties.HostNamePrefix",
	"id":                  "description.ResourceInfo.ID",
	"kaytu_account_id":    "metadata.SourceID",
	"kind":                "description.ResourceInfo.Kind",
	"name":                "description.ResourceInfo.Name",
	"network_acls":        "description.ResourceInfo.Properties.NetworkACLs",
	"provisioning_state":  "description.ResourceInfo.Properties.ProvisioningState",
	"public_port":         "description.ResourceInfo.Properties.PublicPort",
	"resource_group":      "description.ResourceGroup",
	"server_port":         "description.ResourceInfo.Properties.ServerPort",
	"sku":                 "description.ResourceInfo.SKU",
	"tags":                "description.ResourceInfo.Tags",
	"title":               "description.ResourceInfo.Name",
	"type":                "description.ResourceInfo.Type",
	"upstream":            "description.ResourceInfo.Properties.Upstream",
	"version":             "description.ResourceInfo.Properties.Version",
}

func ListSignalrService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSignalrService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSignalrServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, listSignalrServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSignalrServiceFilters = map[string]string{
	"cors":                "description.ResourceInfo.Properties.Cors",
	"diagnostic_settings": "description.DiagnosticSettingsResources",
	"external_ip":         "description.ResourceInfo.Properties.ExternalIP",
	"features":            "description.ResourceInfo.Properties.Features",
	"host_name":           "description.ResourceInfo.Properties.HostName",
	"host_name_prefix":    "description.ResourceInfo.Properties.HostNamePrefix",
	"id":                  "description.ResourceInfo.ID",
	"kaytu_account_id":    "metadata.SourceID",
	"kind":                "description.ResourceInfo.Kind",
	"name":                "description.ResourceType.name",
	"network_acls":        "description.ResourceInfo.Properties.NetworkACLs",
	"provisioning_state":  "description.ResourceInfo.Properties.ProvisioningState",
	"public_port":         "description.ResourceInfo.Properties.PublicPort",
	"resource_group":      "description.ResourceGroup",
	"server_port":         "description.ResourceInfo.Properties.ServerPort",
	"sku":                 "description.ResourceInfo.SKU",
	"tags":                "description.ResourceInfo.Tags",
	"title":               "description.ResourceInfo.Name",
	"type":                "description.ResourceInfo.Type",
	"upstream":            "description.ResourceInfo.Properties.Upstream",
	"version":             "description.ResourceInfo.Properties.Version",
}

func GetSignalrService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSignalrService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSignalrServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, getSignalrServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SignalrService =============================

// ==========================  START: SpringCloudService =============================

type SpringCloudService struct {
	Description   azure.SpringCloudServiceDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

func (r *SpringCloudService) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SpringCloudServiceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SpringCloudServiceHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  SpringCloudService `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type SpringCloudServiceHits struct {
	Total essdk.SearchTotal       `json:"total"`
	Hits  []SpringCloudServiceHit `json:"hits"`
}

type SpringCloudServiceSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  SpringCloudServiceHits `json:"hits"`
}

type SpringCloudServicePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSpringCloudServicePaginator(filters []essdk.BoolFilter, limit *int64) (SpringCloudServicePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_appplatform_spring", filters, limit)
	if err != nil {
		return SpringCloudServicePaginator{}, err
	}

	p := SpringCloudServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SpringCloudServicePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SpringCloudServicePaginator) NextPage(ctx context.Context) ([]SpringCloudService, error) {
	var response SpringCloudServiceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SpringCloudService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSpringCloudServiceFilters = map[string]string{
	"diagnostic_settings": "description.DiagnosticSettingsResource",
	"id":                  "description.ServiceResource.ID",
	"kaytu_account_id":    "metadata.SourceID",
	"name":                "description.ServiceResource.Name",
	"provisioning_state":  "description.ServiceResource.ProvisioningState",
	"resource_group":      "description.ResourceGroup",
	"service_id":          "description.ServiceResource.ID",
	"sku_capacity":        "description.ServiceResource.SKU.Capacity",
	"sku_name":            "description.ServiceResource.SKU.Name",
	"sku_tier":            "description.ServiceResource.SKU.Tier",
	"tags":                "description.ServiceResource.Tags",
	"title":               "description.ServiceResource.Name",
	"type":                "description.ServiceResource.Type",
	"version":             "description.ServiceResource.Plan.Version",
}

func ListSpringCloudService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSpringCloudService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSpringCloudServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, listSpringCloudServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSpringCloudServiceFilters = map[string]string{
	"diagnostic_settings": "description.DiagnosticSettingsResource",
	"id":                  "description.ServiceResource.ID",
	"kaytu_account_id":    "metadata.SourceID",
	"name":                "description.ServiceResource.name",
	"provisioning_state":  "description.ServiceResource.ProvisioningState",
	"resource_group":      "description.ResourceGroup",
	"service_id":          "description.ServiceResource.ID",
	"sku_capacity":        "description.ServiceResource.SKU.Capacity",
	"sku_name":            "description.ServiceResource.SKU.Name",
	"sku_tier":            "description.ServiceResource.SKU.Tier",
	"tags":                "description.ServiceResource.Tags",
	"title":               "description.ServiceResource.Name",
	"type":                "description.ServiceResource.Type",
	"version":             "description.ServiceResource.Plan.Version",
}

func GetSpringCloudService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSpringCloudService")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSpringCloudServicePaginator(essdk.BuildFilter(ctx, d.QueryContext, getSpringCloudServiceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SpringCloudService =============================

// ==========================  START: StreamAnalyticsJob =============================

type StreamAnalyticsJob struct {
	Description   azure.StreamAnalyticsJobDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

func (r *StreamAnalyticsJob) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.StreamAnalyticsJobDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type StreamAnalyticsJobHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  StreamAnalyticsJob `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type StreamAnalyticsJobHits struct {
	Total essdk.SearchTotal       `json:"total"`
	Hits  []StreamAnalyticsJobHit `json:"hits"`
}

type StreamAnalyticsJobSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  StreamAnalyticsJobHits `json:"hits"`
}

type StreamAnalyticsJobPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewStreamAnalyticsJobPaginator(filters []essdk.BoolFilter, limit *int64) (StreamAnalyticsJobPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_streamanalytics_streamingjobs", filters, limit)
	if err != nil {
		return StreamAnalyticsJobPaginator{}, err
	}

	p := StreamAnalyticsJobPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StreamAnalyticsJobPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p StreamAnalyticsJobPaginator) NextPage(ctx context.Context) ([]StreamAnalyticsJob, error) {
	var response StreamAnalyticsJobSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StreamAnalyticsJob
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listStreamAnalyticsJobFilters = map[string]string{
	"compatibility_level": "description.StreamingJob.Properties.CompatibilityLevel",
	"data_locale":         "description.StreamingJob.Properties.DataLocale",
	"diagnostic_settings": "description.DiagnosticSettingsResources",
	"etag":                "description.StreamingJob.Properties.Etag",
	"events_late_arrival_max_delay_in_seconds": "description.StreamingJob.Properties.EventsLateArrivalMaxDelayInSeconds",
	"events_out_of_order_max_delay_in_seconds": "description.StreamingJob.Properties.EventsOutOfOrderMaxDelayInSeconds",
	"events_out_of_order_policy":               "description.StreamingJob.Properties.EventsOutOfOrderPolicy",
	"functions":                                "description.StreamingJob.Properties.Functions",
	"id":                                       "description.StreamingJob.ID",
	"inputs":                                   "description.StreamingJob.Properties.Inputs",
	"job_id":                                   "description.StreamingJob.Properties.JobID",
	"job_state":                                "description.StreamingJob.Properties.JobState",
	"kaytu_account_id":                         "metadata.SourceID",
	"name":                                     "description.StreamingJob.Name",
	"output_error_policy":                      "description.StreamingJob.Properties.OutputErrorPolicy",
	"output_start_mode":                        "description.StreamingJob.Properties.OutputStartMode",
	"outputs":                                  "description.StreamingJob.Properties.Outputs",
	"provisioning_state":                       "description.StreamingJob.Properties.ProvisioningState",
	"resource_group":                           "description.ResourceGroup",
	"sku_name":                                 "description.StreamingJob.Properties.SKU.Name",
	"tags":                                     "description.StreamingJob.Tags",
	"title":                                    "description.StreamingJob.Name",
	"transformation":                           "description.StreamingJob.Properties.Transformation",
	"type":                                     "description.StreamingJob.Type",
}

func ListStreamAnalyticsJob(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStreamAnalyticsJob")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewStreamAnalyticsJobPaginator(essdk.BuildFilter(ctx, d.QueryContext, listStreamAnalyticsJobFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStreamAnalyticsJobFilters = map[string]string{
	"compatibility_level": "description.StreamingJob.Properties.CompatibilityLevel",
	"data_locale":         "description.StreamingJob.Properties.DataLocale",
	"diagnostic_settings": "description.DiagnosticSettingsResources",
	"etag":                "description.StreamingJob.Properties.Etag",
	"events_late_arrival_max_delay_in_seconds": "description.StreamingJob.Properties.EventsLateArrivalMaxDelayInSeconds",
	"events_out_of_order_max_delay_in_seconds": "description.StreamingJob.Properties.EventsOutOfOrderMaxDelayInSeconds",
	"events_out_of_order_policy":               "description.StreamingJob.Properties.EventsOutOfOrderPolicy",
	"functions":                                "description.StreamingJob.Properties.Functions",
	"id":                                       "description.StreamingJob.ID",
	"inputs":                                   "description.StreamingJob.Properties.Inputs",
	"job_id":                                   "description.StreamingJob.Properties.JobID",
	"job_state":                                "description.StreamingJob.Properties.JobState",
	"kaytu_account_id":                         "metadata.SourceID",
	"name":                                     "description.StreamingJob.name",
	"output_error_policy":                      "description.StreamingJob.Properties.OutputErrorPolicy",
	"output_start_mode":                        "description.StreamingJob.Properties.OutputStartMode",
	"outputs":                                  "description.StreamingJob.Properties.Outputs",
	"provisioning_state":                       "description.StreamingJob.Properties.ProvisioningState",
	"resource_group":                           "description.ResourceGroup",
	"sku_name":                                 "description.StreamingJob.Properties.SKU.Name",
	"tags":                                     "description.StreamingJob.Tags",
	"title":                                    "description.StreamingJob.Name",
	"transformation":                           "description.StreamingJob.Properties.Transformation",
	"type":                                     "description.StreamingJob.Type",
}

func GetStreamAnalyticsJob(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStreamAnalyticsJob")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewStreamAnalyticsJobPaginator(essdk.BuildFilter(ctx, d.QueryContext, getStreamAnalyticsJobFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StreamAnalyticsJob =============================

// ==========================  START: StreamAnalyticsCluster =============================

type StreamAnalyticsCluster struct {
	Description   azure.StreamAnalyticsClusterDescription `json:"description"`
	Metadata      azure.Metadata                          `json:"metadata"`
	ResourceJobID int                                     `json:"resource_job_id"`
	SourceJobID   int                                     `json:"source_job_id"`
	ResourceType  string                                  `json:"resource_type"`
	SourceType    string                                  `json:"source_type"`
	ID            string                                  `json:"id"`
	ARN           string                                  `json:"arn"`
	SourceID      string                                  `json:"source_id"`
}

func (r *StreamAnalyticsCluster) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.StreamAnalyticsClusterDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type StreamAnalyticsClusterHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  StreamAnalyticsCluster `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type StreamAnalyticsClusterHits struct {
	Total essdk.SearchTotal           `json:"total"`
	Hits  []StreamAnalyticsClusterHit `json:"hits"`
}

type StreamAnalyticsClusterSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  StreamAnalyticsClusterHits `json:"hits"`
}

type StreamAnalyticsClusterPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewStreamAnalyticsClusterPaginator(filters []essdk.BoolFilter, limit *int64) (StreamAnalyticsClusterPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_streamanalytics_cluster", filters, limit)
	if err != nil {
		return StreamAnalyticsClusterPaginator{}, err
	}

	p := StreamAnalyticsClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StreamAnalyticsClusterPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p StreamAnalyticsClusterPaginator) NextPage(ctx context.Context) ([]StreamAnalyticsCluster, error) {
	var response StreamAnalyticsClusterSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StreamAnalyticsCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listStreamAnalyticsClusterFilters = map[string]string{
	"id":               "description.Cluster.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.StreamingJob.SKU.Name",
	"tags":             "description.StreamingJob.Tags",
	"title":            "description.StreamingJob.SKU.Name",
}

func ListStreamAnalyticsCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStreamAnalyticsCluster")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewStreamAnalyticsClusterPaginator(essdk.BuildFilter(ctx, d.QueryContext, listStreamAnalyticsClusterFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStreamAnalyticsClusterFilters = map[string]string{
	"id":               "description.Cluster.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.StreamingJob.SKU.Name",
	"tags":             "description.StreamingJob.Tags",
	"title":            "description.StreamingJob.SKU.Name",
}

func GetStreamAnalyticsCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStreamAnalyticsCluster")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewStreamAnalyticsClusterPaginator(essdk.BuildFilter(ctx, d.QueryContext, getStreamAnalyticsClusterFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StreamAnalyticsCluster =============================

// ==========================  START: VirtualMachineImagesImageTemplates =============================

type VirtualMachineImagesImageTemplates struct {
	Description   azure.VirtualMachineImagesImageTemplatesDescription `json:"description"`
	Metadata      azure.Metadata                                      `json:"metadata"`
	ResourceJobID int                                                 `json:"resource_job_id"`
	SourceJobID   int                                                 `json:"source_job_id"`
	ResourceType  string                                              `json:"resource_type"`
	SourceType    string                                              `json:"source_type"`
	ID            string                                              `json:"id"`
	ARN           string                                              `json:"arn"`
	SourceID      string                                              `json:"source_id"`
}

func (r *VirtualMachineImagesImageTemplates) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.VirtualMachineImagesImageTemplatesDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type VirtualMachineImagesImageTemplatesHit struct {
	ID      string                             `json:"_id"`
	Score   float64                            `json:"_score"`
	Index   string                             `json:"_index"`
	Type    string                             `json:"_type"`
	Version int64                              `json:"_version,omitempty"`
	Source  VirtualMachineImagesImageTemplates `json:"_source"`
	Sort    []interface{}                      `json:"sort"`
}

type VirtualMachineImagesImageTemplatesHits struct {
	Total essdk.SearchTotal                       `json:"total"`
	Hits  []VirtualMachineImagesImageTemplatesHit `json:"hits"`
}

type VirtualMachineImagesImageTemplatesSearchResponse struct {
	PitID string                                 `json:"pit_id"`
	Hits  VirtualMachineImagesImageTemplatesHits `json:"hits"`
}

type VirtualMachineImagesImageTemplatesPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewVirtualMachineImagesImageTemplatesPaginator(filters []essdk.BoolFilter, limit *int64) (VirtualMachineImagesImageTemplatesPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_virtualmachineimages_imagetemplates", filters, limit)
	if err != nil {
		return VirtualMachineImagesImageTemplatesPaginator{}, err
	}

	p := VirtualMachineImagesImageTemplatesPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p VirtualMachineImagesImageTemplatesPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p VirtualMachineImagesImageTemplatesPaginator) NextPage(ctx context.Context) ([]VirtualMachineImagesImageTemplates, error) {
	var response VirtualMachineImagesImageTemplatesSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []VirtualMachineImagesImageTemplates
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listVirtualMachineImagesImageTemplatesFilters = map[string]string{
	"id":               "description.ImageTemplates.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.ImageTemplate.Name",
	"tags":             "description.ImageTemplate.Tags",
	"title":            "description.ImageTemplate.Name",
}

func ListVirtualMachineImagesImageTemplates(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListVirtualMachineImagesImageTemplates")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewVirtualMachineImagesImageTemplatesPaginator(essdk.BuildFilter(ctx, d.QueryContext, listVirtualMachineImagesImageTemplatesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getVirtualMachineImagesImageTemplatesFilters = map[string]string{
	"id":               "description.ImageTemplates.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.ImageTemplate.Name",
	"tags":             "description.ImageTemplate.Tags",
	"title":            "description.ImageTemplate.Name",
}

func GetVirtualMachineImagesImageTemplates(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetVirtualMachineImagesImageTemplates")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewVirtualMachineImagesImageTemplatesPaginator(essdk.BuildFilter(ctx, d.QueryContext, getVirtualMachineImagesImageTemplatesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: VirtualMachineImagesImageTemplates =============================

// ==========================  START: OperationalInsightsWorkspaces =============================

type OperationalInsightsWorkspaces struct {
	Description   azure.OperationalInsightsWorkspacesDescription `json:"description"`
	Metadata      azure.Metadata                                 `json:"metadata"`
	ResourceJobID int                                            `json:"resource_job_id"`
	SourceJobID   int                                            `json:"source_job_id"`
	ResourceType  string                                         `json:"resource_type"`
	SourceType    string                                         `json:"source_type"`
	ID            string                                         `json:"id"`
	ARN           string                                         `json:"arn"`
	SourceID      string                                         `json:"source_id"`
}

func (r *OperationalInsightsWorkspaces) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.OperationalInsightsWorkspacesDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type OperationalInsightsWorkspacesHit struct {
	ID      string                        `json:"_id"`
	Score   float64                       `json:"_score"`
	Index   string                        `json:"_index"`
	Type    string                        `json:"_type"`
	Version int64                         `json:"_version,omitempty"`
	Source  OperationalInsightsWorkspaces `json:"_source"`
	Sort    []interface{}                 `json:"sort"`
}

type OperationalInsightsWorkspacesHits struct {
	Total essdk.SearchTotal                  `json:"total"`
	Hits  []OperationalInsightsWorkspacesHit `json:"hits"`
}

type OperationalInsightsWorkspacesSearchResponse struct {
	PitID string                            `json:"pit_id"`
	Hits  OperationalInsightsWorkspacesHits `json:"hits"`
}

type OperationalInsightsWorkspacesPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewOperationalInsightsWorkspacesPaginator(filters []essdk.BoolFilter, limit *int64) (OperationalInsightsWorkspacesPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_operationalinsights_workspaces", filters, limit)
	if err != nil {
		return OperationalInsightsWorkspacesPaginator{}, err
	}

	p := OperationalInsightsWorkspacesPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p OperationalInsightsWorkspacesPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p OperationalInsightsWorkspacesPaginator) NextPage(ctx context.Context) ([]OperationalInsightsWorkspaces, error) {
	var response OperationalInsightsWorkspacesSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []OperationalInsightsWorkspaces
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listOperationalInsightsWorkspacesFilters = map[string]string{
	"id":               "description.Workspaces.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Workspace.Name",
	"tags":             "description.Workspace.Tags",
	"title":            "description.Workspace.Name",
}

func ListOperationalInsightsWorkspaces(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListOperationalInsightsWorkspaces")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewOperationalInsightsWorkspacesPaginator(essdk.BuildFilter(ctx, d.QueryContext, listOperationalInsightsWorkspacesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getOperationalInsightsWorkspacesFilters = map[string]string{
	"id":               "description.Workspaces.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Workspace.Name",
	"tags":             "description.Workspace.Tags",
	"title":            "description.Workspace.Name",
}

func GetOperationalInsightsWorkspaces(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetOperationalInsightsWorkspaces")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewOperationalInsightsWorkspacesPaginator(essdk.BuildFilter(ctx, d.QueryContext, getOperationalInsightsWorkspacesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: OperationalInsightsWorkspaces =============================

// ==========================  START: TimeSeriesInsightsEnvironments =============================

type TimeSeriesInsightsEnvironments struct {
	Description   azure.TimeSeriesInsightsEnvironmentsDescription `json:"description"`
	Metadata      azure.Metadata                                  `json:"metadata"`
	ResourceJobID int                                             `json:"resource_job_id"`
	SourceJobID   int                                             `json:"source_job_id"`
	ResourceType  string                                          `json:"resource_type"`
	SourceType    string                                          `json:"source_type"`
	ID            string                                          `json:"id"`
	ARN           string                                          `json:"arn"`
	SourceID      string                                          `json:"source_id"`
}

func (r *TimeSeriesInsightsEnvironments) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.TimeSeriesInsightsEnvironmentsDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type TimeSeriesInsightsEnvironmentsHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  TimeSeriesInsightsEnvironments `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type TimeSeriesInsightsEnvironmentsHits struct {
	Total essdk.SearchTotal                   `json:"total"`
	Hits  []TimeSeriesInsightsEnvironmentsHit `json:"hits"`
}

type TimeSeriesInsightsEnvironmentsSearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  TimeSeriesInsightsEnvironmentsHits `json:"hits"`
}

type TimeSeriesInsightsEnvironmentsPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewTimeSeriesInsightsEnvironmentsPaginator(filters []essdk.BoolFilter, limit *int64) (TimeSeriesInsightsEnvironmentsPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_timeseriesinsights_environments", filters, limit)
	if err != nil {
		return TimeSeriesInsightsEnvironmentsPaginator{}, err
	}

	p := TimeSeriesInsightsEnvironmentsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p TimeSeriesInsightsEnvironmentsPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p TimeSeriesInsightsEnvironmentsPaginator) NextPage(ctx context.Context) ([]TimeSeriesInsightsEnvironments, error) {
	var response TimeSeriesInsightsEnvironmentsSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []TimeSeriesInsightsEnvironments
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listTimeSeriesInsightsEnvironmentsFilters = map[string]string{
	"id":               "description.Environments.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Environment.Name",
	"tags":             "description.Environment.Tags",
	"title":            "description.Environment.Name",
}

func ListTimeSeriesInsightsEnvironments(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListTimeSeriesInsightsEnvironments")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewTimeSeriesInsightsEnvironmentsPaginator(essdk.BuildFilter(ctx, d.QueryContext, listTimeSeriesInsightsEnvironmentsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getTimeSeriesInsightsEnvironmentsFilters = map[string]string{
	"id":               "description.Environments.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Environment.Name",
	"tags":             "description.Environment.Tags",
	"title":            "description.Environment.Name",
}

func GetTimeSeriesInsightsEnvironments(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetTimeSeriesInsightsEnvironments")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewTimeSeriesInsightsEnvironmentsPaginator(essdk.BuildFilter(ctx, d.QueryContext, getTimeSeriesInsightsEnvironmentsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: TimeSeriesInsightsEnvironments =============================

// ==========================  START: SynapseWorkspace =============================

type SynapseWorkspace struct {
	Description   azure.SynapseWorkspaceDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *SynapseWorkspace) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SynapseWorkspaceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SynapseWorkspaceHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  SynapseWorkspace `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type SynapseWorkspaceHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []SynapseWorkspaceHit `json:"hits"`
}

type SynapseWorkspaceSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  SynapseWorkspaceHits `json:"hits"`
}

type SynapseWorkspacePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSynapseWorkspacePaginator(filters []essdk.BoolFilter, limit *int64) (SynapseWorkspacePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_synapse_workspaces", filters, limit)
	if err != nil {
		return SynapseWorkspacePaginator{}, err
	}

	p := SynapseWorkspacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SynapseWorkspacePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SynapseWorkspacePaginator) NextPage(ctx context.Context) ([]SynapseWorkspace, error) {
	var response SynapseWorkspaceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SynapseWorkspace
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSynapseWorkspaceFilters = map[string]string{
	"adla_resource_id":                 "description.Workspace.Properties.AdlaResourceID",
	"connectivity_endpoints":           "description.Workspace.Properties.ConnectivityEndpoints",
	"default_data_lake_storage":        "description.Workspace.Properties.DefaultDataLakeStorage",
	"diagnostic_settings":              "description.DiagnosticSettingsResources",
	"extra_properties":                 "description.Workspace.Properties.ExtraProperties",
	"id":                               "description.Workspace.ID",
	"identity":                         "description.Workspace.Identity",
	"kaytu_account_id":                 "metadata.SourceID",
	"managed_resource_group_name":      "description.Workspace.Properties.ManagedResourceGroupName",
	"managed_virtual_network":          "description.Workspace.Properties.ManagedVirtualNetwork",
	"managed_virtual_network_settings": "description.Workspace.Properties.ManagedVirtualNetworkSettings",
	"name":                             "description.Workspace.Name",
	"provisioning_state":               "description.Workspace.Properties.ProvisioningState",
	"public_network_access":            "description.Workspace.Properties.PublicNetworkAccess",
	"purview_configuration":            "description.Workspace.Properties.PurviewConfiguration",
	"resource_group":                   "description.ResourceGroup",
	"sql_administrator_login":          "description.Workspace.Properties.SQLAdministratorLogin",
	"sql_administrator_login_password": "description.Workspace.Properties.SQLAdministratorLoginPassword",
	"tags":                             "description.Workspace.Tags",
	"title":                            "description.Workspace.Name",
	"type":                             "description.Workspace.Type",
	"virtual_network_profile":          "description.Workspace.Properties.VirtualNetworkProfile",
	"workspace_managed_sql_server_vulnerability_assessments": "description.ServerVulnerabilityAssessments",
	"workspace_repository_configuration":                     "description.Workspace.Properties.WorkspaceRepositoryConfiguration",
	"workspace_uid":                                          "description.Workspace.Properties.WorkspaceUID",
}

func ListSynapseWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSynapseWorkspace")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSynapseWorkspacePaginator(essdk.BuildFilter(ctx, d.QueryContext, listSynapseWorkspaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSynapseWorkspaceFilters = map[string]string{
	"adla_resource_id":                 "description.Workspace.Properties.AdlaResourceID",
	"connectivity_endpoints":           "description.Workspace.Properties.ConnectivityEndpoints",
	"default_data_lake_storage":        "description.Workspace.Properties.DefaultDataLakeStorage",
	"diagnostic_settings":              "description.DiagnosticSettingsResources",
	"extra_properties":                 "description.Workspace.Properties.ExtraProperties",
	"id":                               "description.Workspace.ID",
	"identity":                         "description.Workspace.Identity",
	"kaytu_account_id":                 "metadata.SourceID",
	"managed_resource_group_name":      "description.Workspace.Properties.ManagedResourceGroupName",
	"managed_virtual_network":          "description.Workspace.Properties.ManagedVirtualNetwork",
	"managed_virtual_network_settings": "description.Workspace.Properties.ManagedVirtualNetworkSettings",
	"name":                             "description.Workspace.name",
	"provisioning_state":               "description.Workspace.Properties.ProvisioningState",
	"public_network_access":            "description.Workspace.Properties.PublicNetworkAccess",
	"purview_configuration":            "description.Workspace.Properties.PurviewConfiguration",
	"resource_group":                   "description.ResourceGroup",
	"sql_administrator_login":          "description.Workspace.Properties.SQLAdministratorLogin",
	"sql_administrator_login_password": "description.Workspace.Properties.SQLAdministratorLoginPassword",
	"tags":                             "description.Workspace.Tags",
	"title":                            "description.Workspace.Name",
	"type":                             "description.Workspace.Type",
	"virtual_network_profile":          "description.Workspace.Properties.VirtualNetworkProfile",
	"workspace_managed_sql_server_vulnerability_assessments": "description.ServerVulnerabilityAssessments",
	"workspace_repository_configuration":                     "description.Workspace.Properties.WorkspaceRepositoryConfiguration",
	"workspace_uid":                                          "description.Workspace.Properties.WorkspaceUID",
}

func GetSynapseWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSynapseWorkspace")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSynapseWorkspacePaginator(essdk.BuildFilter(ctx, d.QueryContext, getSynapseWorkspaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SynapseWorkspace =============================

// ==========================  START: SynapseWorkspaceBigdatapools =============================

type SynapseWorkspaceBigdatapools struct {
	Description   azure.SynapseWorkspaceBigdatapoolsDescription `json:"description"`
	Metadata      azure.Metadata                                `json:"metadata"`
	ResourceJobID int                                           `json:"resource_job_id"`
	SourceJobID   int                                           `json:"source_job_id"`
	ResourceType  string                                        `json:"resource_type"`
	SourceType    string                                        `json:"source_type"`
	ID            string                                        `json:"id"`
	ARN           string                                        `json:"arn"`
	SourceID      string                                        `json:"source_id"`
}

func (r *SynapseWorkspaceBigdatapools) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SynapseWorkspaceBigdatapoolsDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SynapseWorkspaceBigdatapoolsHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  SynapseWorkspaceBigdatapools `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type SynapseWorkspaceBigdatapoolsHits struct {
	Total essdk.SearchTotal                 `json:"total"`
	Hits  []SynapseWorkspaceBigdatapoolsHit `json:"hits"`
}

type SynapseWorkspaceBigdatapoolsSearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  SynapseWorkspaceBigdatapoolsHits `json:"hits"`
}

type SynapseWorkspaceBigdatapoolsPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSynapseWorkspaceBigdatapoolsPaginator(filters []essdk.BoolFilter, limit *int64) (SynapseWorkspaceBigdatapoolsPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_synapse_workspaces_bigdatapools", filters, limit)
	if err != nil {
		return SynapseWorkspaceBigdatapoolsPaginator{}, err
	}

	p := SynapseWorkspaceBigdatapoolsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SynapseWorkspaceBigdatapoolsPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SynapseWorkspaceBigdatapoolsPaginator) NextPage(ctx context.Context) ([]SynapseWorkspaceBigdatapools, error) {
	var response SynapseWorkspaceBigdatapoolsSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SynapseWorkspaceBigdatapools
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSynapseWorkspaceBigdatapoolsFilters = map[string]string{
	"id":               "description.BigDataPool.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.BigDataPool.Name",
	"tags":             "description.BigDataPool.Tags",
	"title":            "description.BigDataPool.Name",
}

func ListSynapseWorkspaceBigdatapools(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSynapseWorkspaceBigdatapools")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSynapseWorkspaceBigdatapoolsPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSynapseWorkspaceBigdatapoolsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSynapseWorkspaceBigdatapoolsFilters = map[string]string{
	"id":               "description.BigDataPool.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.BigDataPool.Name",
	"tags":             "description.BigDataPool.Tags",
	"title":            "description.BigDataPool.Name",
}

func GetSynapseWorkspaceBigdatapools(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSynapseWorkspaceBigdatapools")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSynapseWorkspaceBigdatapoolsPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSynapseWorkspaceBigdatapoolsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SynapseWorkspaceBigdatapools =============================

// ==========================  START: SynapseWorkspaceSqlpools =============================

type SynapseWorkspaceSqlpools struct {
	Description   azure.SynapseWorkspaceSqlpoolsDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

func (r *SynapseWorkspaceSqlpools) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SynapseWorkspaceSqlpoolsDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SynapseWorkspaceSqlpoolsHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  SynapseWorkspaceSqlpools `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type SynapseWorkspaceSqlpoolsHits struct {
	Total essdk.SearchTotal             `json:"total"`
	Hits  []SynapseWorkspaceSqlpoolsHit `json:"hits"`
}

type SynapseWorkspaceSqlpoolsSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  SynapseWorkspaceSqlpoolsHits `json:"hits"`
}

type SynapseWorkspaceSqlpoolsPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSynapseWorkspaceSqlpoolsPaginator(filters []essdk.BoolFilter, limit *int64) (SynapseWorkspaceSqlpoolsPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_synapse_workspaces_sqlpools", filters, limit)
	if err != nil {
		return SynapseWorkspaceSqlpoolsPaginator{}, err
	}

	p := SynapseWorkspaceSqlpoolsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SynapseWorkspaceSqlpoolsPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SynapseWorkspaceSqlpoolsPaginator) NextPage(ctx context.Context) ([]SynapseWorkspaceSqlpools, error) {
	var response SynapseWorkspaceSqlpoolsSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SynapseWorkspaceSqlpools
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSynapseWorkspaceSqlpoolsFilters = map[string]string{
	"id":               "description.SqlPool.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.SqlPool.Name",
	"tags":             "description.SqlPool.Tags",
	"title":            "description.SqlPool.Name",
}

func ListSynapseWorkspaceSqlpools(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSynapseWorkspaceSqlpools")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSynapseWorkspaceSqlpoolsPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSynapseWorkspaceSqlpoolsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSynapseWorkspaceSqlpoolsFilters = map[string]string{
	"id":               "description.SqlPool.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.SqlPool.Name",
	"tags":             "description.SqlPool.Tags",
	"title":            "description.SqlPool.Name",
}

func GetSynapseWorkspaceSqlpools(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSynapseWorkspaceSqlpools")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSynapseWorkspaceSqlpoolsPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSynapseWorkspaceSqlpoolsFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SynapseWorkspaceSqlpools =============================

// ==========================  START: Location =============================

type Location struct {
	Description   azure.LocationDescription `json:"description"`
	Metadata      azure.Metadata            `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

func (r *Location) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.LocationDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type LocationHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  Location      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type LocationHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []LocationHit     `json:"hits"`
}

type LocationSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  LocationHits `json:"hits"`
}

type LocationPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewLocationPaginator(filters []essdk.BoolFilter, limit *int64) (LocationPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_resources_subscriptions_locations", filters, limit)
	if err != nil {
		return LocationPaginator{}, err
	}

	p := LocationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LocationPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p LocationPaginator) NextPage(ctx context.Context) ([]Location, error) {
	var response LocationSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []Location
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listLocationFilters = map[string]string{
	"display_name":     "description.Location.DisplayName",
	"id":               "description.Location.ID",
	"kaytu_account_id": "metadata.SourceID",
	"latitude":         "description.Location.Latitude",
	"longitude":        "description.Location.Longitude",
	"name":             "description.Location.Name",
	"title":            "description.Location.Name",
}

func ListLocation(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLocation")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewLocationPaginator(essdk.BuildFilter(ctx, d.QueryContext, listLocationFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLocationFilters = map[string]string{
	"display_name":     "description.Location.DisplayName",
	"id":               "description.Location.ID",
	"kaytu_account_id": "metadata.SourceID",
	"latitude":         "description.Location.Latitude",
	"longitude":        "description.Location.Longitude",
	"name":             "description.Location.name",
	"resource_group":   "description.ResourceGroup",
	"title":            "description.Location.Name",
}

func GetLocation(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLocation")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewLocationPaginator(essdk.BuildFilter(ctx, d.QueryContext, getLocationFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: Location =============================

// ==========================  START: AdUsers =============================

type AdUsers struct {
	Description   azure.AdUsersDescription `json:"description"`
	Metadata      azure.Metadata           `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	ARN           string                   `json:"arn"`
	SourceID      string                   `json:"source_id"`
}

func (r *AdUsers) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.AdUsersDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type AdUsersHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  AdUsers       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type AdUsersHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []AdUsersHit      `json:"hits"`
}

type AdUsersSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  AdUsersHits `json:"hits"`
}

type AdUsersPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewAdUsersPaginator(filters []essdk.BoolFilter, limit *int64) (AdUsersPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_resources_users", filters, limit)
	if err != nil {
		return AdUsersPaginator{}, err
	}

	p := AdUsersPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AdUsersPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p AdUsersPaginator) NextPage(ctx context.Context) ([]AdUsers, error) {
	var response AdUsersSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AdUsers
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listAdUsersFilters = map[string]string{
	"account_enabled":                       "description.AdUsers.accountEnabled",
	"additional_properties":                 "description.AdUsers.CreationType",
	"created_date_time":                     "description.AdUsers.CreatedDateTime",
	"display_name":                          "description.AdUsers.displayName",
	"filter":                                "description.AdUsers.filter",
	"given_name":                            "description.AdUsers.GivenName",
	"id":                                    "description.AdUsers.DirectoryObject.id",
	"im_addresses":                          "description.AdUsers.ImAddresses",
	"kaytu_account_id":                      "metadata.SourceID",
	"kaytu_resource_id":                     "ID",
	"mail":                                  "description.AdUsers.Mail",
	"mail_nickname":                         "description.AdUsers.MailNickname",
	"member_of":                             "description.AdUsers.MemberOf",
	"on_premises_immutable_id":              "description.AdUsers.OnPremisesImmutableId",
	"other_mails":                           "description.AdUsers.OtherMails",
	"password_policies":                     "description.AdUsers.PasswordPolicies",
	"password_profile":                      "description.AdUsers.PasswordProfile",
	"refresh_tokens_valid_from_date_time":   "description.AdUsers.RefreshTokensValidFromDateTime",
	"sign_in_sessions_valid_from_date_time": "description.AdUsers.SignInSessionsValidFromDateTime",
	"surname":                               "description.AdUsers.surname",
	"tenant_id":                             "description.TenantID",
	"title":                                 "description.AdUsers.DisplayName",
	"usage_location":                        "description.AdUsers.UsageLocation",
	"user_principal_name":                   "description.AdUsers.userPrincipalName",
	"user_type":                             "description.AdUsers.userType",
}

func ListAdUsers(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAdUsers")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewAdUsersPaginator(essdk.BuildFilter(ctx, d.QueryContext, listAdUsersFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAdUsersFilters = map[string]string{
	"account_enabled":                       "description.AdUsers.AccountEnabled",
	"additional_properties":                 "description.AdUsers.CreationType",
	"created_date_time":                     "description.AdUsers.CreatedDateTime",
	"display_name":                          "description.AdUsers.DisplayName",
	"given_name":                            "description.AdUsers.GivenName",
	"id":                                    "description.AdUsers.DirectoryObject.id",
	"im_addresses":                          "description.AdUsers.ImAddresses",
	"kaytu_account_id":                      "metadata.SourceID",
	"kaytu_resource_id":                     "ID",
	"mail":                                  "description.AdUsers.Mail",
	"mail_nickname":                         "description.AdUsers.MailNickname",
	"member_of":                             "description.AdUsers.MemberOf",
	"on_premises_immutable_id":              "description.AdUsers.OnPremisesImmutableId",
	"other_mails":                           "description.AdUsers.OtherMails",
	"password_policies":                     "description.AdUsers.PasswordPolicies",
	"password_profile":                      "description.AdUsers.PasswordProfile",
	"refresh_tokens_valid_from_date_time":   "description.AdUsers.RefreshTokensValidFromDateTime",
	"sign_in_sessions_valid_from_date_time": "description.AdUsers.SignInSessionsValidFromDateTime",
	"surname":                               "description.AdUsers.Surname",
	"tenant_id":                             "description.TenantID",
	"title":                                 "description.AdUsers.DisplayName",
	"usage_location":                        "description.AdUsers.UsageLocation",
	"user_principal_name":                   "description.AdUsers.UserPrincipalName",
	"user_type":                             "description.AdUsers.UserType",
}

func GetAdUsers(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAdUsers")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewAdUsersPaginator(essdk.BuildFilter(ctx, d.QueryContext, getAdUsersFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AdUsers =============================

// ==========================  START: AdGroup =============================

type AdGroup struct {
	Description   azure.AdGroupDescription `json:"description"`
	Metadata      azure.Metadata           `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	ARN           string                   `json:"arn"`
	SourceID      string                   `json:"source_id"`
}

func (r *AdGroup) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.AdGroupDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type AdGroupHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  AdGroup       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type AdGroupHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []AdGroupHit      `json:"hits"`
}

type AdGroupSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  AdGroupHits `json:"hits"`
}

type AdGroupPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewAdGroupPaginator(filters []essdk.BoolFilter, limit *int64) (AdGroupPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_resources_groups", filters, limit)
	if err != nil {
		return AdGroupPaginator{}, err
	}

	p := AdGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AdGroupPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p AdGroupPaginator) NextPage(ctx context.Context) ([]AdGroup, error) {
	var response AdGroupSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AdGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listAdGroupFilters = map[string]string{
	"assigned_labels":                  "description.AdGroup.AssignedLabels",
	"classification":                   "description.AdGroup.Classification",
	"created_date_time":                "description.AdGroup.CreatedDateTime",
	"description":                      "description.AdGroup.Description",
	"display_name":                     "description.AdGroup.DisplayName",
	"expiration_date_time":             "description.AdGroup.ExpirationDateTime",
	"group_types":                      "description.AdGroup.GroupTypes",
	"id":                               "description.AdGroup.DirectoryObject.ID",
	"is_assignable_to_role":            "description.AdGroup.Classification",
	"is_subscribed_by_mail":            "description.AdGroup.IsAssignableToRole",
	"kaytu_account_id":                 "metadata.SourceID",
	"mail":                             "description.AdGroup.Mail",
	"mail_enabled":                     "description.AdGroup.MailEnabled",
	"mail_nickname":                    "description.AdGroup.MailNickname",
	"member_ids":                       "description.AdGroup.Members",
	"membership_rule":                  "description.AdGroup.MembershipRule",
	"membership_rule_processing_state": "description.AdGroup.MembershipRuleProcessingState",
	"on_premises_domain_name":          "description.AdGroup.OnPremisesDomainName",
	"on_premises_last_sync_date_time":  "description.AdGroup.OnPremisesLastSyncDateTime",
	"on_premises_net_bios_name":        "description.AdGroup.OnPremisesNetBiosName",
	"on_premises_sam_account_name":     "description.AdGroup.OnPremisesSamAccountName",
	"on_premises_security_identifier":  "description.AdGroup.OnPremisesSecurityIdentifier",
	"on_premises_sync_enabled":         "description.AdGroup.OnPremisesSyncEnabled",
	"owner_ids":                        "description.AdGroup.Owners",
	"proxy_addresses":                  "description.AdGroup.ProxyAddresses",
	"renewed_date_time":                "description.AdGroup.RenewedDateTime",
	"resource_behavior_options":        "description.AdGroup.ResourceBehaviorOptions",
	"resource_provisioning_options":    "description.AdGroup.ResourceProvisioningOptions",
	"security_enabled":                 "description.AdGroup.SecurityEnabled",
	"security_identifier":              "description.AdGroup.SecurityIdentifier",
	"tenant_id":                        "description.TenantID",
	"visibility":                       "description.AdGroup.Visibility",
}

func ListAdGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAdGroup")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewAdGroupPaginator(essdk.BuildFilter(ctx, d.QueryContext, listAdGroupFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAdGroupFilters = map[string]string{
	"assigned_labels":                  "description.AdGroup.AssignedLabels",
	"classification":                   "description.AdGroup.Classification",
	"created_date_time":                "description.AdGroup.CreatedDateTime",
	"description":                      "description.AdGroup.Description",
	"display_name":                     "description.AdGroup.DisplayName",
	"expiration_date_time":             "description.AdGroup.ExpirationDateTime",
	"group_types":                      "description.AdGroup.GroupTypes",
	"id":                               "description.AdGroup.DirectoryObject.ID",
	"is_assignable_to_role":            "description.AdGroup.Classification",
	"is_subscribed_by_mail":            "description.AdGroup.IsAssignableToRole",
	"kaytu_account_id":                 "metadata.SourceID",
	"mail":                             "description.AdGroup.Mail",
	"mail_enabled":                     "description.AdGroup.MailEnabled",
	"mail_nickname":                    "description.AdGroup.MailNickname",
	"member_ids":                       "description.AdGroup.Members",
	"membership_rule":                  "description.AdGroup.MembershipRule",
	"membership_rule_processing_state": "description.AdGroup.MembershipRuleProcessingState",
	"on_premises_domain_name":          "description.AdGroup.OnPremisesDomainName",
	"on_premises_last_sync_date_time":  "description.AdGroup.OnPremisesLastSyncDateTime",
	"on_premises_net_bios_name":        "description.AdGroup.OnPremisesNetBiosName",
	"on_premises_sam_account_name":     "description.AdGroup.OnPremisesSamAccountName",
	"on_premises_security_identifier":  "description.AdGroup.OnPremisesSecurityIdentifier",
	"on_premises_sync_enabled":         "description.AdGroup.OnPremisesSyncEnabled",
	"owner_ids":                        "description.AdGroup.Owners",
	"proxy_addresses":                  "description.AdGroup.ProxyAddresses",
	"renewed_date_time":                "description.AdGroup.RenewedDateTime",
	"resource_behavior_options":        "description.AdGroup.ResourceBehaviorOptions",
	"resource_provisioning_options":    "description.AdGroup.ResourceProvisioningOptions",
	"security_enabled":                 "description.AdGroup.SecurityEnabled",
	"security_identifier":              "description.AdGroup.SecurityIdentifier",
	"tenant_id":                        "description.TenantID",
	"visibility":                       "description.AdGroup.Visibility",
}

func GetAdGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAdGroup")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewAdGroupPaginator(essdk.BuildFilter(ctx, d.QueryContext, getAdGroupFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AdGroup =============================

// ==========================  START: AdServicePrincipal =============================

type AdServicePrincipal struct {
	Description   azure.AdServicePrincipalDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

func (r *AdServicePrincipal) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.AdServicePrincipalDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type AdServicePrincipalHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  AdServicePrincipal `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type AdServicePrincipalHits struct {
	Total essdk.SearchTotal       `json:"total"`
	Hits  []AdServicePrincipalHit `json:"hits"`
}

type AdServicePrincipalSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  AdServicePrincipalHits `json:"hits"`
}

type AdServicePrincipalPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewAdServicePrincipalPaginator(filters []essdk.BoolFilter, limit *int64) (AdServicePrincipalPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_resources_serviceprincipals", filters, limit)
	if err != nil {
		return AdServicePrincipalPaginator{}, err
	}

	p := AdServicePrincipalPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AdServicePrincipalPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p AdServicePrincipalPaginator) NextPage(ctx context.Context) ([]AdServicePrincipal, error) {
	var response AdServicePrincipalSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AdServicePrincipal
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listAdServicePrincipalFilters = map[string]string{
	"account_enabled":              "description.AdServicePrincipal.AccountEnabled",
	"add_ins":                      "description.AdServicePrincipal.AddIns",
	"alternative_names":            "description.AdServicePrincipal.AlternativeNames",
	"app_description":              "description.AdServicePrincipal.Description",
	"app_display_name":             "description.AdServicePrincipal.AppDisplayName",
	"app_id":                       "description.AdServicePrincipal.AppId",
	"app_owner_organization_id":    "description.AdServicePrincipal.AppOwnerOrganizationId",
	"app_role_assignment_required": "description.AdServicePrincipal.AppRoleAssignmentRequired",
	"app_roles":                    "description.AdServicePrincipal.AppRoles",
	"description":                  "description.AdServicePrincipal.Description",
	"display_name":                 "description.AdServicePrincipal.DisplayName",
	"id":                           "description.AdServicePrincipal.DirectoryObject.ID",
	"info":                         "description.AdServicePrincipal.Info",
	"kaytu_account_id":             "metadata.SourceID",
	"key_credentials":              "description.AdServicePrincipal.KeyCredentials",
	"login_url":                    "description.AdServicePrincipal.LoginUrl",
	"logout_url":                   "description.AdServicePrincipal.LogoutUrl",
	"notification_email_addresses": "description.AdServicePrincipal.NotificationEmailAddresses",
	"oauth2_permission_scopes":     "description.AdServicePrincipal.PublishedPermissionScopes",
	"owner_ids":                    "description.AdServicePrincipal.Owners",
	"password_credentials":         "description.AdServicePrincipal.PasswordCredentials",
	"reply_urls":                   "description.AdServicePrincipal.ReplyUrls",
	"service_principal_names":      "description.AdServicePrincipal.ServicePrincipalNames",
	"service_principal_type":       "description.AdServicePrincipal.ServicePrincipalType",
	"sign_in_audience":             "description.AdServicePrincipal.SignInAudience",
	"tags_src":                     "description.AdServicePrincipal.Tags",
	"tenant_id":                    "description.TenantID",
}

func ListAdServicePrincipal(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAdServicePrincipal")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewAdServicePrincipalPaginator(essdk.BuildFilter(ctx, d.QueryContext, listAdServicePrincipalFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAdServicePrincipalFilters = map[string]string{
	"account_enabled":              "description.AdServicePrincipal.AccountEnabled",
	"add_ins":                      "description.AdServicePrincipal.AddIns",
	"alternative_names":            "description.AdServicePrincipal.AlternativeNames",
	"app_description":              "description.AdServicePrincipal.Description",
	"app_display_name":             "description.AdServicePrincipal.AppDisplayName",
	"app_id":                       "description.AdServicePrincipal.AppId",
	"app_owner_organization_id":    "description.AdServicePrincipal.AppOwnerOrganizationId",
	"app_role_assignment_required": "description.AdServicePrincipal.AppRoleAssignmentRequired",
	"app_roles":                    "description.AdServicePrincipal.AppRoles",
	"description":                  "description.AdServicePrincipal.Description",
	"display_name":                 "description.AdServicePrincipal.DisplayName",
	"id":                           "description.AdServicePrincipal.DirectoryObject.ID",
	"info":                         "description.AdServicePrincipal.Info",
	"kaytu_account_id":             "metadata.SourceID",
	"key_credentials":              "description.AdServicePrincipal.KeyCredentials",
	"login_url":                    "description.AdServicePrincipal.LoginUrl",
	"logout_url":                   "description.AdServicePrincipal.LogoutUrl",
	"notification_email_addresses": "description.AdServicePrincipal.NotificationEmailAddresses",
	"oauth2_permission_scopes":     "description.AdServicePrincipal.PublishedPermissionScopes",
	"owner_ids":                    "description.AdServicePrincipal.Owners",
	"password_credentials":         "description.AdServicePrincipal.PasswordCredentials",
	"reply_urls":                   "description.AdServicePrincipal.ReplyUrls",
	"service_principal_names":      "description.AdServicePrincipal.ServicePrincipalNames",
	"service_principal_type":       "description.AdServicePrincipal.ServicePrincipalType",
	"sign_in_audience":             "description.AdServicePrincipal.SignInAudience",
	"tags_src":                     "description.AdServicePrincipal.Tags",
	"tenant_id":                    "description.TenantID",
}

func GetAdServicePrincipal(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAdServicePrincipal")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewAdServicePrincipalPaginator(essdk.BuildFilter(ctx, d.QueryContext, getAdServicePrincipalFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AdServicePrincipal =============================

// ==========================  START: AnalysisServiceServer =============================

type AnalysisServiceServer struct {
	Description   azure.AnalysisServiceServerDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

func (r *AnalysisServiceServer) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.AnalysisServiceServerDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type AnalysisServiceServerHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  AnalysisServiceServer `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type AnalysisServiceServerHits struct {
	Total essdk.SearchTotal          `json:"total"`
	Hits  []AnalysisServiceServerHit `json:"hits"`
}

type AnalysisServiceServerSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  AnalysisServiceServerHits `json:"hits"`
}

type AnalysisServiceServerPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewAnalysisServiceServerPaginator(filters []essdk.BoolFilter, limit *int64) (AnalysisServiceServerPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_analysisservices_servers", filters, limit)
	if err != nil {
		return AnalysisServiceServerPaginator{}, err
	}

	p := AnalysisServiceServerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AnalysisServiceServerPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p AnalysisServiceServerPaginator) NextPage(ctx context.Context) ([]AnalysisServiceServer, error) {
	var response AnalysisServiceServerSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AnalysisServiceServer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listAnalysisServiceServerFilters = map[string]string{
	"id":               "description.Servers.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Server.Properties.ServerFullName",
	"tags":             "description.Server.Tags",
	"title":            "description.Server.Properties.ServerFullName",
}

func ListAnalysisServiceServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAnalysisServiceServer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewAnalysisServiceServerPaginator(essdk.BuildFilter(ctx, d.QueryContext, listAnalysisServiceServerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAnalysisServiceServerFilters = map[string]string{
	"id":               "description.Servers.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Server.name",
	"resource_group":   "description.ResourceGroup",
	"tags":             "description.Server.Tags",
	"title":            "description.Server.Properties.ServerFullName",
}

func GetAnalysisServiceServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAnalysisServiceServer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewAnalysisServiceServerPaginator(essdk.BuildFilter(ctx, d.QueryContext, getAnalysisServiceServerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AnalysisServiceServer =============================

// ==========================  START: PostgresqlServer =============================

type PostgresqlServer struct {
	Description   azure.PostgresqlServerDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *PostgresqlServer) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.PostgresqlServerDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type PostgresqlServerHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  PostgresqlServer `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type PostgresqlServerHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []PostgresqlServerHit `json:"hits"`
}

type PostgresqlServerSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  PostgresqlServerHits `json:"hits"`
}

type PostgresqlServerPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewPostgresqlServerPaginator(filters []essdk.BoolFilter, limit *int64) (PostgresqlServerPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_dbforpostgresql_servers", filters, limit)
	if err != nil {
		return PostgresqlServerPaginator{}, err
	}

	p := PostgresqlServerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PostgresqlServerPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p PostgresqlServerPaginator) NextPage(ctx context.Context) ([]PostgresqlServer, error) {
	var response PostgresqlServerSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PostgresqlServer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listPostgresqlServerFilters = map[string]string{
	"administrator_login":         "description.Server.Properties.AdministratorLogin",
	"backup_retention_days":       "description.Server.Properties.StorageProfile.BackupRetentionDays",
	"byok_enforcement":            "description.Server.Properties.ByokEnforcement",
	"firewall_rules":              "description.FirewallRules",
	"fully_qualified_domain_name": "description.Server.Properties.FullyQualifiedDomainName",
	"geo_redundant_backup":        "description.Server.Properties.StorageProfile.GeoRedundantBackup",
	"id":                          "description.Server.ID",
	"infrastructure_encryption":   "description.Server.Properties.InfrastructureEncryption",
	"kaytu_account_id":            "metadata.SourceID",
	"location":                    "description.Server.Location",
	"master_server_id":            "description.Server.Properties.MasterServerID",
	"minimal_tls_version":         "description.Server.Properties.MinimalTLSVersion",
	"name":                        "description.Server.Name",
	"public_network_access":       "description.Server.Properties.PublicNetworkAccess",
	"replica_capacity":            "description.Server.Properties.ReplicaCapacity",
	"replication_role":            "description.Server.Properties.ReplicationRole",
	"resource_group":              "description.ResourceGroup",
	"server_administrators":       "description.ServerAdministratorResources",
	"server_configurations":       "description.Configurations",
	"server_keys":                 "description.ServerKeys",
	"sku_capacity":                "description.Server.SKU.Capacity",
	"sku_family":                  "description.Server.SKU.Family",
	"sku_name":                    "description.Server.SKU.Name",
	"sku_size":                    "description.Server.SKU.Size",
	"sku_tier":                    "description.Server.SKU.Tier",
	"ssl_enforcement":             "description.Server.Properties.SSLEnforcement",
	"storage_auto_grow":           "description.Server.Properties.StorageProfile.StorageAutogrow",
	"storage_mb":                  "description.Server.Properties.StorageProfile.StorageMB",
	"tags":                        "description.Server.Tags",
	"title":                       "description.Server.Name",
	"type":                        "description.Server.Type",
	"user_visible_state":          "description.Server.Properties.UserVisibleState",
	"version":                     "description.Server.Properties.Version",
}

func ListPostgresqlServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPostgresqlServer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewPostgresqlServerPaginator(essdk.BuildFilter(ctx, d.QueryContext, listPostgresqlServerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPostgresqlServerFilters = map[string]string{
	"administrator_login":         "description.Server.Properties.AdministratorLogin",
	"backup_retention_days":       "description.Server.Properties.StorageProfile.BackupRetentionDays",
	"byok_enforcement":            "description.Server.Properties.ByokEnforcement",
	"firewall_rules":              "description.FirewallRules",
	"fully_qualified_domain_name": "description.Server.Properties.FullyQualifiedDomainName",
	"geo_redundant_backup":        "description.Server.Properties.StorageProfile.GeoRedundantBackup",
	"id":                          "description.Server.ID",
	"infrastructure_encryption":   "description.Server.Properties.InfrastructureEncryption",
	"kaytu_account_id":            "metadata.SourceID",
	"location":                    "description.Server.Location",
	"master_server_id":            "description.Server.Properties.MasterServerID",
	"minimal_tls_version":         "description.Server.Properties.MinimalTLSVersion",
	"name":                        "description.Server.name",
	"public_network_access":       "description.Server.Properties.PublicNetworkAccess",
	"replica_capacity":            "description.Server.Properties.ReplicaCapacity",
	"replication_role":            "description.Server.Properties.ReplicationRole",
	"resource_group":              "description.ResourceGroup",
	"server_administrators":       "description.ServerAdministratorResources",
	"server_configurations":       "description.Configurations",
	"server_keys":                 "description.ServerKeys",
	"sku_capacity":                "description.Server.SKU.Capacity",
	"sku_family":                  "description.Server.SKU.Family",
	"sku_name":                    "description.Server.SKU.Name",
	"sku_size":                    "description.Server.SKU.Size",
	"sku_tier":                    "description.Server.SKU.Tier",
	"ssl_enforcement":             "description.Server.Properties.SSLEnforcement",
	"storage_auto_grow":           "description.Server.Properties.StorageProfile.StorageAutogrow",
	"storage_mb":                  "description.Server.Properties.StorageProfile.StorageMB",
	"tags":                        "description.Server.Tags",
	"title":                       "description.Server.Name",
	"type":                        "description.Server.Type",
	"user_visible_state":          "description.Server.Properties.UserVisibleState",
	"version":                     "description.Server.Properties.Version",
}

func GetPostgresqlServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPostgresqlServer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewPostgresqlServerPaginator(essdk.BuildFilter(ctx, d.QueryContext, getPostgresqlServerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PostgresqlServer =============================

// ==========================  START: PostgresqlFlexibleServer =============================

type PostgresqlFlexibleServer struct {
	Description   azure.PostgresqlFlexibleServerDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

func (r *PostgresqlFlexibleServer) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.PostgresqlFlexibleServerDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type PostgresqlFlexibleServerHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  PostgresqlFlexibleServer `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type PostgresqlFlexibleServerHits struct {
	Total essdk.SearchTotal             `json:"total"`
	Hits  []PostgresqlFlexibleServerHit `json:"hits"`
}

type PostgresqlFlexibleServerSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  PostgresqlFlexibleServerHits `json:"hits"`
}

type PostgresqlFlexibleServerPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewPostgresqlFlexibleServerPaginator(filters []essdk.BoolFilter, limit *int64) (PostgresqlFlexibleServerPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_dbforpostgresql_flexibleservers", filters, limit)
	if err != nil {
		return PostgresqlFlexibleServerPaginator{}, err
	}

	p := PostgresqlFlexibleServerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PostgresqlFlexibleServerPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p PostgresqlFlexibleServerPaginator) NextPage(ctx context.Context) ([]PostgresqlFlexibleServer, error) {
	var response PostgresqlFlexibleServerSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PostgresqlFlexibleServer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listPostgresqlFlexibleServerFilters = map[string]string{
	"id":               "description.Server.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Server.Name",
	"tags":             "description.Server.Tags",
	"title":            "description.Server.Name",
}

func ListPostgresqlFlexibleServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPostgresqlFlexibleServer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewPostgresqlFlexibleServerPaginator(essdk.BuildFilter(ctx, d.QueryContext, listPostgresqlFlexibleServerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPostgresqlFlexibleServerFilters = map[string]string{
	"id":               "description.Server.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Server.Name",
	"tags":             "description.Server.Tags",
	"title":            "description.Server.Name",
}

func GetPostgresqlFlexibleServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPostgresqlFlexibleServer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewPostgresqlFlexibleServerPaginator(essdk.BuildFilter(ctx, d.QueryContext, getPostgresqlFlexibleServerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PostgresqlFlexibleServer =============================

// ==========================  START: StorageSync =============================

type StorageSync struct {
	Description   azure.StorageSyncDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

func (r *StorageSync) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.StorageSyncDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type StorageSyncHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  StorageSync   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type StorageSyncHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []StorageSyncHit  `json:"hits"`
}

type StorageSyncSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  StorageSyncHits `json:"hits"`
}

type StorageSyncPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewStorageSyncPaginator(filters []essdk.BoolFilter, limit *int64) (StorageSyncPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_storagesync_storagesyncservices", filters, limit)
	if err != nil {
		return StorageSyncPaginator{}, err
	}

	p := StorageSyncPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageSyncPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p StorageSyncPaginator) NextPage(ctx context.Context) ([]StorageSync, error) {
	var response StorageSyncSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageSync
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listStorageSyncFilters = map[string]string{
	"id":                          "description.Service.ID",
	"incoming_traffic_policy":     "description.Service.Properties.IncomingTrafficPolicy",
	"kaytu_account_id":            "metadata.SourceID",
	"last_operation_name":         "description.Service.Properties.LastOperationName",
	"last_workflow_id":            "description.Service.Properties.LastWorkflowID",
	"name":                        "description.Service.Name",
	"provisioning_state":          "description.Service.Properties.ProvisioningState",
	"resource_group":              "description.ResourceGroup",
	"storage_sync_service_status": "description.Service.Properties.StorageSyncServiceStatus",
	"storage_sync_service_uid":    "description.Service.Properties.StorageSyncServiceUID",
	"tags":                        "description.Service.Tags",
	"title":                       "description.Service.Name",
	"type":                        "description.Service.Type",
}

func ListStorageSync(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageSync")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewStorageSyncPaginator(essdk.BuildFilter(ctx, d.QueryContext, listStorageSyncFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageSyncFilters = map[string]string{
	"id":                          "description.Service.ID",
	"incoming_traffic_policy":     "description.Service.Properties.IncomingTrafficPolicy",
	"kaytu_account_id":            "metadata.SourceID",
	"last_operation_name":         "description.Service.Properties.LastOperationName",
	"last_workflow_id":            "description.Service.Properties.LastWorkflowID",
	"name":                        "description.Service.name",
	"provisioning_state":          "description.Service.Properties.ProvisioningState",
	"resource_group":              "description.ResourceGroup",
	"storage_sync_service_status": "description.Service.Properties.StorageSyncServiceStatus",
	"storage_sync_service_uid":    "description.Service.Properties.StorageSyncServiceUID",
	"tags":                        "description.Service.Tags",
	"title":                       "description.Service.Name",
	"type":                        "description.Service.Type",
}

func GetStorageSync(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageSync")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewStorageSyncPaginator(essdk.BuildFilter(ctx, d.QueryContext, getStorageSyncFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageSync =============================

// ==========================  START: MssqlManagedInstance =============================

type MssqlManagedInstance struct {
	Description   azure.MssqlManagedInstanceDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

func (r *MssqlManagedInstance) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.MssqlManagedInstanceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type MssqlManagedInstanceHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  MssqlManagedInstance `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type MssqlManagedInstanceHits struct {
	Total essdk.SearchTotal         `json:"total"`
	Hits  []MssqlManagedInstanceHit `json:"hits"`
}

type MssqlManagedInstanceSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  MssqlManagedInstanceHits `json:"hits"`
}

type MssqlManagedInstancePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewMssqlManagedInstancePaginator(filters []essdk.BoolFilter, limit *int64) (MssqlManagedInstancePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_sql_managedinstances", filters, limit)
	if err != nil {
		return MssqlManagedInstancePaginator{}, err
	}

	p := MssqlManagedInstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p MssqlManagedInstancePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p MssqlManagedInstancePaginator) NextPage(ctx context.Context) ([]MssqlManagedInstance, error) {
	var response MssqlManagedInstanceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []MssqlManagedInstance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listMssqlManagedInstanceFilters = map[string]string{
	"administrator_login":          "description.ManagedInstance.Properties.AdministratorLogin",
	"administrator_login_password": "description.ManagedInstance.Properties.AdministratorLoginPassword",
	"collation":                    "description.ManagedInstance.Properties.Collation",
	"dns_zone":                     "description.ManagedInstance.Properties.DNSZone",
	"dns_zone_partner":             "description.ManagedInstance.Properties.DNSZonePartner",
	"encryption_protectors":        "description.ManagedInstanceEncryptionProtectors",
	"fully_qualified_domain_name":  "description.ManagedInstance.Properties.FullyQualifiedDomainName",
	"id":                           "description.ManagedInstance.ID",
	"identity":                     "description.ManagedInstance.Identity",
	"instance_pool_id":             "description.ManagedInstance.Properties.InstancePoolID",
	"kaytu_account_id":             "metadata.SourceID",
	"license_type":                 "description.ManagedInstance.Properties.LicenseType",
	"maintenance_configuration_id": "description.ManagedInstance.Properties.MaintenanceConfigurationID",
	"managed_instance_create_mode": "description.ManagedInstance.Properties.ManagedInstanceCreateMode",
	"minimal_tls_version":          "description.ManagedInstance.Properties.MinimalTLSVersion",
	"name":                         "description.ManagedInstance.Name",
	"proxy_override":               "description.ManagedInstance.Properties.ProxyOverride",
	"public_data_endpoint_enabled": "description.ManagedInstance.Properties.PublicDataEndpointEnabled",
	"resource_group":               "description.ResourceGroup",
	"security_alert_policies":      "description.ManagedDatabaseSecurityAlertPolicies",
	"sku":                          "description.ManagedInstance.SKU",
	"source_managed_instance_id":   "description.ManagedInstance.Properties.SourceManagedInstanceID",
	"state":                        "description.ManagedInstance.Properties.State",
	"storage_size_in_gb":           "description.ManagedInstance.Properties.StorageSizeInGB",
	"subnet_id":                    "description.ManagedInstance.Properties.SubnetID",
	"tags":                         "description.ManagedInstance.Tags",
	"timezone_id":                  "description.ManagedInstance.Properties.TimezoneID",
	"title":                        "description.ManagedInstance.Name",
	"type":                         "description.ManagedInstance.Type",
	"v_cores":                      "description.ManagedInstance.Properties.VCores",
	"vulnerability_assessments":    "description.ManagedInstanceVulnerabilityAssessments",
}

func ListMssqlManagedInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListMssqlManagedInstance")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewMssqlManagedInstancePaginator(essdk.BuildFilter(ctx, d.QueryContext, listMssqlManagedInstanceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getMssqlManagedInstanceFilters = map[string]string{
	"administrator_login":          "description.ManagedInstance.Properties.AdministratorLogin",
	"administrator_login_password": "description.ManagedInstance.Properties.AdministratorLoginPassword",
	"collation":                    "description.ManagedInstance.Properties.Collation",
	"dns_zone":                     "description.ManagedInstance.Properties.DNSZone",
	"dns_zone_partner":             "description.ManagedInstance.Properties.DNSZonePartner",
	"encryption_protectors":        "description.ManagedInstanceEncryptionProtectors",
	"fully_qualified_domain_name":  "description.ManagedInstance.Properties.FullyQualifiedDomainName",
	"id":                           "description.ManagedInstance.ID",
	"identity":                     "description.ManagedInstance.Identity",
	"instance_pool_id":             "description.ManagedInstance.Properties.InstancePoolID",
	"kaytu_account_id":             "metadata.SourceID",
	"license_type":                 "description.ManagedInstance.Properties.LicenseType",
	"maintenance_configuration_id": "description.ManagedInstance.Properties.MaintenanceConfigurationID",
	"managed_instance_create_mode": "description.ManagedInstance.Properties.ManagedInstanceCreateMode",
	"minimal_tls_version":          "description.ManagedInstance.Properties.MinimalTLSVersion",
	"name":                         "description.ManagedInstance.name",
	"proxy_override":               "description.ManagedInstance.Properties.ProxyOverride",
	"public_data_endpoint_enabled": "description.ManagedInstance.Properties.PublicDataEndpointEnabled",
	"resource_group":               "description.ResourceGroup",
	"security_alert_policies":      "description.ManagedDatabaseSecurityAlertPolicies",
	"sku":                          "description.ManagedInstance.SKU",
	"source_managed_instance_id":   "description.ManagedInstance.Properties.SourceManagedInstanceID",
	"state":                        "description.ManagedInstance.Properties.State",
	"storage_size_in_gb":           "description.ManagedInstance.Properties.StorageSizeInGB",
	"subnet_id":                    "description.ManagedInstance.Properties.SubnetID",
	"tags":                         "description.ManagedInstance.Tags",
	"timezone_id":                  "description.ManagedInstance.Properties.TimezoneID",
	"title":                        "description.ManagedInstance.Name",
	"type":                         "description.ManagedInstance.Type",
	"v_cores":                      "description.ManagedInstance.Properties.VCores",
	"vulnerability_assessments":    "description.ManagedInstanceVulnerabilityAssessments",
}

func GetMssqlManagedInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetMssqlManagedInstance")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewMssqlManagedInstancePaginator(essdk.BuildFilter(ctx, d.QueryContext, getMssqlManagedInstanceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: MssqlManagedInstance =============================

// ==========================  START: MssqlManagedInstanceDatabases =============================

type MssqlManagedInstanceDatabases struct {
	Description   azure.MssqlManagedInstanceDatabasesDescription `json:"description"`
	Metadata      azure.Metadata                                 `json:"metadata"`
	ResourceJobID int                                            `json:"resource_job_id"`
	SourceJobID   int                                            `json:"source_job_id"`
	ResourceType  string                                         `json:"resource_type"`
	SourceType    string                                         `json:"source_type"`
	ID            string                                         `json:"id"`
	ARN           string                                         `json:"arn"`
	SourceID      string                                         `json:"source_id"`
}

func (r *MssqlManagedInstanceDatabases) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.MssqlManagedInstanceDatabasesDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type MssqlManagedInstanceDatabasesHit struct {
	ID      string                        `json:"_id"`
	Score   float64                       `json:"_score"`
	Index   string                        `json:"_index"`
	Type    string                        `json:"_type"`
	Version int64                         `json:"_version,omitempty"`
	Source  MssqlManagedInstanceDatabases `json:"_source"`
	Sort    []interface{}                 `json:"sort"`
}

type MssqlManagedInstanceDatabasesHits struct {
	Total essdk.SearchTotal                  `json:"total"`
	Hits  []MssqlManagedInstanceDatabasesHit `json:"hits"`
}

type MssqlManagedInstanceDatabasesSearchResponse struct {
	PitID string                            `json:"pit_id"`
	Hits  MssqlManagedInstanceDatabasesHits `json:"hits"`
}

type MssqlManagedInstanceDatabasesPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewMssqlManagedInstanceDatabasesPaginator(filters []essdk.BoolFilter, limit *int64) (MssqlManagedInstanceDatabasesPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_sql_managedinstances_databases", filters, limit)
	if err != nil {
		return MssqlManagedInstanceDatabasesPaginator{}, err
	}

	p := MssqlManagedInstanceDatabasesPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p MssqlManagedInstanceDatabasesPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p MssqlManagedInstanceDatabasesPaginator) NextPage(ctx context.Context) ([]MssqlManagedInstanceDatabases, error) {
	var response MssqlManagedInstanceDatabasesSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []MssqlManagedInstanceDatabases
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listMssqlManagedInstanceDatabasesFilters = map[string]string{
	"id":               "description.ManagedInstance.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.ManagedInstance.SKU.Name",
	"tags":             "description.ManagedInstance.Tags",
	"title":            "description.ManagedInstance.SKU.Name",
}

func ListMssqlManagedInstanceDatabases(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListMssqlManagedInstanceDatabases")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewMssqlManagedInstanceDatabasesPaginator(essdk.BuildFilter(ctx, d.QueryContext, listMssqlManagedInstanceDatabasesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getMssqlManagedInstanceDatabasesFilters = map[string]string{
	"id":               "description.ManagedInstance.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.ManagedInstance.SKU.Name",
	"tags":             "description.ManagedInstance.Tags",
	"title":            "description.ManagedInstance.SKU.Name",
}

func GetMssqlManagedInstanceDatabases(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetMssqlManagedInstanceDatabases")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewMssqlManagedInstanceDatabasesPaginator(essdk.BuildFilter(ctx, d.QueryContext, getMssqlManagedInstanceDatabasesFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: MssqlManagedInstanceDatabases =============================

// ==========================  START: SqlDatabase =============================

type SqlDatabase struct {
	Description   azure.SqlDatabaseDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

func (r *SqlDatabase) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SqlDatabaseDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SqlDatabaseHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  SqlDatabase   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type SqlDatabaseHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []SqlDatabaseHit  `json:"hits"`
}

type SqlDatabaseSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  SqlDatabaseHits `json:"hits"`
}

type SqlDatabasePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSqlDatabasePaginator(filters []essdk.BoolFilter, limit *int64) (SqlDatabasePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_sql_servers_databases", filters, limit)
	if err != nil {
		return SqlDatabasePaginator{}, err
	}

	p := SqlDatabasePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SqlDatabasePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SqlDatabasePaginator) NextPage(ctx context.Context) ([]SqlDatabase, error) {
	var response SqlDatabaseSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SqlDatabase
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSqlDatabaseFilters = map[string]string{
	"collation":                    "description.Database.Properties.Collation",
	"containment_state":            "description.Database.Properties.ContainmentState",
	"create_mode":                  "description.Database.Properties.CreateMode",
	"current_service_objective_id": "description.Database.Properties.CurrentServiceObjectiveName",
	"database_id":                  "description.Database.Properties.DatabaseID",
	"default_secondary_location":   "description.Database.Properties.DefaultSecondaryLocation",
	"edition":                      "description.Database.Properties.RequestedServiceObjectiveName",
	"elastic_pool_name":            "description.Database.Properties.ElasticPoolID",
	"failover_group_id":            "description.Database.Properties.FailoverGroupID",
	"id":                           "description.Database.ID",
	"kaytu_account_id":             "metadata.SourceID",
	"kind":                         "description.Database.Kind",
	"location":                     "description.Database.Location",
	"max_size_bytes":               "description.Database.Properties.MaxSizeBytes",
	"name":                         "description.Database.Name",
	"read_scale":                   "description.Database.Properties.ReadScale",
	"recommended_index":            "DatabaseProperties.RecommendedIndex",
	"recovery_services_recovery_point_resource_id": "description.Database.Properties.RecoveryServicesRecoveryPointID",
	"requested_service_objective_id":               "description.Database.Properties.RequestedServiceObjectiveName",
	"requested_service_objective_name":             "description.Database.Properties.RequestedServiceObjectiveName",
	"resource_group":                               "description.ResourceGroup",
	"retention_policy_id":                          "description.LongTermRetentionPolicy.ID",
	"retention_policy_name":                        "description.LongTermRetentionPolicy.Name",
	"retention_policy_property":                    "description.LongTermRetentionPolicy",
	"retention_policy_type":                        "description.LongTermRetentionPolicy.Type",
	"sample_name":                                  "description.Database.Properties.SampleName",
	"service_level_objective":                      "description.Database.Properties.RequestedServiceObjectiveName",
	"service_tier_advisors":                        "description.Advisors",
	"source_database_id":                           "description.Database.Properties.SourceDatabaseID",
	"status":                                       "description.Database.Properties.Status",
	"tags":                                         "description.Database.Tags",
	"title":                                        "description.Database.Name",
	"transparent_data_encryption":                  "description.TransparentDataEncryption",
	"type":                                         "description.Database.Type",
	"vulnerability_assessment_scan_records":        "description.VulnerabilityAssessmentScanRecords",
	"vulnerability_assessments":                    "description.DatabaseVulnerabilityAssessments",
	"zone_redundant":                               "description.Database.Properties.ZoneRedundant",
}

func ListSqlDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSqlDatabase")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSqlDatabasePaginator(essdk.BuildFilter(ctx, d.QueryContext, listSqlDatabaseFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSqlDatabaseFilters = map[string]string{
	"collation":                    "description.Database.Properties.Collation",
	"containment_state":            "description.Database.Properties.ContainmentState",
	"create_mode":                  "description.Database.Properties.CreateMode",
	"current_service_objective_id": "description.Database.Properties.CurrentServiceObjectiveName",
	"database_id":                  "description.Database.Properties.DatabaseID",
	"default_secondary_location":   "description.Database.Properties.DefaultSecondaryLocation",
	"edition":                      "description.Database.Properties.RequestedServiceObjectiveName",
	"elastic_pool_name":            "description.Database.Properties.ElasticPoolID",
	"failover_group_id":            "description.Database.Properties.FailoverGroupID",
	"id":                           "description.Database.ID",
	"kaytu_account_id":             "metadata.SourceID",
	"kind":                         "description.Database.Kind",
	"location":                     "description.Database.Location",
	"max_size_bytes":               "description.Database.Properties.MaxSizeBytes",
	"name":                         "description.Database.name",
	"read_scale":                   "description.Database.Properties.ReadScale",
	"recommended_index":            "DatabaseProperties.RecommendedIndex",
	"recovery_services_recovery_point_resource_id": "description.Database.Properties.RecoveryServicesRecoveryPointID",
	"requested_service_objective_id":               "description.Database.Properties.RequestedServiceObjectiveName",
	"requested_service_objective_name":             "description.Database.Properties.RequestedServiceObjectiveName",
	"resource_group":                               "description.ResourceGroup",
	"retention_policy_id":                          "description.LongTermRetentionPolicy.ID",
	"retention_policy_name":                        "description.LongTermRetentionPolicy.Name",
	"retention_policy_property":                    "description.LongTermRetentionPolicy",
	"retention_policy_type":                        "description.LongTermRetentionPolicy.Type",
	"sample_name":                                  "description.Database.Properties.SampleName",
	"service_level_objective":                      "description.Database.Properties.RequestedServiceObjectiveName",
	"service_tier_advisors":                        "description.Advisors",
	"source_database_id":                           "description.Database.Properties.SourceDatabaseID",
	"status":                                       "description.Database.Properties.Status",
	"tags":                                         "description.Database.Tags",
	"title":                                        "description.Database.Name",
	"transparent_data_encryption":                  "description.TransparentDataEncryption",
	"type":                                         "description.Database.Type",
	"vulnerability_assessment_scan_records":        "description.VulnerabilityAssessmentScanRecords",
	"vulnerability_assessments":                    "description.DatabaseVulnerabilityAssessments",
	"zone_redundant":                               "description.Database.Properties.ZoneRedundant",
}

func GetSqlDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSqlDatabase")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSqlDatabasePaginator(essdk.BuildFilter(ctx, d.QueryContext, getSqlDatabaseFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SqlDatabase =============================

// ==========================  START: SqlInstancePool =============================

type SqlInstancePool struct {
	Description   azure.SqlInstancePoolDescription `json:"description"`
	Metadata      azure.Metadata                   `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

func (r *SqlInstancePool) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SqlInstancePoolDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SqlInstancePoolHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  SqlInstancePool `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type SqlInstancePoolHits struct {
	Total essdk.SearchTotal    `json:"total"`
	Hits  []SqlInstancePoolHit `json:"hits"`
}

type SqlInstancePoolSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  SqlInstancePoolHits `json:"hits"`
}

type SqlInstancePoolPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSqlInstancePoolPaginator(filters []essdk.BoolFilter, limit *int64) (SqlInstancePoolPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_sql_instancepools", filters, limit)
	if err != nil {
		return SqlInstancePoolPaginator{}, err
	}

	p := SqlInstancePoolPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SqlInstancePoolPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SqlInstancePoolPaginator) NextPage(ctx context.Context) ([]SqlInstancePool, error) {
	var response SqlInstancePoolSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SqlInstancePool
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSqlInstancePoolFilters = map[string]string{
	"id":    "description.InstancePool.ID",
	"name":  "description.InstancePool.Name",
	"tags":  "description.InstancePool.Tags",
	"title": "description.InstancePool.Name",
}

func ListSqlInstancePool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSqlInstancePool")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSqlInstancePoolPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSqlInstancePoolFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSqlInstancePoolFilters = map[string]string{
	"id":    "description.InstancePool.ID",
	"name":  "description.InstancePool.Name",
	"tags":  "description.InstancePool.Tags",
	"title": "description.InstancePool.Name",
}

func GetSqlInstancePool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSqlInstancePool")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSqlInstancePoolPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSqlInstancePoolFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SqlInstancePool =============================

// ==========================  START: SqlServer =============================

type SqlServer struct {
	Description   azure.SqlServerDescription `json:"description"`
	Metadata      azure.Metadata             `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

func (r *SqlServer) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SqlServerDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SqlServerHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  SqlServer     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type SqlServerHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []SqlServerHit    `json:"hits"`
}

type SqlServerSearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  SqlServerHits `json:"hits"`
}

type SqlServerPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSqlServerPaginator(filters []essdk.BoolFilter, limit *int64) (SqlServerPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_sql_servers", filters, limit)
	if err != nil {
		return SqlServerPaginator{}, err
	}

	p := SqlServerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SqlServerPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SqlServerPaginator) NextPage(ctx context.Context) ([]SqlServer, error) {
	var response SqlServerSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SqlServer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSqlServerFilters = map[string]string{
	"administrator_login":             "description.Server.Properties.AdministratorLogin",
	"administrator_login_password":    "description.Server.Properties.AdministratorLoginPassword",
	"encryption_protector":            "description.EncryptionProtectors",
	"firewall_rules":                  "description.FirewallRules",
	"fully_qualified_domain_name":     "description.Server.Properties.FullyQualifiedDomainName",
	"id":                              "description.Server.ID",
	"kaytu_account_id":                "metadata.SourceID",
	"kind":                            "description.Server.Kind",
	"location":                        "description.Server.Location",
	"minimal_tls_version":             "description.Server.Properties.MinimalTLSVersion",
	"name":                            "description.Server.Name",
	"private_endpoint_connections":    "description.Server.Properties.PrivateEndpointConnections",
	"public_network_access":           "description.Server.Properties.PublicNetworkAccess",
	"resource_group":                  "description.ResourceGroup",
	"server_audit_policy":             "description.ServerBlobAuditingPolicies",
	"server_azure_ad_administrator":   "description.ServerAzureADAdministrators",
	"server_security_alert_policy":    "description.ServerSecurityAlertPolicies",
	"server_vulnerability_assessment": "description.ServerVulnerabilityAssessments",
	"state":                           "description.Server.Properties.State",
	"tags":                            "description.Server.Tags",
	"tags_src":                        "description.Server.Tags",
	"title":                           "description.Server.Name",
	"type":                            "description.Server.Type",
	"version":                         "description.Server.Properties.Version",
	"virtual_network_rules":           "description.VirtualNetworkRules",
}

func ListSqlServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSqlServer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSqlServerPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSqlServerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSqlServerFilters = map[string]string{
	"administrator_login":             "description.Server.Properties.AdministratorLogin",
	"administrator_login_password":    "description.Server.Properties.AdministratorLoginPassword",
	"encryption_protector":            "description.EncryptionProtectors",
	"firewall_rules":                  "description.FirewallRules",
	"fully_qualified_domain_name":     "description.Server.Properties.FullyQualifiedDomainName",
	"id":                              "description.Server.ID",
	"kaytu_account_id":                "metadata.SourceID",
	"kind":                            "description.Server.Kind",
	"location":                        "description.Server.Location",
	"minimal_tls_version":             "description.Server.Properties.MinimalTLSVersion",
	"name":                            "description.Server.name",
	"private_endpoint_connections":    "description.Server.Properties.PrivateEndpointConnections",
	"public_network_access":           "description.Server.Properties.PublicNetworkAccess",
	"resource_group":                  "description.ResourceGroup",
	"server_audit_policy":             "description.ServerBlobAuditingPolicies",
	"server_azure_ad_administrator":   "description.ServerAzureADAdministrators",
	"server_security_alert_policy":    "description.ServerSecurityAlertPolicies",
	"server_vulnerability_assessment": "description.ServerVulnerabilityAssessments",
	"state":                           "description.Server.Properties.State",
	"tags":                            "description.Server.Tags",
	"tags_src":                        "description.Server.Tags",
	"title":                           "description.Server.Name",
	"type":                            "description.Server.Type",
	"version":                         "description.Server.Properties.Version",
	"virtual_network_rules":           "description.VirtualNetworkRules",
}

func GetSqlServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSqlServer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSqlServerPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSqlServerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SqlServer =============================

// ==========================  START: SqlServerJobAgent =============================

type SqlServerJobAgent struct {
	Description   azure.SqlServerJobAgentDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

func (r *SqlServerJobAgent) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SqlServerJobAgentDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SqlServerJobAgentHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  SqlServerJobAgent `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type SqlServerJobAgentHits struct {
	Total essdk.SearchTotal      `json:"total"`
	Hits  []SqlServerJobAgentHit `json:"hits"`
}

type SqlServerJobAgentSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  SqlServerJobAgentHits `json:"hits"`
}

type SqlServerJobAgentPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSqlServerJobAgentPaginator(filters []essdk.BoolFilter, limit *int64) (SqlServerJobAgentPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_sql_servers_jobagents", filters, limit)
	if err != nil {
		return SqlServerJobAgentPaginator{}, err
	}

	p := SqlServerJobAgentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SqlServerJobAgentPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SqlServerJobAgentPaginator) NextPage(ctx context.Context) ([]SqlServerJobAgent, error) {
	var response SqlServerJobAgentSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SqlServerJobAgent
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSqlServerJobAgentFilters = map[string]string{
	"id":               "description.JobAgent.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.JobAgent.Name",
	"tags":             "description.JobAgent.Tags",
	"title":            "description.JobAgent.Name",
}

func ListSqlServerJobAgent(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSqlServerJobAgent")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSqlServerJobAgentPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSqlServerJobAgentFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSqlServerJobAgentFilters = map[string]string{
	"id":               "description.JobAgent.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.JobAgent.Name",
	"tags":             "description.JobAgent.Tags",
	"title":            "description.JobAgent.Name",
}

func GetSqlServerJobAgent(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSqlServerJobAgent")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSqlServerJobAgentPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSqlServerJobAgentFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SqlServerJobAgent =============================

// ==========================  START: SqlVirtualClusters =============================

type SqlVirtualClusters struct {
	Description   azure.SqlVirtualClustersDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

func (r *SqlVirtualClusters) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SqlVirtualClustersDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SqlVirtualClustersHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  SqlVirtualClusters `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type SqlVirtualClustersHits struct {
	Total essdk.SearchTotal       `json:"total"`
	Hits  []SqlVirtualClustersHit `json:"hits"`
}

type SqlVirtualClustersSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  SqlVirtualClustersHits `json:"hits"`
}

type SqlVirtualClustersPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSqlVirtualClustersPaginator(filters []essdk.BoolFilter, limit *int64) (SqlVirtualClustersPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_sql_virtualclusters", filters, limit)
	if err != nil {
		return SqlVirtualClustersPaginator{}, err
	}

	p := SqlVirtualClustersPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SqlVirtualClustersPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SqlVirtualClustersPaginator) NextPage(ctx context.Context) ([]SqlVirtualClusters, error) {
	var response SqlVirtualClustersSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SqlVirtualClusters
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSqlVirtualClustersFilters = map[string]string{
	"id":               "description.VirtualClusters.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.VirtualClusters.Name",
	"tags":             "description.VirtualClusters.Tags",
	"title":            "description.VirtualClusters.Name",
}

func ListSqlVirtualClusters(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSqlVirtualClusters")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSqlVirtualClustersPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSqlVirtualClustersFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSqlVirtualClustersFilters = map[string]string{
	"id":               "description.VirtualClusters.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.VirtualClusters.Name",
	"tags":             "description.VirtualClusters.Tags",
	"title":            "description.VirtualClusters.Name",
}

func GetSqlVirtualClusters(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSqlVirtualClusters")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSqlVirtualClustersPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSqlVirtualClustersFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SqlVirtualClusters =============================

// ==========================  START: SqlServerElasticPool =============================

type SqlServerElasticPool struct {
	Description   azure.SqlServerElasticPoolDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

func (r *SqlServerElasticPool) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SqlServerElasticPoolDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SqlServerElasticPoolHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  SqlServerElasticPool `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type SqlServerElasticPoolHits struct {
	Total essdk.SearchTotal         `json:"total"`
	Hits  []SqlServerElasticPoolHit `json:"hits"`
}

type SqlServerElasticPoolSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  SqlServerElasticPoolHits `json:"hits"`
}

type SqlServerElasticPoolPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSqlServerElasticPoolPaginator(filters []essdk.BoolFilter, limit *int64) (SqlServerElasticPoolPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_sql_servers_elasticpools", filters, limit)
	if err != nil {
		return SqlServerElasticPoolPaginator{}, err
	}

	p := SqlServerElasticPoolPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SqlServerElasticPoolPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SqlServerElasticPoolPaginator) NextPage(ctx context.Context) ([]SqlServerElasticPool, error) {
	var response SqlServerElasticPoolSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SqlServerElasticPool
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSqlServerElasticPoolFilters = map[string]string{
	"creation_date":    "description.Pool.Properties.CreationDate",
	"database_dtu_max": "description.Pool.Properties.PerDatabaseSettings.MaxCapacity",
	"database_dtu_min": "description.Pool.Properties.PerDatabaseSettings.MinCapacity",
	"dtu":              "description.TotalDTU",
	"edition":          "description.Pool.SKU.Tier",
	"id":               "description.Pool.ID",
	"kaytu_account_id": "metadata.SourceID",
	"kind":             "description.Pool.Kind",
	"name":             "description.Pool.Name",
	"resource_group":   "description.ResourceGroup",
	"server_name":      "description.ServerName",
	"state":            "description.Pool.Properties.State",
	"storage_mb":       "description.Pool.Properties.MaxSizeBytes",
	"tags":             "description.Pool.Tags",
	"title":            "description.Pool.Name",
	"type":             "description.Pool.Type",
	"zone_redundant":   "description.Pool.Properties.ZoneRedundant",
}

func ListSqlServerElasticPool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSqlServerElasticPool")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSqlServerElasticPoolPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSqlServerElasticPoolFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSqlServerElasticPoolFilters = map[string]string{
	"creation_date":    "description.Pool.Properties.CreationDate",
	"database_dtu_max": "description.Pool.Properties.PerDatabaseSettings.MaxCapacity",
	"database_dtu_min": "description.Pool.Properties.PerDatabaseSettings.MinCapacity",
	"dtu":              "description.TotalDTU",
	"edition":          "description.Pool.SKU.Tier",
	"id":               "description.Pool.ID",
	"kaytu_account_id": "metadata.SourceID",
	"kind":             "description.Pool.Kind",
	"name":             "description.Pool.Name",
	"resource_group":   "description.ResourceGroup",
	"server_name":      "description.ServerName",
	"state":            "description.Pool.Properties.State",
	"storage_mb":       "description.Pool.Properties.MaxSizeBytes",
	"tags":             "description.Pool.Tags",
	"title":            "description.Pool.Name",
	"type":             "description.Pool.Type",
	"zone_redundant":   "description.Pool.Properties.ZoneRedundant",
}

func GetSqlServerElasticPool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSqlServerElasticPool")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSqlServerElasticPoolPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSqlServerElasticPoolFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SqlServerElasticPool =============================

// ==========================  START: SqlServerVirtualMachine =============================

type SqlServerVirtualMachine struct {
	Description   azure.SqlServerVirtualMachineDescription `json:"description"`
	Metadata      azure.Metadata                           `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

func (r *SqlServerVirtualMachine) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SqlServerVirtualMachineDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SqlServerVirtualMachineHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  SqlServerVirtualMachine `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type SqlServerVirtualMachineHits struct {
	Total essdk.SearchTotal            `json:"total"`
	Hits  []SqlServerVirtualMachineHit `json:"hits"`
}

type SqlServerVirtualMachineSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  SqlServerVirtualMachineHits `json:"hits"`
}

type SqlServerVirtualMachinePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSqlServerVirtualMachinePaginator(filters []essdk.BoolFilter, limit *int64) (SqlServerVirtualMachinePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_sqlvirtualmachine_sqlvirtualmachines", filters, limit)
	if err != nil {
		return SqlServerVirtualMachinePaginator{}, err
	}

	p := SqlServerVirtualMachinePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SqlServerVirtualMachinePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SqlServerVirtualMachinePaginator) NextPage(ctx context.Context) ([]SqlServerVirtualMachine, error) {
	var response SqlServerVirtualMachineSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SqlServerVirtualMachine
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSqlServerVirtualMachineFilters = map[string]string{
	"auto_backup_settings":          "description.VirtualMachine.Properties.AutoBackupSettings",
	"auto_patching_settings":        "description.VirtualMachine.Properties.AutoPatchingSettings",
	"id":                            "description.VirtualMachine.ID",
	"identity":                      "description.VirtualMachine.Identity",
	"kaytu_account_id":              "metadata.SourceID",
	"key_vault_credential_settings": "description.VirtualMachine.Properties.KeyVaultCredentialSettings",
	"name":                          "description.VirtualMachine.Name",
	"provisioning_state":            "description.VirtualMachine.Properties.ProvisioningState",
	"resource_group":                "description.ResourceGroup",
	"server_configurations_management_settings": "description.VirtualMachine.Properties.ServerConfigurationsManagementSettings",
	"sql_image_offer":                       "description.VirtualMachine.Properties.SQLImageOffer",
	"sql_image_sku":                         "description.VirtualMachine.Properties.SQLImageSKU",
	"sql_management":                        "description.VirtualMachine.Properties.SQLManagement",
	"sql_server_license_type":               "description.VirtualMachine.Properties.SQLServerLicenseType",
	"sql_virtual_machine_group_resource_id": "description.VirtualMachine.Properties.SQLVirtualMachineGroupResourceID",
	"storage_configuration_settings":        "description.VirtualMachine.Properties.StorageConfigurationSettings",
	"tags":                                  "description.VirtualMachine.Tags",
	"title":                                 "description.VirtualMachine.Name",
	"type":                                  "description.VirtualMachine.Type",
	"virtual_machine_resource_id":           "description.VirtualMachine.Properties.VirtualMachineResourceID",
	"wsfc_domain_credentials":               "description.VirtualMachine.Properties.WsfcDomainCredentials",
}

func ListSqlServerVirtualMachine(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSqlServerVirtualMachine")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSqlServerVirtualMachinePaginator(essdk.BuildFilter(ctx, d.QueryContext, listSqlServerVirtualMachineFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSqlServerVirtualMachineFilters = map[string]string{
	"auto_backup_settings":          "description.VirtualMachine.Properties.AutoBackupSettings",
	"auto_patching_settings":        "description.VirtualMachine.Properties.AutoPatchingSettings",
	"id":                            "description.VirtualMachine.ID",
	"identity":                      "description.VirtualMachine.Identity",
	"kaytu_account_id":              "metadata.SourceID",
	"key_vault_credential_settings": "description.VirtualMachine.Properties.KeyVaultCredentialSettings",
	"name":                          "description.VirtualMachine.Name",
	"provisioning_state":            "description.VirtualMachine.Properties.ProvisioningState",
	"resource_group":                "description.ResourceGroup",
	"server_configurations_management_settings": "description.VirtualMachine.Properties.ServerConfigurationsManagementSettings",
	"sql_image_offer":                       "description.VirtualMachine.Properties.SQLImageOffer",
	"sql_image_sku":                         "description.VirtualMachine.Properties.SQLImageSKU",
	"sql_management":                        "description.VirtualMachine.Properties.SQLManagement",
	"sql_server_license_type":               "description.VirtualMachine.Properties.SQLServerLicenseType",
	"sql_virtual_machine_group_resource_id": "description.VirtualMachine.Properties.SQLVirtualMachineGroupResourceID",
	"storage_configuration_settings":        "description.VirtualMachine.Properties.StorageConfigurationSettings",
	"tags":                                  "description.VirtualMachine.Tags",
	"title":                                 "description.VirtualMachine.Name",
	"type":                                  "description.VirtualMachine.Type",
	"virtual_machine_resource_id":           "description.VirtualMachine.Properties.VirtualMachineResourceID",
	"wsfc_domain_credentials":               "description.VirtualMachine.Properties.WsfcDomainCredentials",
}

func GetSqlServerVirtualMachine(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSqlServerVirtualMachine")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSqlServerVirtualMachinePaginator(essdk.BuildFilter(ctx, d.QueryContext, getSqlServerVirtualMachineFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SqlServerVirtualMachine =============================

// ==========================  START: SqlServerVirtualMachineGroup =============================

type SqlServerVirtualMachineGroup struct {
	Description   azure.SqlServerVirtualMachineGroupDescription `json:"description"`
	Metadata      azure.Metadata                                `json:"metadata"`
	ResourceJobID int                                           `json:"resource_job_id"`
	SourceJobID   int                                           `json:"source_job_id"`
	ResourceType  string                                        `json:"resource_type"`
	SourceType    string                                        `json:"source_type"`
	ID            string                                        `json:"id"`
	ARN           string                                        `json:"arn"`
	SourceID      string                                        `json:"source_id"`
}

func (r *SqlServerVirtualMachineGroup) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SqlServerVirtualMachineGroupDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SqlServerVirtualMachineGroupHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  SqlServerVirtualMachineGroup `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type SqlServerVirtualMachineGroupHits struct {
	Total essdk.SearchTotal                 `json:"total"`
	Hits  []SqlServerVirtualMachineGroupHit `json:"hits"`
}

type SqlServerVirtualMachineGroupSearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  SqlServerVirtualMachineGroupHits `json:"hits"`
}

type SqlServerVirtualMachineGroupPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSqlServerVirtualMachineGroupPaginator(filters []essdk.BoolFilter, limit *int64) (SqlServerVirtualMachineGroupPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_sqlvirtualmachine_sqlvirtualmachinegroups", filters, limit)
	if err != nil {
		return SqlServerVirtualMachineGroupPaginator{}, err
	}

	p := SqlServerVirtualMachineGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SqlServerVirtualMachineGroupPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SqlServerVirtualMachineGroupPaginator) NextPage(ctx context.Context) ([]SqlServerVirtualMachineGroup, error) {
	var response SqlServerVirtualMachineGroupSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SqlServerVirtualMachineGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSqlServerVirtualMachineGroupFilters = map[string]string{
	"id":               "description.Group.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Group.Name",
	"tags":             "description.Group.Tags",
	"title":            "description.Group.Name",
}

func ListSqlServerVirtualMachineGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSqlServerVirtualMachineGroup")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSqlServerVirtualMachineGroupPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSqlServerVirtualMachineGroupFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSqlServerVirtualMachineGroupFilters = map[string]string{
	"id":               "description.Group.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Group.Name",
	"tags":             "description.Group.Tags",
	"title":            "description.Group.Name",
}

func GetSqlServerVirtualMachineGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSqlServerVirtualMachineGroup")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSqlServerVirtualMachineGroupPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSqlServerVirtualMachineGroupFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SqlServerVirtualMachineGroup =============================

// ==========================  START: SqlServerFlexibleServer =============================

type SqlServerFlexibleServer struct {
	Description   azure.SqlServerFlexibleServerDescription `json:"description"`
	Metadata      azure.Metadata                           `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

func (r *SqlServerFlexibleServer) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.SqlServerFlexibleServerDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type SqlServerFlexibleServerHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  SqlServerFlexibleServer `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type SqlServerFlexibleServerHits struct {
	Total essdk.SearchTotal            `json:"total"`
	Hits  []SqlServerFlexibleServerHit `json:"hits"`
}

type SqlServerFlexibleServerSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  SqlServerFlexibleServerHits `json:"hits"`
}

type SqlServerFlexibleServerPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewSqlServerFlexibleServerPaginator(filters []essdk.BoolFilter, limit *int64) (SqlServerFlexibleServerPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_sql_flexibleservers", filters, limit)
	if err != nil {
		return SqlServerFlexibleServerPaginator{}, err
	}

	p := SqlServerFlexibleServerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SqlServerFlexibleServerPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p SqlServerFlexibleServerPaginator) NextPage(ctx context.Context) ([]SqlServerFlexibleServer, error) {
	var response SqlServerFlexibleServerSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SqlServerFlexibleServer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listSqlServerFlexibleServerFilters = map[string]string{
	"administrator_login":            "description.FlexibleServer.Properties.AdministratorLogin",
	"availability_zone":              "description.FlexibleServer.Properties.AvailabilityZone",
	"backup_retention_days":          "description.FlexibleServer.Properties.Backup.BackupRetentionDays",
	"create_mode":                    "description.FlexibleServer.Properties.CreateMode",
	"flexible_server_configurations": "description.FlexibleServer.Location",
	"fully_qualified_domain_name":    "description.FlexibleServer.Properties.FullyQualifiedDomainName",
	"geo_redundant_backup":           "description.FlexibleServer.Properties.Backup.GeoRedundantBackup",
	"high_availability":              "description.FlexibleServer.Properties.HighAvailability",
	"id":                             "description.FlexibleServer.ID",
	"kaytu_account_id":               "metadata.SourceID",
	"location":                       "description.FlexibleServer.Location",
	"maintenance_window":             "description.FlexibleServer.Properties.MaintenanceWindow",
	"name":                           "description.FlexibleServer.Name",
	"network":                        "description.FlexibleServer.Properties.Network",
	"public_network_access":          "description.FlexibleServer.Properties.Network.PublicNetworkAccess",
	"replica_capacity":               "description.FlexibleServer.Properties.ReplicaCapacity",
	"replication_role":               "description.FlexibleServer.Properties.ReplicationRole",
	"resource_group":                 "description.ResourceGroup",
	"restore_point_in_time":          "description.FlexibleServer.Properties.RestorePointInTime",
	"sku_name":                       "description.FlexibleServer.SKU.Name",
	"sku_tier":                       "description.FlexibleServer.SKU.Tier",
	"source_server_resource_id":      "description.FlexibleServer.Properties.SourceServerResourceID",
	"state":                          "description.FlexibleServer.Properties.State",
	"storage_auto_grow":              "description.FlexibleServer.Properties.Storage.AutoGrow",
	"storage_iops":                   "description.FlexibleServer.Properties.Storage.Iops",
	"storage_size_gb":                "description.FlexibleServer.Properties.Storage.StorageSizeGB",
	"storage_sku":                    "description.FlexibleServer.Properties.Storage.StorageSKU",
	"system_data":                    "description.FlexibleServer.SystemData",
	"tags":                           "description.FlexibleServer.Tags",
	"title":                          "description.FlexibleServer.Name",
	"type":                           "description.FlexibleServer.Type",
	"version":                        "description.FlexibleServer.Properties.Version",
}

func ListSqlServerFlexibleServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSqlServerFlexibleServer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewSqlServerFlexibleServerPaginator(essdk.BuildFilter(ctx, d.QueryContext, listSqlServerFlexibleServerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSqlServerFlexibleServerFilters = map[string]string{
	"administrator_login":            "description.FlexibleServer.Properties.AdministratorLogin",
	"availability_zone":              "description.FlexibleServer.Properties.AvailabilityZone",
	"backup_retention_days":          "description.FlexibleServer.Properties.Backup.BackupRetentionDays",
	"create_mode":                    "description.FlexibleServer.Properties.CreateMode",
	"flexible_server_configurations": "description.FlexibleServer.Location",
	"fully_qualified_domain_name":    "description.FlexibleServer.Properties.FullyQualifiedDomainName",
	"geo_redundant_backup":           "description.FlexibleServer.Properties.Backup.GeoRedundantBackup",
	"high_availability":              "description.FlexibleServer.Properties.HighAvailability",
	"id":                             "description.FlexibleServer.ID",
	"kaytu_account_id":               "metadata.SourceID",
	"location":                       "description.FlexibleServer.Location",
	"maintenance_window":             "description.FlexibleServer.Properties.MaintenanceWindow",
	"name":                           "description.FlexibleServer.Name",
	"network":                        "description.FlexibleServer.Properties.Network",
	"public_network_access":          "description.FlexibleServer.Properties.Network.PublicNetworkAccess",
	"replica_capacity":               "description.FlexibleServer.Properties.ReplicaCapacity",
	"replication_role":               "description.FlexibleServer.Properties.ReplicationRole",
	"resource_group":                 "description.ResourceGroup",
	"restore_point_in_time":          "description.FlexibleServer.Properties.RestorePointInTime",
	"sku_name":                       "description.FlexibleServer.SKU.Name",
	"sku_tier":                       "description.FlexibleServer.SKU.Tier",
	"source_server_resource_id":      "description.FlexibleServer.Properties.SourceServerResourceID",
	"state":                          "description.FlexibleServer.Properties.State",
	"storage_auto_grow":              "description.FlexibleServer.Properties.Storage.AutoGrow",
	"storage_iops":                   "description.FlexibleServer.Properties.Storage.Iops",
	"storage_size_gb":                "description.FlexibleServer.Properties.Storage.StorageSizeGB",
	"storage_sku":                    "description.FlexibleServer.Properties.Storage.StorageSKU",
	"system_data":                    "description.FlexibleServer.SystemData",
	"tags":                           "description.FlexibleServer.Tags",
	"title":                          "description.FlexibleServer.Name",
	"type":                           "description.FlexibleServer.Type",
	"version":                        "description.FlexibleServer.Properties.Version",
}

func GetSqlServerFlexibleServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSqlServerFlexibleServer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewSqlServerFlexibleServerPaginator(essdk.BuildFilter(ctx, d.QueryContext, getSqlServerFlexibleServerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SqlServerFlexibleServer =============================

// ==========================  START: StorageAccount =============================

type StorageAccount struct {
	Description   azure.StorageAccountDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

func (r *StorageAccount) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.StorageAccountDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type StorageAccountHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  StorageAccount `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type StorageAccountHits struct {
	Total essdk.SearchTotal   `json:"total"`
	Hits  []StorageAccountHit `json:"hits"`
}

type StorageAccountSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  StorageAccountHits `json:"hits"`
}

type StorageAccountPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewStorageAccountPaginator(filters []essdk.BoolFilter, limit *int64) (StorageAccountPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_storage_storageaccounts", filters, limit)
	if err != nil {
		return StorageAccountPaginator{}, err
	}

	p := StorageAccountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageAccountPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p StorageAccountPaginator) NextPage(ctx context.Context) ([]StorageAccount, error) {
	var response StorageAccountSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageAccount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listStorageAccountFilters = map[string]string{
	"access_tier":                                            "description.Account.Properties.AccessTier",
	"allow_blob_public_access":                               "description.Account.Properties.AllowBlobPublicAccess",
	"blob_change_feed_enabled":                               "description.BlobServiceProperties.BlobServiceProperties.ChangeFeed.Enabled",
	"blob_container_soft_delete_enabled":                     "description.BlobServiceProperties.BlobServiceProperties.ContainerDeleteRetentionPolicy.Enabled",
	"blob_container_soft_delete_retention_days":              "description.BlobServiceProperties.BlobServiceProperties.ContainerDeleteRetentionPolicy.Days",
	"blob_restore_policy_days":                               "description.BlobServiceProperties.BlobServiceProperties.RestorePolicy.Days",
	"blob_restore_policy_enabled":                            "description.BlobServiceProperties.BlobServiceProperties.RestorePolicy.Enabled",
	"blob_service_logging":                                   "description.Logging",
	"blob_soft_delete_enabled":                               "description.BlobServiceProperties.BlobServiceProperties.ContainerDeleteRetentionPolicy.Enabled",
	"blob_soft_delete_retention_days":                        "description.BlobServiceProperties.BlobServiceProperties.ContainerDeleteRetentionPolicy.Days",
	"blob_versioning_enabled":                                "description.BlobServiceProperties.BlobServiceProperties.IsVersioningEnabled",
	"enable_https_traffic_only":                              "description.Account.Properties.EnableHTTPSTrafficOnly",
	"encryption_key_source":                                  "description.Account.Properties.Encryption.KeySource",
	"encryption_key_vault_properties_key_current_version_id": "description.Account.Properties.Encryption.KeyVaultProperties.CurrentVersionedKeyIdentifier",
	"encryption_key_vault_properties_key_name":               "description.Account.Properties.Encryption.KeyVaultProperties.KeyName",
	"encryption_key_vault_properties_key_vault_uri":          "description.Account.Properties.Encryption.KeyVaultProperties.KeyVaultURI",
	"encryption_key_vault_properties_key_version":            "description.Account.Properties.Encryption.KeyVaultProperties.KeyVersion",
	"encryption_services":                                    "description.Account.Properties.Encryption.Services",
	"failover_in_progress":                                   "description.Account.Properties.FailoverInProgress",
	"file_soft_delete_enabled":                               "description.FileServiceProperties.FileServiceProperties.ShareDeleteRetentionPolicy.Enabled",
	"file_soft_delete_retention_days":                        "description.FileServiceProperties.FileServiceProperties.ShareDeleteRetentionPolicy.Days",
	"id":                                                     "description.Account.ID",
	"is_hns_enabled":                                         "description.Account.Properties.IsHnsEnabled",
	"kaytu_account_id":                                       "metadata.SourceID",
	"kind":                                                   "description.Account.Kind",
	"minimum_tls_version":                                    "description.Account.Properties.MinimumTLSVersion",
	"name":                                                   "description.Account.Name",
	"network_ip_rules":                                       "description.Account.Properties.NetworkRuleSet.IPRules",
	"network_rule_bypass":                                    "description.Account.Properties.NetworkRuleSet.Bypass",
	"network_rule_default_action":                            "description.Account.Properties.NetworkRuleSet.DefaultAction",
	"primary_blob_endpoint":                                  "description.Account.Properties.PrimaryEndpoints.Blob",
	"primary_dfs_endpoint":                                   "description.Account.Properties.PrimaryEndpoints.Dfs",
	"primary_file_endpoint":                                  "description.Account.Properties.PrimaryEndpoints.File",
	"primary_location":                                       "description.Account.Properties.PrimaryLocation",
	"primary_queue_endpoint":                                 "description.Account.Properties.PrimaryEndpoints.Queue",
	"primary_table_endpoint":                                 "description.Account.Properties.PrimaryEndpoints.Table",
	"primary_web_endpoint":                                   "description.Account.Properties.PrimaryEndpoints.Web",
	"private_endpoint_connections":                           "description.Account.Properties.PrivateEndpointConnections",
	"provisioning_state":                                     "description.Account.Properties.ProvisioningState",
	"queue_logging_delete":                                   "description.StorageServiceProperties.Logging.Delete",
	"queue_logging_read":                                     "description.StorageServiceProperties.Logging.Read",
	"queue_logging_retention_days":                           "description.Logging.RetentionPolicy.Days",
	"queue_logging_retention_enabled":                        "description.Logging.RetentionPolicy.Enabled",
	"queue_logging_version":                                  "description.StorageServiceProperties.Logging.Version",
	"queue_logging_write":                                    "description.StorageServiceProperties.Logging.Write",
	"require_infrastructure_encryption":                      "description.Account.Properties.Encryption.RequireInfrastructureEncryption",
	"secondary_location":                                     "description.Account.Properties.SecondaryLocation",
	"sku_name":                                               "description.Account.SKU.Name",
	"sku_tier":                                               "description.Account.SKU.Tier",
	"tags":                                                   "description.Account.Tags",
	"title":                                                  "description.Account.Name",
	"type":                                                   "description.Account.Type",
	"virtual_network_rules":                                  "description.Account.Properties.NetworkRuleSet.VirtualNetworkRules",
}

func ListStorageAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewStorageAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, listStorageAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageAccountFilters = map[string]string{
	"access_tier":                                            "description.Account.Properties.AccessTier",
	"allow_blob_public_access":                               "description.Account.Properties.AllowBlobPublicAccess",
	"blob_change_feed_enabled":                               "description.BlobServiceProperties.BlobServiceProperties.ChangeFeed.Enabled",
	"blob_container_soft_delete_enabled":                     "description.BlobServiceProperties.BlobServiceProperties.ContainerDeleteRetentionPolicy.Enabled",
	"blob_container_soft_delete_retention_days":              "description.BlobServiceProperties.BlobServiceProperties.ContainerDeleteRetentionPolicy.Days",
	"blob_restore_policy_days":                               "description.BlobServiceProperties.BlobServiceProperties.RestorePolicy.Days",
	"blob_restore_policy_enabled":                            "description.BlobServiceProperties.BlobServiceProperties.RestorePolicy.Enabled",
	"blob_service_logging":                                   "description.Logging",
	"blob_soft_delete_enabled":                               "description.BlobServiceProperties.BlobServiceProperties.ContainerDeleteRetentionPolicy.Enabled",
	"blob_soft_delete_retention_days":                        "description.BlobServiceProperties.BlobServiceProperties.ContainerDeleteRetentionPolicy.Days",
	"blob_versioning_enabled":                                "description.BlobServiceProperties.BlobServiceProperties.IsVersioningEnabled",
	"enable_https_traffic_only":                              "description.Account.Properties.EnableHTTPSTrafficOnly",
	"encryption_key_source":                                  "description.Account.Properties.Encryption.KeySource",
	"encryption_key_vault_properties_key_current_version_id": "description.Account.Properties.Encryption.KeyVaultProperties.CurrentVersionedKeyIdentifier",
	"encryption_key_vault_properties_key_name":               "description.Account.Properties.Encryption.KeyVaultProperties.KeyName",
	"encryption_key_vault_properties_key_vault_uri":          "description.Account.Properties.Encryption.KeyVaultProperties.KeyVaultURI",
	"encryption_key_vault_properties_key_version":            "description.Account.Properties.Encryption.KeyVaultProperties.KeyVersion",
	"encryption_services":                                    "description.Account.Properties.Encryption.Services",
	"failover_in_progress":                                   "description.Account.Properties.FailoverInProgress",
	"file_soft_delete_enabled":                               "description.FileServiceProperties.FileServiceProperties.ShareDeleteRetentionPolicy.Enabled",
	"file_soft_delete_retention_days":                        "description.FileServiceProperties.FileServiceProperties.ShareDeleteRetentionPolicy.Days",
	"id":                                                     "description.Account.ID",
	"is_hns_enabled":                                         "description.Account.Properties.IsHnsEnabled",
	"kaytu_account_id":                                       "metadata.SourceID",
	"kind":                                                   "description.Account.Kind",
	"minimum_tls_version":                                    "description.Account.Properties.MinimumTLSVersion",
	"name":                                                   "description.Account.name",
	"network_ip_rules":                                       "description.Account.Properties.NetworkRuleSet.IPRules",
	"network_rule_bypass":                                    "description.Account.Properties.NetworkRuleSet.Bypass",
	"network_rule_default_action":                            "description.Account.Properties.NetworkRuleSet.DefaultAction",
	"primary_blob_endpoint":                                  "description.Account.Properties.PrimaryEndpoints.Blob",
	"primary_dfs_endpoint":                                   "description.Account.Properties.PrimaryEndpoints.Dfs",
	"primary_file_endpoint":                                  "description.Account.Properties.PrimaryEndpoints.File",
	"primary_location":                                       "description.Account.Properties.PrimaryLocation",
	"primary_queue_endpoint":                                 "description.Account.Properties.PrimaryEndpoints.Queue",
	"primary_table_endpoint":                                 "description.Account.Properties.PrimaryEndpoints.Table",
	"primary_web_endpoint":                                   "description.Account.Properties.PrimaryEndpoints.Web",
	"private_endpoint_connections":                           "description.Account.Properties.PrivateEndpointConnections",
	"provisioning_state":                                     "description.Account.Properties.ProvisioningState",
	"queue_logging_delete":                                   "description.StorageServiceProperties.Logging.Delete",
	"queue_logging_read":                                     "description.StorageServiceProperties.Logging.Read",
	"queue_logging_retention_days":                           "description.Logging.RetentionPolicy.Days",
	"queue_logging_retention_enabled":                        "description.Logging.RetentionPolicy.Enabled",
	"queue_logging_version":                                  "description.StorageServiceProperties.Logging.Version",
	"queue_logging_write":                                    "description.StorageServiceProperties.Logging.Write",
	"require_infrastructure_encryption":                      "description.Account.Properties.Encryption.RequireInfrastructureEncryption",
	"resource_group":                                         "description.ResourceGroup",
	"secondary_location":                                     "description.Account.Properties.SecondaryLocation",
	"sku_name":                                               "description.Account.SKU.Name",
	"sku_tier":                                               "description.Account.SKU.Tier",
	"tags":                                                   "description.Account.Tags",
	"title":                                                  "description.Account.Name",
	"type":                                                   "description.Account.Type",
	"virtual_network_rules":                                  "description.Account.Properties.NetworkRuleSet.VirtualNetworkRules",
}

func GetStorageAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewStorageAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, getStorageAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageAccount =============================

// ==========================  START: RecoveryServicesVault =============================

type RecoveryServicesVault struct {
	Description   azure.RecoveryServicesVaultDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

func (r *RecoveryServicesVault) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.RecoveryServicesVaultDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type RecoveryServicesVaultHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  RecoveryServicesVault `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type RecoveryServicesVaultHits struct {
	Total essdk.SearchTotal          `json:"total"`
	Hits  []RecoveryServicesVaultHit `json:"hits"`
}

type RecoveryServicesVaultSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  RecoveryServicesVaultHits `json:"hits"`
}

type RecoveryServicesVaultPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewRecoveryServicesVaultPaginator(filters []essdk.BoolFilter, limit *int64) (RecoveryServicesVaultPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_recoveryservices_vaults", filters, limit)
	if err != nil {
		return RecoveryServicesVaultPaginator{}, err
	}

	p := RecoveryServicesVaultPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RecoveryServicesVaultPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p RecoveryServicesVaultPaginator) NextPage(ctx context.Context) ([]RecoveryServicesVault, error) {
	var response RecoveryServicesVaultSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RecoveryServicesVault
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listRecoveryServicesVaultFilters = map[string]string{
	"diagnostic_settings":               "description.DiagnosticSettingsResource",
	"etag":                              "description.Vault.Etag",
	"id":                                "description.Vault.ID",
	"identity":                          "description.Vault.Identity",
	"kaytu_account_id":                  "metadata.SourceID",
	"name":                              "description.Vault.Name",
	"private_endpoint_connections":      "description.Vault.Properties.PrivateEndpointConnections",
	"private_endpoint_state_for_backup": "description.Vault.Properties.PrivateEndpointStateForBackup",
	"private_endpoint_state_for_site_recovery": "description.Vault.Properties.PrivateEndpointStateForSiteRecovery",
	"provisioning_state":                       "description.Vault.Properties.ProvisioningState",
	"resource_group":                           "description.ResourceGroup",
	"sku_name":                                 "description.Vault.SKU.Name",
	"tags":                                     "description.Vault.Tags",
	"title":                                    "description.Vault.Name",
	"type":                                     "description.Vault.Type",
	"upgrade_details":                          "description.Vault.Properties.UpgradeDetails",
}

func ListRecoveryServicesVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRecoveryServicesVault")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewRecoveryServicesVaultPaginator(essdk.BuildFilter(ctx, d.QueryContext, listRecoveryServicesVaultFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRecoveryServicesVaultFilters = map[string]string{
	"diagnostic_settings":               "description.DiagnosticSettingsResource",
	"etag":                              "description.Vault.Etag",
	"id":                                "description.Vault.ID",
	"identity":                          "description.Vault.Identity",
	"kaytu_account_id":                  "metadata.SourceID",
	"name":                              "description.Vault.Name",
	"private_endpoint_connections":      "description.Vault.Properties.PrivateEndpointConnections",
	"private_endpoint_state_for_backup": "description.Vault.Properties.PrivateEndpointStateForBackup",
	"private_endpoint_state_for_site_recovery": "description.Vault.Properties.PrivateEndpointStateForSiteRecovery",
	"provisioning_state":                       "description.Vault.Properties.ProvisioningState",
	"resource_group":                           "description.ResourceGroup",
	"sku_name":                                 "description.Vault.SKU.Name",
	"tags":                                     "description.Vault.Tags",
	"title":                                    "description.Vault.Name",
	"type":                                     "description.Vault.Type",
	"upgrade_details":                          "description.Vault.Properties.UpgradeDetails",
}

func GetRecoveryServicesVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRecoveryServicesVault")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewRecoveryServicesVaultPaginator(essdk.BuildFilter(ctx, d.QueryContext, getRecoveryServicesVaultFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RecoveryServicesVault =============================

// ==========================  START: HybridKubernetesConnectedCluster =============================

type HybridKubernetesConnectedCluster struct {
	Description   azure.HybridKubernetesConnectedClusterDescription `json:"description"`
	Metadata      azure.Metadata                                    `json:"metadata"`
	ResourceJobID int                                               `json:"resource_job_id"`
	SourceJobID   int                                               `json:"source_job_id"`
	ResourceType  string                                            `json:"resource_type"`
	SourceType    string                                            `json:"source_type"`
	ID            string                                            `json:"id"`
	ARN           string                                            `json:"arn"`
	SourceID      string                                            `json:"source_id"`
}

func (r *HybridKubernetesConnectedCluster) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.HybridKubernetesConnectedClusterDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type HybridKubernetesConnectedClusterHit struct {
	ID      string                           `json:"_id"`
	Score   float64                          `json:"_score"`
	Index   string                           `json:"_index"`
	Type    string                           `json:"_type"`
	Version int64                            `json:"_version,omitempty"`
	Source  HybridKubernetesConnectedCluster `json:"_source"`
	Sort    []interface{}                    `json:"sort"`
}

type HybridKubernetesConnectedClusterHits struct {
	Total essdk.SearchTotal                     `json:"total"`
	Hits  []HybridKubernetesConnectedClusterHit `json:"hits"`
}

type HybridKubernetesConnectedClusterSearchResponse struct {
	PitID string                               `json:"pit_id"`
	Hits  HybridKubernetesConnectedClusterHits `json:"hits"`
}

type HybridKubernetesConnectedClusterPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewHybridKubernetesConnectedClusterPaginator(filters []essdk.BoolFilter, limit *int64) (HybridKubernetesConnectedClusterPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_kubernetes_connectedclusters", filters, limit)
	if err != nil {
		return HybridKubernetesConnectedClusterPaginator{}, err
	}

	p := HybridKubernetesConnectedClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p HybridKubernetesConnectedClusterPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p HybridKubernetesConnectedClusterPaginator) NextPage(ctx context.Context) ([]HybridKubernetesConnectedCluster, error) {
	var response HybridKubernetesConnectedClusterSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []HybridKubernetesConnectedCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listHybridKubernetesConnectedClusterFilters = map[string]string{
	"agent_public_key_certificate": "description.ConnectedCluster.Properties.AgentPublicKeyCertificate",
	"agent_version":                "description.ConnectedCluster.Properties.AgentVersion",
	"connectivity_status":          "description.ConnectedCluster.Properties.ConnectivityStatus",
	"created_by":                   "description.ConnectedCluster.SystemData.CreatedBy",
	"created_by_type":              "description.ConnectedCluster.SystemData.CreatedByType",
	"distribution":                 "description.ConnectedCluster.Properties.Distribution",
	"extensions":                   "description.ConnectedClusterExtensions",
	"identity":                     "description.ConnectedCluster.Identity",
	"infrastructure":               "description.ConnectedCluster.Properties.Infrastructure",
	"kaytu_account_id":             "metadata.SourceID",
	"kubernetes_version":           "description.ConnectedCluster.Properties.KubernetesVersion",
	"last_modified_by":             "description.ConnectedCluster.SystemData.LastModifiedBy",
	"last_modified_by_type":        "description.ConnectedCluster.SystemData.LastModifiedByType",
	"location":                     "description.ConnectedCluster.Location",
	"name":                         "description.ConnectedCluster.Name",
	"offering":                     "description.ConnectedCluster.Properties.Offering",
	"provisioning_state":           "description.ConnectedCluster.Properties.ProvisioningState",
	"resource_group":               "description.ResourceGroup",
	"tags":                         "description.ConnectedCluster.Tags",
	"title":                        "description.ConnectedCluster.Name",
	"total_core_count":             "description.ConnectedCluster.Properties.TotalCoreCount",
	"total_node_count":             "description.ConnectedCluster.Properties.TotalNodeCount",
	"type":                         "description.ConnectedCluster.Type",
}

func ListHybridKubernetesConnectedCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListHybridKubernetesConnectedCluster")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewHybridKubernetesConnectedClusterPaginator(essdk.BuildFilter(ctx, d.QueryContext, listHybridKubernetesConnectedClusterFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getHybridKubernetesConnectedClusterFilters = map[string]string{
	"agent_public_key_certificate": "description.ConnectedCluster.Properties.AgentPublicKeyCertificate",
	"agent_version":                "description.ConnectedCluster.Properties.AgentVersion",
	"connectivity_status":          "description.ConnectedCluster.Properties.ConnectivityStatus",
	"created_by":                   "description.ConnectedCluster.SystemData.CreatedBy",
	"created_by_type":              "description.ConnectedCluster.SystemData.CreatedByType",
	"distribution":                 "description.ConnectedCluster.Properties.Distribution",
	"extensions":                   "description.ConnectedClusterExtensions",
	"identity":                     "description.ConnectedCluster.Identity",
	"infrastructure":               "description.ConnectedCluster.Properties.Infrastructure",
	"kaytu_account_id":             "metadata.SourceID",
	"kubernetes_version":           "description.ConnectedCluster.Properties.KubernetesVersion",
	"last_modified_by":             "description.ConnectedCluster.SystemData.LastModifiedBy",
	"last_modified_by_type":        "description.ConnectedCluster.SystemData.LastModifiedByType",
	"location":                     "description.ConnectedCluster.Location",
	"name":                         "description.ConnectedCluster.Name",
	"offering":                     "description.ConnectedCluster.Properties.Offering",
	"provisioning_state":           "description.ConnectedCluster.Properties.ProvisioningState",
	"resource_group":               "description.ResourceGroup",
	"tags":                         "description.ConnectedCluster.Tags",
	"title":                        "description.ConnectedCluster.Name",
	"total_core_count":             "description.ConnectedCluster.Properties.TotalCoreCount",
	"total_node_count":             "description.ConnectedCluster.Properties.TotalNodeCount",
	"type":                         "description.ConnectedCluster.Type",
}

func GetHybridKubernetesConnectedCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetHybridKubernetesConnectedCluster")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewHybridKubernetesConnectedClusterPaginator(essdk.BuildFilter(ctx, d.QueryContext, getHybridKubernetesConnectedClusterFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: HybridKubernetesConnectedCluster =============================

// ==========================  START: CostManagementCostByResourceType =============================

type CostManagementCostByResourceType struct {
	Description   azure.CostManagementCostByResourceTypeDescription `json:"description"`
	Metadata      azure.Metadata                                    `json:"metadata"`
	ResourceJobID int                                               `json:"resource_job_id"`
	SourceJobID   int                                               `json:"source_job_id"`
	ResourceType  string                                            `json:"resource_type"`
	SourceType    string                                            `json:"source_type"`
	ID            string                                            `json:"id"`
	ARN           string                                            `json:"arn"`
	SourceID      string                                            `json:"source_id"`
}

func (r *CostManagementCostByResourceType) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.CostManagementCostByResourceTypeDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type CostManagementCostByResourceTypeHit struct {
	ID      string                           `json:"_id"`
	Score   float64                          `json:"_score"`
	Index   string                           `json:"_index"`
	Type    string                           `json:"_type"`
	Version int64                            `json:"_version,omitempty"`
	Source  CostManagementCostByResourceType `json:"_source"`
	Sort    []interface{}                    `json:"sort"`
}

type CostManagementCostByResourceTypeHits struct {
	Total essdk.SearchTotal                     `json:"total"`
	Hits  []CostManagementCostByResourceTypeHit `json:"hits"`
}

type CostManagementCostByResourceTypeSearchResponse struct {
	PitID string                               `json:"pit_id"`
	Hits  CostManagementCostByResourceTypeHits `json:"hits"`
}

type CostManagementCostByResourceTypePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewCostManagementCostByResourceTypePaginator(filters []essdk.BoolFilter, limit *int64) (CostManagementCostByResourceTypePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_costmanagement_costbyresourcetype", filters, limit)
	if err != nil {
		return CostManagementCostByResourceTypePaginator{}, err
	}

	p := CostManagementCostByResourceTypePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostManagementCostByResourceTypePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p CostManagementCostByResourceTypePaginator) NextPage(ctx context.Context) ([]CostManagementCostByResourceType, error) {
	var response CostManagementCostByResourceTypeSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostManagementCostByResourceType
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listCostManagementCostByResourceTypeFilters = map[string]string{
	"cost":             "description.CostManagementCostByResourceType.Cost",
	"id":               "ID",
	"kaytu_account_id": "metadata.SourceID",
	"publisher_type":   "description.CostManagementCostByResourceType.PublisherType",
	"resource_type":    "metadata.ResourceType",
	"service_name":     "description.CostManagementCostByResourceType.ServiceName",
	"usage_date":       "description.CostManagementCostByResourceType.UsageDate",
}

func ListCostManagementCostByResourceType(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostManagementCostByResourceType")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewCostManagementCostByResourceTypePaginator(essdk.BuildFilter(ctx, d.QueryContext, listCostManagementCostByResourceTypeFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostManagementCostByResourceTypeFilters = map[string]string{
	"cost":             "description.CostManagementCostByResourceType.Cost",
	"id":               "ID",
	"kaytu_account_id": "metadata.SourceID",
	"publisher_type":   "description.CostManagementCostByResourceType.PublisherType",
	"resource_type":    "metadata.ResourceType",
	"service_name":     "description.CostManagementCostByResourceType.ServiceName",
	"usage_date":       "description.CostManagementCostByResourceType.UsageDate",
}

func GetCostManagementCostByResourceType(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostManagementCostByResourceType")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewCostManagementCostByResourceTypePaginator(essdk.BuildFilter(ctx, d.QueryContext, getCostManagementCostByResourceTypeFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostManagementCostByResourceType =============================

// ==========================  START: CostManagementCostBySubscription =============================

type CostManagementCostBySubscription struct {
	Description   azure.CostManagementCostBySubscriptionDescription `json:"description"`
	Metadata      azure.Metadata                                    `json:"metadata"`
	ResourceJobID int                                               `json:"resource_job_id"`
	SourceJobID   int                                               `json:"source_job_id"`
	ResourceType  string                                            `json:"resource_type"`
	SourceType    string                                            `json:"source_type"`
	ID            string                                            `json:"id"`
	ARN           string                                            `json:"arn"`
	SourceID      string                                            `json:"source_id"`
}

func (r *CostManagementCostBySubscription) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.CostManagementCostBySubscriptionDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type CostManagementCostBySubscriptionHit struct {
	ID      string                           `json:"_id"`
	Score   float64                          `json:"_score"`
	Index   string                           `json:"_index"`
	Type    string                           `json:"_type"`
	Version int64                            `json:"_version,omitempty"`
	Source  CostManagementCostBySubscription `json:"_source"`
	Sort    []interface{}                    `json:"sort"`
}

type CostManagementCostBySubscriptionHits struct {
	Total essdk.SearchTotal                     `json:"total"`
	Hits  []CostManagementCostBySubscriptionHit `json:"hits"`
}

type CostManagementCostBySubscriptionSearchResponse struct {
	PitID string                               `json:"pit_id"`
	Hits  CostManagementCostBySubscriptionHits `json:"hits"`
}

type CostManagementCostBySubscriptionPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewCostManagementCostBySubscriptionPaginator(filters []essdk.BoolFilter, limit *int64) (CostManagementCostBySubscriptionPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_costmanagement_costbysubscription", filters, limit)
	if err != nil {
		return CostManagementCostBySubscriptionPaginator{}, err
	}

	p := CostManagementCostBySubscriptionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostManagementCostBySubscriptionPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p CostManagementCostBySubscriptionPaginator) NextPage(ctx context.Context) ([]CostManagementCostBySubscription, error) {
	var response CostManagementCostBySubscriptionSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostManagementCostBySubscription
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listCostManagementCostBySubscriptionFilters = map[string]string{
	"id":               "ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.CostManagementCostBySubscription",
}

func ListCostManagementCostBySubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostManagementCostBySubscription")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewCostManagementCostBySubscriptionPaginator(essdk.BuildFilter(ctx, d.QueryContext, listCostManagementCostBySubscriptionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostManagementCostBySubscriptionFilters = map[string]string{
	"id":               "ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.CostManagementCostBySubscription",
}

func GetCostManagementCostBySubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostManagementCostBySubscription")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewCostManagementCostBySubscriptionPaginator(essdk.BuildFilter(ctx, d.QueryContext, getCostManagementCostBySubscriptionFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostManagementCostBySubscription =============================

// ==========================  START: LoadBalancer =============================

type LoadBalancer struct {
	Description   azure.LoadBalancerDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

func (r *LoadBalancer) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.LoadBalancerDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type LoadBalancerHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  LoadBalancer  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type LoadBalancerHits struct {
	Total essdk.SearchTotal `json:"total"`
	Hits  []LoadBalancerHit `json:"hits"`
}

type LoadBalancerSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  LoadBalancerHits `json:"hits"`
}

type LoadBalancerPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewLoadBalancerPaginator(filters []essdk.BoolFilter, limit *int64) (LoadBalancerPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_loadbalancers", filters, limit)
	if err != nil {
		return LoadBalancerPaginator{}, err
	}

	p := LoadBalancerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LoadBalancerPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p LoadBalancerPaginator) NextPage(ctx context.Context) ([]LoadBalancer, error) {
	var response LoadBalancerSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LoadBalancer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listLoadBalancerFilters = map[string]string{
	"backend_address_pools":      "description.LoadBalancer.Properties.BackendAddressPools",
	"diagnostic_settings":        "description.DiagnosticSetting",
	"etag":                       "description.LoadBalancer.Etag",
	"extended_location_name":     "description.LoadBalancer.ExtendedLocation.Name",
	"extended_location_type":     "description.LoadBalancer.ExtendedLocation.Type",
	"frontend_ip_configurations": "description.LoadBalancer.Properties.FrontendIPConfigurations",
	"id":                         "description.LoadBalancer.ID",
	"inbound_nat_pools":          "description.LoadBalancer.Properties.InboundNatPools",
	"inbound_nat_rules":          "description.LoadBalancer.Properties.InboundNatRules",
	"kaytu_account_id":           "metadata.SourceID",
	"load_balancing_rules":       "description.LoadBalancer.Properties.LoadBalancingRules",
	"name":                       "description.LoadBalancer.Name",
	"outbound_rules":             "description.LoadBalancer.Properties.OutboundRules",
	"probes":                     "description.LoadBalancer.Properties.Probes",
	"provisioning_state":         "description.LoadBalancer.Properties.ProvisioningState",
	"resource_group":             "description.ResourceGroup",
	"resource_guid":              "description.LoadBalancer.Properties.ResourceGUID",
	"sku_name":                   "description.LoadBalancer.SKU.Name",
	"sku_tier":                   "description.LoadBalancer.SKU.Tier",
	"tags":                       "description.LoadBalancer.Tags",
	"title":                      "description.LoadBalancer.Name",
	"type":                       "description.LoadBalancer.Type",
}

func ListLoadBalancer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLoadBalancer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewLoadBalancerPaginator(essdk.BuildFilter(ctx, d.QueryContext, listLoadBalancerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLoadBalancerFilters = map[string]string{
	"backend_address_pools":      "description.LoadBalancer.Properties.BackendAddressPools",
	"diagnostic_settings":        "description.DiagnosticSetting",
	"etag":                       "description.LoadBalancer.Etag",
	"extended_location_name":     "description.LoadBalancer.ExtendedLocation.Name",
	"extended_location_type":     "description.LoadBalancer.ExtendedLocation.Type",
	"frontend_ip_configurations": "description.LoadBalancer.Properties.FrontendIPConfigurations",
	"id":                         "description.LoadBalancer.ID",
	"inbound_nat_pools":          "description.LoadBalancer.Properties.InboundNatPools",
	"inbound_nat_rules":          "description.LoadBalancer.Properties.InboundNatRules",
	"kaytu_account_id":           "metadata.SourceID",
	"load_balancing_rules":       "description.LoadBalancer.Properties.LoadBalancingRules",
	"name":                       "description.LoadBalancer.Name",
	"outbound_rules":             "description.LoadBalancer.Properties.OutboundRules",
	"probes":                     "description.LoadBalancer.Properties.Probes",
	"provisioning_state":         "description.LoadBalancer.Properties.ProvisioningState",
	"resource_group":             "description.ResourceGroup",
	"resource_guid":              "description.LoadBalancer.Properties.ResourceGUID",
	"sku_name":                   "description.LoadBalancer.SKU.Name",
	"sku_tier":                   "description.LoadBalancer.SKU.Tier",
	"tags":                       "description.LoadBalancer.Tags",
	"title":                      "description.LoadBalancer.Name",
	"type":                       "description.LoadBalancer.Type",
}

func GetLoadBalancer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLoadBalancer")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewLoadBalancerPaginator(essdk.BuildFilter(ctx, d.QueryContext, getLoadBalancerFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LoadBalancer =============================

// ==========================  START: LoadBalancerBackendAddressPool =============================

type LoadBalancerBackendAddressPool struct {
	Description   azure.LoadBalancerBackendAddressPoolDescription `json:"description"`
	Metadata      azure.Metadata                                  `json:"metadata"`
	ResourceJobID int                                             `json:"resource_job_id"`
	SourceJobID   int                                             `json:"source_job_id"`
	ResourceType  string                                          `json:"resource_type"`
	SourceType    string                                          `json:"source_type"`
	ID            string                                          `json:"id"`
	ARN           string                                          `json:"arn"`
	SourceID      string                                          `json:"source_id"`
}

func (r *LoadBalancerBackendAddressPool) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.LoadBalancerBackendAddressPoolDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type LoadBalancerBackendAddressPoolHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  LoadBalancerBackendAddressPool `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type LoadBalancerBackendAddressPoolHits struct {
	Total essdk.SearchTotal                   `json:"total"`
	Hits  []LoadBalancerBackendAddressPoolHit `json:"hits"`
}

type LoadBalancerBackendAddressPoolSearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  LoadBalancerBackendAddressPoolHits `json:"hits"`
}

type LoadBalancerBackendAddressPoolPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewLoadBalancerBackendAddressPoolPaginator(filters []essdk.BoolFilter, limit *int64) (LoadBalancerBackendAddressPoolPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_loadbalancer_backendaddresspools", filters, limit)
	if err != nil {
		return LoadBalancerBackendAddressPoolPaginator{}, err
	}

	p := LoadBalancerBackendAddressPoolPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LoadBalancerBackendAddressPoolPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p LoadBalancerBackendAddressPoolPaginator) NextPage(ctx context.Context) ([]LoadBalancerBackendAddressPool, error) {
	var response LoadBalancerBackendAddressPoolSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LoadBalancerBackendAddressPool
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listLoadBalancerBackendAddressPoolFilters = map[string]string{
	"backend_ip_configurations":              "description.Pool.Properties.BackendIPConfigurations",
	"etag":                                   "description.Pool.Etag",
	"gateway_load_balancer_tunnel_interface": "description.Pool.Properties.TunnelInterfaces",
	"id":                                     "description.Pool.ID",
	"kaytu_account_id":                       "metadata.SourceID",
	"load_balancer_backend_addresses":        "description.Pool.Properties.LoadBalancerBackendAddresses",
	"load_balancer_name":                     "description.LoadBalancer.Name",
	"load_balancing_rules":                   "description.LoadBalancer.Properties.LoadBalancingRules",
	"name":                                   "description.Pool.Name",
	"outbound_rule_id":                       "description.Pool.Properties.OutboundRule.ID",
	"outbound_rules":                         "description.LoadBalancer.Properties.OutboundRules",
	"provisioning_state":                     "description.LoadBalancer.Properties.ProvisioningState",
	"resource_group":                         "description.ResourceGroup",
	"title":                                  "description.Pool.Name",
	"type":                                   "description.Pool.Type",
}

func ListLoadBalancerBackendAddressPool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLoadBalancerBackendAddressPool")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewLoadBalancerBackendAddressPoolPaginator(essdk.BuildFilter(ctx, d.QueryContext, listLoadBalancerBackendAddressPoolFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLoadBalancerBackendAddressPoolFilters = map[string]string{
	"backend_ip_configurations":              "description.Pool.Properties.BackendIPConfigurations",
	"etag":                                   "description.Pool.Etag",
	"gateway_load_balancer_tunnel_interface": "description.Pool.Properties.TunnelInterfaces",
	"id":                                     "description.Pool.ID",
	"kaytu_account_id":                       "metadata.SourceID",
	"load_balancer_backend_addresses":        "description.Pool.Properties.LoadBalancerBackendAddresses",
	"load_balancer_name":                     "description.LoadBalancer.Name",
	"load_balancing_rules":                   "description.LoadBalancer.Properties.LoadBalancingRules",
	"name":                                   "description.Pool.Name",
	"outbound_rule_id":                       "description.Pool.Properties.OutboundRule.ID",
	"outbound_rules":                         "description.LoadBalancer.Properties.OutboundRules",
	"provisioning_state":                     "description.LoadBalancer.Properties.ProvisioningState",
	"resource_group":                         "description.ResourceGroup",
	"title":                                  "description.Pool.Name",
	"type":                                   "description.Pool.Type",
}

func GetLoadBalancerBackendAddressPool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLoadBalancerBackendAddressPool")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewLoadBalancerBackendAddressPoolPaginator(essdk.BuildFilter(ctx, d.QueryContext, getLoadBalancerBackendAddressPoolFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LoadBalancerBackendAddressPool =============================

// ==========================  START: LoadBalancerNatRule =============================

type LoadBalancerNatRule struct {
	Description   azure.LoadBalancerNatRuleDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

func (r *LoadBalancerNatRule) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.LoadBalancerNatRuleDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type LoadBalancerNatRuleHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  LoadBalancerNatRule `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type LoadBalancerNatRuleHits struct {
	Total essdk.SearchTotal        `json:"total"`
	Hits  []LoadBalancerNatRuleHit `json:"hits"`
}

type LoadBalancerNatRuleSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  LoadBalancerNatRuleHits `json:"hits"`
}

type LoadBalancerNatRulePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewLoadBalancerNatRulePaginator(filters []essdk.BoolFilter, limit *int64) (LoadBalancerNatRulePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_loadbalancers_inboundnatrules", filters, limit)
	if err != nil {
		return LoadBalancerNatRulePaginator{}, err
	}

	p := LoadBalancerNatRulePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LoadBalancerNatRulePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p LoadBalancerNatRulePaginator) NextPage(ctx context.Context) ([]LoadBalancerNatRule, error) {
	var response LoadBalancerNatRuleSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LoadBalancerNatRule
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listLoadBalancerNatRuleFilters = map[string]string{
	"backend_ip_configuration":  "description.Rule.Properties.BackendIPConfiguration",
	"backend_port":              "description.Rule.Properties.BackendPort",
	"enable_floating_ip":        "description.Rule.Properties.EnableFloatingIP",
	"enable_tcp_reset":          "description.Rule.Properties.EnableTCPReset",
	"etag":                      "description.Rule.Etag",
	"frontend_ip_configuration": "description.Rule.Properties.FrontendIPConfiguration",
	"frontend_port":             "description.Rule.Properties.FrontendPort",
	"id":                        "description.Rule.ID",
	"idle_timeout_in_minutes":   "description.Rule.Properties.IdleTimeoutInMinutes",
	"kaytu_account_id":          "metadata.SourceID",
	"load_balancer_name":        "description.LoadBalancerName",
	"name":                      "description.Rule.Name",
	"protocol":                  "description.Rule.Properties.Protocol",
	"provisioning_state":        "description.Rule.Properties.ProvisioningState",
	"resource_group":            "description.ResourceGroup",
	"title":                     "description.Rule.Name",
	"type":                      "description.Rule.Type",
}

func ListLoadBalancerNatRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLoadBalancerNatRule")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewLoadBalancerNatRulePaginator(essdk.BuildFilter(ctx, d.QueryContext, listLoadBalancerNatRuleFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLoadBalancerNatRuleFilters = map[string]string{
	"backend_ip_configuration":  "description.Rule.Properties.BackendIPConfiguration",
	"backend_port":              "description.Rule.Properties.BackendPort",
	"enable_floating_ip":        "description.Rule.Properties.EnableFloatingIP",
	"enable_tcp_reset":          "description.Rule.Properties.EnableTCPReset",
	"etag":                      "description.Rule.Etag",
	"frontend_ip_configuration": "description.Rule.Properties.FrontendIPConfiguration",
	"frontend_port":             "description.Rule.Properties.FrontendPort",
	"id":                        "description.Rule.ID",
	"idle_timeout_in_minutes":   "description.Rule.Properties.IdleTimeoutInMinutes",
	"kaytu_account_id":          "metadata.SourceID",
	"load_balancer_name":        "description.LoadBalancerName",
	"name":                      "description.Rule.Name",
	"protocol":                  "description.Rule.Properties.Protocol",
	"provisioning_state":        "description.Rule.Properties.ProvisioningState",
	"resource_group":            "description.ResourceGroup",
	"title":                     "description.Rule.Name",
	"type":                      "description.Rule.Type",
}

func GetLoadBalancerNatRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLoadBalancerNatRule")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewLoadBalancerNatRulePaginator(essdk.BuildFilter(ctx, d.QueryContext, getLoadBalancerNatRuleFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LoadBalancerNatRule =============================

// ==========================  START: LoadBalancerOutboundRule =============================

type LoadBalancerOutboundRule struct {
	Description   azure.LoadBalancerOutboundRuleDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

func (r *LoadBalancerOutboundRule) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.LoadBalancerOutboundRuleDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type LoadBalancerOutboundRuleHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  LoadBalancerOutboundRule `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type LoadBalancerOutboundRuleHits struct {
	Total essdk.SearchTotal             `json:"total"`
	Hits  []LoadBalancerOutboundRuleHit `json:"hits"`
}

type LoadBalancerOutboundRuleSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  LoadBalancerOutboundRuleHits `json:"hits"`
}

type LoadBalancerOutboundRulePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewLoadBalancerOutboundRulePaginator(filters []essdk.BoolFilter, limit *int64) (LoadBalancerOutboundRulePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_loadbalancers_outboundrules", filters, limit)
	if err != nil {
		return LoadBalancerOutboundRulePaginator{}, err
	}

	p := LoadBalancerOutboundRulePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LoadBalancerOutboundRulePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p LoadBalancerOutboundRulePaginator) NextPage(ctx context.Context) ([]LoadBalancerOutboundRule, error) {
	var response LoadBalancerOutboundRuleSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LoadBalancerOutboundRule
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listLoadBalancerOutboundRuleFilters = map[string]string{
	"allocated_outbound_ports":   "description.Rule.Properties.AllocatedOutboundPorts",
	"backend_address_pools":      "description.Rule.Properties.BackendAddressPool",
	"enable_tcp_reset":           "description.Rule.Properties.EnableTCPReset",
	"etag":                       "description.Rule.Etag",
	"frontend_ip_configurations": "description.Rule.Properties.FrontendIPConfigurations",
	"id":                         "description.Rule.ID",
	"idle_timeout_in_minutes":    "description.Rule.Properties.IdleTimeoutInMinutes",
	"kaytu_account_id":           "metadata.SourceID",
	"load_balancer_name":         "description.LoadBalancerName",
	"name":                       "description.Rule.Name",
	"protocol":                   "description.Rule.Properties.Protocol",
	"provisioning_state":         "description.Rule.Properties.ProvisioningState",
	"resource_group":             "description.ResourceGroup",
	"title":                      "description.Rule.Name",
	"type":                       "description.Rule.Type",
}

func ListLoadBalancerOutboundRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLoadBalancerOutboundRule")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewLoadBalancerOutboundRulePaginator(essdk.BuildFilter(ctx, d.QueryContext, listLoadBalancerOutboundRuleFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLoadBalancerOutboundRuleFilters = map[string]string{
	"allocated_outbound_ports":   "description.Rule.Properties.AllocatedOutboundPorts",
	"backend_address_pools":      "description.Rule.Properties.BackendAddressPool",
	"enable_tcp_reset":           "description.Rule.Properties.EnableTCPReset",
	"etag":                       "description.Rule.Etag",
	"frontend_ip_configurations": "description.Rule.Properties.FrontendIPConfigurations",
	"id":                         "description.Rule.ID",
	"idle_timeout_in_minutes":    "description.Rule.Properties.IdleTimeoutInMinutes",
	"kaytu_account_id":           "metadata.SourceID",
	"load_balancer_name":         "description.LoadBalancerName",
	"name":                       "description.Rule.Name",
	"protocol":                   "description.Rule.Properties.Protocol",
	"provisioning_state":         "description.Rule.Properties.ProvisioningState",
	"resource_group":             "description.ResourceGroup",
	"title":                      "description.Rule.Name",
	"type":                       "description.Rule.Type",
}

func GetLoadBalancerOutboundRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLoadBalancerOutboundRule")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewLoadBalancerOutboundRulePaginator(essdk.BuildFilter(ctx, d.QueryContext, getLoadBalancerOutboundRuleFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LoadBalancerOutboundRule =============================

// ==========================  START: LoadBalancerProbe =============================

type LoadBalancerProbe struct {
	Description   azure.LoadBalancerProbeDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

func (r *LoadBalancerProbe) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.LoadBalancerProbeDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type LoadBalancerProbeHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  LoadBalancerProbe `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type LoadBalancerProbeHits struct {
	Total essdk.SearchTotal      `json:"total"`
	Hits  []LoadBalancerProbeHit `json:"hits"`
}

type LoadBalancerProbeSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  LoadBalancerProbeHits `json:"hits"`
}

type LoadBalancerProbePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewLoadBalancerProbePaginator(filters []essdk.BoolFilter, limit *int64) (LoadBalancerProbePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_loadbalancers_probes", filters, limit)
	if err != nil {
		return LoadBalancerProbePaginator{}, err
	}

	p := LoadBalancerProbePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LoadBalancerProbePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p LoadBalancerProbePaginator) NextPage(ctx context.Context) ([]LoadBalancerProbe, error) {
	var response LoadBalancerProbeSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LoadBalancerProbe
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listLoadBalancerProbeFilters = map[string]string{
	"etag":                 "description.Probe.Etag",
	"id":                   "description.Probe.ID",
	"interval_in_seconds":  "description.Probe.Properties.IntervalInSeconds",
	"kaytu_account_id":     "metadata.SourceID",
	"load_balancer_name":   "description.LoadBalancerName",
	"load_balancing_rules": "description.Probe.Properties.LoadBalancingRules",
	"name":                 "description.Probe.Name",
	"number_of_probes":     "description.Probe.Properties.NumberOfProbes",
	"port":                 "description.Probe.Properties.Port",
	"protocol":             "description.Probe.Properties.Protocol",
	"provisioning_state":   "description.Probe.Properties.ProvisioningState",
	"request_path":         "description.Probe.Properties.RequestPath",
	"resource_group":       "description.ResourceGroup",
	"title":                "description.Probe.Name",
	"type":                 "description.Probe.Type",
}

func ListLoadBalancerProbe(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLoadBalancerProbe")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewLoadBalancerProbePaginator(essdk.BuildFilter(ctx, d.QueryContext, listLoadBalancerProbeFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLoadBalancerProbeFilters = map[string]string{
	"etag":                 "description.Probe.Etag",
	"id":                   "description.Probe.ID",
	"interval_in_seconds":  "description.Probe.Properties.IntervalInSeconds",
	"kaytu_account_id":     "metadata.SourceID",
	"load_balancer_name":   "description.LoadBalancerName",
	"load_balancing_rules": "description.Probe.Properties.LoadBalancingRules",
	"name":                 "description.Probe.Name",
	"number_of_probes":     "description.Probe.Properties.NumberOfProbes",
	"port":                 "description.Probe.Properties.Port",
	"protocol":             "description.Probe.Properties.Protocol",
	"provisioning_state":   "description.Probe.Properties.ProvisioningState",
	"request_path":         "description.Probe.Properties.RequestPath",
	"resource_group":       "description.ResourceGroup",
	"title":                "description.Probe.Name",
	"type":                 "description.Probe.Type",
}

func GetLoadBalancerProbe(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLoadBalancerProbe")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewLoadBalancerProbePaginator(essdk.BuildFilter(ctx, d.QueryContext, getLoadBalancerProbeFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LoadBalancerProbe =============================

// ==========================  START: LoadBalancerRule =============================

type LoadBalancerRule struct {
	Description   azure.LoadBalancerRuleDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *LoadBalancerRule) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.LoadBalancerRuleDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type LoadBalancerRuleHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  LoadBalancerRule `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type LoadBalancerRuleHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []LoadBalancerRuleHit `json:"hits"`
}

type LoadBalancerRuleSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  LoadBalancerRuleHits `json:"hits"`
}

type LoadBalancerRulePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewLoadBalancerRulePaginator(filters []essdk.BoolFilter, limit *int64) (LoadBalancerRulePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_network_loadbalancers_loadbalancingrules", filters, limit)
	if err != nil {
		return LoadBalancerRulePaginator{}, err
	}

	p := LoadBalancerRulePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LoadBalancerRulePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p LoadBalancerRulePaginator) NextPage(ctx context.Context) ([]LoadBalancerRule, error) {
	var response LoadBalancerRuleSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LoadBalancerRule
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listLoadBalancerRuleFilters = map[string]string{
	"backend_address_pool_id":      "description.Rule.Properties.BackendAddressPool.ID",
	"backend_address_pools":        "description.Rule.Properties.BackendAddressPools",
	"backend_port":                 "description.Rule.Properties.BackendPort",
	"disable_outbound_snat":        "description.Rule.Properties.DisableOutboundSnat",
	"enable_floating_ip":           "description.Rule.Properties.EnableFloatingIP",
	"enable_tcp_reset":             "description.Rule.Properties.EnableTCPReset",
	"etag":                         "description.Rule.Etag",
	"frontend_ip_configuration_id": "description.Rule.Properties.FrontendIPConfiguration.ID",
	"frontend_port":                "description.Rule.Properties.FrontendPort",
	"id":                           "description.Rule.ID",
	"idle_timeout_in_minutes":      "description.Rule.Properties.IdleTimeoutInMinutes",
	"kaytu_account_id":             "metadata.SourceID",
	"load_balancer_name":           "description.LoadBalancerName",
	"load_distribution":            "description.Rule.Properties.LoadDistribution",
	"name":                         "description.Rule.Name",
	"probe_id":                     "description.Rule.Properties.Probe.ID",
	"protocol":                     "description.Rule.Properties.Protocol",
	"provisioning_state":           "description.Rule.Properties.ProvisioningState",
	"resource_group":               "description.ResourceGroup",
	"title":                        "description.Rule.Name",
	"type":                         "description.Rule.Type",
}

func ListLoadBalancerRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLoadBalancerRule")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewLoadBalancerRulePaginator(essdk.BuildFilter(ctx, d.QueryContext, listLoadBalancerRuleFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLoadBalancerRuleFilters = map[string]string{
	"backend_address_pool_id":      "description.Rule.Properties.BackendAddressPool.ID",
	"backend_address_pools":        "description.Rule.Properties.BackendAddressPools",
	"backend_port":                 "description.Rule.Properties.BackendPort",
	"disable_outbound_snat":        "description.Rule.Properties.DisableOutboundSnat",
	"enable_floating_ip":           "description.Rule.Properties.EnableFloatingIP",
	"enable_tcp_reset":             "description.Rule.Properties.EnableTCPReset",
	"etag":                         "description.Rule.Etag",
	"frontend_ip_configuration_id": "description.Rule.Properties.FrontendIPConfiguration.ID",
	"frontend_port":                "description.Rule.Properties.FrontendPort",
	"id":                           "description.Rule.ID",
	"idle_timeout_in_minutes":      "description.Rule.Properties.IdleTimeoutInMinutes",
	"kaytu_account_id":             "metadata.SourceID",
	"load_balancer_name":           "description.LoadBalancerName",
	"load_distribution":            "description.Rule.Properties.LoadDistribution",
	"name":                         "description.Rule.Name",
	"probe_id":                     "description.Rule.Properties.Probe.ID",
	"protocol":                     "description.Rule.Properties.Protocol",
	"provisioning_state":           "description.Rule.Properties.ProvisioningState",
	"resource_group":               "description.ResourceGroup",
	"title":                        "description.Rule.Name",
	"type":                         "description.Rule.Type",
}

func GetLoadBalancerRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLoadBalancerRule")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewLoadBalancerRulePaginator(essdk.BuildFilter(ctx, d.QueryContext, getLoadBalancerRuleFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LoadBalancerRule =============================

// ==========================  START: ManagementGroup =============================

type ManagementGroup struct {
	Description   azure.ManagementGroupDescription `json:"description"`
	Metadata      azure.Metadata                   `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

func (r *ManagementGroup) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ManagementGroupDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ManagementGroupHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  ManagementGroup `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type ManagementGroupHits struct {
	Total essdk.SearchTotal    `json:"total"`
	Hits  []ManagementGroupHit `json:"hits"`
}

type ManagementGroupSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  ManagementGroupHits `json:"hits"`
}

type ManagementGroupPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewManagementGroupPaginator(filters []essdk.BoolFilter, limit *int64) (ManagementGroupPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_management_groups", filters, limit)
	if err != nil {
		return ManagementGroupPaginator{}, err
	}

	p := ManagementGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ManagementGroupPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ManagementGroupPaginator) NextPage(ctx context.Context) ([]ManagementGroup, error) {
	var response ManagementGroupSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ManagementGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listManagementGroupFilters = map[string]string{
	"display_name":     "description.Group.Properties.DisplayName",
	"id":               "description.Group.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Group.Name",
	"parent":           "description.Group.Properties.Details.Parent",
	"tenant_id":        "description.Group.Properties.TenantID",
	"title":            "description.Group.Name",
	"type":             "description.Group.Type",
}

func ListManagementGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListManagementGroup")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewManagementGroupPaginator(essdk.BuildFilter(ctx, d.QueryContext, listManagementGroupFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getManagementGroupFilters = map[string]string{
	"display_name":     "description.Group.Properties.DisplayName",
	"id":               "description.Group.ID",
	"kaytu_account_id": "metadata.SourceID",
	"name":             "description.Group.Name",
	"parent":           "description.Group.Properties.Details.Parent",
	"tenant_id":        "description.Group.Properties.TenantID",
	"title":            "description.Group.Name",
	"type":             "description.Group.Type",
}

func GetManagementGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetManagementGroup")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewManagementGroupPaginator(essdk.BuildFilter(ctx, d.QueryContext, getManagementGroupFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ManagementGroup =============================

// ==========================  START: ManagementLock =============================

type ManagementLock struct {
	Description   azure.ManagementLockDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

func (r *ManagementLock) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ManagementLockDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ManagementLockHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  ManagementLock `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type ManagementLockHits struct {
	Total essdk.SearchTotal   `json:"total"`
	Hits  []ManagementLockHit `json:"hits"`
}

type ManagementLockSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  ManagementLockHits `json:"hits"`
}

type ManagementLockPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewManagementLockPaginator(filters []essdk.BoolFilter, limit *int64) (ManagementLockPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_management_locks", filters, limit)
	if err != nil {
		return ManagementLockPaginator{}, err
	}

	p := ManagementLockPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ManagementLockPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ManagementLockPaginator) NextPage(ctx context.Context) ([]ManagementLock, error) {
	var response ManagementLockSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ManagementLock
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listManagementLockFilters = map[string]string{
	"id":               "description.Lock.ID",
	"kaytu_account_id": "metadata.SourceID",
	"lock_level":       "description.Lock.Properties.Level",
	"name":             "description.Lock.Name",
	"notes":            "description.Lock.Properties.Notes",
	"owners":           "description.Lock.Properties.Owners",
	"title":            "description.Lock.Name",
	"type":             "description.Lock.Type",
}

func ListManagementLock(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListManagementLock")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewManagementLockPaginator(essdk.BuildFilter(ctx, d.QueryContext, listManagementLockFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getManagementLockFilters = map[string]string{
	"id":               "description.Lock.ID",
	"kaytu_account_id": "metadata.SourceID",
	"lock_level":       "description.Lock.Properties.Level",
	"name":             "description.Lock.Name",
	"notes":            "description.Lock.Properties.Notes",
	"owners":           "description.Lock.Properties.Owners",
	"resource_group":   "description.ResourceGroup",
	"title":            "description.Lock.Name",
	"type":             "description.Lock.Type",
}

func GetManagementLock(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetManagementLock")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewManagementLockPaginator(essdk.BuildFilter(ctx, d.QueryContext, getManagementLockFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ManagementLock =============================

// ==========================  START: ResourceProvider =============================

type ResourceProvider struct {
	Description   azure.ResourceProviderDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *ResourceProvider) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ResourceProviderDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ResourceProviderHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  ResourceProvider `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type ResourceProviderHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []ResourceProviderHit `json:"hits"`
}

type ResourceProviderSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  ResourceProviderHits `json:"hits"`
}

type ResourceProviderPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewResourceProviderPaginator(filters []essdk.BoolFilter, limit *int64) (ResourceProviderPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_resources_providers", filters, limit)
	if err != nil {
		return ResourceProviderPaginator{}, err
	}

	p := ResourceProviderPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ResourceProviderPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ResourceProviderPaginator) NextPage(ctx context.Context) ([]ResourceProvider, error) {
	var response ResourceProviderSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ResourceProvider
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listResourceProviderFilters = map[string]string{
	"id":                 "description.Provider.ID",
	"kaytu_account_id":   "metadata.SourceID",
	"namespace":          "description.Provider.Namespace",
	"registration_state": "description.Provider.RegistrationState",
	"resource_types":     "description.Provider.ResourceTypes",
	"title":              "description.Provider.Namespace",
}

func ListResourceProvider(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListResourceProvider")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewResourceProviderPaginator(essdk.BuildFilter(ctx, d.QueryContext, listResourceProviderFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getResourceProviderFilters = map[string]string{
	"id":                 "description.Provider.ID",
	"kaytu_account_id":   "metadata.SourceID",
	"namespace":          "description.Provider.Namespace",
	"registration_state": "description.Provider.RegistrationState",
	"resource_types":     "description.Provider.ResourceTypes",
	"title":              "description.Provider.Namespace",
}

func GetResourceProvider(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetResourceProvider")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewResourceProviderPaginator(essdk.BuildFilter(ctx, d.QueryContext, getResourceProviderFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ResourceProvider =============================

// ==========================  START: ResourceGroup =============================

type ResourceGroup struct {
	Description   azure.ResourceGroupDescription `json:"description"`
	Metadata      azure.Metadata                 `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

func (r *ResourceGroup) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ResourceGroupDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ResourceGroupHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ResourceGroup `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ResourceGroupHits struct {
	Total essdk.SearchTotal  `json:"total"`
	Hits  []ResourceGroupHit `json:"hits"`
}

type ResourceGroupSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  ResourceGroupHits `json:"hits"`
}

type ResourceGroupPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewResourceGroupPaginator(filters []essdk.BoolFilter, limit *int64) (ResourceGroupPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_resources_resourcegroups", filters, limit)
	if err != nil {
		return ResourceGroupPaginator{}, err
	}

	p := ResourceGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ResourceGroupPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ResourceGroupPaginator) NextPage(ctx context.Context) ([]ResourceGroup, error) {
	var response ResourceGroupSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ResourceGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listResourceGroupFilters = map[string]string{
	"id":                 "description.Group.ID",
	"kaytu_account_id":   "metadata.SourceID",
	"managed_by":         "description.Group.ManagedBy",
	"name":               "description.Group.Name",
	"provisioning_state": "description.Group.Properties.ProvisioningState",
	"tags":               "description.Group.Tags",
	"title":              "description.Group.Name",
	"type":               "description.Group.Type",
}

func ListResourceGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListResourceGroup")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewResourceGroupPaginator(essdk.BuildFilter(ctx, d.QueryContext, listResourceGroupFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getResourceGroupFilters = map[string]string{
	"id":                 "description.Group.ID",
	"kaytu_account_id":   "metadata.SourceID",
	"managed_by":         "description.Group.ManagedBy",
	"name":               "description.Group.Name",
	"provisioning_state": "description.Group.Properties.ProvisioningState",
	"tags":               "description.Group.Tags",
	"title":              "description.Group.Name",
	"type":               "description.Group.Type",
}

func GetResourceGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetResourceGroup")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewResourceGroupPaginator(essdk.BuildFilter(ctx, d.QueryContext, getResourceGroupFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ResourceGroup =============================

// ==========================  START: BotServiceBot =============================

type BotServiceBot struct {
	Description   azure.BotServiceBotDescription `json:"description"`
	Metadata      azure.Metadata                 `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

func (r *BotServiceBot) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.BotServiceBotDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type BotServiceBotHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  BotServiceBot `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type BotServiceBotHits struct {
	Total essdk.SearchTotal  `json:"total"`
	Hits  []BotServiceBotHit `json:"hits"`
}

type BotServiceBotSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  BotServiceBotHits `json:"hits"`
}

type BotServiceBotPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewBotServiceBotPaginator(filters []essdk.BoolFilter, limit *int64) (BotServiceBotPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_botservice_botservices", filters, limit)
	if err != nil {
		return BotServiceBotPaginator{}, err
	}

	p := BotServiceBotPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BotServiceBotPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p BotServiceBotPaginator) NextPage(ctx context.Context) ([]BotServiceBot, error) {
	var response BotServiceBotSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BotServiceBot
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listBotServiceBotFilters = map[string]string{
	"id":    "description.Bot.ID",
	"name":  "description.Bot.Name",
	"tags":  "description.Bot.Tags",
	"title": "description.Bot.Properties.DisplayName",
}

func ListBotServiceBot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBotServiceBot")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewBotServiceBotPaginator(essdk.BuildFilter(ctx, d.QueryContext, listBotServiceBotFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBotServiceBotFilters = map[string]string{
	"id":    "description.Bot.ID",
	"name":  "description.Bot.Name",
	"tags":  "description.Bot.Tags",
	"title": "description.Bot.Properties.DisplayName",
}

func GetBotServiceBot(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBotServiceBot")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewBotServiceBotPaginator(essdk.BuildFilter(ctx, d.QueryContext, getBotServiceBotFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BotServiceBot =============================

// ==========================  START: NetAppAccount =============================

type NetAppAccount struct {
	Description   azure.NetAppAccountDescription `json:"description"`
	Metadata      azure.Metadata                 `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

func (r *NetAppAccount) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.NetAppAccountDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type NetAppAccountHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  NetAppAccount `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type NetAppAccountHits struct {
	Total essdk.SearchTotal  `json:"total"`
	Hits  []NetAppAccountHit `json:"hits"`
}

type NetAppAccountSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  NetAppAccountHits `json:"hits"`
}

type NetAppAccountPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewNetAppAccountPaginator(filters []essdk.BoolFilter, limit *int64) (NetAppAccountPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_netapp_netappaccounts", filters, limit)
	if err != nil {
		return NetAppAccountPaginator{}, err
	}

	p := NetAppAccountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetAppAccountPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p NetAppAccountPaginator) NextPage(ctx context.Context) ([]NetAppAccount, error) {
	var response NetAppAccountSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetAppAccount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listNetAppAccountFilters = map[string]string{
	"id":    "description.Account.ID",
	"name":  "description.Account.Name",
	"tags":  "description.Account.Tags",
	"title": "description.Account.Name",
}

func ListNetAppAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetAppAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewNetAppAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, listNetAppAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetAppAccountFilters = map[string]string{
	"id":    "description.Account.ID",
	"name":  "description.Account.Name",
	"tags":  "description.Account.Tags",
	"title": "description.Account.Name",
}

func GetNetAppAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetAppAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewNetAppAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, getNetAppAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetAppAccount =============================

// ==========================  START: NetAppCapacityPool =============================

type NetAppCapacityPool struct {
	Description   azure.NetAppCapacityPoolDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

func (r *NetAppCapacityPool) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.NetAppCapacityPoolDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type NetAppCapacityPoolHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  NetAppCapacityPool `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type NetAppCapacityPoolHits struct {
	Total essdk.SearchTotal       `json:"total"`
	Hits  []NetAppCapacityPoolHit `json:"hits"`
}

type NetAppCapacityPoolSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  NetAppCapacityPoolHits `json:"hits"`
}

type NetAppCapacityPoolPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewNetAppCapacityPoolPaginator(filters []essdk.BoolFilter, limit *int64) (NetAppCapacityPoolPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_netapp_netappaccounts_capacitypools", filters, limit)
	if err != nil {
		return NetAppCapacityPoolPaginator{}, err
	}

	p := NetAppCapacityPoolPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetAppCapacityPoolPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p NetAppCapacityPoolPaginator) NextPage(ctx context.Context) ([]NetAppCapacityPool, error) {
	var response NetAppCapacityPoolSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetAppCapacityPool
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listNetAppCapacityPoolFilters = map[string]string{
	"id":    "description.CapacityPool.ID",
	"name":  "description.CapacityPool.Name",
	"tags":  "description.CapacityPool.Tags",
	"title": "description.CapacityPool.Name",
}

func ListNetAppCapacityPool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetAppCapacityPool")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewNetAppCapacityPoolPaginator(essdk.BuildFilter(ctx, d.QueryContext, listNetAppCapacityPoolFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetAppCapacityPoolFilters = map[string]string{
	"id":    "description.CapacityPool.ID",
	"name":  "description.CapacityPool.Name",
	"tags":  "description.CapacityPool.Tags",
	"title": "description.CapacityPool.Name",
}

func GetNetAppCapacityPool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetAppCapacityPool")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewNetAppCapacityPoolPaginator(essdk.BuildFilter(ctx, d.QueryContext, getNetAppCapacityPoolFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetAppCapacityPool =============================

// ==========================  START: DashboardGrafana =============================

type DashboardGrafana struct {
	Description   azure.DashboardGrafanaDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

func (r *DashboardGrafana) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DashboardGrafanaDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DashboardGrafanaHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  DashboardGrafana `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type DashboardGrafanaHits struct {
	Total essdk.SearchTotal     `json:"total"`
	Hits  []DashboardGrafanaHit `json:"hits"`
}

type DashboardGrafanaSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  DashboardGrafanaHits `json:"hits"`
}

type DashboardGrafanaPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDashboardGrafanaPaginator(filters []essdk.BoolFilter, limit *int64) (DashboardGrafanaPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_dashboard_grafana", filters, limit)
	if err != nil {
		return DashboardGrafanaPaginator{}, err
	}

	p := DashboardGrafanaPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DashboardGrafanaPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DashboardGrafanaPaginator) NextPage(ctx context.Context) ([]DashboardGrafana, error) {
	var response DashboardGrafanaSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DashboardGrafana
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDashboardGrafanaFilters = map[string]string{
	"id":    "description.Grafana.ID",
	"name":  "description.Grafana.Name",
	"title": "description.Grafana.Name",
}

func ListDashboardGrafana(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDashboardGrafana")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDashboardGrafanaPaginator(essdk.BuildFilter(ctx, d.QueryContext, listDashboardGrafanaFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDashboardGrafanaFilters = map[string]string{
	"id":    "description.Grafana.ID",
	"name":  "description.Grafana.Name",
	"title": "description.Grafana.Name",
}

func GetDashboardGrafana(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDashboardGrafana")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDashboardGrafanaPaginator(essdk.BuildFilter(ctx, d.QueryContext, getDashboardGrafanaFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DashboardGrafana =============================

// ==========================  START: DesktopVirtualizationHostPool =============================

type DesktopVirtualizationHostPool struct {
	Description   azure.DesktopVirtualizationHostPoolDescription `json:"description"`
	Metadata      azure.Metadata                                 `json:"metadata"`
	ResourceJobID int                                            `json:"resource_job_id"`
	SourceJobID   int                                            `json:"source_job_id"`
	ResourceType  string                                         `json:"resource_type"`
	SourceType    string                                         `json:"source_type"`
	ID            string                                         `json:"id"`
	ARN           string                                         `json:"arn"`
	SourceID      string                                         `json:"source_id"`
}

func (r *DesktopVirtualizationHostPool) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DesktopVirtualizationHostPoolDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DesktopVirtualizationHostPoolHit struct {
	ID      string                        `json:"_id"`
	Score   float64                       `json:"_score"`
	Index   string                        `json:"_index"`
	Type    string                        `json:"_type"`
	Version int64                         `json:"_version,omitempty"`
	Source  DesktopVirtualizationHostPool `json:"_source"`
	Sort    []interface{}                 `json:"sort"`
}

type DesktopVirtualizationHostPoolHits struct {
	Total essdk.SearchTotal                  `json:"total"`
	Hits  []DesktopVirtualizationHostPoolHit `json:"hits"`
}

type DesktopVirtualizationHostPoolSearchResponse struct {
	PitID string                            `json:"pit_id"`
	Hits  DesktopVirtualizationHostPoolHits `json:"hits"`
}

type DesktopVirtualizationHostPoolPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDesktopVirtualizationHostPoolPaginator(filters []essdk.BoolFilter, limit *int64) (DesktopVirtualizationHostPoolPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_desktopvirtualization_hostpools", filters, limit)
	if err != nil {
		return DesktopVirtualizationHostPoolPaginator{}, err
	}

	p := DesktopVirtualizationHostPoolPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DesktopVirtualizationHostPoolPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DesktopVirtualizationHostPoolPaginator) NextPage(ctx context.Context) ([]DesktopVirtualizationHostPool, error) {
	var response DesktopVirtualizationHostPoolSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DesktopVirtualizationHostPool
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDesktopVirtualizationHostPoolFilters = map[string]string{
	"id":    "description.HostPool.ID",
	"name":  "description.HostPool.Name",
	"tags":  "description.HostPool.Tags",
	"title": "description.HostPool.Name",
}

func ListDesktopVirtualizationHostPool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDesktopVirtualizationHostPool")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDesktopVirtualizationHostPoolPaginator(essdk.BuildFilter(ctx, d.QueryContext, listDesktopVirtualizationHostPoolFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDesktopVirtualizationHostPoolFilters = map[string]string{
	"id":    "description.HostPool.ID",
	"name":  "description.HostPool.Name",
	"tags":  "description.HostPool.Tags",
	"title": "description.HostPool.Name",
}

func GetDesktopVirtualizationHostPool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDesktopVirtualizationHostPool")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDesktopVirtualizationHostPoolPaginator(essdk.BuildFilter(ctx, d.QueryContext, getDesktopVirtualizationHostPoolFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DesktopVirtualizationHostPool =============================

// ==========================  START: DesktopVirtualizationWorkspace =============================

type DesktopVirtualizationWorkspace struct {
	Description   azure.DesktopVirtualizationWorkspaceDescription `json:"description"`
	Metadata      azure.Metadata                                  `json:"metadata"`
	ResourceJobID int                                             `json:"resource_job_id"`
	SourceJobID   int                                             `json:"source_job_id"`
	ResourceType  string                                          `json:"resource_type"`
	SourceType    string                                          `json:"source_type"`
	ID            string                                          `json:"id"`
	ARN           string                                          `json:"arn"`
	SourceID      string                                          `json:"source_id"`
}

func (r *DesktopVirtualizationWorkspace) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DesktopVirtualizationWorkspaceDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DesktopVirtualizationWorkspaceHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  DesktopVirtualizationWorkspace `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type DesktopVirtualizationWorkspaceHits struct {
	Total essdk.SearchTotal                   `json:"total"`
	Hits  []DesktopVirtualizationWorkspaceHit `json:"hits"`
}

type DesktopVirtualizationWorkspaceSearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  DesktopVirtualizationWorkspaceHits `json:"hits"`
}

type DesktopVirtualizationWorkspacePaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDesktopVirtualizationWorkspacePaginator(filters []essdk.BoolFilter, limit *int64) (DesktopVirtualizationWorkspacePaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_desktopvirtualization_workspaces", filters, limit)
	if err != nil {
		return DesktopVirtualizationWorkspacePaginator{}, err
	}

	p := DesktopVirtualizationWorkspacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DesktopVirtualizationWorkspacePaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DesktopVirtualizationWorkspacePaginator) NextPage(ctx context.Context) ([]DesktopVirtualizationWorkspace, error) {
	var response DesktopVirtualizationWorkspaceSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DesktopVirtualizationWorkspace
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDesktopVirtualizationWorkspaceFilters = map[string]string{
	"id":    "description.Workspace.ID",
	"name":  "description.Workspace.Name",
	"tags":  "description.Workspace.Tags",
	"title": "description.Workspace.Name",
}

func ListDesktopVirtualizationWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDesktopVirtualizationWorkspace")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDesktopVirtualizationWorkspacePaginator(essdk.BuildFilter(ctx, d.QueryContext, listDesktopVirtualizationWorkspaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDesktopVirtualizationWorkspaceFilters = map[string]string{
	"id":    "description.Workspace.ID",
	"name":  "description.Workspace.Name",
	"tags":  "description.Workspace.Tags",
	"title": "description.Workspace.Name",
}

func GetDesktopVirtualizationWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDesktopVirtualizationWorkspace")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDesktopVirtualizationWorkspacePaginator(essdk.BuildFilter(ctx, d.QueryContext, getDesktopVirtualizationWorkspaceFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DesktopVirtualizationWorkspace =============================

// ==========================  START: DevTestLabLab =============================

type DevTestLabLab struct {
	Description   azure.DevTestLabLabDescription `json:"description"`
	Metadata      azure.Metadata                 `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

func (r *DevTestLabLab) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.DevTestLabLabDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type DevTestLabLabHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  DevTestLabLab `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type DevTestLabLabHits struct {
	Total essdk.SearchTotal  `json:"total"`
	Hits  []DevTestLabLabHit `json:"hits"`
}

type DevTestLabLabSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  DevTestLabLabHits `json:"hits"`
}

type DevTestLabLabPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewDevTestLabLabPaginator(filters []essdk.BoolFilter, limit *int64) (DevTestLabLabPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_devtestlab_labs", filters, limit)
	if err != nil {
		return DevTestLabLabPaginator{}, err
	}

	p := DevTestLabLabPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DevTestLabLabPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p DevTestLabLabPaginator) NextPage(ctx context.Context) ([]DevTestLabLab, error) {
	var response DevTestLabLabSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DevTestLabLab
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listDevTestLabLabFilters = map[string]string{
	"id":    "description.Lab.ID",
	"name":  "description.Lab.Properties.VaultName",
	"tags":  "description.Lab.Properties.LabStorageType",
	"title": "description.Lab.Properties.VaultName",
}

func ListDevTestLabLab(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDevTestLabLab")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewDevTestLabLabPaginator(essdk.BuildFilter(ctx, d.QueryContext, listDevTestLabLabFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDevTestLabLabFilters = map[string]string{
	"id":    "description.Lab.ID",
	"name":  "description.Lab.Properties.VaultName",
	"tags":  "description.Lab.Properties.LabStorageType",
	"title": "description.Lab.Properties.VaultName",
}

func GetDevTestLabLab(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDevTestLabLab")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewDevTestLabLabPaginator(essdk.BuildFilter(ctx, d.QueryContext, getDevTestLabLabFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DevTestLabLab =============================

// ==========================  START: PurviewAccount =============================

type PurviewAccount struct {
	Description   azure.PurviewAccountDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

func (r *PurviewAccount) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.PurviewAccountDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type PurviewAccountHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  PurviewAccount `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type PurviewAccountHits struct {
	Total essdk.SearchTotal   `json:"total"`
	Hits  []PurviewAccountHit `json:"hits"`
}

type PurviewAccountSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  PurviewAccountHits `json:"hits"`
}

type PurviewAccountPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewPurviewAccountPaginator(filters []essdk.BoolFilter, limit *int64) (PurviewAccountPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_purview_accounts", filters, limit)
	if err != nil {
		return PurviewAccountPaginator{}, err
	}

	p := PurviewAccountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PurviewAccountPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p PurviewAccountPaginator) NextPage(ctx context.Context) ([]PurviewAccount, error) {
	var response PurviewAccountSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PurviewAccount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listPurviewAccountFilters = map[string]string{
	"id":    "description.Account.ID",
	"name":  "description.Account.Name",
	"tags":  "description.Account.Tags",
	"title": "description.Account.Name",
}

func ListPurviewAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPurviewAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewPurviewAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, listPurviewAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPurviewAccountFilters = map[string]string{
	"id":    "description.Account.ID",
	"name":  "description.Account.Name",
	"tags":  "description.Account.Tags",
	"title": "description.Account.Name",
}

func GetPurviewAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPurviewAccount")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewPurviewAccountPaginator(essdk.BuildFilter(ctx, d.QueryContext, getPurviewAccountFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PurviewAccount =============================

// ==========================  START: PowerBIDedicatedCapacity =============================

type PowerBIDedicatedCapacity struct {
	Description   azure.PowerBIDedicatedCapacityDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

func (r *PowerBIDedicatedCapacity) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.PowerBIDedicatedCapacityDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type PowerBIDedicatedCapacityHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  PowerBIDedicatedCapacity `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type PowerBIDedicatedCapacityHits struct {
	Total essdk.SearchTotal             `json:"total"`
	Hits  []PowerBIDedicatedCapacityHit `json:"hits"`
}

type PowerBIDedicatedCapacitySearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  PowerBIDedicatedCapacityHits `json:"hits"`
}

type PowerBIDedicatedCapacityPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewPowerBIDedicatedCapacityPaginator(filters []essdk.BoolFilter, limit *int64) (PowerBIDedicatedCapacityPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_powerbidedicated_capacities", filters, limit)
	if err != nil {
		return PowerBIDedicatedCapacityPaginator{}, err
	}

	p := PowerBIDedicatedCapacityPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PowerBIDedicatedCapacityPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p PowerBIDedicatedCapacityPaginator) NextPage(ctx context.Context) ([]PowerBIDedicatedCapacity, error) {
	var response PowerBIDedicatedCapacitySearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PowerBIDedicatedCapacity
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listPowerBIDedicatedCapacityFilters = map[string]string{
	"id":    "description.Capacity.ID",
	"name":  "description.Capacity.Name",
	"tags":  "description.Capacity.Tags",
	"title": "description.Capacity.Name",
}

func ListPowerBIDedicatedCapacity(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPowerBIDedicatedCapacity")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewPowerBIDedicatedCapacityPaginator(essdk.BuildFilter(ctx, d.QueryContext, listPowerBIDedicatedCapacityFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPowerBIDedicatedCapacityFilters = map[string]string{
	"id":    "description.Capacity.ID",
	"name":  "description.Capacity.Name",
	"tags":  "description.Capacity.Tags",
	"title": "description.Capacity.Name",
}

func GetPowerBIDedicatedCapacity(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPowerBIDedicatedCapacity")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewPowerBIDedicatedCapacityPaginator(essdk.BuildFilter(ctx, d.QueryContext, getPowerBIDedicatedCapacityFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PowerBIDedicatedCapacity =============================

// ==========================  START: ApplicationInsightsComponent =============================

type ApplicationInsightsComponent struct {
	Description   azure.ApplicationInsightsComponentDescription `json:"description"`
	Metadata      azure.Metadata                                `json:"metadata"`
	ResourceJobID int                                           `json:"resource_job_id"`
	SourceJobID   int                                           `json:"source_job_id"`
	ResourceType  string                                        `json:"resource_type"`
	SourceType    string                                        `json:"source_type"`
	ID            string                                        `json:"id"`
	ARN           string                                        `json:"arn"`
	SourceID      string                                        `json:"source_id"`
}

func (r *ApplicationInsightsComponent) UnmarshalJSON(b []byte) error {
	var rawMsg map[string]json.RawMessage
	if err := json.Unmarshal(b, &rawMsg); err != nil {
		return fmt.Errorf("unmarshalling type %T: %v", r, err)
	}
	for k, v := range rawMsg {
		switch k {
		case "description":
			wrapper := azureDescriber.JSONAllFieldsMarshaller{
				Value: r.Description,
			}
			if err := json.Unmarshal(v, &wrapper); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
			var ok bool
			r.Description, ok = wrapper.Value.(azure.ApplicationInsightsComponentDescription)
			if !ok {
				return fmt.Errorf("unmarshalling type %T: %v", r, fmt.Errorf("expected type %T, got %T", r.Description, wrapper.Value))
			}
		case "metadata":
			if err := json.Unmarshal(v, &r.Metadata); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_job_id":
			if err := json.Unmarshal(v, &r.ResourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_job_id":
			if err := json.Unmarshal(v, &r.SourceJobID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "resource_type":
			if err := json.Unmarshal(v, &r.ResourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_type":
			if err := json.Unmarshal(v, &r.SourceType); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "id":
			if err := json.Unmarshal(v, &r.ID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "arn":
			if err := json.Unmarshal(v, &r.ARN); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		case "source_id":
			if err := json.Unmarshal(v, &r.SourceID); err != nil {
				return fmt.Errorf("unmarshalling type %T: %v", r, err)
			}
		default:
		}
	}
	return nil
}

type ApplicationInsightsComponentHit struct {
	ID      string                       `json:"_id"`
	Score   float64                      `json:"_score"`
	Index   string                       `json:"_index"`
	Type    string                       `json:"_type"`
	Version int64                        `json:"_version,omitempty"`
	Source  ApplicationInsightsComponent `json:"_source"`
	Sort    []interface{}                `json:"sort"`
}

type ApplicationInsightsComponentHits struct {
	Total essdk.SearchTotal                 `json:"total"`
	Hits  []ApplicationInsightsComponentHit `json:"hits"`
}

type ApplicationInsightsComponentSearchResponse struct {
	PitID string                           `json:"pit_id"`
	Hits  ApplicationInsightsComponentHits `json:"hits"`
}

type ApplicationInsightsComponentPaginator struct {
	paginator *essdk.BaseESPaginator
}

func (k Client) NewApplicationInsightsComponentPaginator(filters []essdk.BoolFilter, limit *int64) (ApplicationInsightsComponentPaginator, error) {
	paginator, err := essdk.NewPaginator(k.ES(), "microsoft_applicationinsights_components", filters, limit)
	if err != nil {
		return ApplicationInsightsComponentPaginator{}, err
	}

	p := ApplicationInsightsComponentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApplicationInsightsComponentPaginator) HasNext() bool {
	return !p.paginator.Done()
}

func (p ApplicationInsightsComponentPaginator) NextPage(ctx context.Context) ([]ApplicationInsightsComponent, error) {
	var response ApplicationInsightsComponentSearchResponse
	err := p.paginator.Search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApplicationInsightsComponent
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.UpdateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.UpdateState(hits, nil, "")
	}

	return values, nil
}

var listApplicationInsightsComponentFilters = map[string]string{
	"app_id":                              "description.Component.Properties.AppID",
	"application_type":                    "description.Component.Properties.ApplicationType",
	"connection_string":                   "description.Component.Properties.ConnectionString",
	"creation_date":                       "description.Component.Properties.CreationDate",
	"disable_ip_masking":                  "description.Component.Properties.DisableIPMasking",
	"disable_local_auth":                  "description.Component.Properties.DisableLocalAuth",
	"etag":                                "description.Component.Etag",
	"flow_type":                           "description.Component.Properties.FlowType",
	"force_customer_storage_for_profiler": "description.Component.Properties.ForceCustomerStorageForProfiler",
	"id":                                  "description.Component.ID",
	"immediate_purge_data_on_30_days":     "description.Component.Properties.ImmediatePurgeDataOn30Days",
	"ingestion_mode":                      "description.Component.Properties.IngestionMode",
	"instrumentation_key":                 "description.Component.Properties.InstrumentationKey",
	"kind":                                "description.Component.Kind",
	"name":                                "description.Component.Name",
	"private_link_scoped_resources":       "description.Component.Properties.PrivateLinkScopedResources",
	"provisioning_state":                  "description.Component.Properties.ProvisioningState",
	"public_network_access_for_ingestion": "description.Component.Properties.PublicNetworkAccessForIngestion",
	"public_network_access_for_query":     "description.Component.Properties.PublicNetworkAccessForQuery",
	"request_source":                      "description.Component.Properties.RequestSource",
	"resource_group":                      "description.ResourceGroup",
	"retention_in_days":                   "description.Component.Properties.RetentionInDays",
	"sampling_percentage":                 "description.Component.Properties.SamplingPercentage",
	"tags":                                "description.Component.Tags",
	"tenant_id":                           "description.Component.Properties.TenantID",
	"title":                               "description.Component.Name",
	"type":                                "description.Component.Type",
	"workspace_resource_id":               "description.Component.Properties.WorkspaceResourceID",
}

func ListApplicationInsightsComponent(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApplicationInsightsComponent")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	paginator, err := k.NewApplicationInsightsComponentPaginator(essdk.BuildFilter(ctx, d.QueryContext, listApplicationInsightsComponentFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApplicationInsightsComponentFilters = map[string]string{
	"app_id":                              "description.Component.Properties.AppID",
	"application_type":                    "description.Component.Properties.ApplicationType",
	"connection_string":                   "description.Component.Properties.ConnectionString",
	"creation_date":                       "description.Component.Properties.CreationDate",
	"disable_ip_masking":                  "description.Component.Properties.DisableIPMasking",
	"disable_local_auth":                  "description.Component.Properties.DisableLocalAuth",
	"etag":                                "description.Component.Etag",
	"flow_type":                           "description.Component.Properties.FlowType",
	"force_customer_storage_for_profiler": "description.Component.Properties.ForceCustomerStorageForProfiler",
	"id":                                  "description.Component.ID",
	"immediate_purge_data_on_30_days":     "description.Component.Properties.ImmediatePurgeDataOn30Days",
	"ingestion_mode":                      "description.Component.Properties.IngestionMode",
	"instrumentation_key":                 "description.Component.Properties.InstrumentationKey",
	"kind":                                "description.Component.Kind",
	"name":                                "description.Component.Name",
	"private_link_scoped_resources":       "description.Component.Properties.PrivateLinkScopedResources",
	"provisioning_state":                  "description.Component.Properties.ProvisioningState",
	"public_network_access_for_ingestion": "description.Component.Properties.PublicNetworkAccessForIngestion",
	"public_network_access_for_query":     "description.Component.Properties.PublicNetworkAccessForQuery",
	"request_source":                      "description.Component.Properties.RequestSource",
	"resource_group":                      "description.ResourceGroup",
	"retention_in_days":                   "description.Component.Properties.RetentionInDays",
	"sampling_percentage":                 "description.Component.Properties.SamplingPercentage",
	"tags":                                "description.Component.Tags",
	"tenant_id":                           "description.Component.Properties.TenantID",
	"title":                               "description.Component.Name",
	"type":                                "description.Component.Type",
	"workspace_resource_id":               "description.Component.Properties.WorkspaceResourceID",
}

func GetApplicationInsightsComponent(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApplicationInsightsComponent")

	// create service
	cfg := essdk.GetConfig(d.Connection)
	ke, err := essdk.NewClientCached(cfg, d.ConnectionCache, ctx)
	if err != nil {
		return nil, err
	}
	k := Client{Client: ke}

	limit := int64(1)
	paginator, err := k.NewApplicationInsightsComponentPaginator(essdk.BuildFilter(ctx, d.QueryContext, getApplicationInsightsComponentFilters, "azure", *cfg.AccountID, cfg.EncodedResourceCollectionFilters), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApplicationInsightsComponent =============================
