// Code is generated by go generate. DO NOT EDIT.
package keibi

import (
	"context"
	azure "github.com/kaytu-io/kaytu-azure-describer/azure/model"
	"github.com/turbot/steampipe-plugin-sdk/v4/plugin"
)

// ==========================  START: APIManagement =============================

type APIManagement struct {
	Description   azure.APIManagementDescription `json:"description"`
	Metadata      azure.Metadata                 `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type APIManagementHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  APIManagement `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type APIManagementHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []APIManagementHit `json:"hits"`
}

type APIManagementSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  APIManagementHits `json:"hits"`
}

type APIManagementPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAPIManagementPaginator(filters []BoolFilter, limit *int64) (APIManagementPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_apimanagement_service", filters, limit)
	if err != nil {
		return APIManagementPaginator{}, err
	}

	p := APIManagementPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p APIManagementPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p APIManagementPaginator) NextPage(ctx context.Context) ([]APIManagement, error) {
	var response APIManagementSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []APIManagement
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAPIManagementFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAPIManagement(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAPIManagement")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAPIManagementPaginator(buildFilter(d.KeyColumnQuals, listAPIManagementFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAPIManagementFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.APIManagement.name",
	"resource_group":   "description.ResourceGroup",
}

func GetAPIManagement(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAPIManagement")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAPIManagementPaginator(buildFilter(d.KeyColumnQuals, getAPIManagementFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: APIManagement =============================

// ==========================  START: AppConfiguration =============================

type AppConfiguration struct {
	Description   azure.AppConfigurationDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type AppConfigurationHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  AppConfiguration `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type AppConfigurationHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []AppConfigurationHit `json:"hits"`
}

type AppConfigurationSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  AppConfigurationHits `json:"hits"`
}

type AppConfigurationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAppConfigurationPaginator(filters []BoolFilter, limit *int64) (AppConfigurationPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_appconfiguration_configurationstores", filters, limit)
	if err != nil {
		return AppConfigurationPaginator{}, err
	}

	p := AppConfigurationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppConfigurationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AppConfigurationPaginator) NextPage(ctx context.Context) ([]AppConfiguration, error) {
	var response AppConfigurationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppConfiguration
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAppConfigurationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAppConfiguration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppConfiguration")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAppConfigurationPaginator(buildFilter(d.KeyColumnQuals, listAppConfigurationFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppConfigurationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ConfigurationStore.name",
	"resource_group":   "description.ResourceGroup",
}

func GetAppConfiguration(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppConfiguration")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAppConfigurationPaginator(buildFilter(d.KeyColumnQuals, getAppConfigurationFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppConfiguration =============================

// ==========================  START: AppServiceEnvironment =============================

type AppServiceEnvironment struct {
	Description   azure.AppServiceEnvironmentDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type AppServiceEnvironmentHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  AppServiceEnvironment `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type AppServiceEnvironmentHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []AppServiceEnvironmentHit `json:"hits"`
}

type AppServiceEnvironmentSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  AppServiceEnvironmentHits `json:"hits"`
}

type AppServiceEnvironmentPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAppServiceEnvironmentPaginator(filters []BoolFilter, limit *int64) (AppServiceEnvironmentPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_web_hostingenvironments", filters, limit)
	if err != nil {
		return AppServiceEnvironmentPaginator{}, err
	}

	p := AppServiceEnvironmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppServiceEnvironmentPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AppServiceEnvironmentPaginator) NextPage(ctx context.Context) ([]AppServiceEnvironment, error) {
	var response AppServiceEnvironmentSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppServiceEnvironment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAppServiceEnvironmentFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAppServiceEnvironment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppServiceEnvironment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAppServiceEnvironmentPaginator(buildFilter(d.KeyColumnQuals, listAppServiceEnvironmentFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppServiceEnvironmentFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.AppServiceEnvironmentResource.name",
	"resource_group":   "description.ResourceGroup",
}

func GetAppServiceEnvironment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppServiceEnvironment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAppServiceEnvironmentPaginator(buildFilter(d.KeyColumnQuals, getAppServiceEnvironmentFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppServiceEnvironment =============================

// ==========================  START: AppServiceFunctionApp =============================

type AppServiceFunctionApp struct {
	Description   azure.AppServiceFunctionAppDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type AppServiceFunctionAppHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  AppServiceFunctionApp `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type AppServiceFunctionAppHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []AppServiceFunctionAppHit `json:"hits"`
}

type AppServiceFunctionAppSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  AppServiceFunctionAppHits `json:"hits"`
}

type AppServiceFunctionAppPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAppServiceFunctionAppPaginator(filters []BoolFilter, limit *int64) (AppServiceFunctionAppPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_web_sites", filters, limit)
	if err != nil {
		return AppServiceFunctionAppPaginator{}, err
	}

	p := AppServiceFunctionAppPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppServiceFunctionAppPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AppServiceFunctionAppPaginator) NextPage(ctx context.Context) ([]AppServiceFunctionApp, error) {
	var response AppServiceFunctionAppSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppServiceFunctionApp
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAppServiceFunctionAppFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAppServiceFunctionApp(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppServiceFunctionApp")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAppServiceFunctionAppPaginator(buildFilter(d.KeyColumnQuals, listAppServiceFunctionAppFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppServiceFunctionAppFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Site.name",
	"resource_group":   "description.ResourceGroup",
}

func GetAppServiceFunctionApp(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppServiceFunctionApp")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAppServiceFunctionAppPaginator(buildFilter(d.KeyColumnQuals, getAppServiceFunctionAppFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppServiceFunctionApp =============================

// ==========================  START: AppServiceWebApp =============================

type AppServiceWebApp struct {
	Description   azure.AppServiceWebAppDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type AppServiceWebAppHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  AppServiceWebApp `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type AppServiceWebAppHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []AppServiceWebAppHit `json:"hits"`
}

type AppServiceWebAppSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  AppServiceWebAppHits `json:"hits"`
}

type AppServiceWebAppPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAppServiceWebAppPaginator(filters []BoolFilter, limit *int64) (AppServiceWebAppPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_web_staticsites", filters, limit)
	if err != nil {
		return AppServiceWebAppPaginator{}, err
	}

	p := AppServiceWebAppPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppServiceWebAppPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AppServiceWebAppPaginator) NextPage(ctx context.Context) ([]AppServiceWebApp, error) {
	var response AppServiceWebAppSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppServiceWebApp
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAppServiceWebAppFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAppServiceWebApp(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppServiceWebApp")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAppServiceWebAppPaginator(buildFilter(d.KeyColumnQuals, listAppServiceWebAppFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppServiceWebAppFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Site.name",
	"resource_group":   "description.ResourceGroup",
}

func GetAppServiceWebApp(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppServiceWebApp")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAppServiceWebAppPaginator(buildFilter(d.KeyColumnQuals, getAppServiceWebAppFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppServiceWebApp =============================

// ==========================  START: AppServicePlan =============================

type AppServicePlan struct {
	Description   azure.AppServicePlanDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type AppServicePlanHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  AppServicePlan `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type AppServicePlanHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []AppServicePlanHit `json:"hits"`
}

type AppServicePlanSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  AppServicePlanHits `json:"hits"`
}

type AppServicePlanPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAppServicePlanPaginator(filters []BoolFilter, limit *int64) (AppServicePlanPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_web_plan", filters, limit)
	if err != nil {
		return AppServicePlanPaginator{}, err
	}

	p := AppServicePlanPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AppServicePlanPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AppServicePlanPaginator) NextPage(ctx context.Context) ([]AppServicePlan, error) {
	var response AppServicePlanSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AppServicePlan
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAppServicePlanFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListAppServicePlan(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAppServicePlan")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAppServicePlanPaginator(buildFilter(d.KeyColumnQuals, listAppServicePlanFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAppServicePlanFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Site.name",
	"resource_group":   "description.ResourceGroup",
}

func GetAppServicePlan(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAppServicePlan")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAppServicePlanPaginator(buildFilter(d.KeyColumnQuals, getAppServicePlanFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AppServicePlan =============================

// ==========================  START: ComputeDisk =============================

type ComputeDisk struct {
	Description   azure.ComputeDiskDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type ComputeDiskHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ComputeDisk   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ComputeDiskHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []ComputeDiskHit `json:"hits"`
}

type ComputeDiskSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  ComputeDiskHits `json:"hits"`
}

type ComputeDiskPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeDiskPaginator(filters []BoolFilter, limit *int64) (ComputeDiskPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_disks", filters, limit)
	if err != nil {
		return ComputeDiskPaginator{}, err
	}

	p := ComputeDiskPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeDiskPaginator) NextPage(ctx context.Context) ([]ComputeDisk, error) {
	var response ComputeDiskSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDisk
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeDisk(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDisk")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeDiskPaginator(buildFilter(d.KeyColumnQuals, listComputeDiskFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Disk.name",
	"resource_group":   "description.ResourceGroup",
}

func GetComputeDisk(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDisk")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeDiskPaginator(buildFilter(d.KeyColumnQuals, getComputeDiskFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDisk =============================

// ==========================  START: ComputeDiskReadOps =============================

type ComputeDiskReadOps struct {
	Description   azure.ComputeDiskReadOpsDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type ComputeDiskReadOpsHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  ComputeDiskReadOps `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type ComputeDiskReadOpsHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []ComputeDiskReadOpsHit `json:"hits"`
}

type ComputeDiskReadOpsSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  ComputeDiskReadOpsHits `json:"hits"`
}

type ComputeDiskReadOpsPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeDiskReadOpsPaginator(filters []BoolFilter, limit *int64) (ComputeDiskReadOpsPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_disksreadops", filters, limit)
	if err != nil {
		return ComputeDiskReadOpsPaginator{}, err
	}

	p := ComputeDiskReadOpsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskReadOpsPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeDiskReadOpsPaginator) NextPage(ctx context.Context) ([]ComputeDiskReadOps, error) {
	var response ComputeDiskReadOpsSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskReadOps
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskReadOpsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeDiskReadOps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskReadOps")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeDiskReadOpsPaginator(buildFilter(d.KeyColumnQuals, listComputeDiskReadOpsFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskReadOpsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetComputeDiskReadOps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskReadOps")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeDiskReadOpsPaginator(buildFilter(d.KeyColumnQuals, getComputeDiskReadOpsFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskReadOps =============================

// ==========================  START: ComputeDiskReadOpsDaily =============================

type ComputeDiskReadOpsDaily struct {
	Description   azure.ComputeDiskReadOpsDailyDescription `json:"description"`
	Metadata      azure.Metadata                           `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

type ComputeDiskReadOpsDailyHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  ComputeDiskReadOpsDaily `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type ComputeDiskReadOpsDailyHits struct {
	Total SearchTotal                  `json:"total"`
	Hits  []ComputeDiskReadOpsDailyHit `json:"hits"`
}

type ComputeDiskReadOpsDailySearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  ComputeDiskReadOpsDailyHits `json:"hits"`
}

type ComputeDiskReadOpsDailyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeDiskReadOpsDailyPaginator(filters []BoolFilter, limit *int64) (ComputeDiskReadOpsDailyPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_disksreadopsdaily", filters, limit)
	if err != nil {
		return ComputeDiskReadOpsDailyPaginator{}, err
	}

	p := ComputeDiskReadOpsDailyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskReadOpsDailyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeDiskReadOpsDailyPaginator) NextPage(ctx context.Context) ([]ComputeDiskReadOpsDaily, error) {
	var response ComputeDiskReadOpsDailySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskReadOpsDaily
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskReadOpsDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeDiskReadOpsDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskReadOpsDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeDiskReadOpsDailyPaginator(buildFilter(d.KeyColumnQuals, listComputeDiskReadOpsDailyFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskReadOpsDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetComputeDiskReadOpsDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskReadOpsDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeDiskReadOpsDailyPaginator(buildFilter(d.KeyColumnQuals, getComputeDiskReadOpsDailyFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskReadOpsDaily =============================

// ==========================  START: ComputeDiskReadOpsHourly =============================

type ComputeDiskReadOpsHourly struct {
	Description   azure.ComputeDiskReadOpsHourlyDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

type ComputeDiskReadOpsHourlyHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  ComputeDiskReadOpsHourly `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type ComputeDiskReadOpsHourlyHits struct {
	Total SearchTotal                   `json:"total"`
	Hits  []ComputeDiskReadOpsHourlyHit `json:"hits"`
}

type ComputeDiskReadOpsHourlySearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  ComputeDiskReadOpsHourlyHits `json:"hits"`
}

type ComputeDiskReadOpsHourlyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeDiskReadOpsHourlyPaginator(filters []BoolFilter, limit *int64) (ComputeDiskReadOpsHourlyPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_disksreadopshourly", filters, limit)
	if err != nil {
		return ComputeDiskReadOpsHourlyPaginator{}, err
	}

	p := ComputeDiskReadOpsHourlyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskReadOpsHourlyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeDiskReadOpsHourlyPaginator) NextPage(ctx context.Context) ([]ComputeDiskReadOpsHourly, error) {
	var response ComputeDiskReadOpsHourlySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskReadOpsHourly
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskReadOpsHourlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeDiskReadOpsHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskReadOpsHourly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeDiskReadOpsHourlyPaginator(buildFilter(d.KeyColumnQuals, listComputeDiskReadOpsHourlyFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskReadOpsHourlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetComputeDiskReadOpsHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskReadOpsHourly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeDiskReadOpsHourlyPaginator(buildFilter(d.KeyColumnQuals, getComputeDiskReadOpsHourlyFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskReadOpsHourly =============================

// ==========================  START: ComputeDiskWriteOps =============================

type ComputeDiskWriteOps struct {
	Description   azure.ComputeDiskWriteOpsDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

type ComputeDiskWriteOpsHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  ComputeDiskWriteOps `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type ComputeDiskWriteOpsHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []ComputeDiskWriteOpsHit `json:"hits"`
}

type ComputeDiskWriteOpsSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  ComputeDiskWriteOpsHits `json:"hits"`
}

type ComputeDiskWriteOpsPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeDiskWriteOpsPaginator(filters []BoolFilter, limit *int64) (ComputeDiskWriteOpsPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_diskswriteops", filters, limit)
	if err != nil {
		return ComputeDiskWriteOpsPaginator{}, err
	}

	p := ComputeDiskWriteOpsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskWriteOpsPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeDiskWriteOpsPaginator) NextPage(ctx context.Context) ([]ComputeDiskWriteOps, error) {
	var response ComputeDiskWriteOpsSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskWriteOps
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskWriteOpsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeDiskWriteOps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskWriteOps")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeDiskWriteOpsPaginator(buildFilter(d.KeyColumnQuals, listComputeDiskWriteOpsFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskWriteOpsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetComputeDiskWriteOps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskWriteOps")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeDiskWriteOpsPaginator(buildFilter(d.KeyColumnQuals, getComputeDiskWriteOpsFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskWriteOps =============================

// ==========================  START: ComputeDiskWriteOpsDaily =============================

type ComputeDiskWriteOpsDaily struct {
	Description   azure.ComputeDiskWriteOpsDailyDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

type ComputeDiskWriteOpsDailyHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  ComputeDiskWriteOpsDaily `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type ComputeDiskWriteOpsDailyHits struct {
	Total SearchTotal                   `json:"total"`
	Hits  []ComputeDiskWriteOpsDailyHit `json:"hits"`
}

type ComputeDiskWriteOpsDailySearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  ComputeDiskWriteOpsDailyHits `json:"hits"`
}

type ComputeDiskWriteOpsDailyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeDiskWriteOpsDailyPaginator(filters []BoolFilter, limit *int64) (ComputeDiskWriteOpsDailyPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_diskswriteopsdaily", filters, limit)
	if err != nil {
		return ComputeDiskWriteOpsDailyPaginator{}, err
	}

	p := ComputeDiskWriteOpsDailyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskWriteOpsDailyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeDiskWriteOpsDailyPaginator) NextPage(ctx context.Context) ([]ComputeDiskWriteOpsDaily, error) {
	var response ComputeDiskWriteOpsDailySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskWriteOpsDaily
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskWriteOpsDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeDiskWriteOpsDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskWriteOpsDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeDiskWriteOpsDailyPaginator(buildFilter(d.KeyColumnQuals, listComputeDiskWriteOpsDailyFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskWriteOpsDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetComputeDiskWriteOpsDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskWriteOpsDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeDiskWriteOpsDailyPaginator(buildFilter(d.KeyColumnQuals, getComputeDiskWriteOpsDailyFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskWriteOpsDaily =============================

// ==========================  START: ComputeDiskWriteOpsHourly =============================

type ComputeDiskWriteOpsHourly struct {
	Description   azure.ComputeDiskWriteOpsHourlyDescription `json:"description"`
	Metadata      azure.Metadata                             `json:"metadata"`
	ResourceJobID int                                        `json:"resource_job_id"`
	SourceJobID   int                                        `json:"source_job_id"`
	ResourceType  string                                     `json:"resource_type"`
	SourceType    string                                     `json:"source_type"`
	ID            string                                     `json:"id"`
	ARN           string                                     `json:"arn"`
	SourceID      string                                     `json:"source_id"`
}

type ComputeDiskWriteOpsHourlyHit struct {
	ID      string                    `json:"_id"`
	Score   float64                   `json:"_score"`
	Index   string                    `json:"_index"`
	Type    string                    `json:"_type"`
	Version int64                     `json:"_version,omitempty"`
	Source  ComputeDiskWriteOpsHourly `json:"_source"`
	Sort    []interface{}             `json:"sort"`
}

type ComputeDiskWriteOpsHourlyHits struct {
	Total SearchTotal                    `json:"total"`
	Hits  []ComputeDiskWriteOpsHourlyHit `json:"hits"`
}

type ComputeDiskWriteOpsHourlySearchResponse struct {
	PitID string                        `json:"pit_id"`
	Hits  ComputeDiskWriteOpsHourlyHits `json:"hits"`
}

type ComputeDiskWriteOpsHourlyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeDiskWriteOpsHourlyPaginator(filters []BoolFilter, limit *int64) (ComputeDiskWriteOpsHourlyPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_diskswriteopshourly", filters, limit)
	if err != nil {
		return ComputeDiskWriteOpsHourlyPaginator{}, err
	}

	p := ComputeDiskWriteOpsHourlyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskWriteOpsHourlyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeDiskWriteOpsHourlyPaginator) NextPage(ctx context.Context) ([]ComputeDiskWriteOpsHourly, error) {
	var response ComputeDiskWriteOpsHourlySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskWriteOpsHourly
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskWriteOpsHourlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeDiskWriteOpsHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskWriteOpsHourly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeDiskWriteOpsHourlyPaginator(buildFilter(d.KeyColumnQuals, listComputeDiskWriteOpsHourlyFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskWriteOpsHourlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetComputeDiskWriteOpsHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskWriteOpsHourly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeDiskWriteOpsHourlyPaginator(buildFilter(d.KeyColumnQuals, getComputeDiskWriteOpsHourlyFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskWriteOpsHourly =============================

// ==========================  START: ComputeDiskAccess =============================

type ComputeDiskAccess struct {
	Description   azure.ComputeDiskAccessDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type ComputeDiskAccessHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  ComputeDiskAccess `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type ComputeDiskAccessHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []ComputeDiskAccessHit `json:"hits"`
}

type ComputeDiskAccessSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  ComputeDiskAccessHits `json:"hits"`
}

type ComputeDiskAccessPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeDiskAccessPaginator(filters []BoolFilter, limit *int64) (ComputeDiskAccessPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_diskaccesses", filters, limit)
	if err != nil {
		return ComputeDiskAccessPaginator{}, err
	}

	p := ComputeDiskAccessPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskAccessPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeDiskAccessPaginator) NextPage(ctx context.Context) ([]ComputeDiskAccess, error) {
	var response ComputeDiskAccessSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskAccess
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskAccessFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeDiskAccess(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskAccess")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeDiskAccessPaginator(buildFilter(d.KeyColumnQuals, listComputeDiskAccessFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskAccessFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.DiskAccess.name",
	"resource_group":   "description.ResourceGroup",
}

func GetComputeDiskAccess(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskAccess")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeDiskAccessPaginator(buildFilter(d.KeyColumnQuals, getComputeDiskAccessFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskAccess =============================

// ==========================  START: ComputeVirtualMachineScaleSet =============================

type ComputeVirtualMachineScaleSet struct {
	Description   azure.ComputeVirtualMachineScaleSetDescription `json:"description"`
	Metadata      azure.Metadata                                 `json:"metadata"`
	ResourceJobID int                                            `json:"resource_job_id"`
	SourceJobID   int                                            `json:"source_job_id"`
	ResourceType  string                                         `json:"resource_type"`
	SourceType    string                                         `json:"source_type"`
	ID            string                                         `json:"id"`
	ARN           string                                         `json:"arn"`
	SourceID      string                                         `json:"source_id"`
}

type ComputeVirtualMachineScaleSetHit struct {
	ID      string                        `json:"_id"`
	Score   float64                       `json:"_score"`
	Index   string                        `json:"_index"`
	Type    string                        `json:"_type"`
	Version int64                         `json:"_version,omitempty"`
	Source  ComputeVirtualMachineScaleSet `json:"_source"`
	Sort    []interface{}                 `json:"sort"`
}

type ComputeVirtualMachineScaleSetHits struct {
	Total SearchTotal                        `json:"total"`
	Hits  []ComputeVirtualMachineScaleSetHit `json:"hits"`
}

type ComputeVirtualMachineScaleSetSearchResponse struct {
	PitID string                            `json:"pit_id"`
	Hits  ComputeVirtualMachineScaleSetHits `json:"hits"`
}

type ComputeVirtualMachineScaleSetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeVirtualMachineScaleSetPaginator(filters []BoolFilter, limit *int64) (ComputeVirtualMachineScaleSetPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_virtualmachinescalesets", filters, limit)
	if err != nil {
		return ComputeVirtualMachineScaleSetPaginator{}, err
	}

	p := ComputeVirtualMachineScaleSetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeVirtualMachineScaleSetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeVirtualMachineScaleSetPaginator) NextPage(ctx context.Context) ([]ComputeVirtualMachineScaleSet, error) {
	var response ComputeVirtualMachineScaleSetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeVirtualMachineScaleSet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeVirtualMachineScaleSetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeVirtualMachineScaleSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeVirtualMachineScaleSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeVirtualMachineScaleSetPaginator(buildFilter(d.KeyColumnQuals, listComputeVirtualMachineScaleSetFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeVirtualMachineScaleSetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.VirtualMachineScaleSet.name",
	"resource_group":   "description.ResourceGroup",
}

func GetComputeVirtualMachineScaleSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeVirtualMachineScaleSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeVirtualMachineScaleSetPaginator(buildFilter(d.KeyColumnQuals, getComputeVirtualMachineScaleSetFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeVirtualMachineScaleSet =============================

// ==========================  START: ComputeVirtualMachineScaleSetNetworkInterface =============================

type ComputeVirtualMachineScaleSetNetworkInterface struct {
	Description   azure.ComputeVirtualMachineScaleSetNetworkInterfaceDescription `json:"description"`
	Metadata      azure.Metadata                                                 `json:"metadata"`
	ResourceJobID int                                                            `json:"resource_job_id"`
	SourceJobID   int                                                            `json:"source_job_id"`
	ResourceType  string                                                         `json:"resource_type"`
	SourceType    string                                                         `json:"source_type"`
	ID            string                                                         `json:"id"`
	ARN           string                                                         `json:"arn"`
	SourceID      string                                                         `json:"source_id"`
}

type ComputeVirtualMachineScaleSetNetworkInterfaceHit struct {
	ID      string                                        `json:"_id"`
	Score   float64                                       `json:"_score"`
	Index   string                                        `json:"_index"`
	Type    string                                        `json:"_type"`
	Version int64                                         `json:"_version,omitempty"`
	Source  ComputeVirtualMachineScaleSetNetworkInterface `json:"_source"`
	Sort    []interface{}                                 `json:"sort"`
}

type ComputeVirtualMachineScaleSetNetworkInterfaceHits struct {
	Total SearchTotal                                        `json:"total"`
	Hits  []ComputeVirtualMachineScaleSetNetworkInterfaceHit `json:"hits"`
}

type ComputeVirtualMachineScaleSetNetworkInterfaceSearchResponse struct {
	PitID string                                            `json:"pit_id"`
	Hits  ComputeVirtualMachineScaleSetNetworkInterfaceHits `json:"hits"`
}

type ComputeVirtualMachineScaleSetNetworkInterfacePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeVirtualMachineScaleSetNetworkInterfacePaginator(filters []BoolFilter, limit *int64) (ComputeVirtualMachineScaleSetNetworkInterfacePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_virtualmachinescalesetnetworkinterface", filters, limit)
	if err != nil {
		return ComputeVirtualMachineScaleSetNetworkInterfacePaginator{}, err
	}

	p := ComputeVirtualMachineScaleSetNetworkInterfacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeVirtualMachineScaleSetNetworkInterfacePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeVirtualMachineScaleSetNetworkInterfacePaginator) NextPage(ctx context.Context) ([]ComputeVirtualMachineScaleSetNetworkInterface, error) {
	var response ComputeVirtualMachineScaleSetNetworkInterfaceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeVirtualMachineScaleSetNetworkInterface
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeVirtualMachineScaleSetNetworkInterfaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeVirtualMachineScaleSetNetworkInterface(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeVirtualMachineScaleSetNetworkInterface")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeVirtualMachineScaleSetNetworkInterfacePaginator(buildFilter(d.KeyColumnQuals, listComputeVirtualMachineScaleSetNetworkInterfaceFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeVirtualMachineScaleSetNetworkInterfaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetComputeVirtualMachineScaleSetNetworkInterface(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeVirtualMachineScaleSetNetworkInterface")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeVirtualMachineScaleSetNetworkInterfacePaginator(buildFilter(d.KeyColumnQuals, getComputeVirtualMachineScaleSetNetworkInterfaceFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeVirtualMachineScaleSetNetworkInterface =============================

// ==========================  START: ComputeVirtualMachineScaleSetVm =============================

type ComputeVirtualMachineScaleSetVm struct {
	Description   azure.ComputeVirtualMachineScaleSetVmDescription `json:"description"`
	Metadata      azure.Metadata                                   `json:"metadata"`
	ResourceJobID int                                              `json:"resource_job_id"`
	SourceJobID   int                                              `json:"source_job_id"`
	ResourceType  string                                           `json:"resource_type"`
	SourceType    string                                           `json:"source_type"`
	ID            string                                           `json:"id"`
	ARN           string                                           `json:"arn"`
	SourceID      string                                           `json:"source_id"`
}

type ComputeVirtualMachineScaleSetVmHit struct {
	ID      string                          `json:"_id"`
	Score   float64                         `json:"_score"`
	Index   string                          `json:"_index"`
	Type    string                          `json:"_type"`
	Version int64                           `json:"_version,omitempty"`
	Source  ComputeVirtualMachineScaleSetVm `json:"_source"`
	Sort    []interface{}                   `json:"sort"`
}

type ComputeVirtualMachineScaleSetVmHits struct {
	Total SearchTotal                          `json:"total"`
	Hits  []ComputeVirtualMachineScaleSetVmHit `json:"hits"`
}

type ComputeVirtualMachineScaleSetVmSearchResponse struct {
	PitID string                              `json:"pit_id"`
	Hits  ComputeVirtualMachineScaleSetVmHits `json:"hits"`
}

type ComputeVirtualMachineScaleSetVmPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeVirtualMachineScaleSetVmPaginator(filters []BoolFilter, limit *int64) (ComputeVirtualMachineScaleSetVmPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_virtualmachinescalesetvm", filters, limit)
	if err != nil {
		return ComputeVirtualMachineScaleSetVmPaginator{}, err
	}

	p := ComputeVirtualMachineScaleSetVmPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeVirtualMachineScaleSetVmPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeVirtualMachineScaleSetVmPaginator) NextPage(ctx context.Context) ([]ComputeVirtualMachineScaleSetVm, error) {
	var response ComputeVirtualMachineScaleSetVmSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeVirtualMachineScaleSetVm
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeVirtualMachineScaleSetVmFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeVirtualMachineScaleSetVm(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeVirtualMachineScaleSetVm")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeVirtualMachineScaleSetVmPaginator(buildFilter(d.KeyColumnQuals, listComputeVirtualMachineScaleSetVmFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeVirtualMachineScaleSetVmFilters = map[string]string{
	"instance_id":      "description.ScaleSetVM.InstanceID",
	"keibi_account_id": "metadata.SourceID",
	"resource_group":   "description.ResourceGroup",
	"scale_set_name":   "description.VirtualMachineScaleSet.name",
}

func GetComputeVirtualMachineScaleSetVm(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeVirtualMachineScaleSetVm")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeVirtualMachineScaleSetVmPaginator(buildFilter(d.KeyColumnQuals, getComputeVirtualMachineScaleSetVmFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeVirtualMachineScaleSetVm =============================

// ==========================  START: ComputeSnapshots =============================

type ComputeSnapshots struct {
	Description   azure.ComputeSnapshotsDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type ComputeSnapshotsHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  ComputeSnapshots `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type ComputeSnapshotsHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []ComputeSnapshotsHit `json:"hits"`
}

type ComputeSnapshotsSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  ComputeSnapshotsHits `json:"hits"`
}

type ComputeSnapshotsPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeSnapshotsPaginator(filters []BoolFilter, limit *int64) (ComputeSnapshotsPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_snapshots", filters, limit)
	if err != nil {
		return ComputeSnapshotsPaginator{}, err
	}

	p := ComputeSnapshotsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeSnapshotsPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeSnapshotsPaginator) NextPage(ctx context.Context) ([]ComputeSnapshots, error) {
	var response ComputeSnapshotsSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeSnapshots
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeSnapshotsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeSnapshots(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeSnapshots")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeSnapshotsPaginator(buildFilter(d.KeyColumnQuals, listComputeSnapshotsFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeSnapshotsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Snapshot.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetComputeSnapshots(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeSnapshots")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeSnapshotsPaginator(buildFilter(d.KeyColumnQuals, getComputeSnapshotsFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeSnapshots =============================

// ==========================  START: ComputeAvailabilitySet =============================

type ComputeAvailabilitySet struct {
	Description   azure.ComputeAvailabilitySetDescription `json:"description"`
	Metadata      azure.Metadata                          `json:"metadata"`
	ResourceJobID int                                     `json:"resource_job_id"`
	SourceJobID   int                                     `json:"source_job_id"`
	ResourceType  string                                  `json:"resource_type"`
	SourceType    string                                  `json:"source_type"`
	ID            string                                  `json:"id"`
	ARN           string                                  `json:"arn"`
	SourceID      string                                  `json:"source_id"`
}

type ComputeAvailabilitySetHit struct {
	ID      string                 `json:"_id"`
	Score   float64                `json:"_score"`
	Index   string                 `json:"_index"`
	Type    string                 `json:"_type"`
	Version int64                  `json:"_version,omitempty"`
	Source  ComputeAvailabilitySet `json:"_source"`
	Sort    []interface{}          `json:"sort"`
}

type ComputeAvailabilitySetHits struct {
	Total SearchTotal                 `json:"total"`
	Hits  []ComputeAvailabilitySetHit `json:"hits"`
}

type ComputeAvailabilitySetSearchResponse struct {
	PitID string                     `json:"pit_id"`
	Hits  ComputeAvailabilitySetHits `json:"hits"`
}

type ComputeAvailabilitySetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeAvailabilitySetPaginator(filters []BoolFilter, limit *int64) (ComputeAvailabilitySetPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_availabilityset", filters, limit)
	if err != nil {
		return ComputeAvailabilitySetPaginator{}, err
	}

	p := ComputeAvailabilitySetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeAvailabilitySetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeAvailabilitySetPaginator) NextPage(ctx context.Context) ([]ComputeAvailabilitySet, error) {
	var response ComputeAvailabilitySetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeAvailabilitySet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeAvailabilitySetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeAvailabilitySet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeAvailabilitySet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeAvailabilitySetPaginator(buildFilter(d.KeyColumnQuals, listComputeAvailabilitySetFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeAvailabilitySetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.AvailabilitySet.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetComputeAvailabilitySet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeAvailabilitySet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeAvailabilitySetPaginator(buildFilter(d.KeyColumnQuals, getComputeAvailabilitySetFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeAvailabilitySet =============================

// ==========================  START: ComputeDiskEncryptionSet =============================

type ComputeDiskEncryptionSet struct {
	Description   azure.ComputeDiskEncryptionSetDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

type ComputeDiskEncryptionSetHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  ComputeDiskEncryptionSet `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type ComputeDiskEncryptionSetHits struct {
	Total SearchTotal                   `json:"total"`
	Hits  []ComputeDiskEncryptionSetHit `json:"hits"`
}

type ComputeDiskEncryptionSetSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  ComputeDiskEncryptionSetHits `json:"hits"`
}

type ComputeDiskEncryptionSetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeDiskEncryptionSetPaginator(filters []BoolFilter, limit *int64) (ComputeDiskEncryptionSetPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_diskencryptionset", filters, limit)
	if err != nil {
		return ComputeDiskEncryptionSetPaginator{}, err
	}

	p := ComputeDiskEncryptionSetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeDiskEncryptionSetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeDiskEncryptionSetPaginator) NextPage(ctx context.Context) ([]ComputeDiskEncryptionSet, error) {
	var response ComputeDiskEncryptionSetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeDiskEncryptionSet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeDiskEncryptionSetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeDiskEncryptionSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeDiskEncryptionSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeDiskEncryptionSetPaginator(buildFilter(d.KeyColumnQuals, listComputeDiskEncryptionSetFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeDiskEncryptionSetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.DiskEncryptionSet.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetComputeDiskEncryptionSet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeDiskEncryptionSet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeDiskEncryptionSetPaginator(buildFilter(d.KeyColumnQuals, getComputeDiskEncryptionSetFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeDiskEncryptionSet =============================

// ==========================  START: ComputeGallery =============================

type ComputeGallery struct {
	Description   azure.ComputeGalleryDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type ComputeGalleryHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  ComputeGallery `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type ComputeGalleryHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []ComputeGalleryHit `json:"hits"`
}

type ComputeGallerySearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  ComputeGalleryHits `json:"hits"`
}

type ComputeGalleryPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeGalleryPaginator(filters []BoolFilter, limit *int64) (ComputeGalleryPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_gallery", filters, limit)
	if err != nil {
		return ComputeGalleryPaginator{}, err
	}

	p := ComputeGalleryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeGalleryPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeGalleryPaginator) NextPage(ctx context.Context) ([]ComputeGallery, error) {
	var response ComputeGallerySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeGallery
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeGalleryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeGallery(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeGallery")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeGalleryPaginator(buildFilter(d.KeyColumnQuals, listComputeGalleryFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeGalleryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Gallery.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetComputeGallery(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeGallery")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeGalleryPaginator(buildFilter(d.KeyColumnQuals, getComputeGalleryFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeGallery =============================

// ==========================  START: ComputeImage =============================

type ComputeImage struct {
	Description   azure.ComputeImageDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type ComputeImageHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ComputeImage  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ComputeImageHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []ComputeImageHit `json:"hits"`
}

type ComputeImageSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  ComputeImageHits `json:"hits"`
}

type ComputeImagePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeImagePaginator(filters []BoolFilter, limit *int64) (ComputeImagePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_image", filters, limit)
	if err != nil {
		return ComputeImagePaginator{}, err
	}

	p := ComputeImagePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeImagePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeImagePaginator) NextPage(ctx context.Context) ([]ComputeImage, error) {
	var response ComputeImageSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeImage
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeImageFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeImage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeImage")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeImagePaginator(buildFilter(d.KeyColumnQuals, listComputeImageFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeImageFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "Description.Image.Name",
	"resource_group":   "Description.Image.ResourceGroup",
}

func GetComputeImage(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeImage")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeImagePaginator(buildFilter(d.KeyColumnQuals, getComputeImageFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeImage =============================

// ==========================  START: DataboxEdgeDevice =============================

type DataboxEdgeDevice struct {
	Description   azure.DataboxEdgeDeviceDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type DataboxEdgeDeviceHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  DataboxEdgeDevice `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type DataboxEdgeDeviceHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []DataboxEdgeDeviceHit `json:"hits"`
}

type DataboxEdgeDeviceSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  DataboxEdgeDeviceHits `json:"hits"`
}

type DataboxEdgeDevicePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDataboxEdgeDevicePaginator(filters []BoolFilter, limit *int64) (DataboxEdgeDevicePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_databoxedge_databoxedgedevices", filters, limit)
	if err != nil {
		return DataboxEdgeDevicePaginator{}, err
	}

	p := DataboxEdgeDevicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DataboxEdgeDevicePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DataboxEdgeDevicePaginator) NextPage(ctx context.Context) ([]DataboxEdgeDevice, error) {
	var response DataboxEdgeDeviceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DataboxEdgeDevice
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDataboxEdgeDeviceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDataboxEdgeDevice(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDataboxEdgeDevice")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDataboxEdgeDevicePaginator(buildFilter(d.KeyColumnQuals, listDataboxEdgeDeviceFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDataboxEdgeDeviceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Device.name",
	"resource_group":   "description.ResourceGroup",
}

func GetDataboxEdgeDevice(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDataboxEdgeDevice")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDataboxEdgeDevicePaginator(buildFilter(d.KeyColumnQuals, getDataboxEdgeDeviceFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DataboxEdgeDevice =============================

// ==========================  START: HealthcareService =============================

type HealthcareService struct {
	Description   azure.HealthcareServiceDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type HealthcareServiceHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  HealthcareService `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type HealthcareServiceHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []HealthcareServiceHit `json:"hits"`
}

type HealthcareServiceSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  HealthcareServiceHits `json:"hits"`
}

type HealthcareServicePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewHealthcareServicePaginator(filters []BoolFilter, limit *int64) (HealthcareServicePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_healthcareapis_services", filters, limit)
	if err != nil {
		return HealthcareServicePaginator{}, err
	}

	p := HealthcareServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p HealthcareServicePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p HealthcareServicePaginator) NextPage(ctx context.Context) ([]HealthcareService, error) {
	var response HealthcareServiceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []HealthcareService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listHealthcareServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListHealthcareService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListHealthcareService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewHealthcareServicePaginator(buildFilter(d.KeyColumnQuals, listHealthcareServiceFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getHealthcareServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ServicesDescription.name",
	"resource_group":   "description.ResourceGroup",
}

func GetHealthcareService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetHealthcareService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewHealthcareServicePaginator(buildFilter(d.KeyColumnQuals, getHealthcareServiceFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: HealthcareService =============================

// ==========================  START: HpcCache =============================

type HpcCache struct {
	Description   azure.HpcCacheDescription `json:"description"`
	Metadata      azure.Metadata            `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type HpcCacheHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  HpcCache      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type HpcCacheHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []HpcCacheHit `json:"hits"`
}

type HpcCacheSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  HpcCacheHits `json:"hits"`
}

type HpcCachePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewHpcCachePaginator(filters []BoolFilter, limit *int64) (HpcCachePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_storagecache_caches", filters, limit)
	if err != nil {
		return HpcCachePaginator{}, err
	}

	p := HpcCachePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p HpcCachePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p HpcCachePaginator) NextPage(ctx context.Context) ([]HpcCache, error) {
	var response HpcCacheSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []HpcCache
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listHpcCacheFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListHpcCache(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListHpcCache")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewHpcCachePaginator(buildFilter(d.KeyColumnQuals, listHpcCacheFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getHpcCacheFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Cache.name",
	"resource_group":   "description.ResourceGroup",
}

func GetHpcCache(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetHpcCache")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewHpcCachePaginator(buildFilter(d.KeyColumnQuals, getHpcCacheFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: HpcCache =============================

// ==========================  START: KeyVaultKey =============================

type KeyVaultKey struct {
	Description   azure.KeyVaultKeyDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type KeyVaultKeyHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  KeyVaultKey   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type KeyVaultKeyHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []KeyVaultKeyHit `json:"hits"`
}

type KeyVaultKeySearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  KeyVaultKeyHits `json:"hits"`
}

type KeyVaultKeyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewKeyVaultKeyPaginator(filters []BoolFilter, limit *int64) (KeyVaultKeyPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_keyvault_vaults_keys", filters, limit)
	if err != nil {
		return KeyVaultKeyPaginator{}, err
	}

	p := KeyVaultKeyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KeyVaultKeyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p KeyVaultKeyPaginator) NextPage(ctx context.Context) ([]KeyVaultKey, error) {
	var response KeyVaultKeySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KeyVaultKey
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listKeyVaultKeyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListKeyVaultKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKeyVaultKey")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewKeyVaultKeyPaginator(buildFilter(d.KeyColumnQuals, listKeyVaultKeyFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKeyVaultKeyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Key.name",
	"resource_group":   "description.ResourceGroup",
	"vault_name":       "description.Vault.name",
}

func GetKeyVaultKey(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKeyVaultKey")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewKeyVaultKeyPaginator(buildFilter(d.KeyColumnQuals, getKeyVaultKeyFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KeyVaultKey =============================

// ==========================  START: KubernetesCluster =============================

type KubernetesCluster struct {
	Description   azure.KubernetesClusterDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type KubernetesClusterHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  KubernetesCluster `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type KubernetesClusterHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []KubernetesClusterHit `json:"hits"`
}

type KubernetesClusterSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  KubernetesClusterHits `json:"hits"`
}

type KubernetesClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewKubernetesClusterPaginator(filters []BoolFilter, limit *int64) (KubernetesClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_containerservice_managedclusters", filters, limit)
	if err != nil {
		return KubernetesClusterPaginator{}, err
	}

	p := KubernetesClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KubernetesClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p KubernetesClusterPaginator) NextPage(ctx context.Context) ([]KubernetesCluster, error) {
	var response KubernetesClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KubernetesCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listKubernetesClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListKubernetesCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKubernetesCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewKubernetesClusterPaginator(buildFilter(d.KeyColumnQuals, listKubernetesClusterFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKubernetesClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ManagedCluster.name",
	"resource_group":   "description.ResourceGroup",
}

func GetKubernetesCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKubernetesCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewKubernetesClusterPaginator(buildFilter(d.KeyColumnQuals, getKubernetesClusterFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KubernetesCluster =============================

// ==========================  START: NetworkInterface =============================

type NetworkInterface struct {
	Description   azure.NetworkInterfaceDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type NetworkInterfaceHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  NetworkInterface `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type NetworkInterfaceHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []NetworkInterfaceHit `json:"hits"`
}

type NetworkInterfaceSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  NetworkInterfaceHits `json:"hits"`
}

type NetworkInterfacePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewNetworkInterfacePaginator(filters []BoolFilter, limit *int64) (NetworkInterfacePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_networkinterfaces", filters, limit)
	if err != nil {
		return NetworkInterfacePaginator{}, err
	}

	p := NetworkInterfacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkInterfacePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p NetworkInterfacePaginator) NextPage(ctx context.Context) ([]NetworkInterface, error) {
	var response NetworkInterfaceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkInterface
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkInterfaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListNetworkInterface(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkInterface")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewNetworkInterfacePaginator(buildFilter(d.KeyColumnQuals, listNetworkInterfaceFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkInterfaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Interface.name",
	"resource_group":   "description.ResourceGroup",
}

func GetNetworkInterface(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkInterface")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewNetworkInterfacePaginator(buildFilter(d.KeyColumnQuals, getNetworkInterfaceFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkInterface =============================

// ==========================  START: NetworkWatcherFlowLog =============================

type NetworkWatcherFlowLog struct {
	Description   azure.NetworkWatcherFlowLogDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type NetworkWatcherFlowLogHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  NetworkWatcherFlowLog `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type NetworkWatcherFlowLogHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []NetworkWatcherFlowLogHit `json:"hits"`
}

type NetworkWatcherFlowLogSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  NetworkWatcherFlowLogHits `json:"hits"`
}

type NetworkWatcherFlowLogPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewNetworkWatcherFlowLogPaginator(filters []BoolFilter, limit *int64) (NetworkWatcherFlowLogPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_networkwatchers", filters, limit)
	if err != nil {
		return NetworkWatcherFlowLogPaginator{}, err
	}

	p := NetworkWatcherFlowLogPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkWatcherFlowLogPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p NetworkWatcherFlowLogPaginator) NextPage(ctx context.Context) ([]NetworkWatcherFlowLog, error) {
	var response NetworkWatcherFlowLogSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkWatcherFlowLog
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkWatcherFlowLogFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListNetworkWatcherFlowLog(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkWatcherFlowLog")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewNetworkWatcherFlowLogPaginator(buildFilter(d.KeyColumnQuals, listNetworkWatcherFlowLogFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkWatcherFlowLogFilters = map[string]string{
	"keibi_account_id":     "metadata.SourceID",
	"name":                 "description.ManagedCluster.name",
	"network_watcher_name": "description.NetworkWatcherName",
	"resource_group":       "description.ResourceGroup",
}

func GetNetworkWatcherFlowLog(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkWatcherFlowLog")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewNetworkWatcherFlowLogPaginator(buildFilter(d.KeyColumnQuals, getNetworkWatcherFlowLogFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkWatcherFlowLog =============================

// ==========================  START: RouteTables =============================

type RouteTables struct {
	Description   azure.RouteTablesDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type RouteTablesHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  RouteTables   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type RouteTablesHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []RouteTablesHit `json:"hits"`
}

type RouteTablesSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  RouteTablesHits `json:"hits"`
}

type RouteTablesPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRouteTablesPaginator(filters []BoolFilter, limit *int64) (RouteTablesPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_routetables", filters, limit)
	if err != nil {
		return RouteTablesPaginator{}, err
	}

	p := RouteTablesPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RouteTablesPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RouteTablesPaginator) NextPage(ctx context.Context) ([]RouteTables, error) {
	var response RouteTablesSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RouteTables
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRouteTablesFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRouteTables(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRouteTables")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRouteTablesPaginator(buildFilter(d.KeyColumnQuals, listRouteTablesFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRouteTablesFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.RouteTable.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetRouteTables(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRouteTables")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRouteTablesPaginator(buildFilter(d.KeyColumnQuals, getRouteTablesFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RouteTables =============================

// ==========================  START: NetworkApplicationSecurityGroups =============================

type NetworkApplicationSecurityGroups struct {
	Description   azure.NetworkApplicationSecurityGroupsDescription `json:"description"`
	Metadata      azure.Metadata                                    `json:"metadata"`
	ResourceJobID int                                               `json:"resource_job_id"`
	SourceJobID   int                                               `json:"source_job_id"`
	ResourceType  string                                            `json:"resource_type"`
	SourceType    string                                            `json:"source_type"`
	ID            string                                            `json:"id"`
	ARN           string                                            `json:"arn"`
	SourceID      string                                            `json:"source_id"`
}

type NetworkApplicationSecurityGroupsHit struct {
	ID      string                           `json:"_id"`
	Score   float64                          `json:"_score"`
	Index   string                           `json:"_index"`
	Type    string                           `json:"_type"`
	Version int64                            `json:"_version,omitempty"`
	Source  NetworkApplicationSecurityGroups `json:"_source"`
	Sort    []interface{}                    `json:"sort"`
}

type NetworkApplicationSecurityGroupsHits struct {
	Total SearchTotal                           `json:"total"`
	Hits  []NetworkApplicationSecurityGroupsHit `json:"hits"`
}

type NetworkApplicationSecurityGroupsSearchResponse struct {
	PitID string                               `json:"pit_id"`
	Hits  NetworkApplicationSecurityGroupsHits `json:"hits"`
}

type NetworkApplicationSecurityGroupsPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewNetworkApplicationSecurityGroupsPaginator(filters []BoolFilter, limit *int64) (NetworkApplicationSecurityGroupsPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_applicationsecuritygroups", filters, limit)
	if err != nil {
		return NetworkApplicationSecurityGroupsPaginator{}, err
	}

	p := NetworkApplicationSecurityGroupsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkApplicationSecurityGroupsPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p NetworkApplicationSecurityGroupsPaginator) NextPage(ctx context.Context) ([]NetworkApplicationSecurityGroups, error) {
	var response NetworkApplicationSecurityGroupsSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkApplicationSecurityGroups
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkApplicationSecurityGroupsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListNetworkApplicationSecurityGroups(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkApplicationSecurityGroups")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewNetworkApplicationSecurityGroupsPaginator(buildFilter(d.KeyColumnQuals, listNetworkApplicationSecurityGroupsFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkApplicationSecurityGroupsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ApplicationSecurityGroup.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetNetworkApplicationSecurityGroups(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkApplicationSecurityGroups")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewNetworkApplicationSecurityGroupsPaginator(buildFilter(d.KeyColumnQuals, getNetworkApplicationSecurityGroupsFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkApplicationSecurityGroups =============================

// ==========================  START: NetworkAzureFirewall =============================

type NetworkAzureFirewall struct {
	Description   azure.NetworkAzureFirewallDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type NetworkAzureFirewallHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  NetworkAzureFirewall `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type NetworkAzureFirewallHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []NetworkAzureFirewallHit `json:"hits"`
}

type NetworkAzureFirewallSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  NetworkAzureFirewallHits `json:"hits"`
}

type NetworkAzureFirewallPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewNetworkAzureFirewallPaginator(filters []BoolFilter, limit *int64) (NetworkAzureFirewallPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_azurefirewall", filters, limit)
	if err != nil {
		return NetworkAzureFirewallPaginator{}, err
	}

	p := NetworkAzureFirewallPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkAzureFirewallPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p NetworkAzureFirewallPaginator) NextPage(ctx context.Context) ([]NetworkAzureFirewall, error) {
	var response NetworkAzureFirewallSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkAzureFirewall
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkAzureFirewallFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListNetworkAzureFirewall(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkAzureFirewall")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewNetworkAzureFirewallPaginator(buildFilter(d.KeyColumnQuals, listNetworkAzureFirewallFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkAzureFirewallFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.AzureFirewall.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetNetworkAzureFirewall(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkAzureFirewall")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewNetworkAzureFirewallPaginator(buildFilter(d.KeyColumnQuals, getNetworkAzureFirewallFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkAzureFirewall =============================

// ==========================  START: ExpressRouteCircuit =============================

type ExpressRouteCircuit struct {
	Description   azure.ExpressRouteCircuitDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

type ExpressRouteCircuitHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  ExpressRouteCircuit `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type ExpressRouteCircuitHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []ExpressRouteCircuitHit `json:"hits"`
}

type ExpressRouteCircuitSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  ExpressRouteCircuitHits `json:"hits"`
}

type ExpressRouteCircuitPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewExpressRouteCircuitPaginator(filters []BoolFilter, limit *int64) (ExpressRouteCircuitPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_expressroutecircuit", filters, limit)
	if err != nil {
		return ExpressRouteCircuitPaginator{}, err
	}

	p := ExpressRouteCircuitPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ExpressRouteCircuitPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ExpressRouteCircuitPaginator) NextPage(ctx context.Context) ([]ExpressRouteCircuit, error) {
	var response ExpressRouteCircuitSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ExpressRouteCircuit
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listExpressRouteCircuitFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListExpressRouteCircuit(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListExpressRouteCircuit")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewExpressRouteCircuitPaginator(buildFilter(d.KeyColumnQuals, listExpressRouteCircuitFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getExpressRouteCircuitFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ExpressRouteCircuit.name",
	"resource_group":   "description.ResourceGroup",
}

func GetExpressRouteCircuit(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetExpressRouteCircuit")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewExpressRouteCircuitPaginator(buildFilter(d.KeyColumnQuals, getExpressRouteCircuitFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ExpressRouteCircuit =============================

// ==========================  START: VirtualNetworkGateway =============================

type VirtualNetworkGateway struct {
	Description   azure.VirtualNetworkGatewayDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type VirtualNetworkGatewayHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  VirtualNetworkGateway `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type VirtualNetworkGatewayHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []VirtualNetworkGatewayHit `json:"hits"`
}

type VirtualNetworkGatewaySearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  VirtualNetworkGatewayHits `json:"hits"`
}

type VirtualNetworkGatewayPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewVirtualNetworkGatewayPaginator(filters []BoolFilter, limit *int64) (VirtualNetworkGatewayPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_virtualnetworkgateway", filters, limit)
	if err != nil {
		return VirtualNetworkGatewayPaginator{}, err
	}

	p := VirtualNetworkGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p VirtualNetworkGatewayPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p VirtualNetworkGatewayPaginator) NextPage(ctx context.Context) ([]VirtualNetworkGateway, error) {
	var response VirtualNetworkGatewaySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []VirtualNetworkGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listVirtualNetworkGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListVirtualNetworkGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListVirtualNetworkGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewVirtualNetworkGatewayPaginator(buildFilter(d.KeyColumnQuals, listVirtualNetworkGatewayFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getVirtualNetworkGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.VirtualNetworkGateway.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetVirtualNetworkGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetVirtualNetworkGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewVirtualNetworkGatewayPaginator(buildFilter(d.KeyColumnQuals, getVirtualNetworkGatewayFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: VirtualNetworkGateway =============================

// ==========================  START: DNSZone =============================

type DNSZone struct {
	Description   azure.DNSZoneDescription `json:"description"`
	Metadata      azure.Metadata           `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	ARN           string                   `json:"arn"`
	SourceID      string                   `json:"source_id"`
}

type DNSZoneHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  DNSZone       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type DNSZoneHits struct {
	Total SearchTotal  `json:"total"`
	Hits  []DNSZoneHit `json:"hits"`
}

type DNSZoneSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  DNSZoneHits `json:"hits"`
}

type DNSZonePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDNSZonePaginator(filters []BoolFilter, limit *int64) (DNSZonePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_dnszone", filters, limit)
	if err != nil {
		return DNSZonePaginator{}, err
	}

	p := DNSZonePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DNSZonePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DNSZonePaginator) NextPage(ctx context.Context) ([]DNSZone, error) {
	var response DNSZoneSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DNSZone
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDNSZoneFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDNSZone(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDNSZone")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDNSZonePaginator(buildFilter(d.KeyColumnQuals, listDNSZoneFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDNSZoneFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Zone.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetDNSZone(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDNSZone")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDNSZonePaginator(buildFilter(d.KeyColumnQuals, getDNSZoneFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DNSZone =============================

// ==========================  START: FirewallPolicy =============================

type FirewallPolicy struct {
	Description   azure.FirewallPolicyDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type FirewallPolicyHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  FirewallPolicy `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type FirewallPolicyHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []FirewallPolicyHit `json:"hits"`
}

type FirewallPolicySearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  FirewallPolicyHits `json:"hits"`
}

type FirewallPolicyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewFirewallPolicyPaginator(filters []BoolFilter, limit *int64) (FirewallPolicyPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_firewallpolicy", filters, limit)
	if err != nil {
		return FirewallPolicyPaginator{}, err
	}

	p := FirewallPolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p FirewallPolicyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p FirewallPolicyPaginator) NextPage(ctx context.Context) ([]FirewallPolicy, error) {
	var response FirewallPolicySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []FirewallPolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listFirewallPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListFirewallPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListFirewallPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewFirewallPolicyPaginator(buildFilter(d.KeyColumnQuals, listFirewallPolicyFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getFirewallPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.FirewallPolicy.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetFirewallPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetFirewallPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewFirewallPolicyPaginator(buildFilter(d.KeyColumnQuals, getFirewallPolicyFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: FirewallPolicy =============================

// ==========================  START: FrontdoorWebApplicationFirewallPolicy =============================

type FrontdoorWebApplicationFirewallPolicy struct {
	Description   azure.FrontdoorWebApplicationFirewallPolicyDescription `json:"description"`
	Metadata      azure.Metadata                                         `json:"metadata"`
	ResourceJobID int                                                    `json:"resource_job_id"`
	SourceJobID   int                                                    `json:"source_job_id"`
	ResourceType  string                                                 `json:"resource_type"`
	SourceType    string                                                 `json:"source_type"`
	ID            string                                                 `json:"id"`
	ARN           string                                                 `json:"arn"`
	SourceID      string                                                 `json:"source_id"`
}

type FrontdoorWebApplicationFirewallPolicyHit struct {
	ID      string                                `json:"_id"`
	Score   float64                               `json:"_score"`
	Index   string                                `json:"_index"`
	Type    string                                `json:"_type"`
	Version int64                                 `json:"_version,omitempty"`
	Source  FrontdoorWebApplicationFirewallPolicy `json:"_source"`
	Sort    []interface{}                         `json:"sort"`
}

type FrontdoorWebApplicationFirewallPolicyHits struct {
	Total SearchTotal                                `json:"total"`
	Hits  []FrontdoorWebApplicationFirewallPolicyHit `json:"hits"`
}

type FrontdoorWebApplicationFirewallPolicySearchResponse struct {
	PitID string                                    `json:"pit_id"`
	Hits  FrontdoorWebApplicationFirewallPolicyHits `json:"hits"`
}

type FrontdoorWebApplicationFirewallPolicyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewFrontdoorWebApplicationFirewallPolicyPaginator(filters []BoolFilter, limit *int64) (FrontdoorWebApplicationFirewallPolicyPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_frontdoorwebapplicationfirewallpolicy", filters, limit)
	if err != nil {
		return FrontdoorWebApplicationFirewallPolicyPaginator{}, err
	}

	p := FrontdoorWebApplicationFirewallPolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p FrontdoorWebApplicationFirewallPolicyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p FrontdoorWebApplicationFirewallPolicyPaginator) NextPage(ctx context.Context) ([]FrontdoorWebApplicationFirewallPolicy, error) {
	var response FrontdoorWebApplicationFirewallPolicySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []FrontdoorWebApplicationFirewallPolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listFrontdoorWebApplicationFirewallPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListFrontdoorWebApplicationFirewallPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListFrontdoorWebApplicationFirewallPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewFrontdoorWebApplicationFirewallPolicyPaginator(buildFilter(d.KeyColumnQuals, listFrontdoorWebApplicationFirewallPolicyFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getFrontdoorWebApplicationFirewallPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.WebApplicationFirewallPolicy.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetFrontdoorWebApplicationFirewallPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetFrontdoorWebApplicationFirewallPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewFrontdoorWebApplicationFirewallPolicyPaginator(buildFilter(d.KeyColumnQuals, getFrontdoorWebApplicationFirewallPolicyFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: FrontdoorWebApplicationFirewallPolicy =============================

// ==========================  START: LocalNetworkGateway =============================

type LocalNetworkGateway struct {
	Description   azure.LocalNetworkGatewayDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

type LocalNetworkGatewayHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  LocalNetworkGateway `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type LocalNetworkGatewayHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []LocalNetworkGatewayHit `json:"hits"`
}

type LocalNetworkGatewaySearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  LocalNetworkGatewayHits `json:"hits"`
}

type LocalNetworkGatewayPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewLocalNetworkGatewayPaginator(filters []BoolFilter, limit *int64) (LocalNetworkGatewayPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_localnetworkgateway", filters, limit)
	if err != nil {
		return LocalNetworkGatewayPaginator{}, err
	}

	p := LocalNetworkGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LocalNetworkGatewayPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p LocalNetworkGatewayPaginator) NextPage(ctx context.Context) ([]LocalNetworkGateway, error) {
	var response LocalNetworkGatewaySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LocalNetworkGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listLocalNetworkGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListLocalNetworkGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLocalNetworkGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewLocalNetworkGatewayPaginator(buildFilter(d.KeyColumnQuals, listLocalNetworkGatewayFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLocalNetworkGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.LocalNetworkGateway.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetLocalNetworkGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLocalNetworkGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewLocalNetworkGatewayPaginator(buildFilter(d.KeyColumnQuals, getLocalNetworkGatewayFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LocalNetworkGateway =============================

// ==========================  START: NatGateway =============================

type NatGateway struct {
	Description   azure.NatGatewayDescription `json:"description"`
	Metadata      azure.Metadata              `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

type NatGatewayHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  NatGateway    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type NatGatewayHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []NatGatewayHit `json:"hits"`
}

type NatGatewaySearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  NatGatewayHits `json:"hits"`
}

type NatGatewayPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewNatGatewayPaginator(filters []BoolFilter, limit *int64) (NatGatewayPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_natgateways", filters, limit)
	if err != nil {
		return NatGatewayPaginator{}, err
	}

	p := NatGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NatGatewayPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p NatGatewayPaginator) NextPage(ctx context.Context) ([]NatGateway, error) {
	var response NatGatewaySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NatGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listNatGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListNatGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNatGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewNatGatewayPaginator(buildFilter(d.KeyColumnQuals, listNatGatewayFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNatGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.NatGateway.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetNatGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNatGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewNatGatewayPaginator(buildFilter(d.KeyColumnQuals, getNatGatewayFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NatGateway =============================

// ==========================  START: PrivateLinkService =============================

type PrivateLinkService struct {
	Description   azure.PrivateLinkServiceDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type PrivateLinkServiceHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  PrivateLinkService `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type PrivateLinkServiceHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []PrivateLinkServiceHit `json:"hits"`
}

type PrivateLinkServiceSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  PrivateLinkServiceHits `json:"hits"`
}

type PrivateLinkServicePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewPrivateLinkServicePaginator(filters []BoolFilter, limit *int64) (PrivateLinkServicePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_privatelinkservice", filters, limit)
	if err != nil {
		return PrivateLinkServicePaginator{}, err
	}

	p := PrivateLinkServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PrivateLinkServicePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p PrivateLinkServicePaginator) NextPage(ctx context.Context) ([]PrivateLinkService, error) {
	var response PrivateLinkServiceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PrivateLinkService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listPrivateLinkServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListPrivateLinkService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPrivateLinkService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewPrivateLinkServicePaginator(buildFilter(d.KeyColumnQuals, listPrivateLinkServiceFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPrivateLinkServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.PrivateLinkService.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetPrivateLinkService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPrivateLinkService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewPrivateLinkServicePaginator(buildFilter(d.KeyColumnQuals, getPrivateLinkServiceFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PrivateLinkService =============================

// ==========================  START: RouteFilter =============================

type RouteFilter struct {
	Description   azure.RouteFilterDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type RouteFilterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  RouteFilter   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type RouteFilterHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []RouteFilterHit `json:"hits"`
}

type RouteFilterSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  RouteFilterHits `json:"hits"`
}

type RouteFilterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRouteFilterPaginator(filters []BoolFilter, limit *int64) (RouteFilterPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_routefilter", filters, limit)
	if err != nil {
		return RouteFilterPaginator{}, err
	}

	p := RouteFilterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RouteFilterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RouteFilterPaginator) NextPage(ctx context.Context) ([]RouteFilter, error) {
	var response RouteFilterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RouteFilter
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRouteFilterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRouteFilter(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRouteFilter")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRouteFilterPaginator(buildFilter(d.KeyColumnQuals, listRouteFilterFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRouteFilterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.RouteFilter.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetRouteFilter(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRouteFilter")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRouteFilterPaginator(buildFilter(d.KeyColumnQuals, getRouteFilterFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RouteFilter =============================

// ==========================  START: VpnGateway =============================

type VpnGateway struct {
	Description   azure.VpnGatewayDescription `json:"description"`
	Metadata      azure.Metadata              `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

type VpnGatewayHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  VpnGateway    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type VpnGatewayHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []VpnGatewayHit `json:"hits"`
}

type VpnGatewaySearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  VpnGatewayHits `json:"hits"`
}

type VpnGatewayPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewVpnGatewayPaginator(filters []BoolFilter, limit *int64) (VpnGatewayPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_vpngateway", filters, limit)
	if err != nil {
		return VpnGatewayPaginator{}, err
	}

	p := VpnGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p VpnGatewayPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p VpnGatewayPaginator) NextPage(ctx context.Context) ([]VpnGateway, error) {
	var response VpnGatewaySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []VpnGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listVpnGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListVpnGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListVpnGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewVpnGatewayPaginator(buildFilter(d.KeyColumnQuals, listVpnGatewayFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getVpnGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.VpnGateway.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetVpnGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetVpnGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewVpnGatewayPaginator(buildFilter(d.KeyColumnQuals, getVpnGatewayFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: VpnGateway =============================

// ==========================  START: PublicIPAddress =============================

type PublicIPAddress struct {
	Description   azure.PublicIPAddressDescription `json:"description"`
	Metadata      azure.Metadata                   `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type PublicIPAddressHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  PublicIPAddress `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type PublicIPAddressHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []PublicIPAddressHit `json:"hits"`
}

type PublicIPAddressSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  PublicIPAddressHits `json:"hits"`
}

type PublicIPAddressPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewPublicIPAddressPaginator(filters []BoolFilter, limit *int64) (PublicIPAddressPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_publicipaddresses", filters, limit)
	if err != nil {
		return PublicIPAddressPaginator{}, err
	}

	p := PublicIPAddressPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PublicIPAddressPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p PublicIPAddressPaginator) NextPage(ctx context.Context) ([]PublicIPAddress, error) {
	var response PublicIPAddressSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PublicIPAddress
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listPublicIPAddressFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListPublicIPAddress(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPublicIPAddress")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewPublicIPAddressPaginator(buildFilter(d.KeyColumnQuals, listPublicIPAddressFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPublicIPAddressFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.PublicIPAddress.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetPublicIPAddress(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPublicIPAddress")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewPublicIPAddressPaginator(buildFilter(d.KeyColumnQuals, getPublicIPAddressFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PublicIPAddress =============================

// ==========================  START: PolicyAssignment =============================

type PolicyAssignment struct {
	Description   azure.PolicyAssignmentDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type PolicyAssignmentHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  PolicyAssignment `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type PolicyAssignmentHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []PolicyAssignmentHit `json:"hits"`
}

type PolicyAssignmentSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  PolicyAssignmentHits `json:"hits"`
}

type PolicyAssignmentPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewPolicyAssignmentPaginator(filters []BoolFilter, limit *int64) (PolicyAssignmentPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_authorization_policyassignments", filters, limit)
	if err != nil {
		return PolicyAssignmentPaginator{}, err
	}

	p := PolicyAssignmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PolicyAssignmentPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p PolicyAssignmentPaginator) NextPage(ctx context.Context) ([]PolicyAssignment, error) {
	var response PolicyAssignmentSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PolicyAssignment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listPolicyAssignmentFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListPolicyAssignment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPolicyAssignment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewPolicyAssignmentPaginator(buildFilter(d.KeyColumnQuals, listPolicyAssignmentFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPolicyAssignmentFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Assignment.name",
}

func GetPolicyAssignment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPolicyAssignment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewPolicyAssignmentPaginator(buildFilter(d.KeyColumnQuals, getPolicyAssignmentFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PolicyAssignment =============================

// ==========================  START: RedisCache =============================

type RedisCache struct {
	Description   azure.RedisCacheDescription `json:"description"`
	Metadata      azure.Metadata              `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

type RedisCacheHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  RedisCache    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type RedisCacheHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []RedisCacheHit `json:"hits"`
}

type RedisCacheSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  RedisCacheHits `json:"hits"`
}

type RedisCachePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRedisCachePaginator(filters []BoolFilter, limit *int64) (RedisCachePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_cache_redis", filters, limit)
	if err != nil {
		return RedisCachePaginator{}, err
	}

	p := RedisCachePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RedisCachePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RedisCachePaginator) NextPage(ctx context.Context) ([]RedisCache, error) {
	var response RedisCacheSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RedisCache
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRedisCacheFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRedisCache(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRedisCache")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRedisCachePaginator(buildFilter(d.KeyColumnQuals, listRedisCacheFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRedisCacheFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ResourceType.name",
	"resource_group":   "description.ResourceGroup",
}

func GetRedisCache(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRedisCache")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRedisCachePaginator(buildFilter(d.KeyColumnQuals, getRedisCacheFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RedisCache =============================

// ==========================  START: ResourceLink =============================

type ResourceLink struct {
	Description   azure.ResourceLinkDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type ResourceLinkHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ResourceLink  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ResourceLinkHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []ResourceLinkHit `json:"hits"`
}

type ResourceLinkSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  ResourceLinkHits `json:"hits"`
}

type ResourceLinkPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewResourceLinkPaginator(filters []BoolFilter, limit *int64) (ResourceLinkPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_resources_links", filters, limit)
	if err != nil {
		return ResourceLinkPaginator{}, err
	}

	p := ResourceLinkPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ResourceLinkPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ResourceLinkPaginator) NextPage(ctx context.Context) ([]ResourceLink, error) {
	var response ResourceLinkSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ResourceLink
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listResourceLinkFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListResourceLink(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListResourceLink")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewResourceLinkPaginator(buildFilter(d.KeyColumnQuals, listResourceLinkFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getResourceLinkFilters = map[string]string{
	"id":               "description.ResourceLink.id",
	"keibi_account_id": "metadata.SourceID",
}

func GetResourceLink(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetResourceLink")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewResourceLinkPaginator(buildFilter(d.KeyColumnQuals, getResourceLinkFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ResourceLink =============================

// ==========================  START: RoleAssignment =============================

type RoleAssignment struct {
	Description   azure.RoleAssignmentDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type RoleAssignmentHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  RoleAssignment `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type RoleAssignmentHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []RoleAssignmentHit `json:"hits"`
}

type RoleAssignmentSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  RoleAssignmentHits `json:"hits"`
}

type RoleAssignmentPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRoleAssignmentPaginator(filters []BoolFilter, limit *int64) (RoleAssignmentPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_authorization_elevateaccessroleassignment", filters, limit)
	if err != nil {
		return RoleAssignmentPaginator{}, err
	}

	p := RoleAssignmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RoleAssignmentPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RoleAssignmentPaginator) NextPage(ctx context.Context) ([]RoleAssignment, error) {
	var response RoleAssignmentSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RoleAssignment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRoleAssignmentFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRoleAssignment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRoleAssignment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRoleAssignmentPaginator(buildFilter(d.KeyColumnQuals, listRoleAssignmentFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRoleAssignmentFilters = map[string]string{
	"id":               "description.RoleAssignment.id",
	"keibi_account_id": "metadata.SourceID",
}

func GetRoleAssignment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRoleAssignment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRoleAssignmentPaginator(buildFilter(d.KeyColumnQuals, getRoleAssignmentFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RoleAssignment =============================

// ==========================  START: RoleDefinition =============================

type RoleDefinition struct {
	Description   azure.RoleDefinitionDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type RoleDefinitionHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  RoleDefinition `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type RoleDefinitionHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []RoleDefinitionHit `json:"hits"`
}

type RoleDefinitionSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  RoleDefinitionHits `json:"hits"`
}

type RoleDefinitionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRoleDefinitionPaginator(filters []BoolFilter, limit *int64) (RoleDefinitionPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_authorization_roledefinitions", filters, limit)
	if err != nil {
		return RoleDefinitionPaginator{}, err
	}

	p := RoleDefinitionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RoleDefinitionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RoleDefinitionPaginator) NextPage(ctx context.Context) ([]RoleDefinition, error) {
	var response RoleDefinitionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RoleDefinition
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRoleDefinitionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRoleDefinition(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRoleDefinition")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRoleDefinitionPaginator(buildFilter(d.KeyColumnQuals, listRoleDefinitionFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRoleDefinitionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.RoleDefinition.name",
}

func GetRoleDefinition(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRoleDefinition")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRoleDefinitionPaginator(buildFilter(d.KeyColumnQuals, getRoleDefinitionFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RoleDefinition =============================

// ==========================  START: PolicyDefinition =============================

type PolicyDefinition struct {
	Description   azure.PolicyDefinitionDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type PolicyDefinitionHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  PolicyDefinition `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type PolicyDefinitionHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []PolicyDefinitionHit `json:"hits"`
}

type PolicyDefinitionSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  PolicyDefinitionHits `json:"hits"`
}

type PolicyDefinitionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewPolicyDefinitionPaginator(filters []BoolFilter, limit *int64) (PolicyDefinitionPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_authorization_policydefinition", filters, limit)
	if err != nil {
		return PolicyDefinitionPaginator{}, err
	}

	p := PolicyDefinitionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PolicyDefinitionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p PolicyDefinitionPaginator) NextPage(ctx context.Context) ([]PolicyDefinition, error) {
	var response PolicyDefinitionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PolicyDefinition
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listPolicyDefinitionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListPolicyDefinition(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPolicyDefinition")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewPolicyDefinitionPaginator(buildFilter(d.KeyColumnQuals, listPolicyDefinitionFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPolicyDefinitionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Definition.Name",
}

func GetPolicyDefinition(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPolicyDefinition")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewPolicyDefinitionPaginator(buildFilter(d.KeyColumnQuals, getPolicyDefinitionFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PolicyDefinition =============================

// ==========================  START: SecurityCenterAutoProvisioning =============================

type SecurityCenterAutoProvisioning struct {
	Description   azure.SecurityCenterAutoProvisioningDescription `json:"description"`
	Metadata      azure.Metadata                                  `json:"metadata"`
	ResourceJobID int                                             `json:"resource_job_id"`
	SourceJobID   int                                             `json:"source_job_id"`
	ResourceType  string                                          `json:"resource_type"`
	SourceType    string                                          `json:"source_type"`
	ID            string                                          `json:"id"`
	ARN           string                                          `json:"arn"`
	SourceID      string                                          `json:"source_id"`
}

type SecurityCenterAutoProvisioningHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  SecurityCenterAutoProvisioning `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type SecurityCenterAutoProvisioningHits struct {
	Total SearchTotal                         `json:"total"`
	Hits  []SecurityCenterAutoProvisioningHit `json:"hits"`
}

type SecurityCenterAutoProvisioningSearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  SecurityCenterAutoProvisioningHits `json:"hits"`
}

type SecurityCenterAutoProvisioningPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSecurityCenterAutoProvisioningPaginator(filters []BoolFilter, limit *int64) (SecurityCenterAutoProvisioningPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_security_autoprovisioningsettings", filters, limit)
	if err != nil {
		return SecurityCenterAutoProvisioningPaginator{}, err
	}

	p := SecurityCenterAutoProvisioningPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityCenterAutoProvisioningPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SecurityCenterAutoProvisioningPaginator) NextPage(ctx context.Context) ([]SecurityCenterAutoProvisioning, error) {
	var response SecurityCenterAutoProvisioningSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityCenterAutoProvisioning
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityCenterAutoProvisioningFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSecurityCenterAutoProvisioning(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityCenterAutoProvisioning")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSecurityCenterAutoProvisioningPaginator(buildFilter(d.KeyColumnQuals, listSecurityCenterAutoProvisioningFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityCenterAutoProvisioningFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.AutoProvisioningSetting.name",
}

func GetSecurityCenterAutoProvisioning(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityCenterAutoProvisioning")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSecurityCenterAutoProvisioningPaginator(buildFilter(d.KeyColumnQuals, getSecurityCenterAutoProvisioningFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityCenterAutoProvisioning =============================

// ==========================  START: SecurityCenterContact =============================

type SecurityCenterContact struct {
	Description   azure.SecurityCenterContactDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type SecurityCenterContactHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  SecurityCenterContact `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type SecurityCenterContactHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []SecurityCenterContactHit `json:"hits"`
}

type SecurityCenterContactSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  SecurityCenterContactHits `json:"hits"`
}

type SecurityCenterContactPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSecurityCenterContactPaginator(filters []BoolFilter, limit *int64) (SecurityCenterContactPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_security_securitycontacts", filters, limit)
	if err != nil {
		return SecurityCenterContactPaginator{}, err
	}

	p := SecurityCenterContactPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityCenterContactPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SecurityCenterContactPaginator) NextPage(ctx context.Context) ([]SecurityCenterContact, error) {
	var response SecurityCenterContactSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityCenterContact
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityCenterContactFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSecurityCenterContact(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityCenterContact")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSecurityCenterContactPaginator(buildFilter(d.KeyColumnQuals, listSecurityCenterContactFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityCenterContactFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Contact.name",
}

func GetSecurityCenterContact(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityCenterContact")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSecurityCenterContactPaginator(buildFilter(d.KeyColumnQuals, getSecurityCenterContactFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityCenterContact =============================

// ==========================  START: SecurityCenterJitNetworkAccessPolicy =============================

type SecurityCenterJitNetworkAccessPolicy struct {
	Description   azure.SecurityCenterJitNetworkAccessPolicyDescription `json:"description"`
	Metadata      azure.Metadata                                        `json:"metadata"`
	ResourceJobID int                                                   `json:"resource_job_id"`
	SourceJobID   int                                                   `json:"source_job_id"`
	ResourceType  string                                                `json:"resource_type"`
	SourceType    string                                                `json:"source_type"`
	ID            string                                                `json:"id"`
	ARN           string                                                `json:"arn"`
	SourceID      string                                                `json:"source_id"`
}

type SecurityCenterJitNetworkAccessPolicyHit struct {
	ID      string                               `json:"_id"`
	Score   float64                              `json:"_score"`
	Index   string                               `json:"_index"`
	Type    string                               `json:"_type"`
	Version int64                                `json:"_version,omitempty"`
	Source  SecurityCenterJitNetworkAccessPolicy `json:"_source"`
	Sort    []interface{}                        `json:"sort"`
}

type SecurityCenterJitNetworkAccessPolicyHits struct {
	Total SearchTotal                               `json:"total"`
	Hits  []SecurityCenterJitNetworkAccessPolicyHit `json:"hits"`
}

type SecurityCenterJitNetworkAccessPolicySearchResponse struct {
	PitID string                                   `json:"pit_id"`
	Hits  SecurityCenterJitNetworkAccessPolicyHits `json:"hits"`
}

type SecurityCenterJitNetworkAccessPolicyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSecurityCenterJitNetworkAccessPolicyPaginator(filters []BoolFilter, limit *int64) (SecurityCenterJitNetworkAccessPolicyPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_security_locations_jitnetworkaccesspolicies", filters, limit)
	if err != nil {
		return SecurityCenterJitNetworkAccessPolicyPaginator{}, err
	}

	p := SecurityCenterJitNetworkAccessPolicyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityCenterJitNetworkAccessPolicyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SecurityCenterJitNetworkAccessPolicyPaginator) NextPage(ctx context.Context) ([]SecurityCenterJitNetworkAccessPolicy, error) {
	var response SecurityCenterJitNetworkAccessPolicySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityCenterJitNetworkAccessPolicy
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityCenterJitNetworkAccessPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSecurityCenterJitNetworkAccessPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityCenterJitNetworkAccessPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSecurityCenterJitNetworkAccessPolicyPaginator(buildFilter(d.KeyColumnQuals, listSecurityCenterJitNetworkAccessPolicyFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityCenterJitNetworkAccessPolicyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetSecurityCenterJitNetworkAccessPolicy(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityCenterJitNetworkAccessPolicy")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSecurityCenterJitNetworkAccessPolicyPaginator(buildFilter(d.KeyColumnQuals, getSecurityCenterJitNetworkAccessPolicyFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityCenterJitNetworkAccessPolicy =============================

// ==========================  START: SecurityCenterSetting =============================

type SecurityCenterSetting struct {
	Description   azure.SecurityCenterSettingDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type SecurityCenterSettingHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  SecurityCenterSetting `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type SecurityCenterSettingHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []SecurityCenterSettingHit `json:"hits"`
}

type SecurityCenterSettingSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  SecurityCenterSettingHits `json:"hits"`
}

type SecurityCenterSettingPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSecurityCenterSettingPaginator(filters []BoolFilter, limit *int64) (SecurityCenterSettingPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_security_settings", filters, limit)
	if err != nil {
		return SecurityCenterSettingPaginator{}, err
	}

	p := SecurityCenterSettingPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityCenterSettingPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SecurityCenterSettingPaginator) NextPage(ctx context.Context) ([]SecurityCenterSetting, error) {
	var response SecurityCenterSettingSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityCenterSetting
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityCenterSettingFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSecurityCenterSetting(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityCenterSetting")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSecurityCenterSettingPaginator(buildFilter(d.KeyColumnQuals, listSecurityCenterSettingFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityCenterSettingFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Setting.name",
}

func GetSecurityCenterSetting(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityCenterSetting")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSecurityCenterSettingPaginator(buildFilter(d.KeyColumnQuals, getSecurityCenterSettingFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityCenterSetting =============================

// ==========================  START: SecurityCenterSubscriptionPricing =============================

type SecurityCenterSubscriptionPricing struct {
	Description   azure.SecurityCenterSubscriptionPricingDescription `json:"description"`
	Metadata      azure.Metadata                                     `json:"metadata"`
	ResourceJobID int                                                `json:"resource_job_id"`
	SourceJobID   int                                                `json:"source_job_id"`
	ResourceType  string                                             `json:"resource_type"`
	SourceType    string                                             `json:"source_type"`
	ID            string                                             `json:"id"`
	ARN           string                                             `json:"arn"`
	SourceID      string                                             `json:"source_id"`
}

type SecurityCenterSubscriptionPricingHit struct {
	ID      string                            `json:"_id"`
	Score   float64                           `json:"_score"`
	Index   string                            `json:"_index"`
	Type    string                            `json:"_type"`
	Version int64                             `json:"_version,omitempty"`
	Source  SecurityCenterSubscriptionPricing `json:"_source"`
	Sort    []interface{}                     `json:"sort"`
}

type SecurityCenterSubscriptionPricingHits struct {
	Total SearchTotal                            `json:"total"`
	Hits  []SecurityCenterSubscriptionPricingHit `json:"hits"`
}

type SecurityCenterSubscriptionPricingSearchResponse struct {
	PitID string                                `json:"pit_id"`
	Hits  SecurityCenterSubscriptionPricingHits `json:"hits"`
}

type SecurityCenterSubscriptionPricingPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSecurityCenterSubscriptionPricingPaginator(filters []BoolFilter, limit *int64) (SecurityCenterSubscriptionPricingPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_security_pricings", filters, limit)
	if err != nil {
		return SecurityCenterSubscriptionPricingPaginator{}, err
	}

	p := SecurityCenterSubscriptionPricingPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityCenterSubscriptionPricingPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SecurityCenterSubscriptionPricingPaginator) NextPage(ctx context.Context) ([]SecurityCenterSubscriptionPricing, error) {
	var response SecurityCenterSubscriptionPricingSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityCenterSubscriptionPricing
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityCenterSubscriptionPricingFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSecurityCenterSubscriptionPricing(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityCenterSubscriptionPricing")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSecurityCenterSubscriptionPricingPaginator(buildFilter(d.KeyColumnQuals, listSecurityCenterSubscriptionPricingFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityCenterSubscriptionPricingFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Pricing.name",
}

func GetSecurityCenterSubscriptionPricing(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityCenterSubscriptionPricing")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSecurityCenterSubscriptionPricingPaginator(buildFilter(d.KeyColumnQuals, getSecurityCenterSubscriptionPricingFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityCenterSubscriptionPricing =============================

// ==========================  START: SecurityCenterAutomation =============================

type SecurityCenterAutomation struct {
	Description   azure.SecurityCenterAutomationDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

type SecurityCenterAutomationHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  SecurityCenterAutomation `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type SecurityCenterAutomationHits struct {
	Total SearchTotal                   `json:"total"`
	Hits  []SecurityCenterAutomationHit `json:"hits"`
}

type SecurityCenterAutomationSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  SecurityCenterAutomationHits `json:"hits"`
}

type SecurityCenterAutomationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSecurityCenterAutomationPaginator(filters []BoolFilter, limit *int64) (SecurityCenterAutomationPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_security_automations", filters, limit)
	if err != nil {
		return SecurityCenterAutomationPaginator{}, err
	}

	p := SecurityCenterAutomationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityCenterAutomationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SecurityCenterAutomationPaginator) NextPage(ctx context.Context) ([]SecurityCenterAutomation, error) {
	var response SecurityCenterAutomationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityCenterAutomation
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityCenterAutomationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSecurityCenterAutomation(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityCenterAutomation")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSecurityCenterAutomationPaginator(buildFilter(d.KeyColumnQuals, listSecurityCenterAutomationFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityCenterAutomationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Automation.name",
	"resource_group":   "description.ResourceGroup",
}

func GetSecurityCenterAutomation(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityCenterAutomation")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSecurityCenterAutomationPaginator(buildFilter(d.KeyColumnQuals, getSecurityCenterAutomationFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityCenterAutomation =============================

// ==========================  START: SecurityCenterSubAssessment =============================

type SecurityCenterSubAssessment struct {
	Description   azure.SecurityCenterSubAssessmentDescription `json:"description"`
	Metadata      azure.Metadata                               `json:"metadata"`
	ResourceJobID int                                          `json:"resource_job_id"`
	SourceJobID   int                                          `json:"source_job_id"`
	ResourceType  string                                       `json:"resource_type"`
	SourceType    string                                       `json:"source_type"`
	ID            string                                       `json:"id"`
	ARN           string                                       `json:"arn"`
	SourceID      string                                       `json:"source_id"`
}

type SecurityCenterSubAssessmentHit struct {
	ID      string                      `json:"_id"`
	Score   float64                     `json:"_score"`
	Index   string                      `json:"_index"`
	Type    string                      `json:"_type"`
	Version int64                       `json:"_version,omitempty"`
	Source  SecurityCenterSubAssessment `json:"_source"`
	Sort    []interface{}               `json:"sort"`
}

type SecurityCenterSubAssessmentHits struct {
	Total SearchTotal                      `json:"total"`
	Hits  []SecurityCenterSubAssessmentHit `json:"hits"`
}

type SecurityCenterSubAssessmentSearchResponse struct {
	PitID string                          `json:"pit_id"`
	Hits  SecurityCenterSubAssessmentHits `json:"hits"`
}

type SecurityCenterSubAssessmentPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSecurityCenterSubAssessmentPaginator(filters []BoolFilter, limit *int64) (SecurityCenterSubAssessmentPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_security_subassessments", filters, limit)
	if err != nil {
		return SecurityCenterSubAssessmentPaginator{}, err
	}

	p := SecurityCenterSubAssessmentPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SecurityCenterSubAssessmentPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SecurityCenterSubAssessmentPaginator) NextPage(ctx context.Context) ([]SecurityCenterSubAssessment, error) {
	var response SecurityCenterSubAssessmentSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SecurityCenterSubAssessment
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSecurityCenterSubAssessmentFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSecurityCenterSubAssessment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSecurityCenterSubAssessment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSecurityCenterSubAssessmentPaginator(buildFilter(d.KeyColumnQuals, listSecurityCenterSubAssessmentFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSecurityCenterSubAssessmentFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetSecurityCenterSubAssessment(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSecurityCenterSubAssessment")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSecurityCenterSubAssessmentPaginator(buildFilter(d.KeyColumnQuals, getSecurityCenterSubAssessmentFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SecurityCenterSubAssessment =============================

// ==========================  START: StorageContainer =============================

type StorageContainer struct {
	Description   azure.StorageContainerDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type StorageContainerHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  StorageContainer `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type StorageContainerHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []StorageContainerHit `json:"hits"`
}

type StorageContainerSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  StorageContainerHits `json:"hits"`
}

type StorageContainerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewStorageContainerPaginator(filters []BoolFilter, limit *int64) (StorageContainerPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_storage_storageaccounts_containers", filters, limit)
	if err != nil {
		return StorageContainerPaginator{}, err
	}

	p := StorageContainerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageContainerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p StorageContainerPaginator) NextPage(ctx context.Context) ([]StorageContainer, error) {
	var response StorageContainerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageContainer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listStorageContainerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListStorageContainer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageContainer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewStorageContainerPaginator(buildFilter(d.KeyColumnQuals, listStorageContainerFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageContainerFilters = map[string]string{
	"account_name":     "description.AccountName",
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ListContainerItem.name",
	"resource_group":   "description.ResourceGroup",
}

func GetStorageContainer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageContainer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewStorageContainerPaginator(buildFilter(d.KeyColumnQuals, getStorageContainerFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageContainer =============================

// ==========================  START: StorageBlob =============================

type StorageBlob struct {
	Description   azure.StorageBlobDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type StorageBlobHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  StorageBlob   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type StorageBlobHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []StorageBlobHit `json:"hits"`
}

type StorageBlobSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  StorageBlobHits `json:"hits"`
}

type StorageBlobPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewStorageBlobPaginator(filters []BoolFilter, limit *int64) (StorageBlobPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_storage_blobs", filters, limit)
	if err != nil {
		return StorageBlobPaginator{}, err
	}

	p := StorageBlobPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageBlobPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p StorageBlobPaginator) NextPage(ctx context.Context) ([]StorageBlob, error) {
	var response StorageBlobSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageBlob
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listStorageBlobFilters = map[string]string{
	"keibi_account_id":     "metadata.SourceID",
	"resource_group":       "description.ResourceGroup",
	"storage_account_name": "description.AccountName",
}

func ListStorageBlob(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageBlob")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewStorageBlobPaginator(buildFilter(d.KeyColumnQuals, listStorageBlobFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageBlobFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetStorageBlob(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageBlob")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewStorageBlobPaginator(buildFilter(d.KeyColumnQuals, getStorageBlobFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageBlob =============================

// ==========================  START: StorageBlobService =============================

type StorageBlobService struct {
	Description   azure.StorageBlobServiceDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type StorageBlobServiceHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  StorageBlobService `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type StorageBlobServiceHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []StorageBlobServiceHit `json:"hits"`
}

type StorageBlobServiceSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  StorageBlobServiceHits `json:"hits"`
}

type StorageBlobServicePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewStorageBlobServicePaginator(filters []BoolFilter, limit *int64) (StorageBlobServicePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_storage_blobservices", filters, limit)
	if err != nil {
		return StorageBlobServicePaginator{}, err
	}

	p := StorageBlobServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageBlobServicePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p StorageBlobServicePaginator) NextPage(ctx context.Context) ([]StorageBlobService, error) {
	var response StorageBlobServiceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageBlobService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listStorageBlobServiceFilters = map[string]string{
	"keibi_account_id":     "metadata.SourceID",
	"resource_group":       "description.ResourceGroup",
	"storage_account_name": "description.AccountName",
}

func ListStorageBlobService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageBlobService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewStorageBlobServicePaginator(buildFilter(d.KeyColumnQuals, listStorageBlobServiceFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageBlobServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetStorageBlobService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageBlobService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewStorageBlobServicePaginator(buildFilter(d.KeyColumnQuals, getStorageBlobServiceFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageBlobService =============================

// ==========================  START: StorageQueue =============================

type StorageQueue struct {
	Description   azure.StorageQueueDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type StorageQueueHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  StorageQueue  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type StorageQueueHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []StorageQueueHit `json:"hits"`
}

type StorageQueueSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  StorageQueueHits `json:"hits"`
}

type StorageQueuePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewStorageQueuePaginator(filters []BoolFilter, limit *int64) (StorageQueuePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_storage_queues", filters, limit)
	if err != nil {
		return StorageQueuePaginator{}, err
	}

	p := StorageQueuePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageQueuePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p StorageQueuePaginator) NextPage(ctx context.Context) ([]StorageQueue, error) {
	var response StorageQueueSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageQueue
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listStorageQueueFilters = map[string]string{
	"keibi_account_id":     "metadata.SourceID",
	"name":                 "description.Queue.Name",
	"resource_group":       "description.ResourceGroup",
	"storage_account_name": "description.AccountName",
}

func ListStorageQueue(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageQueue")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewStorageQueuePaginator(buildFilter(d.KeyColumnQuals, listStorageQueueFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageQueueFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetStorageQueue(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageQueue")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewStorageQueuePaginator(buildFilter(d.KeyColumnQuals, getStorageQueueFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageQueue =============================

// ==========================  START: StorageFileShare =============================

type StorageFileShare struct {
	Description   azure.StorageFileShareDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type StorageFileShareHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  StorageFileShare `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type StorageFileShareHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []StorageFileShareHit `json:"hits"`
}

type StorageFileShareSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  StorageFileShareHits `json:"hits"`
}

type StorageFileSharePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewStorageFileSharePaginator(filters []BoolFilter, limit *int64) (StorageFileSharePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_storage_fileshares", filters, limit)
	if err != nil {
		return StorageFileSharePaginator{}, err
	}

	p := StorageFileSharePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageFileSharePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p StorageFileSharePaginator) NextPage(ctx context.Context) ([]StorageFileShare, error) {
	var response StorageFileShareSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageFileShare
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listStorageFileShareFilters = map[string]string{
	"keibi_account_id":     "metadata.SourceID",
	"name":                 "description.FileShare.Name",
	"resource_group":       "description.ResourceGroup",
	"storage_account_name": "description.AccountName",
}

func ListStorageFileShare(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageFileShare")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewStorageFileSharePaginator(buildFilter(d.KeyColumnQuals, listStorageFileShareFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageFileShareFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetStorageFileShare(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageFileShare")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewStorageFileSharePaginator(buildFilter(d.KeyColumnQuals, getStorageFileShareFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageFileShare =============================

// ==========================  START: StorageTable =============================

type StorageTable struct {
	Description   azure.StorageTableDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type StorageTableHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  StorageTable  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type StorageTableHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []StorageTableHit `json:"hits"`
}

type StorageTableSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  StorageTableHits `json:"hits"`
}

type StorageTablePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewStorageTablePaginator(filters []BoolFilter, limit *int64) (StorageTablePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_storage_tables", filters, limit)
	if err != nil {
		return StorageTablePaginator{}, err
	}

	p := StorageTablePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageTablePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p StorageTablePaginator) NextPage(ctx context.Context) ([]StorageTable, error) {
	var response StorageTableSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageTable
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listStorageTableFilters = map[string]string{
	"keibi_account_id":     "metadata.SourceID",
	"name":                 "description.Table.Name",
	"resource_group":       "description.ResourceGroup",
	"storage_account_name": "description.AccountName",
}

func ListStorageTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewStorageTablePaginator(buildFilter(d.KeyColumnQuals, listStorageTableFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageTableFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetStorageTable(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageTable")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewStorageTablePaginator(buildFilter(d.KeyColumnQuals, getStorageTableFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageTable =============================

// ==========================  START: StorageTableService =============================

type StorageTableService struct {
	Description   azure.StorageTableServiceDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

type StorageTableServiceHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  StorageTableService `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type StorageTableServiceHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []StorageTableServiceHit `json:"hits"`
}

type StorageTableServiceSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  StorageTableServiceHits `json:"hits"`
}

type StorageTableServicePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewStorageTableServicePaginator(filters []BoolFilter, limit *int64) (StorageTableServicePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_storage_tableservices", filters, limit)
	if err != nil {
		return StorageTableServicePaginator{}, err
	}

	p := StorageTableServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageTableServicePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p StorageTableServicePaginator) NextPage(ctx context.Context) ([]StorageTableService, error) {
	var response StorageTableServiceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageTableService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listStorageTableServiceFilters = map[string]string{
	"keibi_account_id":     "metadata.SourceID",
	"name":                 "description.TableService.Name",
	"resource_group":       "description.ResourceGroup",
	"storage_account_name": "description.AccountName",
}

func ListStorageTableService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageTableService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewStorageTableServicePaginator(buildFilter(d.KeyColumnQuals, listStorageTableServiceFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageTableServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetStorageTableService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageTableService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewStorageTableServicePaginator(buildFilter(d.KeyColumnQuals, getStorageTableServiceFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageTableService =============================

// ==========================  START: Subnet =============================

type Subnet struct {
	Description   azure.SubnetDescription `json:"description"`
	Metadata      azure.Metadata          `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

type SubnetHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  Subnet        `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type SubnetHits struct {
	Total SearchTotal `json:"total"`
	Hits  []SubnetHit `json:"hits"`
}

type SubnetSearchResponse struct {
	PitID string     `json:"pit_id"`
	Hits  SubnetHits `json:"hits"`
}

type SubnetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSubnetPaginator(filters []BoolFilter, limit *int64) (SubnetPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_virtualnetworks_subnets", filters, limit)
	if err != nil {
		return SubnetPaginator{}, err
	}

	p := SubnetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SubnetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SubnetPaginator) NextPage(ctx context.Context) ([]Subnet, error) {
	var response SubnetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []Subnet
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSubnetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSubnet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSubnet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSubnetPaginator(buildFilter(d.KeyColumnQuals, listSubnetFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSubnetFilters = map[string]string{
	"keibi_account_id":     "metadata.SourceID",
	"name":                 "description.Subnet.name",
	"resource_group":       "description.ResourceGroup",
	"virtual_network_name": "description.VirtualNetworkName",
}

func GetSubnet(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSubnet")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSubnetPaginator(buildFilter(d.KeyColumnQuals, getSubnetFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: Subnet =============================

// ==========================  START: VirtualNetwork =============================

type VirtualNetwork struct {
	Description   azure.VirtualNetworkDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type VirtualNetworkHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  VirtualNetwork `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type VirtualNetworkHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []VirtualNetworkHit `json:"hits"`
}

type VirtualNetworkSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  VirtualNetworkHits `json:"hits"`
}

type VirtualNetworkPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewVirtualNetworkPaginator(filters []BoolFilter, limit *int64) (VirtualNetworkPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_virtualnetworks", filters, limit)
	if err != nil {
		return VirtualNetworkPaginator{}, err
	}

	p := VirtualNetworkPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p VirtualNetworkPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p VirtualNetworkPaginator) NextPage(ctx context.Context) ([]VirtualNetwork, error) {
	var response VirtualNetworkSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []VirtualNetwork
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listVirtualNetworkFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListVirtualNetwork(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListVirtualNetwork")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewVirtualNetworkPaginator(buildFilter(d.KeyColumnQuals, listVirtualNetworkFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getVirtualNetworkFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.VirtualNetwork.name",
	"resource_group":   "description.ResourceGroup",
}

func GetVirtualNetwork(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetVirtualNetwork")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewVirtualNetworkPaginator(buildFilter(d.KeyColumnQuals, getVirtualNetworkFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: VirtualNetwork =============================

// ==========================  START: Tenant =============================

type Tenant struct {
	Description   azure.TenantDescription `json:"description"`
	Metadata      azure.Metadata          `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

type TenantHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  Tenant        `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type TenantHits struct {
	Total SearchTotal `json:"total"`
	Hits  []TenantHit `json:"hits"`
}

type TenantSearchResponse struct {
	PitID string     `json:"pit_id"`
	Hits  TenantHits `json:"hits"`
}

type TenantPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewTenantPaginator(filters []BoolFilter, limit *int64) (TenantPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_resources_tenants", filters, limit)
	if err != nil {
		return TenantPaginator{}, err
	}

	p := TenantPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p TenantPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p TenantPaginator) NextPage(ctx context.Context) ([]Tenant, error) {
	var response TenantSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []Tenant
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listTenantFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListTenant(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListTenant")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewTenantPaginator(buildFilter(d.KeyColumnQuals, listTenantFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getTenantFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetTenant(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetTenant")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewTenantPaginator(buildFilter(d.KeyColumnQuals, getTenantFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: Tenant =============================

// ==========================  START: Subscription =============================

type Subscription struct {
	Description   azure.SubscriptionDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type SubscriptionHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  Subscription  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type SubscriptionHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []SubscriptionHit `json:"hits"`
}

type SubscriptionSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  SubscriptionHits `json:"hits"`
}

type SubscriptionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSubscriptionPaginator(filters []BoolFilter, limit *int64) (SubscriptionPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_resources_subscriptions", filters, limit)
	if err != nil {
		return SubscriptionPaginator{}, err
	}

	p := SubscriptionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SubscriptionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SubscriptionPaginator) NextPage(ctx context.Context) ([]Subscription, error) {
	var response SubscriptionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []Subscription
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSubscriptionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSubscription")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSubscriptionPaginator(buildFilter(d.KeyColumnQuals, listSubscriptionFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSubscriptionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetSubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSubscription")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSubscriptionPaginator(buildFilter(d.KeyColumnQuals, getSubscriptionFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: Subscription =============================

// ==========================  START: ApplicationGateway =============================

type ApplicationGateway struct {
	Description   azure.ApplicationGatewayDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type ApplicationGatewayHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  ApplicationGateway `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type ApplicationGatewayHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []ApplicationGatewayHit `json:"hits"`
}

type ApplicationGatewaySearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  ApplicationGatewayHits `json:"hits"`
}

type ApplicationGatewayPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewApplicationGatewayPaginator(filters []BoolFilter, limit *int64) (ApplicationGatewayPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_applicationgateways", filters, limit)
	if err != nil {
		return ApplicationGatewayPaginator{}, err
	}

	p := ApplicationGatewayPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ApplicationGatewayPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ApplicationGatewayPaginator) NextPage(ctx context.Context) ([]ApplicationGateway, error) {
	var response ApplicationGatewaySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ApplicationGateway
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listApplicationGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListApplicationGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListApplicationGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewApplicationGatewayPaginator(buildFilter(d.KeyColumnQuals, listApplicationGatewayFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getApplicationGatewayFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ApplicationGateway.name",
	"resource_group":   "description.ResourceGroup",
}

func GetApplicationGateway(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetApplicationGateway")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewApplicationGatewayPaginator(buildFilter(d.KeyColumnQuals, getApplicationGatewayFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ApplicationGateway =============================

// ==========================  START: BatchAccount =============================

type BatchAccount struct {
	Description   azure.BatchAccountDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type BatchAccountHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  BatchAccount  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type BatchAccountHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []BatchAccountHit `json:"hits"`
}

type BatchAccountSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  BatchAccountHits `json:"hits"`
}

type BatchAccountPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewBatchAccountPaginator(filters []BoolFilter, limit *int64) (BatchAccountPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_batch_batchaccounts", filters, limit)
	if err != nil {
		return BatchAccountPaginator{}, err
	}

	p := BatchAccountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p BatchAccountPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p BatchAccountPaginator) NextPage(ctx context.Context) ([]BatchAccount, error) {
	var response BatchAccountSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []BatchAccount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listBatchAccountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListBatchAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListBatchAccount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewBatchAccountPaginator(buildFilter(d.KeyColumnQuals, listBatchAccountFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getBatchAccountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Account.name",
	"resource_group":   "description.ResourceGroup",
}

func GetBatchAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetBatchAccount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewBatchAccountPaginator(buildFilter(d.KeyColumnQuals, getBatchAccountFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: BatchAccount =============================

// ==========================  START: CognitiveAccount =============================

type CognitiveAccount struct {
	Description   azure.CognitiveAccountDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type CognitiveAccountHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  CognitiveAccount `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type CognitiveAccountHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []CognitiveAccountHit `json:"hits"`
}

type CognitiveAccountSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  CognitiveAccountHits `json:"hits"`
}

type CognitiveAccountPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCognitiveAccountPaginator(filters []BoolFilter, limit *int64) (CognitiveAccountPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_cognitiveservices_accounts", filters, limit)
	if err != nil {
		return CognitiveAccountPaginator{}, err
	}

	p := CognitiveAccountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CognitiveAccountPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CognitiveAccountPaginator) NextPage(ctx context.Context) ([]CognitiveAccount, error) {
	var response CognitiveAccountSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CognitiveAccount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCognitiveAccountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCognitiveAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCognitiveAccount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCognitiveAccountPaginator(buildFilter(d.KeyColumnQuals, listCognitiveAccountFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCognitiveAccountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Account.name",
	"resource_group":   "description.ResourceGroup",
}

func GetCognitiveAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCognitiveAccount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCognitiveAccountPaginator(buildFilter(d.KeyColumnQuals, getCognitiveAccountFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CognitiveAccount =============================

// ==========================  START: ComputeVirtualMachine =============================

type ComputeVirtualMachine struct {
	Description   azure.ComputeVirtualMachineDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type ComputeVirtualMachineHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  ComputeVirtualMachine `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type ComputeVirtualMachineHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []ComputeVirtualMachineHit `json:"hits"`
}

type ComputeVirtualMachineSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  ComputeVirtualMachineHits `json:"hits"`
}

type ComputeVirtualMachinePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeVirtualMachinePaginator(filters []BoolFilter, limit *int64) (ComputeVirtualMachinePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_virtualmachines", filters, limit)
	if err != nil {
		return ComputeVirtualMachinePaginator{}, err
	}

	p := ComputeVirtualMachinePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeVirtualMachinePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeVirtualMachinePaginator) NextPage(ctx context.Context) ([]ComputeVirtualMachine, error) {
	var response ComputeVirtualMachineSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeVirtualMachine
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeVirtualMachineFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeVirtualMachine(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeVirtualMachine")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeVirtualMachinePaginator(buildFilter(d.KeyColumnQuals, listComputeVirtualMachineFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeVirtualMachineFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.VirtualMachine.name",
	"resource_group":   "description.ResourceGroup",
}

func GetComputeVirtualMachine(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeVirtualMachine")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeVirtualMachinePaginator(buildFilter(d.KeyColumnQuals, getComputeVirtualMachineFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeVirtualMachine =============================

// ==========================  START: ComputeResourceSKU =============================

type ComputeResourceSKU struct {
	Description   azure.ComputeResourceSKUDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type ComputeResourceSKUHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  ComputeResourceSKU `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type ComputeResourceSKUHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []ComputeResourceSKUHit `json:"hits"`
}

type ComputeResourceSKUSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  ComputeResourceSKUHits `json:"hits"`
}

type ComputeResourceSKUPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeResourceSKUPaginator(filters []BoolFilter, limit *int64) (ComputeResourceSKUPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_resourcesku", filters, limit)
	if err != nil {
		return ComputeResourceSKUPaginator{}, err
	}

	p := ComputeResourceSKUPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeResourceSKUPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeResourceSKUPaginator) NextPage(ctx context.Context) ([]ComputeResourceSKU, error) {
	var response ComputeResourceSKUSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeResourceSKU
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeResourceSKUFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeResourceSKU(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeResourceSKU")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeResourceSKUPaginator(buildFilter(d.KeyColumnQuals, listComputeResourceSKUFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeResourceSKUFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetComputeResourceSKU(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeResourceSKU")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeResourceSKUPaginator(buildFilter(d.KeyColumnQuals, getComputeResourceSKUFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeResourceSKU =============================

// ==========================  START: ComputeVirtualMachineCpuUtilization =============================

type ComputeVirtualMachineCpuUtilization struct {
	Description   azure.ComputeVirtualMachineCpuUtilizationDescription `json:"description"`
	Metadata      azure.Metadata                                       `json:"metadata"`
	ResourceJobID int                                                  `json:"resource_job_id"`
	SourceJobID   int                                                  `json:"source_job_id"`
	ResourceType  string                                               `json:"resource_type"`
	SourceType    string                                               `json:"source_type"`
	ID            string                                               `json:"id"`
	ARN           string                                               `json:"arn"`
	SourceID      string                                               `json:"source_id"`
}

type ComputeVirtualMachineCpuUtilizationHit struct {
	ID      string                              `json:"_id"`
	Score   float64                             `json:"_score"`
	Index   string                              `json:"_index"`
	Type    string                              `json:"_type"`
	Version int64                               `json:"_version,omitempty"`
	Source  ComputeVirtualMachineCpuUtilization `json:"_source"`
	Sort    []interface{}                       `json:"sort"`
}

type ComputeVirtualMachineCpuUtilizationHits struct {
	Total SearchTotal                              `json:"total"`
	Hits  []ComputeVirtualMachineCpuUtilizationHit `json:"hits"`
}

type ComputeVirtualMachineCpuUtilizationSearchResponse struct {
	PitID string                                  `json:"pit_id"`
	Hits  ComputeVirtualMachineCpuUtilizationHits `json:"hits"`
}

type ComputeVirtualMachineCpuUtilizationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeVirtualMachineCpuUtilizationPaginator(filters []BoolFilter, limit *int64) (ComputeVirtualMachineCpuUtilizationPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_virtualmachinecpuutilization", filters, limit)
	if err != nil {
		return ComputeVirtualMachineCpuUtilizationPaginator{}, err
	}

	p := ComputeVirtualMachineCpuUtilizationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeVirtualMachineCpuUtilizationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeVirtualMachineCpuUtilizationPaginator) NextPage(ctx context.Context) ([]ComputeVirtualMachineCpuUtilization, error) {
	var response ComputeVirtualMachineCpuUtilizationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeVirtualMachineCpuUtilization
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeVirtualMachineCpuUtilizationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeVirtualMachineCpuUtilization(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeVirtualMachineCpuUtilization")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeVirtualMachineCpuUtilizationPaginator(buildFilter(d.KeyColumnQuals, listComputeVirtualMachineCpuUtilizationFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeVirtualMachineCpuUtilizationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetComputeVirtualMachineCpuUtilization(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeVirtualMachineCpuUtilization")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeVirtualMachineCpuUtilizationPaginator(buildFilter(d.KeyColumnQuals, getComputeVirtualMachineCpuUtilizationFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeVirtualMachineCpuUtilization =============================

// ==========================  START: ComputeVirtualMachineCpuUtilizationDaily =============================

type ComputeVirtualMachineCpuUtilizationDaily struct {
	Description   azure.ComputeVirtualMachineCpuUtilizationDailyDescription `json:"description"`
	Metadata      azure.Metadata                                            `json:"metadata"`
	ResourceJobID int                                                       `json:"resource_job_id"`
	SourceJobID   int                                                       `json:"source_job_id"`
	ResourceType  string                                                    `json:"resource_type"`
	SourceType    string                                                    `json:"source_type"`
	ID            string                                                    `json:"id"`
	ARN           string                                                    `json:"arn"`
	SourceID      string                                                    `json:"source_id"`
}

type ComputeVirtualMachineCpuUtilizationDailyHit struct {
	ID      string                                   `json:"_id"`
	Score   float64                                  `json:"_score"`
	Index   string                                   `json:"_index"`
	Type    string                                   `json:"_type"`
	Version int64                                    `json:"_version,omitempty"`
	Source  ComputeVirtualMachineCpuUtilizationDaily `json:"_source"`
	Sort    []interface{}                            `json:"sort"`
}

type ComputeVirtualMachineCpuUtilizationDailyHits struct {
	Total SearchTotal                                   `json:"total"`
	Hits  []ComputeVirtualMachineCpuUtilizationDailyHit `json:"hits"`
}

type ComputeVirtualMachineCpuUtilizationDailySearchResponse struct {
	PitID string                                       `json:"pit_id"`
	Hits  ComputeVirtualMachineCpuUtilizationDailyHits `json:"hits"`
}

type ComputeVirtualMachineCpuUtilizationDailyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeVirtualMachineCpuUtilizationDailyPaginator(filters []BoolFilter, limit *int64) (ComputeVirtualMachineCpuUtilizationDailyPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_virtualmachinecpuutilizationdaily", filters, limit)
	if err != nil {
		return ComputeVirtualMachineCpuUtilizationDailyPaginator{}, err
	}

	p := ComputeVirtualMachineCpuUtilizationDailyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeVirtualMachineCpuUtilizationDailyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeVirtualMachineCpuUtilizationDailyPaginator) NextPage(ctx context.Context) ([]ComputeVirtualMachineCpuUtilizationDaily, error) {
	var response ComputeVirtualMachineCpuUtilizationDailySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeVirtualMachineCpuUtilizationDaily
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeVirtualMachineCpuUtilizationDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeVirtualMachineCpuUtilizationDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeVirtualMachineCpuUtilizationDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeVirtualMachineCpuUtilizationDailyPaginator(buildFilter(d.KeyColumnQuals, listComputeVirtualMachineCpuUtilizationDailyFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeVirtualMachineCpuUtilizationDailyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetComputeVirtualMachineCpuUtilizationDaily(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeVirtualMachineCpuUtilizationDaily")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeVirtualMachineCpuUtilizationDailyPaginator(buildFilter(d.KeyColumnQuals, getComputeVirtualMachineCpuUtilizationDailyFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeVirtualMachineCpuUtilizationDaily =============================

// ==========================  START: ComputeVirtualMachineCpuUtilizationHourly =============================

type ComputeVirtualMachineCpuUtilizationHourly struct {
	Description   azure.ComputeVirtualMachineCpuUtilizationHourlyDescription `json:"description"`
	Metadata      azure.Metadata                                             `json:"metadata"`
	ResourceJobID int                                                        `json:"resource_job_id"`
	SourceJobID   int                                                        `json:"source_job_id"`
	ResourceType  string                                                     `json:"resource_type"`
	SourceType    string                                                     `json:"source_type"`
	ID            string                                                     `json:"id"`
	ARN           string                                                     `json:"arn"`
	SourceID      string                                                     `json:"source_id"`
}

type ComputeVirtualMachineCpuUtilizationHourlyHit struct {
	ID      string                                    `json:"_id"`
	Score   float64                                   `json:"_score"`
	Index   string                                    `json:"_index"`
	Type    string                                    `json:"_type"`
	Version int64                                     `json:"_version,omitempty"`
	Source  ComputeVirtualMachineCpuUtilizationHourly `json:"_source"`
	Sort    []interface{}                             `json:"sort"`
}

type ComputeVirtualMachineCpuUtilizationHourlyHits struct {
	Total SearchTotal                                    `json:"total"`
	Hits  []ComputeVirtualMachineCpuUtilizationHourlyHit `json:"hits"`
}

type ComputeVirtualMachineCpuUtilizationHourlySearchResponse struct {
	PitID string                                        `json:"pit_id"`
	Hits  ComputeVirtualMachineCpuUtilizationHourlyHits `json:"hits"`
}

type ComputeVirtualMachineCpuUtilizationHourlyPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewComputeVirtualMachineCpuUtilizationHourlyPaginator(filters []BoolFilter, limit *int64) (ComputeVirtualMachineCpuUtilizationHourlyPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_compute_virtualmachinecpuutilizationhourly", filters, limit)
	if err != nil {
		return ComputeVirtualMachineCpuUtilizationHourlyPaginator{}, err
	}

	p := ComputeVirtualMachineCpuUtilizationHourlyPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ComputeVirtualMachineCpuUtilizationHourlyPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ComputeVirtualMachineCpuUtilizationHourlyPaginator) NextPage(ctx context.Context) ([]ComputeVirtualMachineCpuUtilizationHourly, error) {
	var response ComputeVirtualMachineCpuUtilizationHourlySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ComputeVirtualMachineCpuUtilizationHourly
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listComputeVirtualMachineCpuUtilizationHourlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListComputeVirtualMachineCpuUtilizationHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListComputeVirtualMachineCpuUtilizationHourly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewComputeVirtualMachineCpuUtilizationHourlyPaginator(buildFilter(d.KeyColumnQuals, listComputeVirtualMachineCpuUtilizationHourlyFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getComputeVirtualMachineCpuUtilizationHourlyFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetComputeVirtualMachineCpuUtilizationHourly(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetComputeVirtualMachineCpuUtilizationHourly")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewComputeVirtualMachineCpuUtilizationHourlyPaginator(buildFilter(d.KeyColumnQuals, getComputeVirtualMachineCpuUtilizationHourlyFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ComputeVirtualMachineCpuUtilizationHourly =============================

// ==========================  START: ContainerRegistry =============================

type ContainerRegistry struct {
	Description   azure.ContainerRegistryDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type ContainerRegistryHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  ContainerRegistry `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type ContainerRegistryHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []ContainerRegistryHit `json:"hits"`
}

type ContainerRegistrySearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  ContainerRegistryHits `json:"hits"`
}

type ContainerRegistryPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewContainerRegistryPaginator(filters []BoolFilter, limit *int64) (ContainerRegistryPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_containerregistry_registries", filters, limit)
	if err != nil {
		return ContainerRegistryPaginator{}, err
	}

	p := ContainerRegistryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ContainerRegistryPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ContainerRegistryPaginator) NextPage(ctx context.Context) ([]ContainerRegistry, error) {
	var response ContainerRegistrySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ContainerRegistry
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listContainerRegistryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListContainerRegistry(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListContainerRegistry")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewContainerRegistryPaginator(buildFilter(d.KeyColumnQuals, listContainerRegistryFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getContainerRegistryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Registry.name",
	"resource_group":   "description.ResourceGroup",
}

func GetContainerRegistry(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetContainerRegistry")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewContainerRegistryPaginator(buildFilter(d.KeyColumnQuals, getContainerRegistryFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ContainerRegistry =============================

// ==========================  START: CosmosdbAccount =============================

type CosmosdbAccount struct {
	Description   azure.CosmosdbAccountDescription `json:"description"`
	Metadata      azure.Metadata                   `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type CosmosdbAccountHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  CosmosdbAccount `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type CosmosdbAccountHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []CosmosdbAccountHit `json:"hits"`
}

type CosmosdbAccountSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  CosmosdbAccountHits `json:"hits"`
}

type CosmosdbAccountPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCosmosdbAccountPaginator(filters []BoolFilter, limit *int64) (CosmosdbAccountPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_documentdb_databaseaccounts", filters, limit)
	if err != nil {
		return CosmosdbAccountPaginator{}, err
	}

	p := CosmosdbAccountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CosmosdbAccountPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CosmosdbAccountPaginator) NextPage(ctx context.Context) ([]CosmosdbAccount, error) {
	var response CosmosdbAccountSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CosmosdbAccount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCosmosdbAccountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCosmosdbAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCosmosdbAccount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCosmosdbAccountPaginator(buildFilter(d.KeyColumnQuals, listCosmosdbAccountFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCosmosdbAccountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.DatabaseAccountGetResults.name",
	"resource_group":   "description.ResourceGroup",
}

func GetCosmosdbAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCosmosdbAccount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCosmosdbAccountPaginator(buildFilter(d.KeyColumnQuals, getCosmosdbAccountFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CosmosdbAccount =============================

// ==========================  START: CosmosdbMongoDatabase =============================

type CosmosdbMongoDatabase struct {
	Description   azure.CosmosdbMongoDatabaseDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type CosmosdbMongoDatabaseHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  CosmosdbMongoDatabase `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type CosmosdbMongoDatabaseHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []CosmosdbMongoDatabaseHit `json:"hits"`
}

type CosmosdbMongoDatabaseSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  CosmosdbMongoDatabaseHits `json:"hits"`
}

type CosmosdbMongoDatabasePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCosmosdbMongoDatabasePaginator(filters []BoolFilter, limit *int64) (CosmosdbMongoDatabasePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_documentdb_mongodatabases", filters, limit)
	if err != nil {
		return CosmosdbMongoDatabasePaginator{}, err
	}

	p := CosmosdbMongoDatabasePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CosmosdbMongoDatabasePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CosmosdbMongoDatabasePaginator) NextPage(ctx context.Context) ([]CosmosdbMongoDatabase, error) {
	var response CosmosdbMongoDatabaseSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CosmosdbMongoDatabase
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCosmosdbMongoDatabaseFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCosmosdbMongoDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCosmosdbMongoDatabase")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCosmosdbMongoDatabasePaginator(buildFilter(d.KeyColumnQuals, listCosmosdbMongoDatabaseFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCosmosdbMongoDatabaseFilters = map[string]string{
	"account_name":     "description.Account.name",
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.MongoDatabase.name",
	"resource_group":   "description.ResourceGroup",
}

func GetCosmosdbMongoDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCosmosdbMongoDatabase")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCosmosdbMongoDatabasePaginator(buildFilter(d.KeyColumnQuals, getCosmosdbMongoDatabaseFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CosmosdbMongoDatabase =============================

// ==========================  START: CosmosdbSqlDatabase =============================

type CosmosdbSqlDatabase struct {
	Description   azure.CosmosdbSqlDatabaseDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

type CosmosdbSqlDatabaseHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  CosmosdbSqlDatabase `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type CosmosdbSqlDatabaseHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []CosmosdbSqlDatabaseHit `json:"hits"`
}

type CosmosdbSqlDatabaseSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  CosmosdbSqlDatabaseHits `json:"hits"`
}

type CosmosdbSqlDatabasePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCosmosdbSqlDatabasePaginator(filters []BoolFilter, limit *int64) (CosmosdbSqlDatabasePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_documentdb_sqldatabases", filters, limit)
	if err != nil {
		return CosmosdbSqlDatabasePaginator{}, err
	}

	p := CosmosdbSqlDatabasePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CosmosdbSqlDatabasePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CosmosdbSqlDatabasePaginator) NextPage(ctx context.Context) ([]CosmosdbSqlDatabase, error) {
	var response CosmosdbSqlDatabaseSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CosmosdbSqlDatabase
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCosmosdbSqlDatabaseFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCosmosdbSqlDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCosmosdbSqlDatabase")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCosmosdbSqlDatabasePaginator(buildFilter(d.KeyColumnQuals, listCosmosdbSqlDatabaseFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCosmosdbSqlDatabaseFilters = map[string]string{
	"account_name":     "description.Account.name",
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.SqlDatabase.name",
	"resource_group":   "description.ResourceGroup",
}

func GetCosmosdbSqlDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCosmosdbSqlDatabase")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCosmosdbSqlDatabasePaginator(buildFilter(d.KeyColumnQuals, getCosmosdbSqlDatabaseFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CosmosdbSqlDatabase =============================

// ==========================  START: DataFactory =============================

type DataFactory struct {
	Description   azure.DataFactoryDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type DataFactoryHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  DataFactory   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type DataFactoryHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []DataFactoryHit `json:"hits"`
}

type DataFactorySearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  DataFactoryHits `json:"hits"`
}

type DataFactoryPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDataFactoryPaginator(filters []BoolFilter, limit *int64) (DataFactoryPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_datafactory_datafactories", filters, limit)
	if err != nil {
		return DataFactoryPaginator{}, err
	}

	p := DataFactoryPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DataFactoryPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DataFactoryPaginator) NextPage(ctx context.Context) ([]DataFactory, error) {
	var response DataFactorySearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DataFactory
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDataFactoryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDataFactory(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDataFactory")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDataFactoryPaginator(buildFilter(d.KeyColumnQuals, listDataFactoryFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDataFactoryFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Factory.name",
	"resource_group":   "description.ResourceGroup",
}

func GetDataFactory(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDataFactory")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDataFactoryPaginator(buildFilter(d.KeyColumnQuals, getDataFactoryFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DataFactory =============================

// ==========================  START: DataFactoryDataset =============================

type DataFactoryDataset struct {
	Description   azure.DataFactoryDatasetDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type DataFactoryDatasetHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  DataFactoryDataset `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type DataFactoryDatasetHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []DataFactoryDatasetHit `json:"hits"`
}

type DataFactoryDatasetSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  DataFactoryDatasetHits `json:"hits"`
}

type DataFactoryDatasetPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDataFactoryDatasetPaginator(filters []BoolFilter, limit *int64) (DataFactoryDatasetPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_datafactory_datafactorydatasets", filters, limit)
	if err != nil {
		return DataFactoryDatasetPaginator{}, err
	}

	p := DataFactoryDatasetPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DataFactoryDatasetPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DataFactoryDatasetPaginator) NextPage(ctx context.Context) ([]DataFactoryDataset, error) {
	var response DataFactoryDatasetSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DataFactoryDataset
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDataFactoryDatasetFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDataFactoryDataset(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDataFactoryDataset")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDataFactoryDatasetPaginator(buildFilter(d.KeyColumnQuals, listDataFactoryDatasetFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDataFactoryDatasetFilters = map[string]string{
	"factory_name":     "description.Factory.name",
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Dataset.name",
	"resource_group":   "description.ResourceGroup",
}

func GetDataFactoryDataset(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDataFactoryDataset")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDataFactoryDatasetPaginator(buildFilter(d.KeyColumnQuals, getDataFactoryDatasetFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DataFactoryDataset =============================

// ==========================  START: DataFactoryPipeline =============================

type DataFactoryPipeline struct {
	Description   azure.DataFactoryPipelineDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

type DataFactoryPipelineHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  DataFactoryPipeline `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type DataFactoryPipelineHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []DataFactoryPipelineHit `json:"hits"`
}

type DataFactoryPipelineSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  DataFactoryPipelineHits `json:"hits"`
}

type DataFactoryPipelinePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDataFactoryPipelinePaginator(filters []BoolFilter, limit *int64) (DataFactoryPipelinePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_datafactory_datafactorypipelines", filters, limit)
	if err != nil {
		return DataFactoryPipelinePaginator{}, err
	}

	p := DataFactoryPipelinePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DataFactoryPipelinePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DataFactoryPipelinePaginator) NextPage(ctx context.Context) ([]DataFactoryPipeline, error) {
	var response DataFactoryPipelineSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DataFactoryPipeline
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDataFactoryPipelineFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDataFactoryPipeline(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDataFactoryPipeline")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDataFactoryPipelinePaginator(buildFilter(d.KeyColumnQuals, listDataFactoryPipelineFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDataFactoryPipelineFilters = map[string]string{
	"factory_name":     "description.Factory.name",
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Pipeline.name",
	"resource_group":   "description.ResourceGroup",
}

func GetDataFactoryPipeline(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDataFactoryPipeline")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDataFactoryPipelinePaginator(buildFilter(d.KeyColumnQuals, getDataFactoryPipelineFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DataFactoryPipeline =============================

// ==========================  START: DataLakeAnalyticsAccount =============================

type DataLakeAnalyticsAccount struct {
	Description   azure.DataLakeAnalyticsAccountDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

type DataLakeAnalyticsAccountHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  DataLakeAnalyticsAccount `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type DataLakeAnalyticsAccountHits struct {
	Total SearchTotal                   `json:"total"`
	Hits  []DataLakeAnalyticsAccountHit `json:"hits"`
}

type DataLakeAnalyticsAccountSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  DataLakeAnalyticsAccountHits `json:"hits"`
}

type DataLakeAnalyticsAccountPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDataLakeAnalyticsAccountPaginator(filters []BoolFilter, limit *int64) (DataLakeAnalyticsAccountPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_datalakeanalytics_accounts", filters, limit)
	if err != nil {
		return DataLakeAnalyticsAccountPaginator{}, err
	}

	p := DataLakeAnalyticsAccountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DataLakeAnalyticsAccountPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DataLakeAnalyticsAccountPaginator) NextPage(ctx context.Context) ([]DataLakeAnalyticsAccount, error) {
	var response DataLakeAnalyticsAccountSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DataLakeAnalyticsAccount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDataLakeAnalyticsAccountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDataLakeAnalyticsAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDataLakeAnalyticsAccount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDataLakeAnalyticsAccountPaginator(buildFilter(d.KeyColumnQuals, listDataLakeAnalyticsAccountFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDataLakeAnalyticsAccountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.DataLakeAnalyticsAccount.name",
	"resource_group":   "description.ResourceGroup",
}

func GetDataLakeAnalyticsAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDataLakeAnalyticsAccount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDataLakeAnalyticsAccountPaginator(buildFilter(d.KeyColumnQuals, getDataLakeAnalyticsAccountFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DataLakeAnalyticsAccount =============================

// ==========================  START: DataLakeStore =============================

type DataLakeStore struct {
	Description   azure.DataLakeStoreDescription `json:"description"`
	Metadata      azure.Metadata                 `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type DataLakeStoreHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  DataLakeStore `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type DataLakeStoreHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []DataLakeStoreHit `json:"hits"`
}

type DataLakeStoreSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  DataLakeStoreHits `json:"hits"`
}

type DataLakeStorePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDataLakeStorePaginator(filters []BoolFilter, limit *int64) (DataLakeStorePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_datalakestore_accounts", filters, limit)
	if err != nil {
		return DataLakeStorePaginator{}, err
	}

	p := DataLakeStorePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DataLakeStorePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DataLakeStorePaginator) NextPage(ctx context.Context) ([]DataLakeStore, error) {
	var response DataLakeStoreSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DataLakeStore
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDataLakeStoreFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDataLakeStore(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDataLakeStore")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDataLakeStorePaginator(buildFilter(d.KeyColumnQuals, listDataLakeStoreFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDataLakeStoreFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.DataLakeStoreAccount.name",
	"resource_group":   "description.ResourceGroup",
}

func GetDataLakeStore(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDataLakeStore")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDataLakeStorePaginator(buildFilter(d.KeyColumnQuals, getDataLakeStoreFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DataLakeStore =============================

// ==========================  START: DiagnosticSetting =============================

type DiagnosticSetting struct {
	Description   azure.DiagnosticSettingDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type DiagnosticSettingHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  DiagnosticSetting `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type DiagnosticSettingHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []DiagnosticSettingHit `json:"hits"`
}

type DiagnosticSettingSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  DiagnosticSettingHits `json:"hits"`
}

type DiagnosticSettingPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewDiagnosticSettingPaginator(filters []BoolFilter, limit *int64) (DiagnosticSettingPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_insights_guestdiagnosticsettings", filters, limit)
	if err != nil {
		return DiagnosticSettingPaginator{}, err
	}

	p := DiagnosticSettingPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p DiagnosticSettingPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p DiagnosticSettingPaginator) NextPage(ctx context.Context) ([]DiagnosticSetting, error) {
	var response DiagnosticSettingSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []DiagnosticSetting
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listDiagnosticSettingFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListDiagnosticSetting(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListDiagnosticSetting")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewDiagnosticSettingPaginator(buildFilter(d.KeyColumnQuals, listDiagnosticSettingFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getDiagnosticSettingFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.DiagnosticSettingsResource.name",
	"resource_group":   "description.ResourceGroup",
}

func GetDiagnosticSetting(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetDiagnosticSetting")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewDiagnosticSettingPaginator(buildFilter(d.KeyColumnQuals, getDiagnosticSettingFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: DiagnosticSetting =============================

// ==========================  START: EventGridDomain =============================

type EventGridDomain struct {
	Description   azure.EventGridDomainDescription `json:"description"`
	Metadata      azure.Metadata                   `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type EventGridDomainHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  EventGridDomain `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type EventGridDomainHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []EventGridDomainHit `json:"hits"`
}

type EventGridDomainSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  EventGridDomainHits `json:"hits"`
}

type EventGridDomainPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEventGridDomainPaginator(filters []BoolFilter, limit *int64) (EventGridDomainPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_eventgrid_domains", filters, limit)
	if err != nil {
		return EventGridDomainPaginator{}, err
	}

	p := EventGridDomainPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EventGridDomainPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EventGridDomainPaginator) NextPage(ctx context.Context) ([]EventGridDomain, error) {
	var response EventGridDomainSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EventGridDomain
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEventGridDomainFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEventGridDomain(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEventGridDomain")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEventGridDomainPaginator(buildFilter(d.KeyColumnQuals, listEventGridDomainFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEventGridDomainFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Domain.name",
	"resource_group":   "description.ResourceGroup",
}

func GetEventGridDomain(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEventGridDomain")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEventGridDomainPaginator(buildFilter(d.KeyColumnQuals, getEventGridDomainFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EventGridDomain =============================

// ==========================  START: EventGridTopic =============================

type EventGridTopic struct {
	Description   azure.EventGridTopicDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type EventGridTopicHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  EventGridTopic `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type EventGridTopicHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []EventGridTopicHit `json:"hits"`
}

type EventGridTopicSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  EventGridTopicHits `json:"hits"`
}

type EventGridTopicPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEventGridTopicPaginator(filters []BoolFilter, limit *int64) (EventGridTopicPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_eventgrid_topics", filters, limit)
	if err != nil {
		return EventGridTopicPaginator{}, err
	}

	p := EventGridTopicPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EventGridTopicPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EventGridTopicPaginator) NextPage(ctx context.Context) ([]EventGridTopic, error) {
	var response EventGridTopicSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EventGridTopic
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEventGridTopicFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEventGridTopic(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEventGridTopic")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEventGridTopicPaginator(buildFilter(d.KeyColumnQuals, listEventGridTopicFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEventGridTopicFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Topic.name",
	"resource_group":   "description.ResourceGroup",
}

func GetEventGridTopic(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEventGridTopic")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEventGridTopicPaginator(buildFilter(d.KeyColumnQuals, getEventGridTopicFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EventGridTopic =============================

// ==========================  START: EventhubNamespace =============================

type EventhubNamespace struct {
	Description   azure.EventhubNamespaceDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type EventhubNamespaceHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  EventhubNamespace `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type EventhubNamespaceHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []EventhubNamespaceHit `json:"hits"`
}

type EventhubNamespaceSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  EventhubNamespaceHits `json:"hits"`
}

type EventhubNamespacePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewEventhubNamespacePaginator(filters []BoolFilter, limit *int64) (EventhubNamespacePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_eventhub_namespaces", filters, limit)
	if err != nil {
		return EventhubNamespacePaginator{}, err
	}

	p := EventhubNamespacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p EventhubNamespacePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p EventhubNamespacePaginator) NextPage(ctx context.Context) ([]EventhubNamespace, error) {
	var response EventhubNamespaceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []EventhubNamespace
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listEventhubNamespaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListEventhubNamespace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListEventhubNamespace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewEventhubNamespacePaginator(buildFilter(d.KeyColumnQuals, listEventhubNamespaceFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getEventhubNamespaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.EHNamespace.name",
	"resource_group":   "description.ResourceGroup",
}

func GetEventhubNamespace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetEventhubNamespace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewEventhubNamespacePaginator(buildFilter(d.KeyColumnQuals, getEventhubNamespaceFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: EventhubNamespace =============================

// ==========================  START: Frontdoor =============================

type Frontdoor struct {
	Description   azure.FrontdoorDescription `json:"description"`
	Metadata      azure.Metadata             `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

type FrontdoorHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  Frontdoor     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type FrontdoorHits struct {
	Total SearchTotal    `json:"total"`
	Hits  []FrontdoorHit `json:"hits"`
}

type FrontdoorSearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  FrontdoorHits `json:"hits"`
}

type FrontdoorPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewFrontdoorPaginator(filters []BoolFilter, limit *int64) (FrontdoorPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_frontdoors", filters, limit)
	if err != nil {
		return FrontdoorPaginator{}, err
	}

	p := FrontdoorPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p FrontdoorPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p FrontdoorPaginator) NextPage(ctx context.Context) ([]Frontdoor, error) {
	var response FrontdoorSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []Frontdoor
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listFrontdoorFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListFrontdoor(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListFrontdoor")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewFrontdoorPaginator(buildFilter(d.KeyColumnQuals, listFrontdoorFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getFrontdoorFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.FrontDoor.name",
	"resource_group":   "description.ResourceGroup",
}

func GetFrontdoor(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetFrontdoor")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewFrontdoorPaginator(buildFilter(d.KeyColumnQuals, getFrontdoorFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: Frontdoor =============================

// ==========================  START: HdinsightCluster =============================

type HdinsightCluster struct {
	Description   azure.HdinsightClusterDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type HdinsightClusterHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  HdinsightCluster `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type HdinsightClusterHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []HdinsightClusterHit `json:"hits"`
}

type HdinsightClusterSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  HdinsightClusterHits `json:"hits"`
}

type HdinsightClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewHdinsightClusterPaginator(filters []BoolFilter, limit *int64) (HdinsightClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_hdinsight_clusterpools", filters, limit)
	if err != nil {
		return HdinsightClusterPaginator{}, err
	}

	p := HdinsightClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p HdinsightClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p HdinsightClusterPaginator) NextPage(ctx context.Context) ([]HdinsightCluster, error) {
	var response HdinsightClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []HdinsightCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listHdinsightClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListHdinsightCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListHdinsightCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewHdinsightClusterPaginator(buildFilter(d.KeyColumnQuals, listHdinsightClusterFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getHdinsightClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Cluster.name",
	"resource_group":   "description.ResourceGroup",
}

func GetHdinsightCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetHdinsightCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewHdinsightClusterPaginator(buildFilter(d.KeyColumnQuals, getHdinsightClusterFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: HdinsightCluster =============================

// ==========================  START: HybridComputeMachine =============================

type HybridComputeMachine struct {
	Description   azure.HybridComputeMachineDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type HybridComputeMachineHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  HybridComputeMachine `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type HybridComputeMachineHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []HybridComputeMachineHit `json:"hits"`
}

type HybridComputeMachineSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  HybridComputeMachineHits `json:"hits"`
}

type HybridComputeMachinePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewHybridComputeMachinePaginator(filters []BoolFilter, limit *int64) (HybridComputeMachinePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_hybridcompute_machines", filters, limit)
	if err != nil {
		return HybridComputeMachinePaginator{}, err
	}

	p := HybridComputeMachinePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p HybridComputeMachinePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p HybridComputeMachinePaginator) NextPage(ctx context.Context) ([]HybridComputeMachine, error) {
	var response HybridComputeMachineSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []HybridComputeMachine
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listHybridComputeMachineFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListHybridComputeMachine(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListHybridComputeMachine")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewHybridComputeMachinePaginator(buildFilter(d.KeyColumnQuals, listHybridComputeMachineFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getHybridComputeMachineFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Machine.name",
	"resource_group":   "description.ResourceGroup",
}

func GetHybridComputeMachine(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetHybridComputeMachine")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewHybridComputeMachinePaginator(buildFilter(d.KeyColumnQuals, getHybridComputeMachineFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: HybridComputeMachine =============================

// ==========================  START: IOTHub =============================

type IOTHub struct {
	Description   azure.IOTHubDescription `json:"description"`
	Metadata      azure.Metadata          `json:"metadata"`
	ResourceJobID int                     `json:"resource_job_id"`
	SourceJobID   int                     `json:"source_job_id"`
	ResourceType  string                  `json:"resource_type"`
	SourceType    string                  `json:"source_type"`
	ID            string                  `json:"id"`
	ARN           string                  `json:"arn"`
	SourceID      string                  `json:"source_id"`
}

type IOTHubHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IOTHub        `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IOTHubHits struct {
	Total SearchTotal `json:"total"`
	Hits  []IOTHubHit `json:"hits"`
}

type IOTHubSearchResponse struct {
	PitID string     `json:"pit_id"`
	Hits  IOTHubHits `json:"hits"`
}

type IOTHubPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIOTHubPaginator(filters []BoolFilter, limit *int64) (IOTHubPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_devices_iothubs", filters, limit)
	if err != nil {
		return IOTHubPaginator{}, err
	}

	p := IOTHubPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IOTHubPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IOTHubPaginator) NextPage(ctx context.Context) ([]IOTHub, error) {
	var response IOTHubSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IOTHub
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIOTHubFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListIOTHub(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIOTHub")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIOTHubPaginator(buildFilter(d.KeyColumnQuals, listIOTHubFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIOTHubFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.IotHubDescription.name",
	"resource_group":   "description.ResourceGroup",
}

func GetIOTHub(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIOTHub")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIOTHubPaginator(buildFilter(d.KeyColumnQuals, getIOTHubFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IOTHub =============================

// ==========================  START: IOTHubDps =============================

type IOTHubDps struct {
	Description   azure.IOTHubDpsDescription `json:"description"`
	Metadata      azure.Metadata             `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

type IOTHubDpsHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  IOTHubDps     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type IOTHubDpsHits struct {
	Total SearchTotal    `json:"total"`
	Hits  []IOTHubDpsHit `json:"hits"`
}

type IOTHubDpsSearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  IOTHubDpsHits `json:"hits"`
}

type IOTHubDpsPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewIOTHubDpsPaginator(filters []BoolFilter, limit *int64) (IOTHubDpsPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_devices_iothubdpses", filters, limit)
	if err != nil {
		return IOTHubDpsPaginator{}, err
	}

	p := IOTHubDpsPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p IOTHubDpsPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p IOTHubDpsPaginator) NextPage(ctx context.Context) ([]IOTHubDps, error) {
	var response IOTHubDpsSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []IOTHubDps
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listIOTHubDpsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListIOTHubDps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListIOTHubDps")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewIOTHubDpsPaginator(buildFilter(d.KeyColumnQuals, listIOTHubDpsFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getIOTHubDpsFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.IotHubDps.name",
	"resource_group":   "description.ResourceGroup",
}

func GetIOTHubDps(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetIOTHubDps")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewIOTHubDpsPaginator(buildFilter(d.KeyColumnQuals, getIOTHubDpsFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: IOTHubDps =============================

// ==========================  START: KeyVault =============================

type KeyVault struct {
	Description   azure.KeyVaultDescription `json:"description"`
	Metadata      azure.Metadata            `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type KeyVaultHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  KeyVault      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type KeyVaultHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []KeyVaultHit `json:"hits"`
}

type KeyVaultSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  KeyVaultHits `json:"hits"`
}

type KeyVaultPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewKeyVaultPaginator(filters []BoolFilter, limit *int64) (KeyVaultPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_keyvault_vaults", filters, limit)
	if err != nil {
		return KeyVaultPaginator{}, err
	}

	p := KeyVaultPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KeyVaultPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p KeyVaultPaginator) NextPage(ctx context.Context) ([]KeyVault, error) {
	var response KeyVaultSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KeyVault
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listKeyVaultFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListKeyVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKeyVault")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewKeyVaultPaginator(buildFilter(d.KeyColumnQuals, listKeyVaultFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKeyVaultFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Resource.name",
	"resource_group":   "description.ResourceGroup",
}

func GetKeyVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKeyVault")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewKeyVaultPaginator(buildFilter(d.KeyColumnQuals, getKeyVaultFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KeyVault =============================

// ==========================  START: KeyVaultDeletedVault =============================

type KeyVaultDeletedVault struct {
	Description   azure.KeyVaultDeletedVaultDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type KeyVaultDeletedVaultHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  KeyVaultDeletedVault `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type KeyVaultDeletedVaultHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []KeyVaultDeletedVaultHit `json:"hits"`
}

type KeyVaultDeletedVaultSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  KeyVaultDeletedVaultHits `json:"hits"`
}

type KeyVaultDeletedVaultPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewKeyVaultDeletedVaultPaginator(filters []BoolFilter, limit *int64) (KeyVaultDeletedVaultPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_keyvault_deletedvaults", filters, limit)
	if err != nil {
		return KeyVaultDeletedVaultPaginator{}, err
	}

	p := KeyVaultDeletedVaultPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KeyVaultDeletedVaultPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p KeyVaultDeletedVaultPaginator) NextPage(ctx context.Context) ([]KeyVaultDeletedVault, error) {
	var response KeyVaultDeletedVaultSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KeyVaultDeletedVault
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listKeyVaultDeletedVaultFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListKeyVaultDeletedVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKeyVaultDeletedVault")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewKeyVaultDeletedVaultPaginator(buildFilter(d.KeyColumnQuals, listKeyVaultDeletedVaultFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKeyVaultDeletedVaultFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Vault.name",
	"region":           "description.Vault.Properties.Location",
}

func GetKeyVaultDeletedVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKeyVaultDeletedVault")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewKeyVaultDeletedVaultPaginator(buildFilter(d.KeyColumnQuals, getKeyVaultDeletedVaultFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KeyVaultDeletedVault =============================

// ==========================  START: KeyVaultManagedHardwareSecurityModule =============================

type KeyVaultManagedHardwareSecurityModule struct {
	Description   azure.KeyVaultManagedHardwareSecurityModuleDescription `json:"description"`
	Metadata      azure.Metadata                                         `json:"metadata"`
	ResourceJobID int                                                    `json:"resource_job_id"`
	SourceJobID   int                                                    `json:"source_job_id"`
	ResourceType  string                                                 `json:"resource_type"`
	SourceType    string                                                 `json:"source_type"`
	ID            string                                                 `json:"id"`
	ARN           string                                                 `json:"arn"`
	SourceID      string                                                 `json:"source_id"`
}

type KeyVaultManagedHardwareSecurityModuleHit struct {
	ID      string                                `json:"_id"`
	Score   float64                               `json:"_score"`
	Index   string                                `json:"_index"`
	Type    string                                `json:"_type"`
	Version int64                                 `json:"_version,omitempty"`
	Source  KeyVaultManagedHardwareSecurityModule `json:"_source"`
	Sort    []interface{}                         `json:"sort"`
}

type KeyVaultManagedHardwareSecurityModuleHits struct {
	Total SearchTotal                                `json:"total"`
	Hits  []KeyVaultManagedHardwareSecurityModuleHit `json:"hits"`
}

type KeyVaultManagedHardwareSecurityModuleSearchResponse struct {
	PitID string                                    `json:"pit_id"`
	Hits  KeyVaultManagedHardwareSecurityModuleHits `json:"hits"`
}

type KeyVaultManagedHardwareSecurityModulePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewKeyVaultManagedHardwareSecurityModulePaginator(filters []BoolFilter, limit *int64) (KeyVaultManagedHardwareSecurityModulePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_keyvault_managedhsms", filters, limit)
	if err != nil {
		return KeyVaultManagedHardwareSecurityModulePaginator{}, err
	}

	p := KeyVaultManagedHardwareSecurityModulePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KeyVaultManagedHardwareSecurityModulePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p KeyVaultManagedHardwareSecurityModulePaginator) NextPage(ctx context.Context) ([]KeyVaultManagedHardwareSecurityModule, error) {
	var response KeyVaultManagedHardwareSecurityModuleSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KeyVaultManagedHardwareSecurityModule
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listKeyVaultManagedHardwareSecurityModuleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListKeyVaultManagedHardwareSecurityModule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKeyVaultManagedHardwareSecurityModule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewKeyVaultManagedHardwareSecurityModulePaginator(buildFilter(d.KeyColumnQuals, listKeyVaultManagedHardwareSecurityModuleFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKeyVaultManagedHardwareSecurityModuleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ManagedHsm.name",
	"resource_group":   "description.ResourceGroup",
}

func GetKeyVaultManagedHardwareSecurityModule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKeyVaultManagedHardwareSecurityModule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewKeyVaultManagedHardwareSecurityModulePaginator(buildFilter(d.KeyColumnQuals, getKeyVaultManagedHardwareSecurityModuleFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KeyVaultManagedHardwareSecurityModule =============================

// ==========================  START: KeyVaultSecret =============================

type KeyVaultSecret struct {
	Description   azure.KeyVaultSecretDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type KeyVaultSecretHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  KeyVaultSecret `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type KeyVaultSecretHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []KeyVaultSecretHit `json:"hits"`
}

type KeyVaultSecretSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  KeyVaultSecretHits `json:"hits"`
}

type KeyVaultSecretPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewKeyVaultSecretPaginator(filters []BoolFilter, limit *int64) (KeyVaultSecretPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_keyvault_vaults_secrets", filters, limit)
	if err != nil {
		return KeyVaultSecretPaginator{}, err
	}

	p := KeyVaultSecretPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KeyVaultSecretPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p KeyVaultSecretPaginator) NextPage(ctx context.Context) ([]KeyVaultSecret, error) {
	var response KeyVaultSecretSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KeyVaultSecret
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listKeyVaultSecretFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListKeyVaultSecret(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKeyVaultSecret")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewKeyVaultSecretPaginator(buildFilter(d.KeyColumnQuals, listKeyVaultSecretFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKeyVaultSecretFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.SecretItem.name",
	"resource_group":   "description.ResourceGroup",
}

func GetKeyVaultSecret(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKeyVaultSecret")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewKeyVaultSecretPaginator(buildFilter(d.KeyColumnQuals, getKeyVaultSecretFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KeyVaultSecret =============================

// ==========================  START: KustoCluster =============================

type KustoCluster struct {
	Description   azure.KustoClusterDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type KustoClusterHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  KustoCluster  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type KustoClusterHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []KustoClusterHit `json:"hits"`
}

type KustoClusterSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  KustoClusterHits `json:"hits"`
}

type KustoClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewKustoClusterPaginator(filters []BoolFilter, limit *int64) (KustoClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_kusto_clusters", filters, limit)
	if err != nil {
		return KustoClusterPaginator{}, err
	}

	p := KustoClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p KustoClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p KustoClusterPaginator) NextPage(ctx context.Context) ([]KustoCluster, error) {
	var response KustoClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []KustoCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listKustoClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListKustoCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListKustoCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewKustoClusterPaginator(buildFilter(d.KeyColumnQuals, listKustoClusterFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getKustoClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Cluster.name",
	"resource_group":   "description.ResourceGroup",
}

func GetKustoCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetKustoCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewKustoClusterPaginator(buildFilter(d.KeyColumnQuals, getKustoClusterFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: KustoCluster =============================

// ==========================  START: LogAlert =============================

type LogAlert struct {
	Description   azure.LogAlertDescription `json:"description"`
	Metadata      azure.Metadata            `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type LogAlertHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  LogAlert      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type LogAlertHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []LogAlertHit `json:"hits"`
}

type LogAlertSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  LogAlertHits `json:"hits"`
}

type LogAlertPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewLogAlertPaginator(filters []BoolFilter, limit *int64) (LogAlertPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_insights_activitylogalerts", filters, limit)
	if err != nil {
		return LogAlertPaginator{}, err
	}

	p := LogAlertPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LogAlertPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p LogAlertPaginator) NextPage(ctx context.Context) ([]LogAlert, error) {
	var response LogAlertSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LogAlert
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listLogAlertFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListLogAlert(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLogAlert")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewLogAlertPaginator(buildFilter(d.KeyColumnQuals, listLogAlertFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLogAlertFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ActivityLogAlertResource.name",
	"resource_group":   "description.ResourceGroup",
}

func GetLogAlert(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLogAlert")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewLogAlertPaginator(buildFilter(d.KeyColumnQuals, getLogAlertFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LogAlert =============================

// ==========================  START: LogProfile =============================

type LogProfile struct {
	Description   azure.LogProfileDescription `json:"description"`
	Metadata      azure.Metadata              `json:"metadata"`
	ResourceJobID int                         `json:"resource_job_id"`
	SourceJobID   int                         `json:"source_job_id"`
	ResourceType  string                      `json:"resource_type"`
	SourceType    string                      `json:"source_type"`
	ID            string                      `json:"id"`
	ARN           string                      `json:"arn"`
	SourceID      string                      `json:"source_id"`
}

type LogProfileHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  LogProfile    `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type LogProfileHits struct {
	Total SearchTotal     `json:"total"`
	Hits  []LogProfileHit `json:"hits"`
}

type LogProfileSearchResponse struct {
	PitID string         `json:"pit_id"`
	Hits  LogProfileHits `json:"hits"`
}

type LogProfilePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewLogProfilePaginator(filters []BoolFilter, limit *int64) (LogProfilePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_insights_logprofiles", filters, limit)
	if err != nil {
		return LogProfilePaginator{}, err
	}

	p := LogProfilePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LogProfilePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p LogProfilePaginator) NextPage(ctx context.Context) ([]LogProfile, error) {
	var response LogProfileSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LogProfile
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listLogProfileFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListLogProfile(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLogProfile")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewLogProfilePaginator(buildFilter(d.KeyColumnQuals, listLogProfileFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLogProfileFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.LogProfileResource.name",
	"resource_group":   "description.ResourceGroup",
}

func GetLogProfile(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLogProfile")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewLogProfilePaginator(buildFilter(d.KeyColumnQuals, getLogProfileFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LogProfile =============================

// ==========================  START: LogicAppWorkflow =============================

type LogicAppWorkflow struct {
	Description   azure.LogicAppWorkflowDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type LogicAppWorkflowHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  LogicAppWorkflow `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type LogicAppWorkflowHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []LogicAppWorkflowHit `json:"hits"`
}

type LogicAppWorkflowSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  LogicAppWorkflowHits `json:"hits"`
}

type LogicAppWorkflowPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewLogicAppWorkflowPaginator(filters []BoolFilter, limit *int64) (LogicAppWorkflowPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_logic_workflows", filters, limit)
	if err != nil {
		return LogicAppWorkflowPaginator{}, err
	}

	p := LogicAppWorkflowPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LogicAppWorkflowPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p LogicAppWorkflowPaginator) NextPage(ctx context.Context) ([]LogicAppWorkflow, error) {
	var response LogicAppWorkflowSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LogicAppWorkflow
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listLogicAppWorkflowFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListLogicAppWorkflow(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLogicAppWorkflow")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewLogicAppWorkflowPaginator(buildFilter(d.KeyColumnQuals, listLogicAppWorkflowFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLogicAppWorkflowFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Workflow.name",
	"resource_group":   "description.ResourceGroup",
}

func GetLogicAppWorkflow(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLogicAppWorkflow")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewLogicAppWorkflowPaginator(buildFilter(d.KeyColumnQuals, getLogicAppWorkflowFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LogicAppWorkflow =============================

// ==========================  START: MachineLearningWorkspace =============================

type MachineLearningWorkspace struct {
	Description   azure.MachineLearningWorkspaceDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

type MachineLearningWorkspaceHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  MachineLearningWorkspace `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type MachineLearningWorkspaceHits struct {
	Total SearchTotal                   `json:"total"`
	Hits  []MachineLearningWorkspaceHit `json:"hits"`
}

type MachineLearningWorkspaceSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  MachineLearningWorkspaceHits `json:"hits"`
}

type MachineLearningWorkspacePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewMachineLearningWorkspacePaginator(filters []BoolFilter, limit *int64) (MachineLearningWorkspacePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_machinelearning_workspaces", filters, limit)
	if err != nil {
		return MachineLearningWorkspacePaginator{}, err
	}

	p := MachineLearningWorkspacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p MachineLearningWorkspacePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p MachineLearningWorkspacePaginator) NextPage(ctx context.Context) ([]MachineLearningWorkspace, error) {
	var response MachineLearningWorkspaceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []MachineLearningWorkspace
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listMachineLearningWorkspaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListMachineLearningWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListMachineLearningWorkspace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewMachineLearningWorkspacePaginator(buildFilter(d.KeyColumnQuals, listMachineLearningWorkspaceFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getMachineLearningWorkspaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Workspace.name",
	"resource_group":   "description.ResourceGroup",
}

func GetMachineLearningWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetMachineLearningWorkspace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewMachineLearningWorkspacePaginator(buildFilter(d.KeyColumnQuals, getMachineLearningWorkspaceFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: MachineLearningWorkspace =============================

// ==========================  START: MariadbServer =============================

type MariadbServer struct {
	Description   azure.MariadbServerDescription `json:"description"`
	Metadata      azure.Metadata                 `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type MariadbServerHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  MariadbServer `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type MariadbServerHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []MariadbServerHit `json:"hits"`
}

type MariadbServerSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  MariadbServerHits `json:"hits"`
}

type MariadbServerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewMariadbServerPaginator(filters []BoolFilter, limit *int64) (MariadbServerPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_dbformariadb_servers", filters, limit)
	if err != nil {
		return MariadbServerPaginator{}, err
	}

	p := MariadbServerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p MariadbServerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p MariadbServerPaginator) NextPage(ctx context.Context) ([]MariadbServer, error) {
	var response MariadbServerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []MariadbServer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listMariadbServerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListMariadbServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListMariadbServer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewMariadbServerPaginator(buildFilter(d.KeyColumnQuals, listMariadbServerFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getMariadbServerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Server.name",
	"resource_group":   "description.ResourceGroup",
}

func GetMariadbServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetMariadbServer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewMariadbServerPaginator(buildFilter(d.KeyColumnQuals, getMariadbServerFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: MariadbServer =============================

// ==========================  START: MysqlServer =============================

type MysqlServer struct {
	Description   azure.MysqlServerDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type MysqlServerHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  MysqlServer   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type MysqlServerHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []MysqlServerHit `json:"hits"`
}

type MysqlServerSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  MysqlServerHits `json:"hits"`
}

type MysqlServerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewMysqlServerPaginator(filters []BoolFilter, limit *int64) (MysqlServerPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_dbformysql_servers", filters, limit)
	if err != nil {
		return MysqlServerPaginator{}, err
	}

	p := MysqlServerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p MysqlServerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p MysqlServerPaginator) NextPage(ctx context.Context) ([]MysqlServer, error) {
	var response MysqlServerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []MysqlServer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listMysqlServerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListMysqlServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListMysqlServer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewMysqlServerPaginator(buildFilter(d.KeyColumnQuals, listMysqlServerFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getMysqlServerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Server.name",
	"resource_group":   "description.ResourceGroup",
}

func GetMysqlServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetMysqlServer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewMysqlServerPaginator(buildFilter(d.KeyColumnQuals, getMysqlServerFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: MysqlServer =============================

// ==========================  START: NetworkSecurityGroup =============================

type NetworkSecurityGroup struct {
	Description   azure.NetworkSecurityGroupDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type NetworkSecurityGroupHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  NetworkSecurityGroup `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type NetworkSecurityGroupHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []NetworkSecurityGroupHit `json:"hits"`
}

type NetworkSecurityGroupSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  NetworkSecurityGroupHits `json:"hits"`
}

type NetworkSecurityGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewNetworkSecurityGroupPaginator(filters []BoolFilter, limit *int64) (NetworkSecurityGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_classicnetwork_networksecuritygroups", filters, limit)
	if err != nil {
		return NetworkSecurityGroupPaginator{}, err
	}

	p := NetworkSecurityGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkSecurityGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p NetworkSecurityGroupPaginator) NextPage(ctx context.Context) ([]NetworkSecurityGroup, error) {
	var response NetworkSecurityGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkSecurityGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkSecurityGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListNetworkSecurityGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkSecurityGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewNetworkSecurityGroupPaginator(buildFilter(d.KeyColumnQuals, listNetworkSecurityGroupFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkSecurityGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.SecurityGroup.name",
	"resource_group":   "description.ResourceGroup",
}

func GetNetworkSecurityGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkSecurityGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewNetworkSecurityGroupPaginator(buildFilter(d.KeyColumnQuals, getNetworkSecurityGroupFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkSecurityGroup =============================

// ==========================  START: NetworkWatcher =============================

type NetworkWatcher struct {
	Description   azure.NetworkWatcherDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type NetworkWatcherHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  NetworkWatcher `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type NetworkWatcherHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []NetworkWatcherHit `json:"hits"`
}

type NetworkWatcherSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  NetworkWatcherHits `json:"hits"`
}

type NetworkWatcherPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewNetworkWatcherPaginator(filters []BoolFilter, limit *int64) (NetworkWatcherPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_networkwatchers", filters, limit)
	if err != nil {
		return NetworkWatcherPaginator{}, err
	}

	p := NetworkWatcherPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p NetworkWatcherPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p NetworkWatcherPaginator) NextPage(ctx context.Context) ([]NetworkWatcher, error) {
	var response NetworkWatcherSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []NetworkWatcher
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listNetworkWatcherFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListNetworkWatcher(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListNetworkWatcher")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewNetworkWatcherPaginator(buildFilter(d.KeyColumnQuals, listNetworkWatcherFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getNetworkWatcherFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Watcher.name",
	"resource_group":   "description.ResourceGroup",
}

func GetNetworkWatcher(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetNetworkWatcher")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewNetworkWatcherPaginator(buildFilter(d.KeyColumnQuals, getNetworkWatcherFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: NetworkWatcher =============================

// ==========================  START: SearchService =============================

type SearchService struct {
	Description   azure.SearchServiceDescription `json:"description"`
	Metadata      azure.Metadata                 `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type SearchServiceHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  SearchService `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type SearchServiceHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []SearchServiceHit `json:"hits"`
}

type SearchServiceSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  SearchServiceHits `json:"hits"`
}

type SearchServicePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSearchServicePaginator(filters []BoolFilter, limit *int64) (SearchServicePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_search_searchservices", filters, limit)
	if err != nil {
		return SearchServicePaginator{}, err
	}

	p := SearchServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SearchServicePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SearchServicePaginator) NextPage(ctx context.Context) ([]SearchService, error) {
	var response SearchServiceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SearchService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSearchServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSearchService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSearchService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSearchServicePaginator(buildFilter(d.KeyColumnQuals, listSearchServiceFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSearchServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Service.name",
	"resource_group":   "description.ResourceGroup",
}

func GetSearchService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSearchService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSearchServicePaginator(buildFilter(d.KeyColumnQuals, getSearchServiceFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SearchService =============================

// ==========================  START: ServiceFabricCluster =============================

type ServiceFabricCluster struct {
	Description   azure.ServiceFabricClusterDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type ServiceFabricClusterHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  ServiceFabricCluster `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type ServiceFabricClusterHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []ServiceFabricClusterHit `json:"hits"`
}

type ServiceFabricClusterSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  ServiceFabricClusterHits `json:"hits"`
}

type ServiceFabricClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewServiceFabricClusterPaginator(filters []BoolFilter, limit *int64) (ServiceFabricClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_servicefabric_clusters", filters, limit)
	if err != nil {
		return ServiceFabricClusterPaginator{}, err
	}

	p := ServiceFabricClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ServiceFabricClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ServiceFabricClusterPaginator) NextPage(ctx context.Context) ([]ServiceFabricCluster, error) {
	var response ServiceFabricClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ServiceFabricCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listServiceFabricClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListServiceFabricCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListServiceFabricCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewServiceFabricClusterPaginator(buildFilter(d.KeyColumnQuals, listServiceFabricClusterFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getServiceFabricClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Cluster.name",
	"resource_group":   "description.ResourceGroup",
}

func GetServiceFabricCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetServiceFabricCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewServiceFabricClusterPaginator(buildFilter(d.KeyColumnQuals, getServiceFabricClusterFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ServiceFabricCluster =============================

// ==========================  START: ServicebusNamespace =============================

type ServicebusNamespace struct {
	Description   azure.ServicebusNamespaceDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

type ServicebusNamespaceHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  ServicebusNamespace `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type ServicebusNamespaceHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []ServicebusNamespaceHit `json:"hits"`
}

type ServicebusNamespaceSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  ServicebusNamespaceHits `json:"hits"`
}

type ServicebusNamespacePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewServicebusNamespacePaginator(filters []BoolFilter, limit *int64) (ServicebusNamespacePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_servicebus_namespaces", filters, limit)
	if err != nil {
		return ServicebusNamespacePaginator{}, err
	}

	p := ServicebusNamespacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ServicebusNamespacePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ServicebusNamespacePaginator) NextPage(ctx context.Context) ([]ServicebusNamespace, error) {
	var response ServicebusNamespaceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ServicebusNamespace
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listServicebusNamespaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListServicebusNamespace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListServicebusNamespace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewServicebusNamespacePaginator(buildFilter(d.KeyColumnQuals, listServicebusNamespaceFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getServicebusNamespaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.SBNamespace.name",
	"resource_group":   "description.ResourceGroup",
}

func GetServicebusNamespace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetServicebusNamespace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewServicebusNamespacePaginator(buildFilter(d.KeyColumnQuals, getServicebusNamespaceFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ServicebusNamespace =============================

// ==========================  START: SignalrService =============================

type SignalrService struct {
	Description   azure.SignalrServiceDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type SignalrServiceHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  SignalrService `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type SignalrServiceHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []SignalrServiceHit `json:"hits"`
}

type SignalrServiceSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  SignalrServiceHits `json:"hits"`
}

type SignalrServicePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSignalrServicePaginator(filters []BoolFilter, limit *int64) (SignalrServicePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_signalrservice_signalr", filters, limit)
	if err != nil {
		return SignalrServicePaginator{}, err
	}

	p := SignalrServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SignalrServicePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SignalrServicePaginator) NextPage(ctx context.Context) ([]SignalrService, error) {
	var response SignalrServiceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SignalrService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSignalrServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSignalrService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSignalrService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSignalrServicePaginator(buildFilter(d.KeyColumnQuals, listSignalrServiceFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSignalrServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ResourceType.name",
	"resource_group":   "description.ResourceGroup",
}

func GetSignalrService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSignalrService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSignalrServicePaginator(buildFilter(d.KeyColumnQuals, getSignalrServiceFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SignalrService =============================

// ==========================  START: SpringCloudService =============================

type SpringCloudService struct {
	Description   azure.SpringCloudServiceDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type SpringCloudServiceHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  SpringCloudService `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type SpringCloudServiceHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []SpringCloudServiceHit `json:"hits"`
}

type SpringCloudServiceSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  SpringCloudServiceHits `json:"hits"`
}

type SpringCloudServicePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSpringCloudServicePaginator(filters []BoolFilter, limit *int64) (SpringCloudServicePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_appplatform_spring", filters, limit)
	if err != nil {
		return SpringCloudServicePaginator{}, err
	}

	p := SpringCloudServicePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SpringCloudServicePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SpringCloudServicePaginator) NextPage(ctx context.Context) ([]SpringCloudService, error) {
	var response SpringCloudServiceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SpringCloudService
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSpringCloudServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSpringCloudService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSpringCloudService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSpringCloudServicePaginator(buildFilter(d.KeyColumnQuals, listSpringCloudServiceFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSpringCloudServiceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ServiceResource.name",
	"resource_group":   "description.ResourceGroup",
}

func GetSpringCloudService(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSpringCloudService")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSpringCloudServicePaginator(buildFilter(d.KeyColumnQuals, getSpringCloudServiceFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SpringCloudService =============================

// ==========================  START: StreamAnalyticsJob =============================

type StreamAnalyticsJob struct {
	Description   azure.StreamAnalyticsJobDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type StreamAnalyticsJobHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  StreamAnalyticsJob `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type StreamAnalyticsJobHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []StreamAnalyticsJobHit `json:"hits"`
}

type StreamAnalyticsJobSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  StreamAnalyticsJobHits `json:"hits"`
}

type StreamAnalyticsJobPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewStreamAnalyticsJobPaginator(filters []BoolFilter, limit *int64) (StreamAnalyticsJobPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_streamanalytics_streamingjobs", filters, limit)
	if err != nil {
		return StreamAnalyticsJobPaginator{}, err
	}

	p := StreamAnalyticsJobPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StreamAnalyticsJobPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p StreamAnalyticsJobPaginator) NextPage(ctx context.Context) ([]StreamAnalyticsJob, error) {
	var response StreamAnalyticsJobSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StreamAnalyticsJob
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listStreamAnalyticsJobFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListStreamAnalyticsJob(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStreamAnalyticsJob")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewStreamAnalyticsJobPaginator(buildFilter(d.KeyColumnQuals, listStreamAnalyticsJobFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStreamAnalyticsJobFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.StreamingJob.name",
	"resource_group":   "description.ResourceGroup",
}

func GetStreamAnalyticsJob(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStreamAnalyticsJob")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewStreamAnalyticsJobPaginator(buildFilter(d.KeyColumnQuals, getStreamAnalyticsJobFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StreamAnalyticsJob =============================

// ==========================  START: SynapseWorkspace =============================

type SynapseWorkspace struct {
	Description   azure.SynapseWorkspaceDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type SynapseWorkspaceHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  SynapseWorkspace `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type SynapseWorkspaceHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []SynapseWorkspaceHit `json:"hits"`
}

type SynapseWorkspaceSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  SynapseWorkspaceHits `json:"hits"`
}

type SynapseWorkspacePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSynapseWorkspacePaginator(filters []BoolFilter, limit *int64) (SynapseWorkspacePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_synapse_workspaces", filters, limit)
	if err != nil {
		return SynapseWorkspacePaginator{}, err
	}

	p := SynapseWorkspacePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SynapseWorkspacePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SynapseWorkspacePaginator) NextPage(ctx context.Context) ([]SynapseWorkspace, error) {
	var response SynapseWorkspaceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SynapseWorkspace
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSynapseWorkspaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSynapseWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSynapseWorkspace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSynapseWorkspacePaginator(buildFilter(d.KeyColumnQuals, listSynapseWorkspaceFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSynapseWorkspaceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Workspace.name",
	"resource_group":   "description.ResourceGroup",
}

func GetSynapseWorkspace(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSynapseWorkspace")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSynapseWorkspacePaginator(buildFilter(d.KeyColumnQuals, getSynapseWorkspaceFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SynapseWorkspace =============================

// ==========================  START: Location =============================

type Location struct {
	Description   azure.LocationDescription `json:"description"`
	Metadata      azure.Metadata            `json:"metadata"`
	ResourceJobID int                       `json:"resource_job_id"`
	SourceJobID   int                       `json:"source_job_id"`
	ResourceType  string                    `json:"resource_type"`
	SourceType    string                    `json:"source_type"`
	ID            string                    `json:"id"`
	ARN           string                    `json:"arn"`
	SourceID      string                    `json:"source_id"`
}

type LocationHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  Location      `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type LocationHits struct {
	Total SearchTotal   `json:"total"`
	Hits  []LocationHit `json:"hits"`
}

type LocationSearchResponse struct {
	PitID string       `json:"pit_id"`
	Hits  LocationHits `json:"hits"`
}

type LocationPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewLocationPaginator(filters []BoolFilter, limit *int64) (LocationPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_resources_subscriptions_locations", filters, limit)
	if err != nil {
		return LocationPaginator{}, err
	}

	p := LocationPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LocationPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p LocationPaginator) NextPage(ctx context.Context) ([]Location, error) {
	var response LocationSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []Location
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listLocationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListLocation(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLocation")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewLocationPaginator(buildFilter(d.KeyColumnQuals, listLocationFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLocationFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Location.name",
	"resource_group":   "description.ResourceGroup",
}

func GetLocation(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLocation")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewLocationPaginator(buildFilter(d.KeyColumnQuals, getLocationFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: Location =============================

// ==========================  START: AdUsers =============================

type AdUsers struct {
	Description   azure.AdUsersDescription `json:"description"`
	Metadata      azure.Metadata           `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	ARN           string                   `json:"arn"`
	SourceID      string                   `json:"source_id"`
}

type AdUsersHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  AdUsers       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type AdUsersHits struct {
	Total SearchTotal  `json:"total"`
	Hits  []AdUsersHit `json:"hits"`
}

type AdUsersSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  AdUsersHits `json:"hits"`
}

type AdUsersPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAdUsersPaginator(filters []BoolFilter, limit *int64) (AdUsersPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_resources_users", filters, limit)
	if err != nil {
		return AdUsersPaginator{}, err
	}

	p := AdUsersPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AdUsersPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AdUsersPaginator) NextPage(ctx context.Context) ([]AdUsers, error) {
	var response AdUsersSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AdUsers
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAdUsersFilters = map[string]string{
	"account_enabled":     "description.AdUsers.accountEnabled",
	"display_name":        "description.AdUsers.displayName",
	"filter":              "description.AdUsers.filter",
	"id":                  "description.AdUsers.DirectoryObject.id",
	"keibi_account_id":    "metadata.SourceID",
	"surname":             "description.AdUsers.surname",
	"user_principal_name": "description.AdUsers.userPrincipalName",
	"user_type":           "description.AdUsers.userType",
}

func ListAdUsers(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAdUsers")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAdUsersPaginator(buildFilter(d.KeyColumnQuals, listAdUsersFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAdUsersFilters = map[string]string{
	"id":               "description.AdUsers.DirectoryObject.id",
	"keibi_account_id": "metadata.SourceID",
}

func GetAdUsers(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAdUsers")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAdUsersPaginator(buildFilter(d.KeyColumnQuals, getAdUsersFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AdUsers =============================

// ==========================  START: AdGroup =============================

type AdGroup struct {
	Description   azure.AdGroupDescription `json:"description"`
	Metadata      azure.Metadata           `json:"metadata"`
	ResourceJobID int                      `json:"resource_job_id"`
	SourceJobID   int                      `json:"source_job_id"`
	ResourceType  string                   `json:"resource_type"`
	SourceType    string                   `json:"source_type"`
	ID            string                   `json:"id"`
	ARN           string                   `json:"arn"`
	SourceID      string                   `json:"source_id"`
}

type AdGroupHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  AdGroup       `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type AdGroupHits struct {
	Total SearchTotal  `json:"total"`
	Hits  []AdGroupHit `json:"hits"`
}

type AdGroupSearchResponse struct {
	PitID string      `json:"pit_id"`
	Hits  AdGroupHits `json:"hits"`
}

type AdGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAdGroupPaginator(filters []BoolFilter, limit *int64) (AdGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_resources_groups", filters, limit)
	if err != nil {
		return AdGroupPaginator{}, err
	}

	p := AdGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AdGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AdGroupPaginator) NextPage(ctx context.Context) ([]AdGroup, error) {
	var response AdGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AdGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAdGroupFilters = map[string]string{
	"display_name":             "description.AdGroup.DisplayName",
	"keibi_account_id":         "metadata.SourceID",
	"mail":                     "description.AdGroup.Mail",
	"mail_enabled":             "description.AdGroup.MailEnabled",
	"on_premises_sync_enabled": "description.AdGroup.OnPremisesSyncEnabled",
	"security_enabled":         "description.AdGroup.SecurityEnabled",
}

func ListAdGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAdGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAdGroupPaginator(buildFilter(d.KeyColumnQuals, listAdGroupFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAdGroupFilters = map[string]string{
	"id":               "description.AdGroup.DirectoryObject.ID",
	"keibi_account_id": "metadata.SourceID",
}

func GetAdGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAdGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAdGroupPaginator(buildFilter(d.KeyColumnQuals, getAdGroupFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AdGroup =============================

// ==========================  START: AdServicePrincipal =============================

type AdServicePrincipal struct {
	Description   azure.AdServicePrincipalDescription `json:"description"`
	Metadata      azure.Metadata                      `json:"metadata"`
	ResourceJobID int                                 `json:"resource_job_id"`
	SourceJobID   int                                 `json:"source_job_id"`
	ResourceType  string                              `json:"resource_type"`
	SourceType    string                              `json:"source_type"`
	ID            string                              `json:"id"`
	ARN           string                              `json:"arn"`
	SourceID      string                              `json:"source_id"`
}

type AdServicePrincipalHit struct {
	ID      string             `json:"_id"`
	Score   float64            `json:"_score"`
	Index   string             `json:"_index"`
	Type    string             `json:"_type"`
	Version int64              `json:"_version,omitempty"`
	Source  AdServicePrincipal `json:"_source"`
	Sort    []interface{}      `json:"sort"`
}

type AdServicePrincipalHits struct {
	Total SearchTotal             `json:"total"`
	Hits  []AdServicePrincipalHit `json:"hits"`
}

type AdServicePrincipalSearchResponse struct {
	PitID string                 `json:"pit_id"`
	Hits  AdServicePrincipalHits `json:"hits"`
}

type AdServicePrincipalPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewAdServicePrincipalPaginator(filters []BoolFilter, limit *int64) (AdServicePrincipalPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_resources_serviceprincipals", filters, limit)
	if err != nil {
		return AdServicePrincipalPaginator{}, err
	}

	p := AdServicePrincipalPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p AdServicePrincipalPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p AdServicePrincipalPaginator) NextPage(ctx context.Context) ([]AdServicePrincipal, error) {
	var response AdServicePrincipalSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []AdServicePrincipal
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listAdServicePrincipalFilters = map[string]string{
	"account_enabled":        "description.AdServicePrincipal.AccountEnabled",
	"display_name":           "description.AdServicePrincipal.DisplayName",
	"keibi_account_id":       "metadata.SourceID",
	"service_principal_type": "description.AdServicePrincipal.ServicePrincipalType",
}

func ListAdServicePrincipal(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListAdServicePrincipal")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewAdServicePrincipalPaginator(buildFilter(d.KeyColumnQuals, listAdServicePrincipalFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getAdServicePrincipalFilters = map[string]string{
	"id":               "description.AdServicePrincipal.DirectoryObject.ID",
	"keibi_account_id": "metadata.SourceID",
}

func GetAdServicePrincipal(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetAdServicePrincipal")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewAdServicePrincipalPaginator(buildFilter(d.KeyColumnQuals, getAdServicePrincipalFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: AdServicePrincipal =============================

// ==========================  START: PostgresqlServer =============================

type PostgresqlServer struct {
	Description   azure.PostgresqlServerDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type PostgresqlServerHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  PostgresqlServer `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type PostgresqlServerHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []PostgresqlServerHit `json:"hits"`
}

type PostgresqlServerSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  PostgresqlServerHits `json:"hits"`
}

type PostgresqlServerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewPostgresqlServerPaginator(filters []BoolFilter, limit *int64) (PostgresqlServerPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_dbforpostgresql_servers", filters, limit)
	if err != nil {
		return PostgresqlServerPaginator{}, err
	}

	p := PostgresqlServerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p PostgresqlServerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p PostgresqlServerPaginator) NextPage(ctx context.Context) ([]PostgresqlServer, error) {
	var response PostgresqlServerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []PostgresqlServer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listPostgresqlServerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListPostgresqlServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListPostgresqlServer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewPostgresqlServerPaginator(buildFilter(d.KeyColumnQuals, listPostgresqlServerFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getPostgresqlServerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Server.name",
	"resource_group":   "description.ResourceGroup",
}

func GetPostgresqlServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetPostgresqlServer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewPostgresqlServerPaginator(buildFilter(d.KeyColumnQuals, getPostgresqlServerFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: PostgresqlServer =============================

// ==========================  START: StorageSync =============================

type StorageSync struct {
	Description   azure.StorageSyncDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type StorageSyncHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  StorageSync   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type StorageSyncHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []StorageSyncHit `json:"hits"`
}

type StorageSyncSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  StorageSyncHits `json:"hits"`
}

type StorageSyncPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewStorageSyncPaginator(filters []BoolFilter, limit *int64) (StorageSyncPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_storagesync_storagesyncservices", filters, limit)
	if err != nil {
		return StorageSyncPaginator{}, err
	}

	p := StorageSyncPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageSyncPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p StorageSyncPaginator) NextPage(ctx context.Context) ([]StorageSync, error) {
	var response StorageSyncSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageSync
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listStorageSyncFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListStorageSync(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageSync")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewStorageSyncPaginator(buildFilter(d.KeyColumnQuals, listStorageSyncFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageSyncFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Service.name",
	"resource_group":   "description.ResourceGroup",
}

func GetStorageSync(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageSync")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewStorageSyncPaginator(buildFilter(d.KeyColumnQuals, getStorageSyncFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageSync =============================

// ==========================  START: MssqlManagedInstance =============================

type MssqlManagedInstance struct {
	Description   azure.MssqlManagedInstanceDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type MssqlManagedInstanceHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  MssqlManagedInstance `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type MssqlManagedInstanceHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []MssqlManagedInstanceHit `json:"hits"`
}

type MssqlManagedInstanceSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  MssqlManagedInstanceHits `json:"hits"`
}

type MssqlManagedInstancePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewMssqlManagedInstancePaginator(filters []BoolFilter, limit *int64) (MssqlManagedInstancePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_sql_managedinstances", filters, limit)
	if err != nil {
		return MssqlManagedInstancePaginator{}, err
	}

	p := MssqlManagedInstancePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p MssqlManagedInstancePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p MssqlManagedInstancePaginator) NextPage(ctx context.Context) ([]MssqlManagedInstance, error) {
	var response MssqlManagedInstanceSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []MssqlManagedInstance
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listMssqlManagedInstanceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListMssqlManagedInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListMssqlManagedInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewMssqlManagedInstancePaginator(buildFilter(d.KeyColumnQuals, listMssqlManagedInstanceFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getMssqlManagedInstanceFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ManagedInstance.name",
	"resource_group":   "description.ResourceGroup",
}

func GetMssqlManagedInstance(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetMssqlManagedInstance")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewMssqlManagedInstancePaginator(buildFilter(d.KeyColumnQuals, getMssqlManagedInstanceFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: MssqlManagedInstance =============================

// ==========================  START: SqlDatabase =============================

type SqlDatabase struct {
	Description   azure.SqlDatabaseDescription `json:"description"`
	Metadata      azure.Metadata               `json:"metadata"`
	ResourceJobID int                          `json:"resource_job_id"`
	SourceJobID   int                          `json:"source_job_id"`
	ResourceType  string                       `json:"resource_type"`
	SourceType    string                       `json:"source_type"`
	ID            string                       `json:"id"`
	ARN           string                       `json:"arn"`
	SourceID      string                       `json:"source_id"`
}

type SqlDatabaseHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  SqlDatabase   `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type SqlDatabaseHits struct {
	Total SearchTotal      `json:"total"`
	Hits  []SqlDatabaseHit `json:"hits"`
}

type SqlDatabaseSearchResponse struct {
	PitID string          `json:"pit_id"`
	Hits  SqlDatabaseHits `json:"hits"`
}

type SqlDatabasePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSqlDatabasePaginator(filters []BoolFilter, limit *int64) (SqlDatabasePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_sql_servers_databases", filters, limit)
	if err != nil {
		return SqlDatabasePaginator{}, err
	}

	p := SqlDatabasePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SqlDatabasePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SqlDatabasePaginator) NextPage(ctx context.Context) ([]SqlDatabase, error) {
	var response SqlDatabaseSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SqlDatabase
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSqlDatabaseFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSqlDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSqlDatabase")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSqlDatabasePaginator(buildFilter(d.KeyColumnQuals, listSqlDatabaseFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSqlDatabaseFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Database.name",
	"resource_group":   "description.ResourceGroup",
}

func GetSqlDatabase(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSqlDatabase")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSqlDatabasePaginator(buildFilter(d.KeyColumnQuals, getSqlDatabaseFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SqlDatabase =============================

// ==========================  START: SqlServer =============================

type SqlServer struct {
	Description   azure.SqlServerDescription `json:"description"`
	Metadata      azure.Metadata             `json:"metadata"`
	ResourceJobID int                        `json:"resource_job_id"`
	SourceJobID   int                        `json:"source_job_id"`
	ResourceType  string                     `json:"resource_type"`
	SourceType    string                     `json:"source_type"`
	ID            string                     `json:"id"`
	ARN           string                     `json:"arn"`
	SourceID      string                     `json:"source_id"`
}

type SqlServerHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  SqlServer     `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type SqlServerHits struct {
	Total SearchTotal    `json:"total"`
	Hits  []SqlServerHit `json:"hits"`
}

type SqlServerSearchResponse struct {
	PitID string        `json:"pit_id"`
	Hits  SqlServerHits `json:"hits"`
}

type SqlServerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSqlServerPaginator(filters []BoolFilter, limit *int64) (SqlServerPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_sql_servers", filters, limit)
	if err != nil {
		return SqlServerPaginator{}, err
	}

	p := SqlServerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SqlServerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SqlServerPaginator) NextPage(ctx context.Context) ([]SqlServer, error) {
	var response SqlServerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SqlServer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSqlServerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSqlServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSqlServer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSqlServerPaginator(buildFilter(d.KeyColumnQuals, listSqlServerFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSqlServerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Server.name",
	"resource_group":   "description.ResourceGroup",
}

func GetSqlServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSqlServer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSqlServerPaginator(buildFilter(d.KeyColumnQuals, getSqlServerFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SqlServer =============================

// ==========================  START: SqlServerElasticPool =============================

type SqlServerElasticPool struct {
	Description   azure.SqlServerElasticPoolDescription `json:"description"`
	Metadata      azure.Metadata                        `json:"metadata"`
	ResourceJobID int                                   `json:"resource_job_id"`
	SourceJobID   int                                   `json:"source_job_id"`
	ResourceType  string                                `json:"resource_type"`
	SourceType    string                                `json:"source_type"`
	ID            string                                `json:"id"`
	ARN           string                                `json:"arn"`
	SourceID      string                                `json:"source_id"`
}

type SqlServerElasticPoolHit struct {
	ID      string               `json:"_id"`
	Score   float64              `json:"_score"`
	Index   string               `json:"_index"`
	Type    string               `json:"_type"`
	Version int64                `json:"_version,omitempty"`
	Source  SqlServerElasticPool `json:"_source"`
	Sort    []interface{}        `json:"sort"`
}

type SqlServerElasticPoolHits struct {
	Total SearchTotal               `json:"total"`
	Hits  []SqlServerElasticPoolHit `json:"hits"`
}

type SqlServerElasticPoolSearchResponse struct {
	PitID string                   `json:"pit_id"`
	Hits  SqlServerElasticPoolHits `json:"hits"`
}

type SqlServerElasticPoolPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSqlServerElasticPoolPaginator(filters []BoolFilter, limit *int64) (SqlServerElasticPoolPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_sql_elasticpools", filters, limit)
	if err != nil {
		return SqlServerElasticPoolPaginator{}, err
	}

	p := SqlServerElasticPoolPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SqlServerElasticPoolPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SqlServerElasticPoolPaginator) NextPage(ctx context.Context) ([]SqlServerElasticPool, error) {
	var response SqlServerElasticPoolSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SqlServerElasticPool
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSqlServerElasticPoolFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSqlServerElasticPool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSqlServerElasticPool")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSqlServerElasticPoolPaginator(buildFilter(d.KeyColumnQuals, listSqlServerElasticPoolFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSqlServerElasticPoolFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Pool.Name",
	"resource_group":   "description.ResourceGroup",
	"server_name":      "description.ServerName",
}

func GetSqlServerElasticPool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSqlServerElasticPool")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSqlServerElasticPoolPaginator(buildFilter(d.KeyColumnQuals, getSqlServerElasticPoolFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SqlServerElasticPool =============================

// ==========================  START: SqlServerVirtualMachine =============================

type SqlServerVirtualMachine struct {
	Description   azure.SqlServerVirtualMachineDescription `json:"description"`
	Metadata      azure.Metadata                           `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

type SqlServerVirtualMachineHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  SqlServerVirtualMachine `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type SqlServerVirtualMachineHits struct {
	Total SearchTotal                  `json:"total"`
	Hits  []SqlServerVirtualMachineHit `json:"hits"`
}

type SqlServerVirtualMachineSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  SqlServerVirtualMachineHits `json:"hits"`
}

type SqlServerVirtualMachinePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSqlServerVirtualMachinePaginator(filters []BoolFilter, limit *int64) (SqlServerVirtualMachinePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_sql_virtualmachines", filters, limit)
	if err != nil {
		return SqlServerVirtualMachinePaginator{}, err
	}

	p := SqlServerVirtualMachinePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SqlServerVirtualMachinePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SqlServerVirtualMachinePaginator) NextPage(ctx context.Context) ([]SqlServerVirtualMachine, error) {
	var response SqlServerVirtualMachineSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SqlServerVirtualMachine
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSqlServerVirtualMachineFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSqlServerVirtualMachine(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSqlServerVirtualMachine")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSqlServerVirtualMachinePaginator(buildFilter(d.KeyColumnQuals, listSqlServerVirtualMachineFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSqlServerVirtualMachineFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.VirtualMachine.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetSqlServerVirtualMachine(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSqlServerVirtualMachine")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSqlServerVirtualMachinePaginator(buildFilter(d.KeyColumnQuals, getSqlServerVirtualMachineFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SqlServerVirtualMachine =============================

// ==========================  START: SqlServerFlexibleServer =============================

type SqlServerFlexibleServer struct {
	Description   azure.SqlServerFlexibleServerDescription `json:"description"`
	Metadata      azure.Metadata                           `json:"metadata"`
	ResourceJobID int                                      `json:"resource_job_id"`
	SourceJobID   int                                      `json:"source_job_id"`
	ResourceType  string                                   `json:"resource_type"`
	SourceType    string                                   `json:"source_type"`
	ID            string                                   `json:"id"`
	ARN           string                                   `json:"arn"`
	SourceID      string                                   `json:"source_id"`
}

type SqlServerFlexibleServerHit struct {
	ID      string                  `json:"_id"`
	Score   float64                 `json:"_score"`
	Index   string                  `json:"_index"`
	Type    string                  `json:"_type"`
	Version int64                   `json:"_version,omitempty"`
	Source  SqlServerFlexibleServer `json:"_source"`
	Sort    []interface{}           `json:"sort"`
}

type SqlServerFlexibleServerHits struct {
	Total SearchTotal                  `json:"total"`
	Hits  []SqlServerFlexibleServerHit `json:"hits"`
}

type SqlServerFlexibleServerSearchResponse struct {
	PitID string                      `json:"pit_id"`
	Hits  SqlServerFlexibleServerHits `json:"hits"`
}

type SqlServerFlexibleServerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewSqlServerFlexibleServerPaginator(filters []BoolFilter, limit *int64) (SqlServerFlexibleServerPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_sql_flexibleservers", filters, limit)
	if err != nil {
		return SqlServerFlexibleServerPaginator{}, err
	}

	p := SqlServerFlexibleServerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p SqlServerFlexibleServerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p SqlServerFlexibleServerPaginator) NextPage(ctx context.Context) ([]SqlServerFlexibleServer, error) {
	var response SqlServerFlexibleServerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []SqlServerFlexibleServer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listSqlServerFlexibleServerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListSqlServerFlexibleServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListSqlServerFlexibleServer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewSqlServerFlexibleServerPaginator(buildFilter(d.KeyColumnQuals, listSqlServerFlexibleServerFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getSqlServerFlexibleServerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.FlexibleServer.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetSqlServerFlexibleServer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetSqlServerFlexibleServer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewSqlServerFlexibleServerPaginator(buildFilter(d.KeyColumnQuals, getSqlServerFlexibleServerFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: SqlServerFlexibleServer =============================

// ==========================  START: StorageAccount =============================

type StorageAccount struct {
	Description   azure.StorageAccountDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type StorageAccountHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  StorageAccount `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type StorageAccountHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []StorageAccountHit `json:"hits"`
}

type StorageAccountSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  StorageAccountHits `json:"hits"`
}

type StorageAccountPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewStorageAccountPaginator(filters []BoolFilter, limit *int64) (StorageAccountPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_classicstorage_storageaccounts", filters, limit)
	if err != nil {
		return StorageAccountPaginator{}, err
	}

	p := StorageAccountPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p StorageAccountPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p StorageAccountPaginator) NextPage(ctx context.Context) ([]StorageAccount, error) {
	var response StorageAccountSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []StorageAccount
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listStorageAccountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListStorageAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListStorageAccount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewStorageAccountPaginator(buildFilter(d.KeyColumnQuals, listStorageAccountFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getStorageAccountFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Account.name",
	"resource_group":   "description.ResourceGroup",
}

func GetStorageAccount(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetStorageAccount")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewStorageAccountPaginator(buildFilter(d.KeyColumnQuals, getStorageAccountFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: StorageAccount =============================

// ==========================  START: RecoveryServicesVault =============================

type RecoveryServicesVault struct {
	Description   azure.RecoveryServicesVaultDescription `json:"description"`
	Metadata      azure.Metadata                         `json:"metadata"`
	ResourceJobID int                                    `json:"resource_job_id"`
	SourceJobID   int                                    `json:"source_job_id"`
	ResourceType  string                                 `json:"resource_type"`
	SourceType    string                                 `json:"source_type"`
	ID            string                                 `json:"id"`
	ARN           string                                 `json:"arn"`
	SourceID      string                                 `json:"source_id"`
}

type RecoveryServicesVaultHit struct {
	ID      string                `json:"_id"`
	Score   float64               `json:"_score"`
	Index   string                `json:"_index"`
	Type    string                `json:"_type"`
	Version int64                 `json:"_version,omitempty"`
	Source  RecoveryServicesVault `json:"_source"`
	Sort    []interface{}         `json:"sort"`
}

type RecoveryServicesVaultHits struct {
	Total SearchTotal                `json:"total"`
	Hits  []RecoveryServicesVaultHit `json:"hits"`
}

type RecoveryServicesVaultSearchResponse struct {
	PitID string                    `json:"pit_id"`
	Hits  RecoveryServicesVaultHits `json:"hits"`
}

type RecoveryServicesVaultPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewRecoveryServicesVaultPaginator(filters []BoolFilter, limit *int64) (RecoveryServicesVaultPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_recoveryservices_vault", filters, limit)
	if err != nil {
		return RecoveryServicesVaultPaginator{}, err
	}

	p := RecoveryServicesVaultPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p RecoveryServicesVaultPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p RecoveryServicesVaultPaginator) NextPage(ctx context.Context) ([]RecoveryServicesVault, error) {
	var response RecoveryServicesVaultSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []RecoveryServicesVault
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listRecoveryServicesVaultFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListRecoveryServicesVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListRecoveryServicesVault")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewRecoveryServicesVaultPaginator(buildFilter(d.KeyColumnQuals, listRecoveryServicesVaultFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getRecoveryServicesVaultFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Vault.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetRecoveryServicesVault(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetRecoveryServicesVault")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewRecoveryServicesVaultPaginator(buildFilter(d.KeyColumnQuals, getRecoveryServicesVaultFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: RecoveryServicesVault =============================

// ==========================  START: HybridKubernetesConnectedCluster =============================

type HybridKubernetesConnectedCluster struct {
	Description   azure.HybridKubernetesConnectedClusterDescription `json:"description"`
	Metadata      azure.Metadata                                    `json:"metadata"`
	ResourceJobID int                                               `json:"resource_job_id"`
	SourceJobID   int                                               `json:"source_job_id"`
	ResourceType  string                                            `json:"resource_type"`
	SourceType    string                                            `json:"source_type"`
	ID            string                                            `json:"id"`
	ARN           string                                            `json:"arn"`
	SourceID      string                                            `json:"source_id"`
}

type HybridKubernetesConnectedClusterHit struct {
	ID      string                           `json:"_id"`
	Score   float64                          `json:"_score"`
	Index   string                           `json:"_index"`
	Type    string                           `json:"_type"`
	Version int64                            `json:"_version,omitempty"`
	Source  HybridKubernetesConnectedCluster `json:"_source"`
	Sort    []interface{}                    `json:"sort"`
}

type HybridKubernetesConnectedClusterHits struct {
	Total SearchTotal                           `json:"total"`
	Hits  []HybridKubernetesConnectedClusterHit `json:"hits"`
}

type HybridKubernetesConnectedClusterSearchResponse struct {
	PitID string                               `json:"pit_id"`
	Hits  HybridKubernetesConnectedClusterHits `json:"hits"`
}

type HybridKubernetesConnectedClusterPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewHybridKubernetesConnectedClusterPaginator(filters []BoolFilter, limit *int64) (HybridKubernetesConnectedClusterPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_hybridkubernetes_connectedcluster", filters, limit)
	if err != nil {
		return HybridKubernetesConnectedClusterPaginator{}, err
	}

	p := HybridKubernetesConnectedClusterPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p HybridKubernetesConnectedClusterPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p HybridKubernetesConnectedClusterPaginator) NextPage(ctx context.Context) ([]HybridKubernetesConnectedCluster, error) {
	var response HybridKubernetesConnectedClusterSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []HybridKubernetesConnectedCluster
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listHybridKubernetesConnectedClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListHybridKubernetesConnectedCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListHybridKubernetesConnectedCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewHybridKubernetesConnectedClusterPaginator(buildFilter(d.KeyColumnQuals, listHybridKubernetesConnectedClusterFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getHybridKubernetesConnectedClusterFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.ConnectedCluster.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetHybridKubernetesConnectedCluster(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetHybridKubernetesConnectedCluster")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewHybridKubernetesConnectedClusterPaginator(buildFilter(d.KeyColumnQuals, getHybridKubernetesConnectedClusterFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: HybridKubernetesConnectedCluster =============================

// ==========================  START: CostManagementCostByResourceType =============================

type CostManagementCostByResourceType struct {
	Description   azure.CostManagementCostByResourceTypeDescription `json:"description"`
	Metadata      azure.Metadata                                    `json:"metadata"`
	ResourceJobID int                                               `json:"resource_job_id"`
	SourceJobID   int                                               `json:"source_job_id"`
	ResourceType  string                                            `json:"resource_type"`
	SourceType    string                                            `json:"source_type"`
	ID            string                                            `json:"id"`
	ARN           string                                            `json:"arn"`
	SourceID      string                                            `json:"source_id"`
}

type CostManagementCostByResourceTypeHit struct {
	ID      string                           `json:"_id"`
	Score   float64                          `json:"_score"`
	Index   string                           `json:"_index"`
	Type    string                           `json:"_type"`
	Version int64                            `json:"_version,omitempty"`
	Source  CostManagementCostByResourceType `json:"_source"`
	Sort    []interface{}                    `json:"sort"`
}

type CostManagementCostByResourceTypeHits struct {
	Total SearchTotal                           `json:"total"`
	Hits  []CostManagementCostByResourceTypeHit `json:"hits"`
}

type CostManagementCostByResourceTypeSearchResponse struct {
	PitID string                               `json:"pit_id"`
	Hits  CostManagementCostByResourceTypeHits `json:"hits"`
}

type CostManagementCostByResourceTypePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCostManagementCostByResourceTypePaginator(filters []BoolFilter, limit *int64) (CostManagementCostByResourceTypePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_costmanagement_costbyresourcetype", filters, limit)
	if err != nil {
		return CostManagementCostByResourceTypePaginator{}, err
	}

	p := CostManagementCostByResourceTypePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostManagementCostByResourceTypePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CostManagementCostByResourceTypePaginator) NextPage(ctx context.Context) ([]CostManagementCostByResourceType, error) {
	var response CostManagementCostByResourceTypeSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostManagementCostByResourceType
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCostManagementCostByResourceTypeFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCostManagementCostByResourceType(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostManagementCostByResourceType")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCostManagementCostByResourceTypePaginator(buildFilter(d.KeyColumnQuals, listCostManagementCostByResourceTypeFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostManagementCostByResourceTypeFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCostManagementCostByResourceType(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostManagementCostByResourceType")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCostManagementCostByResourceTypePaginator(buildFilter(d.KeyColumnQuals, getCostManagementCostByResourceTypeFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostManagementCostByResourceType =============================

// ==========================  START: CostManagementCostBySubscription =============================

type CostManagementCostBySubscription struct {
	Description   azure.CostManagementCostBySubscriptionDescription `json:"description"`
	Metadata      azure.Metadata                                    `json:"metadata"`
	ResourceJobID int                                               `json:"resource_job_id"`
	SourceJobID   int                                               `json:"source_job_id"`
	ResourceType  string                                            `json:"resource_type"`
	SourceType    string                                            `json:"source_type"`
	ID            string                                            `json:"id"`
	ARN           string                                            `json:"arn"`
	SourceID      string                                            `json:"source_id"`
}

type CostManagementCostBySubscriptionHit struct {
	ID      string                           `json:"_id"`
	Score   float64                          `json:"_score"`
	Index   string                           `json:"_index"`
	Type    string                           `json:"_type"`
	Version int64                            `json:"_version,omitempty"`
	Source  CostManagementCostBySubscription `json:"_source"`
	Sort    []interface{}                    `json:"sort"`
}

type CostManagementCostBySubscriptionHits struct {
	Total SearchTotal                           `json:"total"`
	Hits  []CostManagementCostBySubscriptionHit `json:"hits"`
}

type CostManagementCostBySubscriptionSearchResponse struct {
	PitID string                               `json:"pit_id"`
	Hits  CostManagementCostBySubscriptionHits `json:"hits"`
}

type CostManagementCostBySubscriptionPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewCostManagementCostBySubscriptionPaginator(filters []BoolFilter, limit *int64) (CostManagementCostBySubscriptionPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_costmanagement_costbysubscription", filters, limit)
	if err != nil {
		return CostManagementCostBySubscriptionPaginator{}, err
	}

	p := CostManagementCostBySubscriptionPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p CostManagementCostBySubscriptionPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p CostManagementCostBySubscriptionPaginator) NextPage(ctx context.Context) ([]CostManagementCostBySubscription, error) {
	var response CostManagementCostBySubscriptionSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []CostManagementCostBySubscription
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listCostManagementCostBySubscriptionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListCostManagementCostBySubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListCostManagementCostBySubscription")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewCostManagementCostBySubscriptionPaginator(buildFilter(d.KeyColumnQuals, listCostManagementCostBySubscriptionFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getCostManagementCostBySubscriptionFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func GetCostManagementCostBySubscription(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetCostManagementCostBySubscription")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewCostManagementCostBySubscriptionPaginator(buildFilter(d.KeyColumnQuals, getCostManagementCostBySubscriptionFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: CostManagementCostBySubscription =============================

// ==========================  START: LoadBalancer =============================

type LoadBalancer struct {
	Description   azure.LoadBalancerDescription `json:"description"`
	Metadata      azure.Metadata                `json:"metadata"`
	ResourceJobID int                           `json:"resource_job_id"`
	SourceJobID   int                           `json:"source_job_id"`
	ResourceType  string                        `json:"resource_type"`
	SourceType    string                        `json:"source_type"`
	ID            string                        `json:"id"`
	ARN           string                        `json:"arn"`
	SourceID      string                        `json:"source_id"`
}

type LoadBalancerHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  LoadBalancer  `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type LoadBalancerHits struct {
	Total SearchTotal       `json:"total"`
	Hits  []LoadBalancerHit `json:"hits"`
}

type LoadBalancerSearchResponse struct {
	PitID string           `json:"pit_id"`
	Hits  LoadBalancerHits `json:"hits"`
}

type LoadBalancerPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewLoadBalancerPaginator(filters []BoolFilter, limit *int64) (LoadBalancerPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_network_loadbalancers", filters, limit)
	if err != nil {
		return LoadBalancerPaginator{}, err
	}

	p := LoadBalancerPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LoadBalancerPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p LoadBalancerPaginator) NextPage(ctx context.Context) ([]LoadBalancer, error) {
	var response LoadBalancerSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LoadBalancer
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listLoadBalancerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListLoadBalancer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLoadBalancer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewLoadBalancerPaginator(buildFilter(d.KeyColumnQuals, listLoadBalancerFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLoadBalancerFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.LoadBalancer.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetLoadBalancer(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLoadBalancer")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewLoadBalancerPaginator(buildFilter(d.KeyColumnQuals, getLoadBalancerFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LoadBalancer =============================

// ==========================  START: LoadBalancerBackendAddressPool =============================

type LoadBalancerBackendAddressPool struct {
	Description   azure.LoadBalancerBackendAddressPoolDescription `json:"description"`
	Metadata      azure.Metadata                                  `json:"metadata"`
	ResourceJobID int                                             `json:"resource_job_id"`
	SourceJobID   int                                             `json:"source_job_id"`
	ResourceType  string                                          `json:"resource_type"`
	SourceType    string                                          `json:"source_type"`
	ID            string                                          `json:"id"`
	ARN           string                                          `json:"arn"`
	SourceID      string                                          `json:"source_id"`
}

type LoadBalancerBackendAddressPoolHit struct {
	ID      string                         `json:"_id"`
	Score   float64                        `json:"_score"`
	Index   string                         `json:"_index"`
	Type    string                         `json:"_type"`
	Version int64                          `json:"_version,omitempty"`
	Source  LoadBalancerBackendAddressPool `json:"_source"`
	Sort    []interface{}                  `json:"sort"`
}

type LoadBalancerBackendAddressPoolHits struct {
	Total SearchTotal                         `json:"total"`
	Hits  []LoadBalancerBackendAddressPoolHit `json:"hits"`
}

type LoadBalancerBackendAddressPoolSearchResponse struct {
	PitID string                             `json:"pit_id"`
	Hits  LoadBalancerBackendAddressPoolHits `json:"hits"`
}

type LoadBalancerBackendAddressPoolPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewLoadBalancerBackendAddressPoolPaginator(filters []BoolFilter, limit *int64) (LoadBalancerBackendAddressPoolPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_lb_backendaddresspools", filters, limit)
	if err != nil {
		return LoadBalancerBackendAddressPoolPaginator{}, err
	}

	p := LoadBalancerBackendAddressPoolPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LoadBalancerBackendAddressPoolPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p LoadBalancerBackendAddressPoolPaginator) NextPage(ctx context.Context) ([]LoadBalancerBackendAddressPool, error) {
	var response LoadBalancerBackendAddressPoolSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LoadBalancerBackendAddressPool
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listLoadBalancerBackendAddressPoolFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListLoadBalancerBackendAddressPool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLoadBalancerBackendAddressPool")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewLoadBalancerBackendAddressPoolPaginator(buildFilter(d.KeyColumnQuals, listLoadBalancerBackendAddressPoolFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLoadBalancerBackendAddressPoolFilters = map[string]string{
	"keibi_account_id":   "metadata.SourceID",
	"load_balancer_name": "description.LoadBalancer.Name",
	"name":               "description.Pool.Name",
	"resource_group":     "description.ResourceGroup",
}

func GetLoadBalancerBackendAddressPool(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLoadBalancerBackendAddressPool")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewLoadBalancerBackendAddressPoolPaginator(buildFilter(d.KeyColumnQuals, getLoadBalancerBackendAddressPoolFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LoadBalancerBackendAddressPool =============================

// ==========================  START: LoadBalancerNatRule =============================

type LoadBalancerNatRule struct {
	Description   azure.LoadBalancerNatRuleDescription `json:"description"`
	Metadata      azure.Metadata                       `json:"metadata"`
	ResourceJobID int                                  `json:"resource_job_id"`
	SourceJobID   int                                  `json:"source_job_id"`
	ResourceType  string                               `json:"resource_type"`
	SourceType    string                               `json:"source_type"`
	ID            string                               `json:"id"`
	ARN           string                               `json:"arn"`
	SourceID      string                               `json:"source_id"`
}

type LoadBalancerNatRuleHit struct {
	ID      string              `json:"_id"`
	Score   float64             `json:"_score"`
	Index   string              `json:"_index"`
	Type    string              `json:"_type"`
	Version int64               `json:"_version,omitempty"`
	Source  LoadBalancerNatRule `json:"_source"`
	Sort    []interface{}       `json:"sort"`
}

type LoadBalancerNatRuleHits struct {
	Total SearchTotal              `json:"total"`
	Hits  []LoadBalancerNatRuleHit `json:"hits"`
}

type LoadBalancerNatRuleSearchResponse struct {
	PitID string                  `json:"pit_id"`
	Hits  LoadBalancerNatRuleHits `json:"hits"`
}

type LoadBalancerNatRulePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewLoadBalancerNatRulePaginator(filters []BoolFilter, limit *int64) (LoadBalancerNatRulePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_lb_natrules", filters, limit)
	if err != nil {
		return LoadBalancerNatRulePaginator{}, err
	}

	p := LoadBalancerNatRulePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LoadBalancerNatRulePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p LoadBalancerNatRulePaginator) NextPage(ctx context.Context) ([]LoadBalancerNatRule, error) {
	var response LoadBalancerNatRuleSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LoadBalancerNatRule
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listLoadBalancerNatRuleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListLoadBalancerNatRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLoadBalancerNatRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewLoadBalancerNatRulePaginator(buildFilter(d.KeyColumnQuals, listLoadBalancerNatRuleFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLoadBalancerNatRuleFilters = map[string]string{
	"keibi_account_id":   "metadata.SourceID",
	"load_balancer_name": "description.LoadBalancerName",
	"name":               "description.Rule.Name",
	"resource_group":     "description.ResourceGroup",
}

func GetLoadBalancerNatRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLoadBalancerNatRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewLoadBalancerNatRulePaginator(buildFilter(d.KeyColumnQuals, getLoadBalancerNatRuleFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LoadBalancerNatRule =============================

// ==========================  START: LoadBalancerOutboundRule =============================

type LoadBalancerOutboundRule struct {
	Description   azure.LoadBalancerOutboundRuleDescription `json:"description"`
	Metadata      azure.Metadata                            `json:"metadata"`
	ResourceJobID int                                       `json:"resource_job_id"`
	SourceJobID   int                                       `json:"source_job_id"`
	ResourceType  string                                    `json:"resource_type"`
	SourceType    string                                    `json:"source_type"`
	ID            string                                    `json:"id"`
	ARN           string                                    `json:"arn"`
	SourceID      string                                    `json:"source_id"`
}

type LoadBalancerOutboundRuleHit struct {
	ID      string                   `json:"_id"`
	Score   float64                  `json:"_score"`
	Index   string                   `json:"_index"`
	Type    string                   `json:"_type"`
	Version int64                    `json:"_version,omitempty"`
	Source  LoadBalancerOutboundRule `json:"_source"`
	Sort    []interface{}            `json:"sort"`
}

type LoadBalancerOutboundRuleHits struct {
	Total SearchTotal                   `json:"total"`
	Hits  []LoadBalancerOutboundRuleHit `json:"hits"`
}

type LoadBalancerOutboundRuleSearchResponse struct {
	PitID string                       `json:"pit_id"`
	Hits  LoadBalancerOutboundRuleHits `json:"hits"`
}

type LoadBalancerOutboundRulePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewLoadBalancerOutboundRulePaginator(filters []BoolFilter, limit *int64) (LoadBalancerOutboundRulePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_lb_outboundrules", filters, limit)
	if err != nil {
		return LoadBalancerOutboundRulePaginator{}, err
	}

	p := LoadBalancerOutboundRulePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LoadBalancerOutboundRulePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p LoadBalancerOutboundRulePaginator) NextPage(ctx context.Context) ([]LoadBalancerOutboundRule, error) {
	var response LoadBalancerOutboundRuleSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LoadBalancerOutboundRule
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listLoadBalancerOutboundRuleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListLoadBalancerOutboundRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLoadBalancerOutboundRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewLoadBalancerOutboundRulePaginator(buildFilter(d.KeyColumnQuals, listLoadBalancerOutboundRuleFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLoadBalancerOutboundRuleFilters = map[string]string{
	"keibi_account_id":   "metadata.SourceID",
	"load_balancer_name": "description.LoadBalancerName",
	"name":               "description.Rule.Name",
	"resource_group":     "description.ResourceGroup",
}

func GetLoadBalancerOutboundRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLoadBalancerOutboundRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewLoadBalancerOutboundRulePaginator(buildFilter(d.KeyColumnQuals, getLoadBalancerOutboundRuleFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LoadBalancerOutboundRule =============================

// ==========================  START: LoadBalancerProbe =============================

type LoadBalancerProbe struct {
	Description   azure.LoadBalancerProbeDescription `json:"description"`
	Metadata      azure.Metadata                     `json:"metadata"`
	ResourceJobID int                                `json:"resource_job_id"`
	SourceJobID   int                                `json:"source_job_id"`
	ResourceType  string                             `json:"resource_type"`
	SourceType    string                             `json:"source_type"`
	ID            string                             `json:"id"`
	ARN           string                             `json:"arn"`
	SourceID      string                             `json:"source_id"`
}

type LoadBalancerProbeHit struct {
	ID      string            `json:"_id"`
	Score   float64           `json:"_score"`
	Index   string            `json:"_index"`
	Type    string            `json:"_type"`
	Version int64             `json:"_version,omitempty"`
	Source  LoadBalancerProbe `json:"_source"`
	Sort    []interface{}     `json:"sort"`
}

type LoadBalancerProbeHits struct {
	Total SearchTotal            `json:"total"`
	Hits  []LoadBalancerProbeHit `json:"hits"`
}

type LoadBalancerProbeSearchResponse struct {
	PitID string                `json:"pit_id"`
	Hits  LoadBalancerProbeHits `json:"hits"`
}

type LoadBalancerProbePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewLoadBalancerProbePaginator(filters []BoolFilter, limit *int64) (LoadBalancerProbePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_lb_probes", filters, limit)
	if err != nil {
		return LoadBalancerProbePaginator{}, err
	}

	p := LoadBalancerProbePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LoadBalancerProbePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p LoadBalancerProbePaginator) NextPage(ctx context.Context) ([]LoadBalancerProbe, error) {
	var response LoadBalancerProbeSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LoadBalancerProbe
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listLoadBalancerProbeFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListLoadBalancerProbe(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLoadBalancerProbe")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewLoadBalancerProbePaginator(buildFilter(d.KeyColumnQuals, listLoadBalancerProbeFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLoadBalancerProbeFilters = map[string]string{
	"keibi_account_id":   "metadata.SourceID",
	"load_balancer_name": "description.LoadBalancerName",
	"name":               "description.Probe.Name",
	"resource_group":     "description.ResourceGroup",
}

func GetLoadBalancerProbe(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLoadBalancerProbe")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewLoadBalancerProbePaginator(buildFilter(d.KeyColumnQuals, getLoadBalancerProbeFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LoadBalancerProbe =============================

// ==========================  START: LoadBalancerRule =============================

type LoadBalancerRule struct {
	Description   azure.LoadBalancerRuleDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type LoadBalancerRuleHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  LoadBalancerRule `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type LoadBalancerRuleHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []LoadBalancerRuleHit `json:"hits"`
}

type LoadBalancerRuleSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  LoadBalancerRuleHits `json:"hits"`
}

type LoadBalancerRulePaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewLoadBalancerRulePaginator(filters []BoolFilter, limit *int64) (LoadBalancerRulePaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_lb_rules", filters, limit)
	if err != nil {
		return LoadBalancerRulePaginator{}, err
	}

	p := LoadBalancerRulePaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p LoadBalancerRulePaginator) HasNext() bool {
	return !p.paginator.done
}

func (p LoadBalancerRulePaginator) NextPage(ctx context.Context) ([]LoadBalancerRule, error) {
	var response LoadBalancerRuleSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []LoadBalancerRule
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listLoadBalancerRuleFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListLoadBalancerRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListLoadBalancerRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewLoadBalancerRulePaginator(buildFilter(d.KeyColumnQuals, listLoadBalancerRuleFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getLoadBalancerRuleFilters = map[string]string{
	"keibi_account_id":   "metadata.SourceID",
	"load_balancer_name": "description.LoadBalancerName",
	"name":               "description.Rule.Name",
	"resource_group":     "description.ResourceGroup",
}

func GetLoadBalancerRule(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetLoadBalancerRule")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewLoadBalancerRulePaginator(buildFilter(d.KeyColumnQuals, getLoadBalancerRuleFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: LoadBalancerRule =============================

// ==========================  START: ManagementGroup =============================

type ManagementGroup struct {
	Description   azure.ManagementGroupDescription `json:"description"`
	Metadata      azure.Metadata                   `json:"metadata"`
	ResourceJobID int                              `json:"resource_job_id"`
	SourceJobID   int                              `json:"source_job_id"`
	ResourceType  string                           `json:"resource_type"`
	SourceType    string                           `json:"source_type"`
	ID            string                           `json:"id"`
	ARN           string                           `json:"arn"`
	SourceID      string                           `json:"source_id"`
}

type ManagementGroupHit struct {
	ID      string          `json:"_id"`
	Score   float64         `json:"_score"`
	Index   string          `json:"_index"`
	Type    string          `json:"_type"`
	Version int64           `json:"_version,omitempty"`
	Source  ManagementGroup `json:"_source"`
	Sort    []interface{}   `json:"sort"`
}

type ManagementGroupHits struct {
	Total SearchTotal          `json:"total"`
	Hits  []ManagementGroupHit `json:"hits"`
}

type ManagementGroupSearchResponse struct {
	PitID string              `json:"pit_id"`
	Hits  ManagementGroupHits `json:"hits"`
}

type ManagementGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewManagementGroupPaginator(filters []BoolFilter, limit *int64) (ManagementGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_management_groups", filters, limit)
	if err != nil {
		return ManagementGroupPaginator{}, err
	}

	p := ManagementGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ManagementGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ManagementGroupPaginator) NextPage(ctx context.Context) ([]ManagementGroup, error) {
	var response ManagementGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ManagementGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listManagementGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListManagementGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListManagementGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewManagementGroupPaginator(buildFilter(d.KeyColumnQuals, listManagementGroupFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getManagementGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Group.Name",
}

func GetManagementGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetManagementGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewManagementGroupPaginator(buildFilter(d.KeyColumnQuals, getManagementGroupFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ManagementGroup =============================

// ==========================  START: ManagementLock =============================

type ManagementLock struct {
	Description   azure.ManagementLockDescription `json:"description"`
	Metadata      azure.Metadata                  `json:"metadata"`
	ResourceJobID int                             `json:"resource_job_id"`
	SourceJobID   int                             `json:"source_job_id"`
	ResourceType  string                          `json:"resource_type"`
	SourceType    string                          `json:"source_type"`
	ID            string                          `json:"id"`
	ARN           string                          `json:"arn"`
	SourceID      string                          `json:"source_id"`
}

type ManagementLockHit struct {
	ID      string         `json:"_id"`
	Score   float64        `json:"_score"`
	Index   string         `json:"_index"`
	Type    string         `json:"_type"`
	Version int64          `json:"_version,omitempty"`
	Source  ManagementLock `json:"_source"`
	Sort    []interface{}  `json:"sort"`
}

type ManagementLockHits struct {
	Total SearchTotal         `json:"total"`
	Hits  []ManagementLockHit `json:"hits"`
}

type ManagementLockSearchResponse struct {
	PitID string             `json:"pit_id"`
	Hits  ManagementLockHits `json:"hits"`
}

type ManagementLockPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewManagementLockPaginator(filters []BoolFilter, limit *int64) (ManagementLockPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_management_locks", filters, limit)
	if err != nil {
		return ManagementLockPaginator{}, err
	}

	p := ManagementLockPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ManagementLockPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ManagementLockPaginator) NextPage(ctx context.Context) ([]ManagementLock, error) {
	var response ManagementLockSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ManagementLock
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listManagementLockFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListManagementLock(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListManagementLock")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewManagementLockPaginator(buildFilter(d.KeyColumnQuals, listManagementLockFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getManagementLockFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Lock.Name",
	"resource_group":   "description.ResourceGroup",
}

func GetManagementLock(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetManagementLock")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewManagementLockPaginator(buildFilter(d.KeyColumnQuals, getManagementLockFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ManagementLock =============================

// ==========================  START: ResourceProvider =============================

type ResourceProvider struct {
	Description   azure.ResourceProviderDescription `json:"description"`
	Metadata      azure.Metadata                    `json:"metadata"`
	ResourceJobID int                               `json:"resource_job_id"`
	SourceJobID   int                               `json:"source_job_id"`
	ResourceType  string                            `json:"resource_type"`
	SourceType    string                            `json:"source_type"`
	ID            string                            `json:"id"`
	ARN           string                            `json:"arn"`
	SourceID      string                            `json:"source_id"`
}

type ResourceProviderHit struct {
	ID      string           `json:"_id"`
	Score   float64          `json:"_score"`
	Index   string           `json:"_index"`
	Type    string           `json:"_type"`
	Version int64            `json:"_version,omitempty"`
	Source  ResourceProvider `json:"_source"`
	Sort    []interface{}    `json:"sort"`
}

type ResourceProviderHits struct {
	Total SearchTotal           `json:"total"`
	Hits  []ResourceProviderHit `json:"hits"`
}

type ResourceProviderSearchResponse struct {
	PitID string               `json:"pit_id"`
	Hits  ResourceProviderHits `json:"hits"`
}

type ResourceProviderPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewResourceProviderPaginator(filters []BoolFilter, limit *int64) (ResourceProviderPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_resources_providers", filters, limit)
	if err != nil {
		return ResourceProviderPaginator{}, err
	}

	p := ResourceProviderPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ResourceProviderPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ResourceProviderPaginator) NextPage(ctx context.Context) ([]ResourceProvider, error) {
	var response ResourceProviderSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ResourceProvider
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listResourceProviderFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListResourceProvider(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListResourceProvider")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewResourceProviderPaginator(buildFilter(d.KeyColumnQuals, listResourceProviderFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getResourceProviderFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"namespace":        "description.Provider.Namespace",
}

func GetResourceProvider(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetResourceProvider")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewResourceProviderPaginator(buildFilter(d.KeyColumnQuals, getResourceProviderFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ResourceProvider =============================

// ==========================  START: ResourceGroup =============================

type ResourceGroup struct {
	Description   azure.ResourceGroupDescription `json:"description"`
	Metadata      azure.Metadata                 `json:"metadata"`
	ResourceJobID int                            `json:"resource_job_id"`
	SourceJobID   int                            `json:"source_job_id"`
	ResourceType  string                         `json:"resource_type"`
	SourceType    string                         `json:"source_type"`
	ID            string                         `json:"id"`
	ARN           string                         `json:"arn"`
	SourceID      string                         `json:"source_id"`
}

type ResourceGroupHit struct {
	ID      string        `json:"_id"`
	Score   float64       `json:"_score"`
	Index   string        `json:"_index"`
	Type    string        `json:"_type"`
	Version int64         `json:"_version,omitempty"`
	Source  ResourceGroup `json:"_source"`
	Sort    []interface{} `json:"sort"`
}

type ResourceGroupHits struct {
	Total SearchTotal        `json:"total"`
	Hits  []ResourceGroupHit `json:"hits"`
}

type ResourceGroupSearchResponse struct {
	PitID string            `json:"pit_id"`
	Hits  ResourceGroupHits `json:"hits"`
}

type ResourceGroupPaginator struct {
	paginator *baseESPaginator
}

func (k Client) NewResourceGroupPaginator(filters []BoolFilter, limit *int64) (ResourceGroupPaginator, error) {
	paginator, err := newPaginator(k.es, "microsoft_resources_resourcegroups", filters, limit)
	if err != nil {
		return ResourceGroupPaginator{}, err
	}

	p := ResourceGroupPaginator{
		paginator: paginator,
	}

	return p, nil
}

func (p ResourceGroupPaginator) HasNext() bool {
	return !p.paginator.done
}

func (p ResourceGroupPaginator) NextPage(ctx context.Context) ([]ResourceGroup, error) {
	var response ResourceGroupSearchResponse
	err := p.paginator.search(ctx, &response)
	if err != nil {
		return nil, err
	}

	var values []ResourceGroup
	for _, hit := range response.Hits.Hits {
		values = append(values, hit.Source)
	}

	hits := int64(len(response.Hits.Hits))
	if hits > 0 {
		p.paginator.updateState(hits, response.Hits.Hits[hits-1].Sort, response.PitID)
	} else {
		p.paginator.updateState(hits, nil, "")
	}

	return values, nil
}

var listResourceGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
}

func ListResourceGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("ListResourceGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	paginator, err := k.NewResourceGroupPaginator(buildFilter(d.KeyColumnQuals, listResourceGroupFilters, "azure", *cfg.AccountID), d.QueryContext.Limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			d.StreamListItem(ctx, v)
		}
	}

	return nil, nil
}

var getResourceGroupFilters = map[string]string{
	"keibi_account_id": "metadata.SourceID",
	"name":             "description.Group.Name",
}

func GetResourceGroup(ctx context.Context, d *plugin.QueryData, _ *plugin.HydrateData) (interface{}, error) {
	plugin.Logger(ctx).Trace("GetResourceGroup")

	// create service
	cfg := GetConfig(d.Connection)
	k, err := NewClientCached(cfg, d.ConnectionManager.Cache, ctx)
	if err != nil {
		return nil, err
	}

	limit := int64(1)
	paginator, err := k.NewResourceGroupPaginator(buildFilter(d.KeyColumnQuals, getResourceGroupFilters, "azure", *cfg.AccountID), &limit)
	if err != nil {
		return nil, err
	}

	for paginator.HasNext() {
		page, err := paginator.NextPage(ctx)
		if err != nil {
			return nil, err
		}

		for _, v := range page {
			return v, nil
		}
	}

	return nil, nil
}

// ==========================  END: ResourceGroup =============================
